{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeM2000/CANE/blob/master/code/Automatic_Keyword_Extraction_for_Citation_Graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuD0jZxIOT1l"
      },
      "source": [
        "# ***Libraries & Tools***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym4yPFSiOT1n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from itertools import chain, groupby, product\n",
        "from enum import Enum\n",
        "from typing import Callable, DefaultDict, Dict, List, Optional, Set, Tuple\n",
        "from typing import Any\n",
        "import string\n",
        "from collections import Counter, defaultdict\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import yake\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pytextrank\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZnBgerVOT1p"
      },
      "outputs": [],
      "source": [
        "nltk.data.path.append(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ouGEm3OT1p"
      },
      "source": [
        "# ***Abstracts Retrieval***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxLpRn67OT1p",
        "outputId": "7a56f600-87b3-4438-d1c1-dd35cdca0729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of extracted abstracts: 2277\n"
          ]
        }
      ],
      "source": [
        "def extract_abstracts(file_path):\n",
        "    # Read the contents of the file\n",
        "    with open(file_path, 'r') as file:\n",
        "        abstracts = file.readlines()\n",
        "\n",
        "   # Remove any leading or trailing whitespace characters from each line\n",
        "    abstracts = [abstract.strip() for abstract in abstracts if abstract.strip()]\n",
        "\n",
        "    # Track the number of abstracts\n",
        "    num_abstracts = len(abstracts)\n",
        "\n",
        "    return abstracts, num_abstracts\n",
        "\n",
        "# Example usage\n",
        "file_path = 'cora/data.txt'\n",
        "abstracts, num_abstracts = extract_abstracts(file_path)\n",
        "\n",
        "# Display the number of extracted abstracts\n",
        "print(f'Number of extracted abstracts: {num_abstracts}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIVfh1WkOT1q",
        "outputId": "b6a65ce4-0969-4cdb-dd2d-fb5869db9bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Several computer algorithms discovering patterns groups protein sequences use based fitting parameters statistical model group related sequences These include hidden Markov model HMM algorithms multiple sequence alignment MEME Gibbs sampler algorithms discovering motifs These algorithms sometimes prone producing models incorrect two patterns combined The statistical model produced situation convex combination weighted average two different models This paper presents solution problem convex combinations form heuristic based using extremely low variance Dirichlet mixture priors part statistical model This heuristic call megaprior heuristic increases strength ie decreases variance prior proportion size sequence dataset This causes column final model strongly resemble mean single component prior regardless size dataset We describe cause convex combination problem analyze mathematically motivate describe implementation megaprior heuristic show effectively eliminate problem convex combinations protein sequence pattern discovery',\n",
              " 'This paper describes preliminary work aims apply learning strategies medical followup study An investigation application three machine learning algorithmsR FOIL InductH identify risk factors govern colposuspension cure rate made The goal study induce generalised description explanation classification attribute colposuspension cure rate completely cured improved unchanged worse examples questionnaires We looked set rules described risk factors result differences cure rate The results encouraging indicate machine learning play useful role large scale medical problem solving',\n",
              " 'In cellular telephone systems important problem dynamically allocate communication resource channels maximize service stochastic caller environment This problem naturally formulated dynamic programming problem use reinforcement learning RL method find dynamic channel allocation policies better previous heuristic solutions The policies obtained perform well broad variety call traffic patterns We present results large cellular system In cellular communication systems important problem allocate communication resource bandwidth maximize service provided set mobile callers whose demand service changes stochastically A given geographical area divided mutually disjoint cells cell serves calls within boundaries see Figure The total system bandwidth divided channels channel centered around frequency Each channel used simultaneously different cells provided cells sufficiently separated spatially interference The minimum separation distance simultaneous reuse channel called channel reuse constraint When call requests service given cell either free channel one violate channel reuse constraint may assigned call else call blocked system happen free channel found Also mobile caller crosses one cell another call handed cell entry new free channel provided call new cell If channel available call must droppeddisconnected system One objective channel allocation policy allocate available channels calls number blocked calls minimized An additional objective minimize number calls dropped handed busy cell These two objectives must weighted appropriately reflect relative importance since dropping existing calls generally undesirable blocking new calls approximately states',\n",
              " 'In paper bring techniques operations research bear problem choosing optimal actions partially observable stochastic domains We begin introducing theory Markov decision processes mdps partially observable mdps pomdps We outline novel algorithm solving pomdps line show cases finitememory controller extracted solution pomdp We conclude discussion approach relates previous work complexity finding exact solutions pomdps possibilities finding approximate solutions',\n",
              " 'Graphical models enhance representational power probability models qualitative characterization properties This also leads greater efficiency terms computational algorithms empower representations The increasing complexity models however quickly renders exact probabilistic calculations infeasible We propose principled framework approximating graphical models based variational methods We develop variational techniques perspective unifies expands applicability graphical models These methods allow recursive computation upper lower bounds quantities interest Such bounds yield considerably information mere approximations provide inherent error metric tailoring approximations individually cases considered These desirable properties concomitant variational methods unlikely arise result deterministic stochastic approximations',\n",
              " 'Realtime Decision algorithms class incremental resourcebounded Horvitz anytime Dean algorithms evaluating influence diagrams We present test domain realtime decision algorithms results experiments several Realtime Decision Algorithms domain The results demonstrate high performance two algorithms decisionevaluation variant Incremental Probabilisitic Inference DAmbrosio variant algorithm suggested Goldszmidt Goldszmidt PKreduced We discuss implications experimental results explore broader applicability algorithms',\n",
              " 'Speedup learning seeks improve computational efficiency problem solving experience In paper develop formal framework learning efficient problem solving random problems solutions We apply framework two different representations learned knowledge namely control rules macrooperators prove theorems identify sufficient conditions learning representation Our proofs constructive accompanied learning algorithms Our framework captures empirical explanationbased speedup learning unified fashion We illustrate framework implementations two domains symbolic integration Eight Puzzle This work integrates many strands experimental theoretical work machine learning including empirical learning control rules macrooperator learning',\n",
              " 'In previous paper SM showed finite automata could used define objective functions assessing quality alignment two sequences In paper show results using cost functions We also show extend Hischbergs linear space algorithm Hir setting thus generalizing result Myers Miller MMb',\n",
              " 'We present offline variant mistakebound model learning Just like well studied online model learner offline model learn unknown concept sequence elements instance space makes guess test trials In models aim learner make mistakes possible The difference models online model set possible elements known offline model sequence elements ie identity elements well order presented known learner advance We give combinatorial characterization number mistakes offline model We apply characterization solve several natural questions arise new model First compare mistake bounds offline learner learner learning concept classes online scenario We show number mistakes online learning log n factor offline learning n length sequence In addition show offline algorithm make constant number mistakes sequence online algorithm also make constant number mistakes The second issue address effect ordering elements number mistakes offline learner It turns sequences offline learner guarantee one mistake yet permutation sequence forces err many elements We prove however gap offline mistake bounds permutations sequence nmany elements larger multiplicative factor log n present examples obtain gap',\n",
              " 'Wahba Wang Gu Klein Klein introduced Smoothing Spline ANalysis VAriance SS ANOVA method data exponential families Based RKPACK fits SS ANOVA models Gaussian data introduce GRKPACK collection Fortran subroutines binary binomial Poisson Gamma data We also show calculate Bayesian confidence intervals SS ANOVA estimates',\n",
              " 'This paper presents evolutionary approach incremental approach find learning rules several supervised learning tasks In evolutionary approach potential solutions represented variable length mathematical LISP S expressions Thus similar Genetic Programming GP employs fixed set nonproblem specific functions solve variety problems The model tested three Monks parity problems The results indicate usefulness encoding schema discovering learning rules simple supervised learning problems However hard learning problems require special attention terms need larger size codings potential solutions ability generalisation testing set In order find better solutions issues hill climbing strategy incremental coding potential solutions used discovering learning rules problems It found strategy larger solutions easily coded less computational effort Although better performance achieved training hard learning problems ability generalisation testing cases observed poor',\n",
              " 'The key quantity needed Bayesian hypothesis testing model selection marginal likelihood model also known integrated likelihood marginal probability data In paper describe way use posterior simulation output estimate marginal likelihoods We describe basic LaplaceMetropolis estimator models without random effects For models random effects compound LaplaceMetropolis estimator introduced This estimator applied data World Fertility Survey shown give accurate results Batching simulation output used assess uncertainty involved using compound LaplaceMetropolis estimator The method allows us test effects independent variables random effects model also test presence random effects',\n",
              " 'The overfit problem empirical learning utility problem explanationbased learning describe similar phenomenon degradation performance due increase amount learned knowledge Plotting performance learned knowledge course learning performance response reveals common trend several learning methods Modeling trend allows control system constrain amount learned knowledge achieve peak performance avoid general utility problem Experiments evaluate particular empirical model trend analysis learners derive several formal models If evidence suggests general utility problem modeled using mechanisms different learning paradigms model serves unify paradigms one framework capable comparing selecting different learning methods based predicted achievable performance',\n",
              " 'Hidden Markov Models HMMs applied problems statistical modeling database searching multiple sequence alignment protein families protein domains These methods demonstrated globin family protein kinase catalytic domain EFhand calcium binding motif In case parameters HMM estimated training set unaligned sequences After HMM built used obtain multiple alignment training sequences It also used search SWISSPROT database sequences members given protein family contain given domain The HMM produces multiple alignments good quality agree closely alignments produced programs incorporate threedimensional structural information When employed discrimination tests examining closely sequences database fit globin kinase EFhand HMMs HMM able distinguish members families nonmembers high degree accuracy Both HMM PROFILESEARCH technique used search relationships protein sequence multiply aligned sequences perform better tests PROSITE dictionary sites patterns proteins The HMM appears slight advantage',\n",
              " 'This paper explores effect initial weight selection feedforward networks learning simple functions backpropagation technique We first demonstrate use Monte Carlo techniques magnitude initial condition vector weight space significant parameter convergence time variability In order understand result additional deterministic experiments performed The results experiments demonstrate extreme sensitivity back propagation initial weight configuration',\n",
              " 'Some forms memory rely temporarily system brain structures located medial temporal lobe includes hippocampus The recall recent events one task relies crucially proper functioning system As event becomes less recent medial temporal lobe becomes less critical recall event recollection appears rely upon neocortex It proposed process called consolidation responsible transfer memory medial temporal lobe neocortex We examine network model proposed P Alvarez L Squire designed incorporate known features consolidation propose several possible experiments intended help evaluate performance model realistic conditions Finally implement extended version model accommodate varying assumptions number areas connections within brain memory capacity examine performance model Alvarez Squires original task',\n",
              " 'The map eye brain vertebrates topographic ie neighbouring points eye map neighbouring points brain In addition two eyes innervate target structure two sets fibres segregate form ocular dominance stripes Experimental evidence frog goldfish suggests two phenomena may subserved mechanisms We present computational model addresses formation topography ocular dominance The model based form competitive learning subtractive enforcement weight normalization rule Inputs model distributed patterns activity presented simultaneously eyes An important aspect model ocular dominance segregation occur two eyes positively correlated whereas previous models tended assume zero negative correlations eyes This allows investigation dependence pattern stripes degree correlation eyes find increasing correlation leads narrower stripes Experiments suggested test prediction',\n",
              " 'We examine methods estimate average variance test error rates set classifiers We begin process drawing classifier random example Given validation data average test error rate estimated validating single classifier Given test example inputs variance computed exactly Next consider process drawing classifier random using examples Once expected test error rate validated validating single classifier However variance must estimated validating classifers yields loose uncertain bounds',\n",
              " 'We consider formal models learning noisy data Specifically focus learning probability approximately correct model defined Valiant Two widely studied models noise setting classification noise malicious errors However realistic model combining two types noise formalized We define learning environment based natural combination two noise models We first show hypothesis testing possible model We next describe simple technique learning model describe powerful technique based statistical query learning We show noise tolerance improved technique roughly optimal respect desired learning accuracy provides smooth tradeoff tolerable amounts two types noise Finally show statistical query simulation yields learning algorithms combinations noise models thus demonstrating statistical query specification truly An important goal research machine learning determine tasks automated determine information computation requirements One way answer questions development investigation formal models machine learning capture task learning plausible assumptions In work consider formal model learning examples called probably approximately correct PAC learning defined Valiant Val In setting learner attempts approximate unknown target concept simply viewing positive negative examples concept An adversary chooses specified function class hidden f gvalued target function defined specified domain examples chooses probability distribution domain The goal learner output polynomial time high probability hypothesis close target function respect distribution examples The learner gains information target function distribution interacting example oracle At request learner oracle draws example randomly according hidden distribution labels according hidden target function returns labelled example learner A class functions F said PAC learnable captures generic fault tolerance learning algorithm',\n",
              " 'We present decision tree based approach function approximation reinforcement learning We compare approach table lookup neural network function approximator three problems well known mountain car pole balance problems well simulated automobile race car We find decision tree provide better learning performance neural network function approximation solve large problems infeasible using table lookup',\n",
              " 'An approach develop new game playing strategies based artificial evolution neural networks presented Evolution directed discover strategies Othello randommoving opponent later fffi search program The networks discovered first standard positional strategy subsequently mobility strategy advanced strategy rarely seen outside tournaments The latter discovery demonstrates evolutionary neural networks develop novel solutions turning initial disadvantage advantage changed environment',\n",
              " 'We derive general bounds complexity learning Statistical Query model PAC model classification noise We considering problem boosting accuracy weak learning algorithms fall within Statistical Query model This new model introduced Kearns provide general framework efficient PAC learning presence classification noise We first show general scheme boosting accuracy weak SQ learning algorithms proving weak SQ learning equivalent strong SQ learning The boosting efficient used show main result first general upper bounds complexity strong SQ learning Specifically derive simultaneous upper bounds respect number queries Olog VapnikChervonenkis dimension query space Olog inverse minimum tolerance O log In addition show general upper bounds nearly optimal describing class learning problems simultaneously lower bound number queries log We apply boosting results SQ model learning PAC model classification noise Since nearly PAC learning algorithms cast SQ model apply boosting techniques convert PAC algorithms highly efficient SQ algorithms By simulating efficient SQ algorithms PAC model classification noise show nearly PAC algorithms converted highly efficient PAC algorithms tolerate classification noise We give upper bound sample complexity noisetolerant PAC algorithms nearly optimal respect noise rate We also give upper bounds space complexity hypothesis size show two measures fact independent noise rate We note running times noisetolerant PAC algorithms efficient This sequence simulations also demonstrates possible boost accuracy nearly PAC algorithms even presence noise This provides partial answer open problem Schapire first theoretical evidence empirical result Drucker Schapire Simard',\n",
              " 'The tremendous current effort propose neurally inspired methods computation forces closer scrutiny real world application potential models This paper categorizes applications classes particularly discusses features applications make efficiently amenable neural network methods Computational machines deterministic mappings inputs outputs many computational mechanisms proposed problem solutions Neural network features include parallel execution adaptive learning generalization fault tolerance Often much effort given model applications already implemented much efficient way alternate technology Neural networks potentially powerful devices many classes applications However proposed class applications neural networks efficient large commonly occurring nature Comparison supervised unsupervised generalizing systems also included',\n",
              " 'Subjectivism become dominant philosophical foundation Bayesian inference Yet practice Bayesian analyses performed socalled noninformative priors priors constructed formal rule We review plethora techniques constructing priors discuss practical philosophical issues arise used We give special emphasis Jeffreyss rules discuss evolution point view interpretation priors away unique representation ignorance toward notion chosen convention We conclude problems raised research priors chosen formal rules serious may dismissed lightly sample sizes small relative number parameters estimated dangerous put faith default solution asymptotics take Jeffreyss rules variants remain reasonable choices We also provide annotated bibliography fl Robert E Kass Professor Larry Wasserman Associate Professor Department Statistics Carnegie Mellon University Pittsburgh Pennsylvania The work authors supported NSF grant DMS NIH grant RCA The authors thank Nick Polson helping annotations Jim Berger Teddy Seidenfeld Arnold Zellner useful comments discussion',\n",
              " 'Recurrent neural networks become popular models system identification time series prediction NARX Nonlinear AutoRegressive models eXogenous inputs neural network models popular subclass recurrent networks used many applications Though embedded memory found recurrent network models particularly prominent NARX models We show using intelligent memory order selection pruning good initial heuristics significantly improves generalization predictive performance nonlinear systems problems diverse grammatical inference time series prediction',\n",
              " 'This paper presents incremental concept learning approach identiflcation concepts high overall accuracy The main idea address concept overlap central problem learning multiple descriptions Many traditional inductive algorithms disjunctive version space family considered face problem The approach focuses combinations confldent possibly overlapping concepts original stochastic complexity formula The focusing ecient organized simulated annealingbased beam search The experiments show approach especially suitable developing incremental learning algorithms following advantages flrst generates highly accurate concepts second overcomes certain degree sensitivity order examples third handles noisy examples',\n",
              " 'Casebased reasoning CBR great deal offer supporting creative design particularly processes rely heavily previous design experience framing problem evaluating design alternatives However existing CBR systems living potential They tend adapt reuse old solutions routine ways producing robust uninspired results Little research effort directed towards kinds situation assessment evaluation assimilation processes facilitate exploration ideas elaboration redefinition problems crucial creative design Also typically rigid control structures facilitate kinds strategic control opportunism inherent creative reasoning In paper describe types behavior would like casebased design systems support based study designers working mechanical engineering problem We show standard CBR framework extended describe architecture developing experiment ideas',\n",
              " 'In paper present framework building probabilistic automata parameterized contextdependent probabilities Gibbs distributions used model state transitions output generation parameter estimation carried using EM algorithm Mstep uses generalized iterative scaling procedure We discuss relations certain classes stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model constructed using methodology',\n",
              " 'One characteristics design designers rely extensively past experience order create new designs Because memorybased techniques artificial intelligence help store organise retrieve reuse experiential knowledge held memory good candidates aiding designers Another characteristic design phenomenon exploration early stages design configuration A designer begins illstructured partially defined problem specification process exploration gradually refines modifies hisher understanding problem improves In paper describe demex interactive computeraided design system employs memorybased techniques help users explore design problems pose system order acquire better understanding requirements problems demex applied domain structural design buildings',\n",
              " 'Uppropagation algorithm inverting learning neural network generative models Sensory input processed inverting model generates patterns hidden variables using topdown connections The inversion process iterative utilizing negative feedback loop depends error signal propagated bottomup connections The error signal also used learn generative model examples The algorithm benchmarked principal component analysis In doctrine unconscious inference Helmholtz argued perceptions formed interaction bottomup sensory data topdown expectations According one interpretation doctrine perception procedure sequential hypothesis testing We propose new algorithm called uppropagation realizes interpretation layered neural networks It uses topdown connections generate hypotheses bottomup connections revise It important understand difference uppropagation ancestor backpropagation algorithm Backpropagation learning algorithm recognition models As shown Figure bottomup connections recognize patterns topdown connections propagate error signal used learn recognition model In contrast uppropagation algorithm inverting learning generative models shown Figure b Topdown connections generate patterns set hidden variables Sensory input processed inverting generative model recovering hidden variables could generated sensory data This operation called either pattern recognition pattern analysis depending meaning hidden variables Inversion generative model done iteratively negative feedback loop driven error signal bottomup connections The error signal also used learning connections experiments images handwritten digits',\n",
              " 'This paper demonstrates exploitation certain vision processing techniques index case base surfaces The surfaces result reinforcement learning represent optimum choice actions achieve goal anywhere state space This paper shows strong features occur interaction system environment detected early learning process Such features allow system identify identical similar task solved previously retrieve relevant surface This results orders magnitude increase learning rate',\n",
              " 'Combining different machine learning algorithms system produce benefits beyond either method could achieve alone This paper demonstrates genetic algorithms used conjunction lazy learning solve examples difficult class delayed reinforcement learning problems better either method alone This class class differential games includes numerous important control problems arise robotics planning game playing areas solutions differential games suggest solution strategies general class planning control problems We conducted series experiments applying three learning approacheslazy Qlearning knearest neighbor kNN genetic algorithmto particular differential game called pursuit game Our experiments demonstrate kNN great difficulty solving problem lazy version Qlearning performed moderately well genetic algorithm performed even better These results motivated next step experiments hypothesized kNN difficulty good examplesa common source difficulty lazy learning Therefore used genetic algorithm bootstrapping method kNN create system provide examples Our experiments demonstrate resulting joint system learned solve pursuit games high degree accuracyoutperforming either method aloneand relatively small memory requirements',\n",
              " 'We describe hierarchical generative model viewed nonlinear generalization factor analysis implemented neural network The model uses bottomup topdown lateral connections perform Bayesian perceptual inference correctly Once perceptual inference performed connection strengths updated using simple learning rule requires locally available information We demon strate network learns extract sparse distributed hierarchical representations',\n",
              " 'In applications neuroevolution individual population represents complete neural network Recent work SANE system however demonstrated evolving individual neurons often produces efficient genetic search This paper demonstrates SANE solve easy tasks quickly often stalls larger problems A hierarchical approach neuroevolution presented overcomes SANEs difficulties integrating neuronlevel exploratory search networklevel exploitive search In robot arm manipulation task hierarchical approach outperforms neuronbased search networkbased search',\n",
              " 'Reinforcement learning addresses problem learning select actions order maximize ones performance unknown environments To scale reinforcement learning complex realworld tasks typically studied AI one must ultimately able discover structure world order abstract away myriad details operate tractable problem spaces This paper presents SKILLS algorithm SKILLS discovers skills partially defined action policies arise context multiple related tasks Skills collapse whole action sequences single operators They learned minimizing compactness action policies using description length argument representation Empirical results simple grid navigation tasks illustrate successful discovery structure reinforcement learning',\n",
              " 'We consider generalization mistakebound model learning f gvalued functions learner must satisfy general constraint number M incorrect predictions number M incorrect predictions We describe generalpurpose optimal algorithm formulation problem We describe several applications general results involving situations learner wishes satisfy linear inequalities M M',\n",
              " 'A critical issue users Markov Chain Monte Carlo MCMC methods applications determine safe stop sampling use samples estimate characteristics distribution interest Research methods computing theoretical convergence bounds holds promise future currently yielded relatively little practical use applied work Consequently MCMC users address convergence problem applying diagnostic tools output produced running samplers After giving brief overview area provide expository review thirteen convergence diagnostics describing theoretical basis practical implementation We compare performance two simple models conclude methods fail detect sorts convergence failure designed identify We thus recommend combination strategies aimed evaluating accelerating MCMC sampler convergence including applying diagnostic procedures small number parallel chains monitoring autocorrelations crosscorrelations modifying parameterizations sampling algorithms appropriately We emphasize however possible say certainty finite sample MCMC algorithm representative underlying stationary distribution Mary Kathryn Cowles Assistant Professor Biostatistics Harvard School Public Health Boston MA Bradley P Carlin Associate Professor Division Biostatistics School Public Health University Minnesota Minneapolis MN Much work done first author graduate student Divison Biostatistics University Minnesota Assistant Professor Biostatistics Section Department Preventive Societal Medicine University Nebraska Medical Center Omaha NE The work authors supported part National Institute Allergy Infectious Diseases FIRST Award RAI The authors thank developers diagnostics studied sharing insights experiences software Drs Thomas Louis Luke Tierney helpful discussions suggestions greatly improved manuscript',\n",
              " 'Although detection invariant structure given set input patterns vital many recognition tasks connectionist learning rules tend focus directions high variance principal components The prediction paradigm often used reconcile dichotomy suggest direct approach invariant learning based antiHebbian learning rule An unsupervised twolayer network implementing method competitive setting learns extract coherent depth information randomdot stereograms',\n",
              " 'Instancebased learning methods explicitly remember data receive They usually training phase prediction time perform computation Then take query search database similar datapoints build online local model local average local regression predict output value In paper review advantages instance based methods autonomous systems also note ensuing cost hopelessly slow computation database grows large We present evaluate new way structuring database new algorithm accessing maintains advantages instancebased learning Earlier attempts combat cost instancebased learning sacrificed explicit retention data applicable instancebased predictions based small number near neighbors reintroduce explicit training phase form interpolative data structure Our approach builds multiresolution data structure summarize database experiences resolutions interest simultaneously This permits us query database exibility conventional linear search greatly reduced computational cost',\n",
              " 'Discrete Bayesian models used model uncertainty mobilerobot navigation question actions chosen remains largely unexplored This paper presents optimal solution problem formulated partially observable Markov decision process Since solving optimal control policy intractable general goes explore variety heuristic control strategies The control strategies compared experimentally simulation runs robot',\n",
              " 'This NRL NCARAI technical note AIC describes work Salzbergs NGE I recently implemented algorithm run case studies The purpose note publicize implementation note curious result using This implementation NGE available WWW address',\n",
              " 'Technical Report No Department Statistics University Toronto Abstract I present new Markov chain sampling method appropriate distributions isolated modes Like recentlydeveloped method simulated tempering tempered transition method uses series distributions interpolate distribution interest distribution sampling easier The new method advantage require approximate values normalizing constants distributions needed simulated tempering tedious estimate Simulated tempering performs random walk along series distributions used In contrast tempered transitions new method move systematically desired distribution easilysampled distribution back desired distribution This systematic movement avoids inefficiency random walk advantage unfortunately cancelled increase number interpolating distributions required Because sampling efficiency tempered transition method simple problems similar simulated tempering On complex distributions however simulated tempering tempered transitions may perform differently Which better depends ways interpolating distributions deceptive',\n",
              " 'We describe ongoing project develop adaptive training system ATS dynamically models students learning processes provide specialized tutoring adapted students knowledge state learning style The student modeling component ATS MLModeler uses machine learning ML techniques emulate students novicetoexpert transition MLModeler infers learning methods student used reach current knowledge state comparing students solution trace expert solution generating plausible hypotheses misconceptions errors student made A casebased approach used generate hypotheses incorrectly applying analogy overgeneralization overspecialization The student expert models use networkbased representation includes abstract concepts relationships well strategies problem solving Fuzzy methods used represent uncertainty student model This paper describes design ATS MLModeler gives detailed example system would model tutor student typical session The domain use example highschool level chemistry',\n",
              " 'Metacognition addresses issues knowledge cognition regulating cognition We argue regulation process improved growing experience Therefore mental models needed facilitate reuse previous regulation processes We satisfy requirement describing casebased approach Introspection Planning utilises previous experience obtained reasoning metalevel object level The introspection plans used approach support various metacognitive tasks identified generation selfquestions As example introspection planning metacognitive behaviour system IULIAN described',\n",
              " 'Graphical Markov models use graphs either undirected directed mixed represent possible dependences among statistical variables Applications undirected graphs UDGs include models spatial dependence image analysis acyclic directed graphs ADGs especially convenient statistical analysis arise fields genetics psychometrics models expert systems Bayesian belief networks Lauritzen Wermuth Frydenberg LWF introduced Markov property chain graphs mixed graphs used represent simultaneously causal associative dependencies include UDGs ADGs special cases In paper alternative Markov property AMP chain graphs introduced ways direct extension ADG Markov property LWF property chain graph',\n",
              " 'The fault hierarchy representation widely used expert systems diagnosis complex mechanical devices This paper describes theory revision algorithm revises fault hierarchies This task presents several challenges typical training instances missing feature values pattern missing features significant rather merely effect noise quality candidate theory depends correctness diagnoses returns set tests uses reach diagnoses This paper describes addresses challenges reports experiments use improve performance two fielded diagnostic systems fl This extended version paper appeared Proceedings Fifth International Workshop Principles Diagnosis Dx New York October We gratefully acknowledge receiving helpful comments CheoungNam Lee Glenn Meredith Chandra Mouleeswaran z Current address Robotics Laboratory Computer Science Department Stanford University Stanford CA email langleyflamingostanfordedu phone fax',\n",
              " 'Machine learning game strategies often depended competitive methods continually develop new strategies capable defeating previous ones We use inclusive definition game consider framework within competitive algorithm makes repeated use strategy learning component learn strategies defeat given set opponents We describe game learning terms sets H X first second player strategies connect model familiar models concept learning We show importance ideas teaching set specification number k new context The performance several competitive algorithms investigated using worstcase randomized strategy learning algorithms Our central result Theorem competitive algorithm solves games total number strategies polynomial lgjHj lgjX j k Its use demonstrated including application concept learning new kind counterexample oracle We conclude complexity analysis game learning list number new questions arising work',\n",
              " 'Most work attempts give bounds generalization error hypothesis generated learning algorithm based methods theory uniform convergence These bounds apriori bounds hold distribution examples calculated data observed In paper propose different approach bounding generalization error data observed A selfbounding learning algorithm algorithm addition hypothesis outputs outputs reliable upper bound generalization error hypothesis We first explore idea statistical query learning framework Kearns After give explicit self bounding algorithm learning algorithms based local search',\n",
              " 'In paper propose new framework studying Markov decision processes MDPs based ideas statistical mechanics The goal learning MDPs find policy yields maximum expected return time In choosing policies agents must therefore weigh prospects shortterm versus longterm gains We study simple MDP agent must constantly decide exploratory jumps local reward mining state space The number policies choose grows exponentially size state space N We view expected returns defining energy landscape policy space Methods statistical mechanics used analyze landscape thermodynamic limit N We calculate overall distribution expected returns well distribution returns policies fixed Hamming distance optimal one We briefly discuss problem learning optimal policies empirical estimates expected return As first step relate findings entropy limit hightemperature learning Numerical simulations support theoretical results',\n",
              " 'This paper shows neural networks use continuous activation functions VC dimension least large square number weights w This result settles longstanding open question namely whether wellknown Ow log w bound known hardthreshold nets also held general sigmoidal nets Implications number samples needed valid generalization discussed',\n",
              " 'Novel online learning algorithms self adaptive learning rates parameters blind separation signals proposed The main motivation development new learning rules improve convergence speed reduce crosstalking especially nonstationary signals Furthermore discovered conditions proposed neural network models associated learning algorithms exhibit random switch attention ie ability chaotic random switching crossover output signals way specified separated signal may appear various outputs different time windows Validity performance dynamic properties proposed learning algorithms investigated computer simulation experiments',\n",
              " 'I present modular network architecture learning algorithm based incremental dynamic programming allows single learning agent learn solve multiple Markovian decision tasks MDTs significant transfer learning across tasks I consider class MDTs called composite tasks formed temporally concatenating number simpler elemental MDTs The architecture trained set composite elemental MDTs The temporal structure composite task assumed unknown architecture learns produce temporal decomposition It shown certain conditions solution composite MDT constructed computationally inexpensive modifications solutions constituent elemental MDTs',\n",
              " 'Scientists engineers face recurring problems constructing testing modifying numerical simulation programs The process coding revising simulators extremely timeconsuming almost always written conventional programming languages Scientists engineers therefore benefit software facilitates construction programs simulating physical systems Our research adapts methodology deductive program synthesis problem constructing numerical simulation codes We focused simulators represented second order functional programs composed numerical integration root extraction routines We developed system uses first order Horn logic synthesize numerical simulators built components Our approach based two ideas First axiomatize relationship integration differentiation We neither attempt require complete axiomatization mathematical analysis Second system uses representation functions reified objects Function objects encoded lambda expressions Our knowledge base includes axiomatization term equality lambda calculus It also includes axioms defining semantics numerical integration root extraction routines We use depth bounded SLD resolution construct proofs synthesize programs Our system successfully constructed numerical simulators computational design jet engine nozzles sailing yachts among others Our results demonstrate deductive synthesis techniques used construct numerical simulation programs realistic applications Ellman Murata Automatic design optimization highly sensitive problem formulation The choice objective function constraints design parameters dramatically impact computational cost optimization quality resulting design The best formulation varies one application another A design engineer usually know best formulation advance In order address problem developed system supports interactive formulation testing reformulation design optimization strategies Our system includes executable dataflow language representing optimization strategies The language allows engineer define multiple stages optimization using different approximations objective constraints different abstractions design space We also developed set transformations reformulate strategies represented language The transformations approximate objective constraint functions abstract reparameterize search spaces divide optimization process multiple stages The system applicable principle design problem expressed terms constrained op',\n",
              " 'Bayesian networks provide language qualitatively representing conditional independence properties distribution This allows natural compact representation distribution eases knowledge acquisition supports effective inference algorithms It wellknown however certain independencies capture qualitatively within Bayesian network structure independencies hold certain contexts ie given specific assignment values certain variables In paper propose formal notion contextspecific independence CSI based regularities conditional probability tables CPTs node We present technique analogous based dseparation determining independence holds given network We focus particular qualitative representation schemetreestructured CPTs capturing CSI We suggest ways representation used support effective inference algorithms In particular present structural decomposition resulting network improve performance clustering algorithms alternative algorithm based cutset conditioning',\n",
              " 'The eligibility trace one basic mechanisms used reinforcement learning handle delayed reward In paper introduce new kind eligibility trace replacing trace analyze theoretically show results faster reliable learning conventional trace Both kinds trace assign credit prior events according recently occurred conventional trace gives greater credit repeated events Our analysis conventional replacetrace versions oine TD algorithm applied undiscounted absorbing Markov chains First show methods converge repeated presentations training set predictions two well known Monte Carlo methods We analyze relative efficiency two Monte Carlo methods We show method corresponding conventional TD biased whereas method corresponding replacetrace TD unbiased In addition show method corresponding replacing traces closely related maximum likelihood solution tasks mean squared error always lower long run Computational results confirm analyses show applicable generally In particular show replacing traces significantly improve performance reduce parameter sensitivity MountainCar task full reinforcementlearning problem continuous state space using featurebased function approximator',\n",
              " 'Reading studied decades variety cognitive disciplines yet theories exist sufficiently describe explain people accomplish complete task reading realworld texts In particular type knowledge intensive reading known creative reading largely ignored past research We argue creative reading aspect practically reading experiences result theory overlooks insufficient We built results psychology artificial intelligence education order produce functional theory complete reading process The overall framework describes set tasks necessary reading performed Within framework developed theory creative reading The theory implemented ISAAC Integrated Story Analysis And Creativity system reading system reads science fiction stories',\n",
              " 'We study problem combining updates special instance theory change counterfactual conditionals propositional knowledgebases Intuitively update means world described knowledgebase changed This opposed revisions another instance theory change knowledge static world changes A counterfactual implication statement form If A case B would also case negation A may derivable current knowledge We present decidable logic called VCU update counterfactual implication connectives object language Our update operator generalization operators previously proposed studied literature We show operator satisfies certain postulates set forth reasonable update The logic VCU extension D K Lewis logic VCU counterfactual conditionals The semantics VCU multimodal propositional calculus based possible worlds The infamous Ramsey Rule becomes derivation rule sound complete axiomatization We show Gardenfors Triviality Theorem impossibility combine theory change counterfactual conditionals via Ramsey Rule hold logic It thus seen Triviality Theorem applies revision operators updates fl A preliminary version paper presented Second International Conference Principles Knowledge Representation Reasoning Cambridge Massachusetts April The work partially performed author visiting Department Computer Science University Toronto',\n",
              " 'Many neural net learning algorithms aim finding simple nets explain training data The expectation simpler networks better generalization test data Occams razor Previous implementations however use measures simplicity lack power universality elegance based Kolmogorov complexity Solomonoffs algorithmic probability Likewise previous approaches especially Bayesian kind suffer problem choosing appropriate priors This paper addresses issues It first reviews basic concepts algorithmic complexity theory relevant machine learning SolomonoffLevin distribution universal prior deals prior problem The universal prior leads probabilistic method finding algorithmically simple problem solutions high generalization capability The method based Levin complexity timebounded generalization Kolmogorov complexity inspired Levins optimal universal search algorithm For given problem solution candidates computed efficient selfsizing programs influence runtime storage size The probabilistic search algorithm finds good programs ones quickly computing algorithmically probable solutions fitting training data Simulations focus task discovering algorithmically simple neural networks low Kolmogorov complexity high generalization capability It demonstrated method least certain toy problems computationally feasible lead generalization results unmatchable previous neural net algorithms Much remains done however make large scale applications incremental learning feasible',\n",
              " 'We studied problem generating expressive musical performances context tenor saxophone interpretations We done several recordings tenor sax playing different Jazz ballads different degrees expressiveness including inexpressive interpretation ballad These recordings analyzed using SMS spectral modeling techniques extract information related several expressive parameters This set parameters scores constitute set cases examples casebased system From set cases system infers set possible expressive transformations given new phrase applying similarity criteria based background musical knowledge new phrase set cases Finally SaxEx applies inferred expressive transformations new phrase using synthesis capabilities SMS',\n",
              " 'One surprising recurring phenomena observed experiments boosting test error generated classifier usually increase size becomes large often observed decrease even training error reaches zero In paper show phenomenon related distribution margins training examples respect generated voting classification rule margin example simply difference number correct votes maximum number votes received incorrect label We show techniques used analysis Vapniks support vector classifiers neural networks small weights applied voting methods relate margin distribution test error We also show theoretically experimentally boosting especially effective increasing margins training examples Finally compare explanation based biasvariance decomposition',\n",
              " 'Realworld learning tasks may involve highdimensional data sets arbitrary patterns missing data In paper present framework based maximum likelihood density estimation learning data sets We use mixture models density estimates make two distinct appeals ExpectationMaximization EM principle Dempster et al deriving learning algorithmEM used estimation mixture components coping missing data The resulting algorithm applicable wide range supervised well unsupervised learning problems Results classification benchmarkthe iris data setare presented',\n",
              " 'The hierarchical feature map system recognizes input story instance particular script classifying three levels scripts tracks role bindings The recognition taxonomy ie breakdown script tracks roles extracted automatically independently script examples script instantiations unsupervised selforganizing process The process resembles human learning differentiation frequently encountered scripts become gradually detailed The resulting structure hierachical pyramid feature maps The hierarchy visualizes taxonomy maps lay topology level The number input lines selforganization time considerably reduced compared ordinary singlelevel feature mapping The system recognize incomplete stories recover missing events The taxonomy also serves memory organization scriptbased episodic memory The maps assign unique memory location script instantiation The salient parts input data separated resources concentrated representing accurately',\n",
              " 'It shown static neural approaches adaptive target detection replaced efficient sequential alternative The latter inspired observation biological systems employ sequential eyemovements pattern recognition A system described builds adaptive model timevarying inputs artificial fovea controlled adaptive neural controller The controller uses adaptive model learning sequential generation fovea trajectories causing fovea move target visual scene The system also learns track moving targets No teacher provides desired activations eyemuscles various times The goal information shape target Since task rewardonlyatgoal task involves complex temporal credit assignment problem Some implications adaptive attentive systems general discussed',\n",
              " 'We present treestructured architecture supervised learning The statistical model underlying architecture hierarchical mixture model mixture coefficients mixture components generalized linear models GLIMs Learning treated maximum likelihood problem particular present ExpectationMaximization EM algorithm adjusting parameters architecture We also develop online learning algorithm parameters updated incrementally Comparative simulation results presented robot dynamics domain We want thank Geoffrey Hinton Tony Robinson Mitsuo Kawato Daniel Wolpert helpful comments manuscript This project supported part grant McDonnellPew Foundation grant ATR Human Information Processing Research Laboratories grant Siemens Corporation grant IRI National Science Foundation grant NJ Office Naval Research The project also supported NSF grant ASC support Center Biological Computational Learning MIT including funds provided DARPA HPCC program NSF grant ECS support Initiative Intelligent Control MIT Michael I Jordan NSF Presidential Young Investigator',\n",
              " 'The EM algorithm performs maximum likelihood estimation data variables unobserved We present function resembles negative free energy show M step maximizes function respect model parameters E step maximizes respect distribution unobserved variables From perspective easy justify incremental variant EM algorithm distribution one unobserved variables recalculated E step This variant shown empirically give faster convergence mixture estimation problem A variant algorithm exploits sparse conditional distributions also described wide range variant algorithms also seen possible',\n",
              " 'A network WilsonCowan oscillators constructed emergent properties synchronization desynchronization investigated computer simulation formal analysis The network twodimensional matrix oscillator coupled neighbors We show analytically chain locally coupled oscillators piecewise linear approximation WilsonCowan oscillator synchronizes present technique rapidly entrain finite numbers oscillators The coupling strengths change fast time scale based Hebbian rule A global separator introduced receives input sends feedback oscillator matrix The global separator used desynchronize different oscillator groups Unlike many models properties network emerge local connections preserve spatial relationships among components critical encoding Gestalt principles feature grouping The ability synchronize desynchronize oscillator groups within network offers promising approach pattern segmentation figureground segregation based oscillatory correlation',\n",
              " 'In paper I describe implementation probabilistic regression model BUGS BUGS program carries Bayesian inference statistical problems using simulation technique known Gibbs sampling It possible implement surprisingly complex regression models environment I demonstrate simultaneous inference interpolant inputdependent noise level',\n",
              " 'Classifying hand complex data coming psychology experiments long difficult task quantity data classify amount training may require One way alleviate problem use machine learning techniques We built classifier based decision trees reproduces classifying process used two humans sample data learns classify unseen data The automatic classifier proved accurate constant much faster classification hand',\n",
              " 'The estimation training methods neural network literature usually simple form gradient descent algorithm suitable implementation hardware using massively parallel computations For ordinary computers massively parallel optimization algorithms several SAS procedures usually far efficient This talk shows fit neural networks using SASOR R fl SASETS R fl SASSTAT R fl software',\n",
              " 'Selecting right reference class right interval faced conflicting candidates possibility establishing subset style dominance problem Kyburgs Evidential Probability system Various methods proposed Loui Kyburg solve problem way intuitively appealing justifiable within Kyburgs framework The scheme proposed paper leads stronger statistical assertions without sacrificing much intuitive appeal Kyburgs latest proposal',\n",
              " 'We apply reinforcement learning methods learn domainspecific heuristics job shop scheduling A repairbased scheduler starts criticalpath schedule incrementally repairs constraint violations goal finding short conflictfree schedule The temporal difference algorithm T D applied train neural network learn heuristic evaluation function states This evaluation function used onestep lookahead search procedure find good solutions new scheduling problems We evaluate approach synthetic problems problems NASA space shuttle payload processing task The evaluation function trained problems involving small number jobs tested larger problems The TD scheduler performs better best known existing algorithm taskZwebens iterative repair method based simulated annealing The results suggest reinforcement learning provide new method constructing highperformance scheduling systems',\n",
              " 'A neural network approach classic inverted pendulum task presented This task task keeping rigid pole hinged cart free fall plane roughly vertical orientation moving cart horizontally plane keeping cart within maximum distance starting position This task constitutes difficult control problem parameters cartpole system known precisely variable It also forms basis even complex controllearning problem controller must learn proper actions successfully balancing pole given current state system failure signal pole angle vertical becomes great cart exceeds one boundaries placed position The approach presented demonstrated effective realtime control small selfcontained minirobot specially outfitted task Origins details learning scheme specifics minirobot hardware results actual learning trials presented',\n",
              " 'Platts resourceallocation network RAN Platt b modified reinforcementlearning paradigm restart existing hidden units rather adding new units After restarting units continue learn via backpropagation The resulting restart algorithm tested Qlearning network learns solve inverted pendulum problem Solutions found faster average restart algorithm without',\n",
              " 'We propose new processing paradigm called Expandable Split Window ESW paradigm exploiting finegrain parallelism This paradigm considers window instructions possibly dependencies single unit exploits finegrain parallelism overlapping execution multiple windows The basic idea connect multiple sequential processors decoupled decentralized manner achieve overall multiple issue This processing paradigm shares number properties restricted dataflow machines derived sequential von Neumann architecture We also present implementation Expandable Split Window execution model preliminary performance results',\n",
              " 'Algorithms based Nested Generalized Exemplar NGE theory Salzberg classify new data points computing distance nearest generalized exemplar ie either point axisparallel rectangle They combine distancebased character nearest neighbor NN classifiers axisparallel rectangle representation employed many rulelearning systems An implementation NGE compared knearest neighbor kNN algorithm domains found significantly inferior kNN Several modifications NGE studied understand cause poor performance These show performance substantially improved preventing NGE creating overlapping rectangles still allowing complete nesting rectangles Performance improved modifying distance metric allow weights features Salzberg Best results obtained study weights computed using mutual information features output class The best version NGE developed batch algorithm BNGE FW MI usertunable parameters BNGE FW MI performance comparable firstnearest neighbor algorithm also incorporating feature weights However knearest neighbor algorithm still significantly superior BNGE FW MI domains inferior We conclude even improvements NGE approach sensitive shape decision boundaries classification problems In domains decision boundaries axisparallel NGE approach produce excellent generalization interpretable hypotheses In domains tested NGE algorithms require much less memory store generalized exemplars required NN algorithms',\n",
              " 'Selecting good model set input points cross validation computationally intensive process especially number possible models number training points high Techniques gradient descent helpful searching space models problems local minima importantly lack distance metric various models reduce applicability search methods Hoeffding Races technique finding good model data quickly discarding bad models concentrating computational effort differentiating better ones This paper focuses special case leaveoneout cross validation applied memorybased learning algorithms also argue applicable class model selection problems',\n",
              " 'In many learning problems learning system presented values features actually irrelevant concept trying learn The FOCUS algorithm due Almuallim Dietterich performs explicit search smallest possible input feature set S permits consistent mapping features S output feature The FOCUS algorithm also seen algorithm learning determinations functional dependencies suggested Another algorithm learning determinations appears The FOCUS algorithm superpolynomial runtime Almuallim Dietterich leave open question tractability underlying problem In paper problem shown NPcomplete We also describe briefly experiments demonstrate benefits determination learning show finding lowestcardinality determinations easier practice finding minimal determi Define MINFEATURES problem follows given set X examples composed binary value specifying value target feature vector binary values specifying values features number n determine whether exists feature set S We show MINFEATURES NPcomplete reducing VERTEXCOVER MINFEATURES The VERTEXCOVER problem may stated question given graph G vertices V edges E subset V V size edge E connected least one vertex V We may reduce instance VERTEXCOVER instance MINFEATURES mapping edge E example X one input feature every vertex V In proof reported result reduction set covering The proof therefore fails show NPcompleteness nations',\n",
              " 'An unsupervised learning algorithm multilayer network stochastic neurons described Bottomup recognition connections convert input representations successive hidden layers topdown generative connections reconstruct representation one layer representation layer In wake phase neurons driven recognition connections generative connections adapted increase probability would reconstruct correct activity vector layer In sleep phase neurons driven generative connections recognition connections adapted increase probability would produce Supervised learning algorithms multilayer neural networks face two problems They require teacher specify desired output network require method communicating error information connections The wakesleep algorithm avoids problems When external teaching signal matched goal required force hidden units extract underlying structure In wakesleep algorithm goal learn representations economical describe allow input reconstructed accurately We quantify goal imagining communication game vector raw sensory inputs communicated receiver first sending hidden representation sending difference input vector topdown reconstruction hidden representation The aim learning minimize description length total number bits would required communicate input vectors way No communication actually takes place minimizing description length would required forces network learn economical representations capture underlying regularities data correct activity vector layer',\n",
              " 'Properly structured software libraries crucial success software reuse Specifically structure software library ought reect functional similarity stored software components order facilitate retrieval process We propose application artificial neural network technology achieve structured library In detail utilize artificial neural network adhering unsupervised learning paradigm The distinctive feature model make semantic relationship stored software components geographically explicit Thus actual user software library gets notion semantic relationship components terms geographical closeness',\n",
              " 'Learning fundamental component intelligence key consideration designing cognitive architectures Soar Laird et al This chapter considers question constitutes appropriate generalpurpose learning mechanism We interested mechanisms might explain reproduce rich variety learning capabilities humans ranging learning perceptualmotor skills ride bicycle learning highly cognitive tasks play chess Research learning fields cognitive science artificial intelligence neurobiology statistics led identification two distinct classes learning methods inductive analytic Inductive methods neural network Backpropagation learn general laws finding statistical correlations regularities among large set training examples In contrast analytical methods ExplanationBased Learning acquire general laws many fewer training examples They rely instead prior knowledge analyze individual training examples detail use analysis distinguish relevant example features irrelevant The question considered chapter best combine inductive analytical learning architecture seeks cover range learning exhibited intelligent systems humans We present specific learning mechanism Explanation Based Neural Network learning EBNN blends two types learning present experimental results demonstrating ability learn control strategies mobile robot using',\n",
              " 'Simulation plays important role stochastic geometry related fields simplest random set models tend intractable analysis Many simulation algorithms deliver approximate samples random set models example simulating equilibrium distribution Markov chain spatial birthanddeath process The samples usually fail exact algorithm simulates Markov chain long finite time thus convergence equilibrium approximate The seminal work Propp Wilson made important contribution simulation proposing coupling method Coupling Past CFTP delivers perfect say exact simulations Markov chains In paper introduce new idea perfect simulation illustrate using two common models stochastic geometry dead leaves model Boolean model conditioned cover finite set points',\n",
              " 'In recent years casebased reasoning demonstrated highly useful problem solving complex domains Also mixed paradigm approaches emerged combining CBR induction techniques aiming verifying knowledge andor building efficient case memory However complex domains induction whole problem space often possible time consuming In paper approach presented owing close interaction CBR part attempts induce rules particular context ie problem solved CBRoriented system These rules may used indexing purposes similarity assessment order support CBR process future',\n",
              " 'This paper demonstrates tandem use finite automata learning algorithm utility planner adversarial robotic domain For many applications robot agents need predict movement objects environment plan avoid When robot reasoning model object machine learning techniques used generate one In project learn DFA model adversarial robot use automaton predict next move adversary The robot agent plans path avoid adversary predicted location fulfilling goal requirements',\n",
              " 'Claudia Cargnoni Dipartimento Statistico Universita di Firenze Firenze Italy Peter Muller Assistant Professor Mike West Professor Institute Statistics Decision Sciences Duke University Durham NC Research Cargnoni performed visiting ISDS Muller West partially supported NSF grant DMS',\n",
              " 'Our theoretical understanding properties genetic algorithms GAs used function optimization GAFOs strong would like Traditional schema analysis provides first order insights doesnt capture nonlinear dynamics GA search process well Markov chain theory used primarily steady state analysis GAs In paper explore use transient Markov chain analysis model understand behavior finite population GAFOs observed transition steady states This approach appears provide new insights circumstances GAFOs perform well Some preliminary results presented initial evaluation merits approach provided',\n",
              " 'In paper consider application training noise multilayer perceptron input variables relevance determination Noise injection modified order penalize irrelevant features The proposed algorithm attractive requires tuning single parameter This parameter controls penalization inputs together complexity model After presentation method experimental evidences given simulated data sets',\n",
              " 'COINS Technical Report January Abstract In paper present new multivariate decision tree algorithm LMDT combines linear machines decision trees LMDT constructs test decision tree training linear machine eliminating irrelevant noisy variables controlled manner To examine LMDTs ability find good generalizations present results variety domains We compare LMDT empirically univariate decision tree algorithm observe multivariate tests appropriate bias given data set LMDT finds small accurate trees',\n",
              " 'Reinforcement learning RL modelfree tuning adaptation method control dynamic systems Contrary supervised learning based usually gradient descent techniques RL require model sensitivity function process Hence RL applied systems poorly understood uncertain nonlinear reasons untractable conventional methods In reinforcement learning overall controller performance evaluated scalar measure called reinforcement Depending type control task reinforcement may represent evaluation recent control action often entire sequence past control moves In latter case RL system learns predict outcome individual control action This prediction used adjust parameters controller The mathematical background RL closely related optimal control dynamic programming This paper gives comprehensive overview RL methods presents application attitude control satellite Some well known applications literature reviewed well',\n",
              " 'A biologically motivated mechanism selforganizing neural network modifiable lateral connections presented The weight modification rules purely activitydependent unsupervised local The lateral interaction weights initially random develop Mexican hat shape around neuron At time external input weights selforganize form topological map input space The algorithm demonstrates selforganization bootstrap using input information Predictions algorithm agree well experimental observations development lateral connections cortical feature maps',\n",
              " 'Some main users statistical methods economists social scientists epidemiologists discovering fields rest statistical causal foundations The blurring foundations years follows lack mathematical notation capable distinguishing causal equational relationships By providing formal natural explication relations graphical methods potential revolutionize statistics used knowledgerich applications Statisticians response beginning realize causality metaphysical deadend meaningful concept clear mathematical underpinning The paper surveys developments outlines future challenges',\n",
              " 'This paper describes new method inducing logic programs examples attempts integrate best aspects existing ILP methods single coherent framework In particular combines bottomup method similar Golem topdown method similar Foil It also includes method predicate invention similar Champ elegant solution noisy oracle problem allows system learn recursive programs without requiring complete set positive examples Systematic experimental comparisons Golem Foil range problems used clearly demonstrate advantages approach',\n",
              " 'We present deterministic techniques computing upper lower bounds marginal probabilities sigmoid noisyOR networks These techniques become useful size network clique size precludes exact computations We illustrate tightness bounds numerical experi ments',\n",
              " 'MIT Computational Cognitive Science Technical Report Abstract We develop recursive nodeelimination formalism efficiently approximating large probabilistic networks No constraints set network topologies Yet formalism straightforwardly integrated exact methods whenever arebecome applicable The approximations use controlled maintain consistently upper lower bounds desired quantities times We show Boltzmann machines sigmoid belief networks combination ie chain graphs handled within framework The accuracy methods verified exper imentally',\n",
              " 'We prove lower bound ln ffi VCdimC number random examples required distributionfree learning concept class C VCdimC VapnikChervonenkis dimension ffi accuracy confidence parameters This improves previous best lower bound ln ffi VCdimC comes close known general upper bound O ffi VCdimC ln consistent algorithms We show many interesting concept classes including kCNF kDNF bound actually tight within constant factor',\n",
              " 'The ability handle temporal variation important dealing realworld dynamic signals In many applications inputs come fixedrate sequences rather signals time scales vary one instance next thus modeling dynamic signals requires ability recognize sequences also ability handle temporal changes signal This paper discusses Tau Net neural network modeling dynamic signals application speech In Tau Net sequence learning accomplished using combination prediction recurrence timedelay connections Temporal variability modeled adaptable time constants network adjusted respect prediction error Adapting time constants changes time scale network adapted value networks time constant provides measure temporal variation signal Tau Net applied several simple signals sets sine waves differing frequency phase multidimensional signal representing walking gait children energy contour simple speech utterance Tau Net also shown work voicing distinction task using synthetic speech data In paper Tau Net applied two speakerindependent tasks vowel recognition faeiyuxg consonant recognition fptkg using speech data taken TIMIT database It shown Tau Nets trained mediumrate tokens achieved performance networks without time constants trained tokens rates performed better networks without time constants trained mediumrate tokens Our results demonstrate Tau Nets ability identify vowels consonants variable speech rates extrapolating rates represented training set',\n",
              " 'Backpropagation learning BP known serious limitations generalising knowledge certain types learning material BPSOM extension BP overcomes limitations BPSOM combination multilayered feedforward network MFN trained BP Kohonens selforganising maps SOMs In earlier reports shown BPSOM improved generalisation performance whereas decreased simultaneously number necessary hidden units without loss generalisation performance These two effects use SOM learning training MFNs In paper focus two additional effects First show BPSOM training activations hidden units MFNs tend oscillate among limited number discrete values Second identify SOM elements adequate organisers instances task hand We visualise effects argue lead intelligible neural networks employed basis automatic rule extraction',\n",
              " 'The discrimination powers Multilayer perceptron MLP Learning Vector Quantisation LVQ networks compared overlapping Gaussian distributions It shown analytically Monte Carlo studies MLP network handles high dimensional problems efficient way LVQ This mainly due sigmoidal form MLP transfer function also fact MLP uses hyperplanes efficiently Both algorithms equally robust limited training sets learning curves fall like M M training set size compared theoretical predictions statistical estimates VapnikChervonenkis bounds',\n",
              " 'In article approximate rate convergence Gibbs sampler normal approximation target distribution Based approximation consider many implementational issues Gibbs sampler eg updating strategy parameterization blocking We give theoretical results justify approximation illustrate methods number realistic examples',\n",
              " 'Instancebased learning methods explicitly remember data receive They usually training phase prediction time perform computation Then take query search database similar datapoints build online local model local average local regression predict output value In paper review advantages instance based methods autonomous systems also note ensuing cost hopelessly slow computation database grows large We present evaluate new way structuring database new algorithm accessing maintains advantages instancebased learning Earlier attempts combat cost instancebased learning sacrificed explicit retention data applicable instancebased predictions based small number near neighbors reintroduce explicit training phase form interpolative data structure Our approach builds multiresolution data structure summarize database experiences resolutions interest simultaneously This permits us query database exibility conventional linear search greatly reduced computational cost',\n",
              " 'We implemented reinforcement learning architecture reactive component two layer control system simulated race car We found separating layers expedited gradually improving competition multagent interaction We ran experiments test tuning decomposition coordination low level behaviors We extended control system allow passing cars tested ability avoid collisions The best design used reinforcement learning separate networks behavior coarse coded input simple rule based coordination mechanism',\n",
              " 'This study concerned whether possible detect information contained training data background knowledge relevant solving learning problem whether irrelevant information eliminated preprocessing starting learning process A case study data preprocessing hybrid genetic algorithm shows elimination irrelevant features substantially improve efficiency learning In addition costsensitive feature elimination effective reducing costs induced hypotheses',\n",
              " 'Hierarchical genetic programming HGP approaches rely discovery modification use new functions accelerate evolution This paper provides qualitative explanation improved behavior HGP based analysis evolution process dual perspective diversity causality From static point view use HGP approach enables manipulation population higher diversity programs Higher diversity increases exploratory ability genetic search process demonstrated theoretical experimental fitness distributions expanded structural complexity individuals From dynamic point view analysis causality crossover operator suggests HGP discovers exploits useful structures bottomup hierarchical manner Diversity causality complementary affecting exploration exploitation genetic search Unlike machine learning techniques need extra machinery control tradeoff HGP automatically trades exploration exploitation',\n",
              " 'Previous neural network learning algorithms sequence processing computationally expensive perform poorly comes long time lags This paper first introduces simple principle reducing descriptions event sequences without loss information A consequence principle unexpected inputs relevant This insight leads construction neural architectures learn divide conquer recursively decomposing sequences I describe two architectures The first functions selforganizing multilevel hierarchy recurrent networks The second involving two recurrent networks tries collapse multilevel predictor hierarchy single recurrent net Experiments show system require less computation per time step many fewer training sequences conventional training algorithms recurrent nets',\n",
              " 'A neural network model selforganization ocular dominance lateral connections binocular input presented The selforganizing process results network afferent weights neuron organize smooth hillshaped receptive fields primarily one retinas neurons common eye preference form connected intertwined patches lateral connections primarily link regions eye preference Similar selforganization cortical structures observed experimentally strabismic kittens The model shows patterned lateral connections cortex may develop based correlated activity explains lateral connection patterns follow receptive field properties ocular dominance',\n",
              " 'Relaxation oscillations exhibiting one time scale arise naturally many physical systems This paper proposes method numerically integrate large systems relaxation oscillators The numerical technique called singular limit method derived analysis relaxation oscillations singular limit In limit system evolution gives rise time instants fast dynamics takes place intervals slow dynamics takes place A full description method given LEGION locally excitatory globally inhibitory oscillator networks fast dynamics characterized jumping leads dramatic phase shifts captured method iterative operation slow dynamics entirely solved The singular limit method evaluated computer experiments produces remarkable speedup compared methods integrating systems The speedup makes possible simulate largescale oscillator networks',\n",
              " 'A selforganizing model spiking neurons dynamic thresholds lateral excitatory inhibitory connections presented tested image segmentation task The model integrates two previously separate lines research modeling visual cortex Laterally connected selforganizing maps used model afferent structures lateral connections could selforganize inputdriven Hebbian adaptation Spiking neurons leaky integrator synapses used model image segmentation binding synchronization desynchronization neuronal activity Although approaches differ model neuron overall layout laterally connected twodimensional network This paper shows selforganization segmentation achieved network thus presenting unified model development func tional dynamics primary visual cortex',\n",
              " 'The full Bayesian method applying neural networks prediction problem set priorhyperprior structure net perform necessary integrals However integrals tractable analytically Markov Chain Monte Carlo MCMC methods slow especially parameter space highdimensional Using Gaussian processes approximate weight space integral analytically small number hyperparameters need integrated MCMC methods We applied idea classification problems obtaining ex cellent results realworld problems investigated far',\n",
              " 'Recently Propp Wilson proposed algorithm called Coupling Past CFTP allows approximate perfect ie exact simulation stationary distribution certain finite state space Markov chains Perfect Sampling using CFTP successfully extended context point processes amongst authors Haggstrom et al In Gibbs sampling applied bivariate point process penetrable spheres mixture model However general running time CFTP terms number transitions independent state sampled Thus impatient user aborts long runs may introduce subtle bias user impatience bias Fill introduced exact sampling algorithm finite state space Markov chains contrast CFTP unbiased user impatience Fills algorithm form rejection sampling similar CFTP requires sufficient monotonicity properties transition kernel used We show Fills version rejection sampling extended infinite state space context produce exact sample penetrable spheres mixture process related models Following use Gibbs sampling make use partial order mixture model state space Thus',\n",
              " 'Cells visual cortex selective ocular dominance orientation input also size spatial frequency The simulations reported paper show size selectivity could develop Hebbian selforganization receptive fields different sizes could organize columns like orientation ocular dominance The lateral connections network selforganize cooperatively simultaneously receptive field sizes produce patterns lateral connectivity closely follow receptive field organization Together previous work ocular dominance orientation selectivity results suggest single Hebbian selforganizing process give rise major receptive field properties visual cortex also structured patterns lateral interactions verified experimentally others predicted model The model also suggests functional role selforganized structures The afferent receptive fields develop sparse coding visual input recurrent lateral interactions eliminate redundancies cortical activity patterns allowing cortex efficiently process massive amounts visual information',\n",
              " 'A pilot study described practical application artificial neural networks The limit cycle attitude control satellite selected test case One sources limit cycle position dependent error observed attitude A Reinforcement Learning method selected able adapt controller cost function optimised An estimate cost function learned neural critic In approach estimated cost function directly represented function parameters linear controller The critic implemented CMAC network Results simulations show method able find optimal parameters without unstable behaviour In particular case large discontinuities attitude measurements method shows clear improvement compared conventional approach RMS attitude error decreases approximately',\n",
              " 'In nutshell describe generic ILP problem following given set E positive negative examples target predicate background knowledge B world usually logic program including facts auxiliary predicates task find logic program H hypothesis positive examples deduced B H negative example In paper review results achieved area discuss techniques used Moreover prove following new results Predicates described nonrecursive local clauses k literals PAClearnable distribution This generalizes previous result valid constrained clauses Predicates described k nonrecursive local clauses PAClearnable distribution This generalizes previous result non construc tive valid class distributions Finally introduce believe first theoretical framework learning Prolog clauses presence errors To purpose introduce new noise model call fixed attribute noise model learning propositional concepts Boolean domain This new noise model interest',\n",
              " 'The ExpectationMaximization algorithm given Dempster et al enjoyed considerable popularity solving MAP estimation problems This note gives simple derivation algorithm due Luttrell better illustrates convergence properties algorithm variants The algorithm illustrated two examples pooling data multiple noisy sources fitting mixture density',\n",
              " 'We consider problem incorporate prior knowledge supervised learning techniques We set problem framework regularization theory consider case know approximated function radial symmetry The problem solved two alternative ways use invariance constraint regularization theory framework derive rotation invariant version Radial Basis Functions use radial symmetry create new virtual examples given data set We show two apparently different methods learning',\n",
              " 'I present computational results suggesting gainadaptation algorithms based part connectionist learning methods may improve least squares classical parameterestimation methods stochastic timevarying linear systems The new algorithms evaluated respect classical methods along three dimensions asymptotic error computational complexity required prior knowledge system The new algorithms order complexity LMS methods On n dimensionality system whereas leastsquares methods Kalman filter On The new methods also improve Kalman filter require complete statistical model system varies time In simple computational experiment new methods shown produce asymptotic error levels near optimal Kalman filter significantly leastsquares LMS methods The new methods may perform better even Kalman filter error filters model system varies time',\n",
              " 'Windowing proposed procedure efficient memory use ID decision tree learning algorithm However previous work shown windowing may often lead decrease performance In work try argue separateandconquer rule learning algorithms appropriate windowing divideandconquer algorithms learn rules independently less susceptible changes class distributions In particular present new windowing algorithm achieves additional gains efficiency exploiting property separateandconquer algorithms While presented algorithm suitable redundant noisefree data sets also briefly discuss problem noisy data windowing present preliminary ideas might solved extension algorithm introduced paper',\n",
              " 'This article describes comprehensive approach automatic theory revision Given imperfect theory approach combines explanation attempts incorrectly classified examples order identify failing portions theory For theory fault correlated subsets examples used inductively generate correction Because corrections focused tend preserve structure original theory Because system starts approximate domain theory general fewer training examples required attain given level performance classification accuracy compared purely empirical system The approach applies classification systems employing propositional Hornclause theory The system tested variety application domains results presented problems domains molecular biology plant disease diagnosis',\n",
              " 'Suppose one wishes sample density x using Markov chain Monte Carlo MCMC An auxiliary variable u conditional distribution ujx defined giving joint distribution x u xujx A MCMC scheme samples joint distribution lead substantial gains efficiency compared standard approaches The revolutionary algorithm Swendsen Wang one example In addition reviewing SwendsenWang algorithm generalizations paper introduces new auxiliary variable method called partial decoupling Two applications Bayesian image analysis considered The first binary classification problem partial decoupling performs SW single site Metropolis The second PET reconstruction uses gray level prior Geman McClure A generalized SwendsenWang algorithm developed problem reduces computing time point MCMC viable method posterior exploration',\n",
              " 'In paper analyse theoretical properties slice sampler We find algorithm extremely robust geometric ergodicity properties For case one auxiliary variable demonstrate algorithm stochastically monotone deduce analytic bounds total variation distance stationarity method using FosterLyapunov drift condition methodology',\n",
              " 'This paper studies well combination simulated annealing ADFs solves genetic programming GP style program discovery problems On suite composed evenkparity problems k analyses performance simulated annealing ADFs compared using ADFs In contrast GP results suite simulated annealing run ADFs problem size increases advantage using standard GP program representation marginal When performance simulated annealing compared GP algorithm using ADFs evenparity problem GP advantageous evenparity problem SA GP equal evenparity problem SA advantageous',\n",
              " 'Most learning algorithms work effectively training data contain completely specified labeled samples In many diagnostic tasks however data include values attributes model blocking process hides values attributes learner While blockers remove values critical attributes handicap learner paper instead focuses blockers remove irrelevant attribute values ie values needed classify instance given values unblocked attributes We first motivate formalize model superfluousvalue blocking demonstrate omissions useful proving certain classes seem hard learn general PAC model viz decision trees DNF formulae trivial learn setting We also show model extended deal theory revision ie modifying existing formula blockers occasionally include superfluous values exclude required values cor ruptions training data',\n",
              " 'This paper presents approach automatic discovery functions Genetic Programming The approach based discovery useful building blocks analyzing evolution trace generalizing blocks define new functions finally adapting problem representation onthefly Adaptating representation determines hierarchical organization extended function set enables restructuring search space solutions found easily Measures complexity solution trees defined adaptive representation framework The minimum description length principle applied justify feasibility approaches based hierarchy discovered functions suggest alternative ways defining problems fitness function Preliminary empirical results presented',\n",
              " 'A decision problem associated fundamental nonconvex model linearly inseparable pattern sets shown NPcomplete Another nonconvex model employs norm instead norm solved polynomial time solving n linear programs n usually small dimensionality pattern space An effective LPbased finite algorithm proposed solving latter model The algorithm employed obtain nonconvex piecewiselinear function separating points representing measurements made fine needle aspirates taken benign malignant human breasts A computer program trained samples correctly diagnosed new samples encountered currently use University Wisconsin Hospitals Introduction The fundamental problem wish address',\n",
              " 'Many connectionist approaches musical expectancy music composition let question What next overshadow equally important question When next One escape latter question one temporal structure considering perception musical meter We view perception metrical structure dynamic process temporal organization external musical events synchronizes entrains listeners internal processing mechanisms This article introduces novel connectionist unit based upon mathematical model entrainment capable phase frequencylocking periodic components incoming rhythmic patterns Networks units selforganize temporally structured responses rhythmic patterns The resulting network behavior embodies perception metrical structure The article concludes discussion implications approach theories metrical structure musical expectancy',\n",
              " 'Over years several packages developed provide workbench genetic algorithm GA research Most packages use generational model inspired GENESIS A adopted steadystate model used Genitor Unfortunately deficiencies working orderbased problems packing routing scheduling This paper describes LibGA developed specifically orderbased problems also works easily kinds problems It offers easy use userfriendly interface allows comparisons made generational steadystate genetic algorithms particular problem It includes variety genetic operators reproduction crossover mutation LibGA makes easy use operators new ways particular applications develop include new operators Finally offers unique new feature dynamic generation gap',\n",
              " 'Human episodic memory provides seemingly unlimited storage everyday experiences retrieval system allows us access experiences partial activation components The system believed consist fast temporary storage hippocampus slow longterm storage within neocortex This paper presents neural network model hippocampal episodic memory inspired Damasios idea Convergence Zones The model consists layer perceptual feature maps binding layer A perceptual feature pattern coarse coded binding layer stored weights layers A partial activation stored features activates binding pattern turn reactivates entire stored pattern For many configurations model theoretical lower bound memory capacity derived order magnitude higher number units model several orders magnitude higher number bindinglayer units Computational simulations indicate average capacity order magnitude larger theoretical lower bound making connectivity layers sparser causes even increase capacity Simulations also show descriptive binding patterns used errors tend plausible patterns confused similar patterns slight cost capacity The convergencezone episodic memory therefore accounts immediate storage associative retrieval capability large capacity hippocampal memory shows memory encoding areas much smaller perceptual maps consist rather coarse computational units sparsely connected perceptual maps',\n",
              " 'Empirical Learning Results POLLYANNA The value empirical learning demonstrated results testing theory space search TSS component POLLYANNA Empirical data shows approximations generated generic simplifying assumptions widely varying levels accuracy efficiency The candidate theory space includes theories Pareto optimal combinations accuracy efficiency well others nonoptimal Empirical learning thus needed separate optimal theories nonoptimal ones It works filter process generating approximations generic simplifying assumptions Empirical tests serve additional purpose well Theory space search collects data precisely characterizes tradeoff accuracy efficiency among candidate approximate theories The tradeoff data used select theory best balances competing objectives accuracy efficiency manner appropriate intended performance context The feasibility empirical learning also addressed results testing theory space search component POLLYANNA In order empirical testing feasible candidate approximate theories must operationally usable Candidate hearts theories generated POLLYANNA shown operationally usable experimental results theory space search TSS phase learning They run real machine producing results compared training examples Feasibility also depends information computation costs empirical testing Information costs result need supply system training examples Computation costs result need execute candidate theories Both types costs grow numbers candidate theories tested Experimental results show empirical testing POLLYANNA limited computation costs executing candidate theories information costs obtaining many training examples POLLYANNA contrasts respect traditional inductive learning systems The feasibility empirical learning depends also intended performance context resources available context learning Measurements theory space search phase indicate TSS algorithms performing exhaustive search would feasible hearts domain although may feasible applications TSS algorithms avoid exhaustive search hold considerably promise',\n",
              " 'In paper adopt generalsum stochastic games framework multiagent reinforcement learning Our work extends previous work Littman zerosum stochastic games broader framework We design multiagent Qlearning method framework prove converges Nash equilibrium specified conditions This algorithm useful finding optimal strategy exists unique Nash equilibrium game When exist multiple Nash equilibria game algorithm combined learning techniques find optimal strategies',\n",
              " 'Rising operating costs structural transformations resizing globalization companies world brought focus emerging discipline knowledge management concerned making knowledge pay Corporate memories form important part knowledge management initiatives company In paper discuss viewing corporate memories distributed case libraries benefit existing techniques distributed casebased reasoning resource discovery exploitation previous expertise We present two techniques developed context multiagent casebased reasoning accessing exploiting past experience corporate memory resources The first approach called Negotiated Retrieval deals retrieving assembling case pieces different resources corporate memory form good overall case The second approach based Federated Peer Learning deals two modes cooperation called DistCBR ColCBR let agent exploit experience expertise peer agents achieve local task fl The first author would like acknowledge support National Science Foundation Grant Nos IRI EEC The second authors research reported paper developed IIIA inside ANALOG Project funded Spanish CICYT grant The content paper necessarily reflect position policy US Government Kingdom Spain Government Catalonia Government official endorsement inferred',\n",
              " 'When learning reasoning failures knowledge system behaves powerful lever deciding went wrong system deciding system needs learn A number benefits arise systems possess knowledge operation knowledge Abstract knowledge cognition used select diagnosis repair strategies among alternatives Specific kinds selfknowledge used distinguish failure hypothesis candidates Making selfknowledge explicit also facilitate use knowledge across domains provide principled way incorporate new learning strategies To illustrate advantages selfknowledge learning provide implemented examples two different systems A plan execution system called RAPTER story understanding system called MetaAQUA',\n",
              " 'Theory revision integrates inductive learning background knowledge combining training examples coarse domain theory produce accurate theory There two challenges theory revision theoryguided systems face First representation language appropriate initial theory may inappropriate improved theory While original representation may concisely express initial theory accurate theory forced use representation may bulky cumbersome difficult reach Second theory structure suitable coarse domain theory may insufficient finetuned theory Systems produce small local changes theory limited value accomplishing complex structural alterations may required Consequently advanced theoryguided learning systems require flexible representation flexible structure An analysis various theory revision systems theoryguided learning systems reveals specific strengths weaknesses terms two desired properties Designed capture underlying qualities system new system uses theoryguided constructive induction Experiments three domains show improvement previous theoryguided systems This leads study behavior limitations potential theoryguided constructive induction',\n",
              " 'If experiment requires statistical analysis establish result one better experiment Ernest Rutherford Most proponents cold fusion reporting excess heat electrolysis experiments claiming one main characteristics cold fusion irreproducibility JR Huizenga Cold Fusion p Abstract Amid ever increasing research various aspects neural computing much progress evident theoretical advances empirical studies On empirical side wealth data experimental studies reported It however clear best report neural computing experiments may replicated interested researchers In particular nature iterative learning randomised initial architecture backpropagation training multilayer perceptron precise replication reported result virtually impossible The outcome experimental replication reported results touchstone scientific method option researchers popular subfield neural computing In paper address issue replicability experiments based backpropagation training multilayer perceptrons although many results applicable subfield plagued characteristics First attempt produce complete abstract specification neural computing experiment From specification identify full range parameters needed support maximum replicability use show absolute replicability option practice We propose statistical framework support replicability We demonstrate framework empirical studies replicability respect experimental controls validity implementations backpropagation algorithm Finally suggest degree replicability neural computing experiment estimated reflected claimed precision empirical results reported',\n",
              " 'In paper propose unsupervised neural network allowing robot learn sensorimotor associations delayed reward The robot task learn meaning pictograms order survive maze First introduce new neural conditioning rule PCR Probabilistic Conditioning Rule allowing test hypotheses associations visual categories movements given time span Second describe real maze experiment mobile robot We propose neural architecture solve problem discuss difficulty build visual categories dynamically associating movements Third propose use algorithm simulation order test exhaustively We give results different kind mazes compare system adapted version Qlearning algorithm Finally conclude showing limitations approaches take account intrinsic complexity reasonning based image recognition',\n",
              " 'We present framework analysis synthesis acoustical instruments based datadriven probabilistic inference modeling Audio time series boundary conditions played instrument recorded nonlinear mapping control data audio space inferred using general inference framework ClusterWeighted Modeling The resulting model used realtime synthesis audio sequences new input data',\n",
              " 'In many realworld domains task machine learning algorithms learn theory predicting numerical values In particular several standard test domains used Inductive Logic Programming ILP concerned predicting numerical values examples relational mostly nondeterminate background knowledge However far ILP algorithm except one predict numbers cope nondeterminate background knowledge The exception covering algorithm called FORS In paper present Structural Regression Trees SRT new algorithm applied class problems integrating statistical method regression trees ILP SRT constructs tree containing literal atomic formula negation conjunction literals node assigns numerical value leaf SRT provides comprehensible results purely statistical methods applied class problems ILP systems handle Experiments several realworld domains demonstrate approach competitive existing methods indicating advantages expense predictive accuracy',\n",
              " 'A quantitative practical Bayesian framework described learning mappings feedforward networks The framework makes possible objective comparisons solutions using alternative network architectures objective stopping rules network pruning growing procedures objective choice magnitude type weight decay terms additive regularisers penalising large weights etc measure effective number welldetermined parameters model quantified estimates error bars network parameters network output objective comparisons alternative learning interpolation models splines radial basis functions The Bayesian evidence automatically embodies Occams razor penalising overflexible overcomplex models The Bayesian approach helps detect poor underlying assumptions learning models For learning models well matched problem good correlation generalisation ability This paper makes use Bayesian framework regularisation model comparison described companion paper Bayesian interpolation MacKay This framework due Gull Skilling Gull Bayesian evidence obtained',\n",
              " 'Simultaneous multithreading technique permits multiple independent threads issue multiple instructions cycle In previous work demonstrated performance potential simultaneous multithreading based somewhat idealized model In paper show throughput gains simultaneous multithreading achieved without extensive changes conventional wideissue superscalar either hardware structures sizes We present architecture simultaneous multithreading achieves three goals minimizes architectural impact conventional superscalar design minimal performance impact single thread executing alone achieves significant throughput gains running multiple threads Our simultaneous multithreading architecture achieves throughput instructions per cycle fold improvement unmodified superscalar similar hardware resources This speedup enhanced advantage multithreading previously unexploited architectures ability favor fetch issue threads efficiently using processor cycle thereby providing best instructions processor',\n",
              " 'The theory revision problem problem best go revising deficient domain theory using information contained examples expose inaccuracies In paper present approach theory revision problem propositional domain theories The approach described called PTR uses probabilities associated domain theory elements numerically track ow proof theory This allows us measure precise role clause literal allowing preventing desired undesired derivation given example This information used efficiently locate repair awed elements theory PTR proved converge theory correctly classifies examples shown experimentally fast accurate even deep theories',\n",
              " 'New methodology fully Bayesian mixture analysis developed making use reversible jump Markov chain Monte Carlo methods capable jumping parameter subspaces corresponding different numbers components mixture A sample full joint distribution unknown variables thereby generated used basis thorough presentation many aspects posterior distribution The methodology applied analysis univariate normal mixtures using hierarchical prior model offers approach dealing weak prior information avoiding mathematical pitfalls using improper priors mixture context',\n",
              " 'Northeastern University College Computer Science Technical Report NUCCS fl We gratefully acknowledge substantial contributions effort provided Andy Barto sparked original interest questions whose continued encouragement insightful comments criticisms helped us greatly Recent discussions Satinder Singh Vijay Gullapalli also helpful impact work Special thanks also Rich Sutton influenced thinking subject numerous ways This work supported Grant IRI National Science Foundation U S Air Force',\n",
              " 'Active learning differs passive learning examples learning algorithm assumes least control part input domain receives information In situations active learning provably powerful learning examples alone giving better generalization fixed number training examples In paper consider problem learning binary concept absence noise Valiant We describe formalism active concept learning called selective sampling show may approximately implemented neural network In selective sampling learner receives distribution information environment queries oracle parts domain considers useful We test implementation called SGnetwork three domains observe significant improvement generalization',\n",
              " 'High performance architectures always deal performancelimiting impact branch operations Microprocessor designs going deal problem well move towards deeper pipelines support multiple instruction issue Branch prediction schemes often used alleviate negative impact branch operations allowing speculative execution instructions unresolved branch Another technique eliminate branch instructions altogether Predication remove forward branch instructions translating instructions following branch predicate form This paper analyzes variety existing predication models eliminating branch operations effect elimination branch prediction schemes existing processors including single issue architectures simple prediction mechanisms newer multiissue designs correspondingly sophisticated branch predictors The effect branch prediction accuracy branch penalty basic block size studied hhhhhhhhhhhhhhhhhhhhhhhh',\n",
              " 'This paper describes model complementarity rules precedents classification task Under model precedents assist rulebased reasoning operationalizing abstract rule antecedents Conversely rules assist casebased reasoning case elaboration process inferring case facts order increase similarity cases term reformulation process replacing term whose precedents weakly match case terms whose precedents strongly match case Fully exploiting complementarity requires control strategy characterized impartiality absence arbitrary ordering restrictions use rules precedents An impartial control strategy implemented GREBE domain Texas workers compensation law In preliminary evaluation GREBEs performance found good slightly better performance law students task A case classified belonging particular category relating description criteria category membership The justifications warrants Toulmin relate case category vary widely generality antecedents For example consider warrants classifying case legal category negligence A rule An action negligent actor fails use reasonable care failure proximate cause injury general antecedent terms eg breach reasonable care Conversely precedent Dr Jones negligent failed count sponges surgery result left sponge Smith specific antecedent terms eg failure count sponges Both types warrants used classification systems relate cases categories Classification systems used precedents help match antecedents rules cases Completing match difficult terms antecedent opentextured ie significant uncertainty whether match specific facts Gardner McCarty Sridharan This problem results generality gap separating abstract terms specific facts Porter et al Precedents opentextured term ie past cases term applied used bridge gap Unlike rule antecedents antecedents precedents level generality cases generality gap exists precedents new cases Precedents therefore reduce problem matching specific case facts opentextured terms problem matching two sets specific facts For example injured employees entitlement workers compensation depends whether injured activity furtherance employment Determining whether particular case classified compensable injury therefore requires matching specific facts case eg John injured automobile accident driving office opentextured term activity furtherance employment The gap generality case description abstract term makes match problematical However completing match may much easier precedents term activity furtherance employment eg Marys injury compensable occurred driving work activity furtherance employment Bills injury compensable occurred driving house deliver pizza activity furtherance employment In case Johns driving office closely matches Marys driving work',\n",
              " 'We introduce modelbased average reward Reinforcement Learning method called Hlearning compare discounted counterpart Adaptive RealTime Dynamic Programming simulated robot scheduling task We also introduce extension Hlearning automatically explores unexplored parts state space always choosing greedy actions respect current value function We show Autoexploratory Hlearning performs better original Hlearning previously studied exploration methods random recencybased counterbased exploration',\n",
              " 'This paper proposes using fuzzy logic techniques dynamically control parameter settings genetic algorithms GAs We describe Dynamic Parametric GA GA uses fuzzy knowledgebased system control GA parameters We introduce technique automatically designing tuning fuzzy knowledgebase system using GAs Results initial experiments show performance improvement simple static GA One Dynamic Parametric GA system designed automatic method demonstrated improvement application included design phase may indicate general applicability Dynamic Parametric GA wide range ap plications',\n",
              " 'In previous work Olshausen Field algorithm described learning linear sparse codes trained natural images produces set basis functions spatially localized oriented bandpass ie waveletlike This note shows algorithm may interpreted within maximumlikelihood framework Several useful insights emerge connection makes explicit relation statistical independence ie factorial coding shows formal relationship algorithm Bell Sejnowski suggests adapt parameters previously fixed This report describes research done within Center Biological Computational Learning Department Brain Cognitive Sciences Massachusetts Institute Technology This research sponsored Individual National Research Service Award BAO NIMH FMH grant National Science Foundation contract ASC award includes funds ARPA provided HPCC program CBCL',\n",
              " 'We study layered belief networks binary random variables conditional probabilities Prchildjparents depend monotonically weighted sums parents For networks give efficient algorithms computing rigorous bounds marginal probabilities evidence output layer Our methods apply generally computation upper lower bounds well generic transfer function parameterizations conditional probability tables sigmoid noisyOR We also prove rates convergence accuracy bounds function network size Our results derived applying theory large deviations weighted sums parents node network Bounds marginal probabilities computed two contributions one assuming weighted sums fall near mean values assuming This gives rise interesting tradeoff probable explanations evidence improbable deviations mean In networks child N parents gap upper lower bounds behaves sum two terms one order p In addition providing rates convergence large networks methods also yield efficient algorithms approximate inference fixed networks',\n",
              " 'Feature selection proven valuable technique supervised learning improving predictive accuracy reducing number attributes considered task We investigate potential similar benefits unsupervised learning task conceptual clustering The issues raised feature selection absence class labels discussed implementation sequential feature selection algorithm based existing conceptual clustering system described Additionally present second implementation employs technique improving efficiency search optimal description compare performance algorithms',\n",
              " 'Robust flexible sufficiently general vision systems recognition description complex dimensional objects require adequate armamentarium representations learning mechanisms This paper briefly analyzes strengths weaknesses different learning paradigms symbol processing systems connectionist networks statistical syntactic pattern recognition systems possible candidates providing capabilities points several promising directions integrating multiple paradigms synergistic fashion towards goal',\n",
              " 'A selforganizing neural network sequence classification called SARDNET described analyzed experimentally SARDNET extends Kohonen Feature Map architecture activation retention decay order create unique distributed response patterns different sequences SARDNET yields extremely dense yet descriptive representations sequential input training iterations The network proven successful mapping arbitrary sequences binary real numbers well phonemic representations English words Potential applications include isolated spoken word recognition cognitive science models sequence processing',\n",
              " 'LIACC Technical Report Abstract In paper address problem acquiring knowledge integration Our aim construct integrated knowledge base several separate sources The objective integration construct one system exploits knowledge available good performance The aim paper discuss methodology knowledge integration present concrete results In experiments performance integrated theory exceeded performance individual theories quite significant amount Also performance fluctuate much experiments repeated These results indicate knowledge integration complement existing ML methods',\n",
              " 'In introduction define term bias used machine learning systems We motivate importance automated methods evaluating selecting biases using framework bias selection search bias metabias spaces Recent research field machine learning bias summarized',\n",
              " 'A method initial results comparative study ABSTRACT A standard approach determining decision trees learn examples A disadvantage approach decision tree learned difficult modify suit different decision making situations Such problems arise example attribute assigned node measured significant change costs measuring attributes frequency distribution events different decision classes An attractive approach resolving problem learn store knowledge form decision rules generate whenever needed decision tree suitable given situation An additional advantage approach facilitates building compact decision trees much simpler logically equivalent conventional decision trees compact trees meant decision trees may contain branches assigned set values nodes assigned derived attributes ie attributes logical mathematical functions original ones The paper describes efficient method AQDT takes decision rules generated AQtype learning system AQ AQ builds decision tree optimizing given optimality criterion The method work two modes standard mode produces conventional decision trees compact mode produces compact decision trees The preliminary experiments AQDT shown decision trees generated decision rules conventional compact outperformed generated examples wellknown C program terms simplicity predictive accuracy',\n",
              " 'OGI CSE Technical Report Abstract Smoothing regularizers radial basis functions studied extensively general smoothing regularizers projective basis functions PBFs widelyused sigmoidal PBFs heretofore proposed We derive new classes algebraicallysimple th order smoothing regularizers networks projective basis functions f W x P N fi fl u general transfer functions g These simple algebraic forms RW enable direct enforcement smoothness without need costly Monte Carlo integrations SW The regularizers tested illustrative sample problems compared quadratic weight decay The new regularizers shown yield better generalization errors',\n",
              " 'We address problem musical variation identification different musical sequences variations implications mental representations music According reductionist theories listeners judge structural importance musical events forming mental representations These judgments may result production reduced memory representations retain musical gist In study improvised music performance pianists produced variations melodies Analyses musical events retained across variations provided support reductionist account structural importance A neural network trained produce reduced memory representations melodies represented structurally important events efficiently others Agreement among musicians improvisations network model musictheoretic predictions suggest perceived constancy across musical variation natural result reductionist mechanism producing memory representations',\n",
              " 'Ensemble learning variational free energy minimization tool introduced neural networks Hinton van Camp learning described terms optimization ensemble parameter vectors The optimized ensemble approximation posterior probability distribution parameters This tool applied variety statistical inference problems In paper I study linear regression model parameters hyperparameters I demonstrate evidence approximation optimization regularization constants derived detail free energy minimization view point',\n",
              " 'The self regenerative MCMC tool constructing Markov chain given stationary distribution constructing auxiliary chain stationary distribution Elements auxiliary chain picked suitable random number times resulting chain stationary distribution Sahu Zhigljavsky In article provide generic adaptation scheme algorithm The adaptive scheme use knowledge stationary distribution gathered far update course simulation This method easy implement often leads considerable improvement We obtain theoretical results adaptive scheme Our proposed methodology illustrated number realistic examples Bayesian computation performance compared available MCMC techniques In one applications develop nonlinear dynamics model modeling predatorprey relationships wild',\n",
              " 'Conceptual analogy CA approach integrates conceptualization ie memory organization based prior experiences analogical reasoning Borner It implemented prototypically tested support design process building engineering Borner Janetzko Borner There number features distinguish CA standard approaches CBR AR First CA automatically extracts knowledge needed support design tasks ie complex case representations relevance object features relations proper adaptations attributevalue representations prior layouts Secondly effectively determines similarity complex case representations terms adaptability Thirdly implemented integrated highly interactive adaptive system architecture allows incremental knowledge acquisition user support This paper surveys basic assumptions psychological results influenced development CA It sketches knowledge representation formalisms employed characterizes subprocesses needed integrate memory organization analogical reasoning',\n",
              " 'Even sophisticated branchprediction techniques necessarily suffer mispredictions even relatively small mispredict rates hurt performance substantially currentgeneration processors In paper investigate schemes improving performance face imperfect branch predictors processor simultaneously execute code taken nottaken outcomes branch This paper presents data regarding limits multipath execution considers fetchbandwidth needs multipath execution discusses various dynamic confidenceprediction schemes gauge likelihood branch mispredictions Our evaluations consider executing along several paths Using paths relatively simple confidence predictor multipath execution garners speedups compared singlepath case average speedup SPECint suite While associated increases instructionfetchbandwidth requirements surprising less expected result significance separate returnaddress stack forked path Overall results indicate multipath execution offers significant improvements singlepath performance could especially useful combined multithreading hardware costs amortized approaches',\n",
              " 'This paper presents algorithms robustness analysis Bayesian networks global neighborhoods Robust Bayesian inference calculation bounds posterior values given perturbations probabilistic model We present algorithms robust inference including expected utility expected value variance bounds global perturbations modeled contaminated constant density ratio constant density bounded total variation classes distributions c fl Carnegie Mellon University',\n",
              " 'This paper describes selflearning control system mobile robot Based local sensor data robot taught avoid collisions obstacles The feedback control system binaryvalued external reinforcement signal indicates whether collision occured A reinforcement learning scheme used find correct mapping input sensor space output steering signal space An adaptive quantisation scheme introduced discrete division input space built scratch system',\n",
              " 'Rules extracted trained feedforward networks used explanation validation crossreferencing network output decisions This paper introduces rule evaluation ordering mechanism orders rules extracted feedforward networks based three performance measures Detailed experiments using three rule extraction techniques applied Wisconsin breast cancer database illustrate power proposed methods Moreover method integrating output decisions extracted rulebased system corresponding trained network proposed The integrated system provides improvements',\n",
              " 'Standard methods inducing structure weight values recurrent neural networks fit assumed class architectures every task This simplification necessary interactions network structure function well understood Evolutionary computation includes genetic algorithms evolutionary programming populationbased search method shown promise complex tasks This paper argues genetic algorithms inappropriate network acquisition describes evolutionary program called GNARL simultaneously acquires structure weights recurrent networks This algorithms empirical acquisition method allows emergence complex behaviors topologies potentially excluded artificial architectural constraints imposed standard network induction methods',\n",
              " 'A new mechanism genetic encoding neural networks proposed loosely based marker structure biological DNA The mechanism allows aspects network structure including number nodes connectivity evolved genetic algorithms The effectiveness encoding scheme demonstrated object recognition task requires artificial creatures whose behaviour driven neural network develop highlevel finitestate exploration discrimination strategies The task requires solving sensorymotor grounding problem ie developing functional understanding effects creatures movement sensory input',\n",
              " 'We study multivariate smoothing spline estimate function several variables based ANOVA decomposition sums main effect functions one variable twofactor interaction functions two variables etc We derive Bayesian confidence intervals components decomposition demonstrate even multiple smoothing parameters efficiently computed using publicly available code RKPACK originally designed compute estimates We carry small Monte Carlo study see closely actual properties componentwise confidence intervals match nominal confidence levels Lastly analyze lake acidity data function calcium concentration latitude longitude using polynomial thin plate spline main effects model',\n",
              " 'appear Cowan J Tesauro G Alspector J eds Advances Neural Information Processing Systems San Francisco CA Morgan Kaufmann Publishers This paper written tersely accomodate page limitation Presented refereed poster session Conference Neural Information Processing SystemsNatural Synthetic November Denver CO Supported NSF grants DMS DMS National Eye InstituteNIH grants EY EY',\n",
              " 'Virtually largescale sequencing projects use automatic sequenceassembly programs aid determination DNA sequences The computergenerated assemblies require substantial handediting transform submissions GenBank As size sequencing projects increases becomes essential improve quality automated assemblies timeconsuming handediting may reduced Current ABI sequencing technology uses base calls made fluorescentlylabeled DNA fragments run gels We present new representation fluorescent trace data associated individual base calls This representation used fragment assembly improve quality assemblies We demonstrate one use endtrimming suboptimal data results significant improvement quality subsequent assemblies',\n",
              " 'Extensive research done extracting parallelism single instruction stream processors This paper presents results investigation ways modify MIMD architectures allow extract instruction level parallelism achieved current superscalar VLIW machines A new architecture proposed utilizes advantages multiple instruction stream design addressing limitations prevented MIMD architectures performing ILP operation A new code scheduling mechanism described support new architecture partitioning instructions across multiple processing elements order exploit level parallelism',\n",
              " 'This paper describes single chip Multiple Instruction Stream Computer MISC capable extracting instruction level parallelism broad spectrum programs The MISC architecture uses multiple asynchronous processing elements separate program streams executed parallel integrates conflictfree message passing system lowest level processor design facilitate low latency intraMISC communication This approach allows increased machine parallelism minimal code expansion provides alternative approach single instruction stream multiissue machines SuperScalar VLIW',\n",
              " 'In paper define examine two versions bridge problem The first variant bridge problem determistic model agent knows superset transitions priori probabilities transitions intact In second variant transitions break fixed probability time step These problems applicable planning uncertain domains well packet routing computer network We show agent act optimally models reduction Markov decision processes We describe methods solving note methods intractable reasonably sized problems Finally suggest neurodynamic programming method value function approximation types models',\n",
              " 'If several mental states reliably distinguished recognizing patterns EEG paralyzed person could communicate device like wheelchair composing sequencesof mental states In article report study comparing four representations EEG signals classification twolayer neural network sigmoid activation functions The neural network implemented CNAPS server processor SIMD architecture Adaptive Solutions Inc gaining fold decrease training time Sun',\n",
              " 'Recurrent perceptron classifiers generalize classical perceptron model They take account correlations dependences among input coordinates arise linear digital filtering This paper provides tight bounds sample complexity associated fitting models experimental data',\n",
              " 'I present general taxonomy neural net architectures processing timevarying patterns This taxonomy subsumes many existing architectures literature points several promising architectures yet examined Any architecture processes timevarying patterns requires two conceptually distinct components shortterm memory holds relevant past events associator uses shortterm memory classify predict My taxonomy based characterization shortterm memory models along dimensions form content adaptability Experiments predicting future values financial time series US dollarSwiss franc exchange rates presented using several alternative memory models The results experiments serve baseline sophisticated architectures compared Neural networks proven promising alternative traditional techniques nonlinear temporal prediction tasks eg Curtiss Brandemuehl Kreider Lapedes Farber Weigend Huberman Rumelhart However temporal prediction particularly challenging problem conventional neural net architectures algorithms well suited patterns vary time The prototypical use neural nets structural pattern recognition In task collection featuresvisual semantic otherwiseis presented network network must categorize input feature pattern belonging one classes For example network might trained classify animal species based set attributes describing living creatures tail lives water carnivorous network could trained recognize visual patterns twodimensional pixel array letter fA B Zg In tasks network presented relevant information simultaneously In contrast temporal pattern recognition involves processing patterns evolve time The appropriate response particular point time depends current input potentially previous inputs This illustrated Figure shows basic framework temporal prediction problem I assume time quantized discrete steps sensible assumption many time series interest intrinsically discrete continuous series sampled fixed interval The input time denoted xt For univariate series input',\n",
              " 'DISLEX artificial neural network model mental lexicon It built test computationally whether lexicon could consist separate feature maps different lexical modalities lexical semantics connected ordered pathways In model orthographic phonological semantic feature maps associations formed unsupervised process based cooccurrence lexical symbol meaning After model organized various damage lexical system simulated resulting dyslexic categoryspecific aphasic impairments similar observed human patients',\n",
              " 'In paper describe new selforganizing decomposition technique learning highdimensional mappings Problem decomposition performed errordriven manner resulting subtasks patches equally well approximated Our method combines unsupervised learning scheme Feature Maps Koh nonlinear approximator Backpropagation RHW The resulting learning system stable effective changing environments plain backpropagation much powerful extended feature maps proposed RS RMS Extensions method give rise active exploration strategies autonomous agents facing unknown environments The appropriateness general purpose method demonstrated ex ample mathematical function approximation',\n",
              " 'Irrelevant features weakly relevant features may reduce comprehensibility accuracy concepts induced supervised learning algorithms We formulate search feature subset abstract search problem probabilistic estimates Searching space using evaluation function random variable requires trading accuracy estimates increased state exploration We show recent feature subset selection algorithms machine learning literature fit search problem simple hill climbing approaches conduct small experiment using bestfirst search technique',\n",
              " 'As field Genetic Programming GP matures breadth application increases need parallel implementations becomes absolutely necessary The transputerbased system recently presented Koza one rare parallel implementations Until today implementation proposed parallel GP using SIMD architecture except dataparallel approach although others exploited workstation farms pipelined supercomputers One reason certainly apparent difficulty dealing parallel evaluation different Sexpressions single instruction executed time every processor The aim paper present implementation parallel GP SIMD system processor efficiently evaluate different Sexpression We implemented approach MasPar MP computer present timing results To extent SIMD machines like MasPar available offer costeffective cycles scien tific experimentation useful approach',\n",
              " 'Reinforcement learning problem generating optimal behavior sequential decisionmaking environment given opportunity interacting Many algorithms solving reinforcementlearning problems work computing improved estimates optimal value function We extend prior analyses reinforcementlearning algorithms present powerful new theorem provide unified analysis valuefunctionbased reinforcementlearning algorithms The usefulness theorem lies allows asynchronous convergence complex reinforcementlearning algorithm proven verifying simpler synchronous algorithm converges We illustrate application theorem analyzing convergence Qlearning modelbased reinforcement learning Qlearning multistate updates Qlearning Markov games risksensitive reinforcement learning',\n",
              " 'Hyperspectral image sensors provide images large number contiguous spectral channels per pixel enable information different materials within pixel obtained The problem spectrally unmixing materials may viewed specific case blind source separation problem data consists mixed signals case minerals goal determine contribution mineral mix without prior knowledge minerals mix The technique Independent Component Analysis ICA assumes spectral components close statistically independent provides unsupervised method blind source separation We introduce contextual ICA context hyperspectral data analysis apply method mineral data synthetically mixed minerals real image signatures',\n",
              " 'Partially observable Markov decision processes POMDPs allow one model complex dynamic decision control problems include action outcome uncertainty imperfect observability The control problem formulated dynamic optimization problem value function combining costs rewards multiple steps In paper propose analyse test various incremental methods computing bounds value function control problems infinite discounted horizon criteria The methods described tested include novel incremental versions gridbased linear interpolation method simple lower bound method Sondiks updates Both work arbitrary points belief space enhanced various heuristic point selection strategies Also introduced new method computing initial upper bound fast informed bound method This method able improve significantly standard commonly used upper bound computed MDPbased method The quality resulting bounds tested maze navigation problem states actions observations',\n",
              " 'The energy prediction competition involved prediction series building energy loads series environmental input variables Nonlinear regression using neural networks popular technique modeling tasks Since obvious large timewindow inputs appropriate preprocessing inputs best viewed regression problem many possible input variables may actually irrelevant prediction output variable Because finite data set show random correlations irrelevant inputs output conventional neural network even regularisation weight decay set coefficients junk inputs zero Thus irrelevant variables hurt models performance The Automatic Relevance Determination ARD model puts prior regression parameters embodies concept relevance This done simple soft way introducing multiple regularisation constants one associated input Using Bayesian methods regularisation constants junk inputs automatically inferred large preventing inputs causing significant overfitting',\n",
              " 'Several different approaches used describe concepts supervised learning tasks In paper describe two approaches prototypebased incremental neural networks casebased reasoning approaches We show improve prototypebased neural network model storing specific instances CBR memory system This leads us propose coprocessing hybrid model classification',\n",
              " 'Extensive research done extracting parallelism single instruction stream processors This paper presents investigation ways modify MIMD architectures allow extract instruction level parallelism achieved current superscalar VLIW machines A new architecture proposed utilizes advantages multiple instruction stream design addressing limitations prevented MIMD architectures performing ILP operation A new code scheduling mechanism described support new architecture partitioning instructions across multiple processing elements order exploit level parallelism',\n",
              " 'A performance prediction method presented indicating performance range MIMD parallel processor systems neural network simulations The total execution time parallel application modeled sum calculation communication times The method scalable based times measured one processor one communication link performance speedup efficiency predicted larger processor system It validated quantitatively applying two popular neural networks backpropagation Kohonen selforganizing feature map decomposed GCel transputer system Agreement model measurements within',\n",
              " 'Algorithms learning classification trees successes artificial intelligence statistics many years This paper outlines tree learning algorithm derived using Bayesian statistics This introduces Bayesian techniques splitting smoothing tree averaging The splitting rule similar Quinlans information gain smoothing averaging replace pruning Comparative experiments reimplementations minimum encoding approach Quinlans C Quinlan et al Breiman et als CART Breiman et al show full Bayesian algorithm produce Publication This paper final draft submitted publication Statistics Computing journal version minor changes appeared Volume pages accurate predictions versions approaches though pay computational price',\n",
              " 'pomdps general models sequential decisions actions observations probabilistic Many problems interest formulated pomdps yet use pomdps limited lack effective algorithms Recently started change number problems robot navigation planning beginning formulated solved pomdps The advantage pomdp approach clean semantics ability produce principled solutions integrate physical information gathering actions In paper pursue approach context two learning tasks learning sort vector numbers learning decision trees data Both problems formulated pomdps solved general pomdp algorithm The main lessons results use suitable heuristics representations allows solution sorting classification pomdps nontrivial sizes quality resulting solutions competitive best algorithms problematic aspects decision tree learning test misclassification costs noisy tests missing values naturally accommodated',\n",
              " 'Given arbitrary learning situation difficult determine appropriate learning strategy The goal research provide general representation processing framework introspective reasoning strategy selection The learning framework introspective system perform reasoning task As system also records trace reasoning along results reasoning If reasoning failure occurs system retrieves applies introspective explanation failure order understand error repair knowledge base A knowledge structure called MetaExplanation Pattern used explain conclusions derived conclusions fail If reasoning represented explicit declarative manner system examine reasoning analyze reasoning failures identify needs learn select appropriate learning strategies order learn required knowledge without overreli ance programmer',\n",
              " 'We describe ongoing project develop adaptive training system ATS dynamically models students learning processes provide specialized tutoring adapted students knowledge state learning style The student modeling component ATS MLModeler uses machine learning ML techniques emulate students novicetoexpert transition MLModeler infers learning methods student used reach current knowledge state comparing students solution trace expert solution generating plausible hypotheses misconceptions errors student made A casebased approach used generate hypotheses incorrectly applying analogy overgeneralization overspecialization The student expert models use networkbased representation includes abstract concepts relationships well strategies problem solving Fuzzy methods used represent uncertainty student model This paper describes design ATS MLModeler gives detailed example system would model tutor student typical session The domain use example highschool level chemistry',\n",
              " 'Many algorithms parameters set user For machine learning algorithms parameter setting nontrivial task influence knowledge model returned algorithm Parameter values usually set approximately according characteristics target problem obtained different ways The usual way use background knowledge target problem perform testing experiments The paper presents approach automated model selection based local optimization uses empirical evaluation constructed concept description guide search The approach tested using inductive concept learning system Magnus',\n",
              " 'This paper presents method learning logic programs without explicit negative examples exploiting assumption output completeness A mode declaration supplied target predicate training input assumed accompanied legal outputs Any outputs generated incomplete program implicitly represent negative examples however large numbers ground negative examples never need generated This method incorporated two ILP systems Chillin IFoil use intensional background knowledge Tests two natural language acquisition tasks caserole mapping pasttense learning illustrate advantages approach',\n",
              " 'Instancebased learning methods explicitly remember data receive They usually training phase prediction time perform computation Then take query search database similar datapoints build online local model local average local regression predict output value In paper review advantages instance based methods autonomous systems also note ensuing cost hopelessly slow computation database grows large We present evaluate new way structuring database new algorithm accessing maintains advantages instancebased learning Earlier attempts combat cost instancebased learning sacrificed explicit retention data applicable instancebased predictions based small number near neighbors reintroduce explicit training phase form interpolative data structure Our approach builds multiresolution data structure summarize database experiences resolutions interest simultaneously This permits us query database exibility conventional linear search greatly reduced computational cost',\n",
              " 'In paper introduce new agglomerative clustering algorithm pattern cluster represented collection fuzzy hyperboxes Initially number hyperboxes calculated represent pattern samples Then algorithm applies multiresolution techniques progressively combine hyperboxes hierarchial manner Such agglomerative scheme found yield encouraging results realworld clustering problems',\n",
              " 'This paper introduces randomized technique partitioning examples using oblique hyperplanes Standard decision tree techniques ID descendants partition set points axisparallel hyperplanes Our method contrast attempts find hyperplanes orientation The purpose general technique find smaller equally accurate decision trees created methods We tested algorithm real simulated data found cases produces surprisingly small trees without losing predictive accuracy Small trees allow us turn obtain simple qualitative descriptions problem domain',\n",
              " 'This paper introduces ICET new algorithm costsensitive classification ICET uses genetic algorithm evolve population biases decision tree induction algorithm The fitness function genetic algorithm average cost classification using decision tree including costs tests features measurements costs classification errors ICET compared three algorithms costsensitive classification EG CSID IDX also C classifies without regard cost The five algorithms evaluated empirically five realworld medical datasets Three sets experiments performed The first set examines baseline performance five algorithms five datasets establishes ICET performs significantly better competitors The second set tests robustness ICET variety conditions shows ICET maintains advantage The third set looks ICETs search bias space discovers way improve search',\n",
              " 'This paper highlights role mathematical programming particularly linear programming training neural networks A neural network description given terms separating planes input space suggests use linear programming determining planes A standard description terms mean square error output space also given leads use unconstrained minimization techniques training neural network The linear programming approach demonstrated brief description system breast cancer diagnosis use last four years major medical facility',\n",
              " 'Dissatisfaction existing standard casebased reasoning CBR systems prompted us investigate make systems creative broadly would mean creative This paper discusses three research goals understanding creative processes better investigating role cases CBR creative problem solving understanding framework supports interesting kind casebased reasoning In addition discusses methodological issues study creativity particular use CBR research paradigm exploring creativity',\n",
              " 'This work presents application machine learning characterizing important property natural DNA sequences compositional inhomogeneity Compositional segments often correspond meaningful biological units Taking account inhomogeneity prerequisite successful recognition functional features DNA sequences especially proteincoding genes Here present technique DNA segmentation using hidden Markov models A DNA sequence represented chain homogeneous segments described one statistically discriminated hidden states whose contents form firstorder Markov chain The technique used describe compare chromosomes I IV completely sequenced Saccharomyces cerevisiae yeast genome Our results indicate existence well separated states gives support isochore theory We also explore models likelihood landscape analyze dynamics optimization process thus addressing problem reliability obtained optima efficiency algorithms',\n",
              " 'Weight modifications traditional neural nets computed hardwired algorithms Without exception previous weight change algorithms many specific limitations Is principle possible overcome limitations hardwired algorithms allowing neural nets run improve weight change algorithms This paper constructively demonstrates answer principle yes I derive initial gradientbased sequence learning algorithm selfreferential recurrent network speak weight matrix terms activations It uses input output units observing errors explicitly analyzing modifying weight matrix including parts weight matrix responsible analyzing modifying weight matrix The result first introspective neural net explicit potential control adaptive parameters A disadvantage algorithm high computational complexity per time step independent sequence length equals On conn logn conn n conn number connections Another disadvantage high number local minima unusually complex error surface The purpose paper however come efficient introspective selfreferential weight change algorithm show algorithms possible',\n",
              " 'This paper discusses problem implement manytomany multiassociative mapping within connectionist models Traditional symbolic approaches work explicit representation alternatives via stored links implicitly enumerative algorithms Classical pattern association models ignore issue generating multiple outputs single input pattern recent research recurrent networks promising field clearly focused upon multiassociativity goal In paper define multiassociative memory MM several possible variants discuss utility general cognitive modeling We extend sequential cascaded networks Pollack fit task perform several initial experiments demonstrate feasibility concept',\n",
              " 'Human visual systems maintain stable internal representation scene even though image retina constantly changing eye movements Such stabilization theoretically effected dynamic shifts receptive field RF neurons visual system This paper examines neural circuit learn generate shifts The shifts controlled eye position signals compensate movement retinal image caused eye movements The development neural shifter circuit Olshausen Anderson Van Essen modeled using triadic connections These connections gated signals indicate direction gaze eye position signals In simulations neural model exposed sequences stimuli paired appropriate eye position signals The initially',\n",
              " 'This paper tries identify rules factors predictive outcome international conflict management attempts We use C advanced Machine Learning algorithm generating decision trees prediction rules cases CONFMAN database The results show simple patterns rules often understandable also reliable complex rules Simple decision trees able improve chances correctly predicting outcome conflict management attempt This suggests mediation repetitive conflicts per se results achieved far',\n",
              " 'c fl UWCC COMMA Technical Report No February x No part article may reproduced commercial purposes Abstract A technique described allows unimodal function optimization methods extended efficiently locate optima multimodal problems We describe algorithm based traditional genetic algorithm GA This involves iterating GA uses knowledge gained one iteration avoid researching subsequent iterations regions problem space solutions already found This achieved applying fitness derating function raw fitness function fitness values depressed regions problem space solutions already found Consequently likelihood discovering new solution iteration dramatically increased The technique may used various styles GA optimization methods simulated annealing The effectiveness algorithm demonstrated number multimodal test functions The technique least fast fitness sharing methods It provides speedup p problem p optima depending value p convergence time complexity',\n",
              " 'In paper examine intuition TD meant operate approximating asynchronous value iteration We note important class discrete acyclic stochastic tasks value iteration inefficient compared DAGSP algorithm essentially performs one sweep instead many working backwards goal The question address paper whether analogous algorithm used large stochastic state spaces requiring function approximation We present algorithm analyze give comparative results TD several domains state Using VI solve MDPs belonging either special classes quite inefficient since VI performs backups entire space whereas backups useful improving V fl frontier alreadycorrect notyetcorrect V fl values In fact classical algorithms problem classes compute V fl efficiently explicitly working backwards deterministic class Dijkstras shortestpath algorithm acyclic class DirectedAcyclicGraphShortestPaths DAGSP DAGSP first topologically sorts MDP producing linear ordering states every state x precedes states reachable x Then runs list reverse performing one backup per state Worstcase bounds VI Dijkstra DAGSP deterministic domains X states A actionsstate Although presents DAGSP deterministic acyclic problems applies straightforwardly',\n",
              " 'Automatic design optimization highly sensitive problem formulation The choice objective function constraints design parameters dramatically impact computational cost optimization quality resulting design The best formulation varies one application another A design engineer usually know best formulation advance In order address problem developed system supports interactive formulation testing reformulation design optimization strategies Our system includes executable dataflow language representing optimization strategies The language allows engineer define multiple stages optimization using different approximations objective constraints different abstractions design space We also developed set transformations reformulate strategies represented language The transformations approximate objective constraint functions abstractor reparameterize search spaces divide optimization process multiple stages The system applicable principle design problem expressed terms constrained optimization however expect system useful design artifact governed algebraic ordinary differential equations We tested system problems racing yacht design jet engine nozzle design We report experimental results demonstrating reformulation techniques significantly improve performance automatic design optimization Our research demonstrates viability reformulation methodology combines symbolic program transformation numerical experimentation It important first step research program aimed automating entire strategy formulation process fl Fully accepted Research Engineering Design',\n",
              " 'The classification performance neural network combined sixband LandsatTM oneband ERSSAR PRI imagery scene carried Different combinations data either raw segmented filtered using available ground truth polygons training test sets created The training sets used learning test sets used verification neural network The different combinations evaluated',\n",
              " 'The problem modeling complicated data sequences DNA speech often arises practice Most algorithms select hypothesis within model class assuming observed sequence direct output underlying generation process In paper consider case output passes memoryless noisy channel observation In particular show class Markov chains variable memory length learning affected factors despite superpolynomial still small practical cases Markov models variable memory length probabilistic finite suffix automata introduced learning theory Ron Singer Tishby also described polynomial time learning algorithm We present modification algorithm uses noisecorrupted sample knowledge noise structure The algorithm still viable noise known exactly good estimation available Finally experimental results presented removing noise corrupted English text measure performance learning algorithm affected size noisy sample noise rate',\n",
              " 'We present evaluate implemented system rapidly easily build intelligent software agents Webbased tasks Our design centered around two basic functions ScoreThisLink ScoreThisPage If given highly accurate functions standard heuristic search would lead efficient retrieval useful information Our approach allows users tailor systems behavior providing approximate advice functions This advice mapped neural network implementations two functions Subsequent reinforcements Web eg dead links ratings retrieved pages user wishes provide respectively used refine link pagescoring functions Hence architecture provides appealing middle ground nonadaptive agent programming languages systems solely learn user preferences users ratings pages We describe internal representation Web pages major predicates advice language advice mapped neural networks mechanisms refining advice based subsequent feedback We also present case study provide simple advice specialize generalpurpose system homepage finder An empirical study demonstrates approach leads effective homepage finder leading commercial Web search site',\n",
              " 'In concept learning objects domain grouped together based similarity determined attributes used describe Existing concept learners require set attributes known advance presented entirety learning begins Additionally systems possess mechanisms altering attribute set concepts learned Consequently veridical attribute set relevant task concepts used must supplied onset learning turn usefulness concepts limited task attributes originally selected In order efficiently accommodate changing contexts concept learner must able alter set descriptors without discarding prior knowledge domain We introduce notion attributeincrementation dynamic modification attribute set used describe instances problem domain We implemented capability concept learning system evaluated along several dimensions using existing concept formation system com parison',\n",
              " 'It shown Bayesian inference data modeled mixture distribution feasibly performed via Monte Carlo simulation This method exhibits true Bayesian predictive distribution implicitly integrating entire underlying parameter space An infinite number mixture components accommodated without difficulty using prior distribution mixing proportions selects reasonable subset components explain finite training set The need decide correct number components thereby avoided The feasibility method shown empirically simple classification task',\n",
              " 'This article presents new reinforcement learning method called SANE Symbiotic Adaptive NeuroEvolution evolves population neurons genetic algorithms form neural network capable performing task Symbiotic evolution promotes cooperation specialization results fast efficient genetic search discourages convergence suboptimal solutions In inverted pendulum problem SANE formed effective networks times faster Adaptive Heuristic Critic times faster Qlearning GENITOR neuroevolution approach without loss generalization Such efficient learning combined domain assumptions make SANE promising approach broad range reinforcement learning problems including many realworld applications',\n",
              " 'The paper concerns probabilistic evaluation plans presence unmeasured variables plan consisting several concurrent sequential actions We establish graphical criterion recognizing effects given plan predicted passive observations measured variables When criterion satisfied closedform expression provided probability plan achieve specified goal',\n",
              " 'We introduce technique enhance ability dynamic ILP processors exploit speculatively executed parallelism Existing branch prediction mechanisms used establish dynamic window ILP extracted limited abilities create large accurate dynamic window ii initiate large number instructions window every cycle iii traverse multiple branches control flow graph per prediction We introduce control flow prediction uses information control flow graph program overcome limitations We discuss information present control flow graph represented using multiblocks conveyed hardware using Control Flow Tables Control Flow Prediction Buffers We evaluate potential control flow prediction abstract machine dynamic ILP processing model Our results indicate control flow prediction powerful effective assist hardware making informed run time decisions program control flow',\n",
              " 'We develop mean field theory sigmoid belief networks based ideas statistical mechanics Our mean field theory provides tractable approximation true probability distribution networks also yields lower bound likelihood evidence We demonstrate utility framework benchmark problem statistical pattern recognitionthe classification handwritten digits',\n",
              " 'Many learning experience systems use information extracted problem solving experiences modify performance element PE forming new element PE solve similar problems efficiently However transformations improve performance one set problems degrade performance sets new PE always better original PE depends distribution problems We therefore seek performance element whose expected performance distribution optimal Unfortunately actual distribution needed determine element optimal usually known Moreover task finding optimal element even knowing distribution intractable interesting spaces elements This paper presents method palo sidesteps problems using set samples estimate unknown distribution using set transformations hillclimb local optimum This process based mathematically rigorous form utility analysis particular uses statistical techniques determine whether result proposed transformation better original system We also present efficient way implementing learning system context general class performance elements include empirical evidence approach work effectively fl Much work performed University Toronto supported Institute Robotics Intelligent Systems operating grant National Science Engineering Research Council Canada We also gratefully acknowledge receiving many helpful comments William Cohen Dave Mitchell Dale Schuurmans anonymous referees',\n",
              " 'Compositional QLearning CQL Singh modular approach learning perform composite tasks made several elemental tasks reinforcement learning Skills acquired performing elemental tasks also applied solve composite tasks Individual skills compete right act winning skills included decomposition composite task We extend original CQL concept two ways general reward function agent one actuator We use CQL architecture acquire skills performing composite tasks simulated twolinked manipulator large state action spaces The manipulator nonlinear dynamical system require endeffector specific positions workspace Fast function approximation Qmodules achieved use array Cerebellar Model Articulation Controller CMAC Albus Our research interests involve scaling machine learning methods especially reinforcement learning autonomous robot control We interested function approximators suitable reinforcement learning problems large state spaces Cerebellar Model Articulation Controller CMAC Albus permit fast online learning good local generalization In addition interested task decomposition reinforcement learning use hierarchical modular function approximator architectures We examining effectiveness modified Hierarchical Mixtures Experts HME Jordan Jacobs approach reinforcement learning since original HME developed mainly supervised learning batch learning tasks The incorporation domain knowledge reinforcement learning agents important way extending capabilities Default policies specified domain knowledge also used restrict size stateaction space leading faster learning We investigating use QLearning Watkins planning tasks using classifier system Holland encode necessary conditionaction rules Jordan M Jacobs R Hierarchical mixtures experts EM algorithm Technical Report MIT Computational Cognitive Science',\n",
              " 'The processing performed feedforward neural network often interpreted use decision hyperplanes layer The adaptation process however normally explained using picture gradient descent error landscape In paper dynamics decision hyperplanes used model adaptation process A electromechanical analogy drawn dynamics hyperplanes determined interaction forces hyperplanes particles represent patterns Relaxation system determined increasing hyperplane inertia mass This picture used clarify dynamics learning go way explaining learning deadlocks escaping certain local minima Furthermore network plasticity introduced dynamic property system reduction necessary consequence information storage Hyperplane inertia used explain avoid destructive relearning trained networks',\n",
              " 'Modifications Recursive AutoAssociative Memory presented allow store deeper complex data structures previously reported These modifications include adding extra layers compressor reconstructor networks employing integer rather realvalued representations preconditioning weights presetting representations compatible The resulting system tested data set syntactic trees extracted Penn Treebank',\n",
              " 'The problem combining preferences arises several applications combining results different search engines This work describes efficient algorithm combining multiple preferences We first give formal framework problem We describe analyze new boosting algorithm combining preferences called RankBoost We also describe efficient implementation algorithm restricted case We discuss two experiments carried assess performance RankBoost In first experiment used algorithm combine different search strategies query expension given domain For task compare performance RankBoost individual search strategies The second experiment collaborativefiltering task specifically making movie recommendations Here present results comparing RankBoost nearest neighbor regression algorithms',\n",
              " 'This paper shows decision trees used improve performance casebased learning CBL systems We introduce performance task machine learning systems called semiflexible prediction lies classification task performed decision tree algorithms flexible prediction task performed conceptual clustering systems In semiflexible prediction learning improve prediction specific set features known priori rather single known feature classification arbitrary set features conceptual clustering We describe one task natural language processing present experiments compare solutions problem using decision trees CBL hybrid approach combines two In hybrid approach decision trees used specify features included knearest neighbor case retrieval Results experiments show hybrid approach outperforms decision tree casebased approaches well two casebased systems incorporate expert knowledge case retrieval algorithms Results clearly indicate decision trees used improve performance CBL systems without reliance potentially expensive expert knowledge',\n",
              " 'Technical Report No Department Statistics University Toronto We describe linear network models correlations realvalued visible variables using one realvalued hidden variables factor analysis model This model seen linear version Helmholtz machine parameters learned using wakesleep method learning primary generative model assisted recognition model whose role fill values hidden variables based values visible variables The generative recognition models jointly learned wake sleep phases using delta rule This learning procedure comparable simplicity Ojas version Hebbian learning produces somewhat different representation correlations terms principal components We argue simplicity wakesleep learning makes factor analysis plau sible alternative Hebbian learning model activitydependent cortical plasticity',\n",
              " 'A Bayesian method estimating amino acid distributions states hidden Markov model HMM protein family columns multiple alignment family introduced This method uses Dirichlet mixture densities priors amino acid distributions These mixture densities determined examination previously constructed HMMs multiple alignments It shown Bayesian method improve quality HMMs produced small training sets Specific experiments EFhand motif reported priors shown produce HMMs higher likelihood unseen data fewer false positives false negatives database search task',\n",
              " 'This paper proposes simple cost model machine learning applications based notion net present value The model extends unifies models used Pazzani et al Masand PiatetskyShapiro It attempts answer question Should given machine learning system prototype stage fielded The models inputs systems confusion matrix cash flow matrix application cost per decision onetime cost deploying system rate return investment Like Provost Fawcetts ROC convex hull method present model used decisionmaking even input variables known exactly Despite simplicity number nontrivial consequences For example free lunch theorems learning theory longer apply',\n",
              " 'This paper demonstrates use graphs mathematical tool expressing independenices formal language communicating processing causal information statistical analysis We show complex information external interventions organized represented graphically conversely graphical representation used facilitate quantitative predictions effects interventions We first review Markovian account causation show directed acyclic graphs DAGs offer economical scheme representing conditional independence assumptions deducing displaying logical consequences assumptions We introduce manipulative account causation show DAG defines simple transformation tells us probability distribution change result external interventions system Using transformation possible quantify nonexperimental data effects external interventions specify conditions randomized experiments necessary Finally paper offers graphical interpretation Rubins model causal effects demonstrates equivalence manipulative account causation We exemplify tradeoffs two approaches deriving nonparametric bounds treatment effects conditions imperfect compliance',\n",
              " 'In casebased design adaptation design case new design requirements plays important role If sufficient adapt predefined set design parameters task easily automated If however farreaching creative changes required current systems provide limited success This paper describes approach creative design adaptation based notion creativity goal oriented shift focus search process An evolving representation used restructure search space designs similar example case lie focus search This focus used starting point create new designs',\n",
              " 'We consider novel nonlinear model time series analysis The study model emphasizes theoretical aspects well practical applicability The architecture model demonstrated sufficiently rich sense approximating unknown functional forms yet retains simple intuitive characteristics linear models A comparison established nonlinear models emphasized theoretical issues backed prediction results benchmark time series well computer generated data sets Efficient estimation algorithms seen applicable made possible mixture based structure model Large sample properties estimators discussed well well specified well misspecified settings We also demonstrate inference pertaining data structure may made parameterization model resulting better intuitive understanding structure performance model',\n",
              " 'The coverage learning algorithm number concepts learned algorithm samples given size This paper asks whether good learning algorithms designed maximizing coverage The paper extends previous upper bound coverage Boolean concept learning algorithm describes two algorithmsMultiBalls LargeBallwhose coverage approaches upper bound Experimental measurement coverage ID FRINGE algorithms shows coverage far bound Further analysis LargeBall shows although learns many concepts seem interesting concepts Hence coverage maximization alone appear yield practicallyuseful learning algorithms The paper concludes definition coverage within bias suggests way coverage maximization could applied strengthen weak preference biases',\n",
              " 'At previous FOGA workshop presented initial results using Markov models analyze transient behavior genetic algorithms GAs used function optimizers GAFOs In paper states Markov model ordered via simple mathematically convenient lexicographic ordering used initially Nix Vose In paper explore alternative orderings states based interesting semantic properties average fitness degree homogeneity average attractive force etc We also explore lumping techniques reducing size state space Analysis reordered lumped Markov models provides new insights transient behavior GAs general GAFOs particular',\n",
              " 'An important aspect creative design concept emergence Though emergence important mechanism either well understood limited domain shapes This deficiency compensated considering definitions emergent behaviour Artificial Life ALife research community With new insights proposed computational technique called evolving representations design genes extended emergent behaviour We demonstrate emergent behaviour coevolutionary model design This coevolutionary approach design allows solution space structure space evolve response problem space behaviour space Since behaviour space active participant behaviour may emerge new structures end design process This paper hypothesizes emergent behaviour identified using technique The floor plan example Gero Schnier extended demonstrate behaviour emerge coevolutionary design process',\n",
              " 'We investigate learnability PAC model data used learning attributes labels either corrupted incomplete In order prove main results define new complexity measure statistical query SQ learning algorithms The view SQ algorithm maximum queries algorithm number input bits query depends We show restricted view SQ algorithm class general sufficient condition learnability models attribute noise covered missing attributes We show since algorithms question statistical also simultaneously tolerate classification noise Classes results hold therefore learned simultaneous attribute noise classification noise include kDNF ktermDNF DNF representations conjunctions relevant variables uniform distribution decision lists These noise models first PAC models training data attributes labels may corrupted random process Previous researchers shown class kDNF learnable attribute noise attribute noise rate known exactly We show attribute noise learnability results either without classification noise also hold exact noise rate known provided learner instead polynomially good approximation noise rate In addition show results also hold one noise rate distinct noise rate attribute Our results learning random covering require learner told even approximation covering rate addition hold setting distinct covering rates attribute Finally give lower bounds number examples required learning presence attribute noise covering',\n",
              " 'This study describes new Hidden Markov Model HMM system segmenting uncharacterized genomic DNA sequences exons introns intergenic regions Separate HMM modules designed trained specific regions DNA exons introns intergenic regions splice sites The models tied together form biologically feasible topology The integrated HMM trained set eukaryotic DNA sequences tested using segment separate set sequences The resulting HMM system called VEIL Viterbi ExonIntron Locator obtains overall accuracy test data total bases correctly labelled correlation coefficient Using stringent test exact exon prediction VEIL correctly located ends coding exons exons predicts exactly correct These results compare favorably best previous results gene structure prediction demonstrate benefits using HMMs problem',\n",
              " 'Recently increased interest lifelong machine learning methods transfer knowledge across multiple learning tasks Such methods repeatedly found outperform conventional singletask learning algorithms learning tasks appropriately related To increase robustness approaches methods desirable reason relatedness individual learning tasks order avoid danger arising tasks unrelated thus potentially misleading This paper describes taskclustering TC algorithm TC clusters learning tasks classes mutually related tasks When facing new learning task TC first determines related task cluster exploits information selectively task cluster An empirical study carried mobile robot domain shows TC outperforms nonselective counterpart situations small number tasks relevant',\n",
              " 'Belief revision belief update proposed two types belief change serving different purposes Belief revision intended capture changes agents belief state reflecting new information static world Belief update intended capture changes belief response changing world We argue belief revision belief update restrictive routine belief change involves elements We present model generalized update allows updates response external changes inform agent prior beliefs This model update combines aspects revision update providing realistic characterization belief change We show certain assumptions original update postulates satisfied We also demonstrate plain revision plain update special cases model way formally verifies intuition revision suitable static belief change',\n",
              " 'We propose Bayesian framework regression problems covers areas usually dealt function approximation An online learning algorithm derived solves regression problems Kalman filter Its solution always improves increasing model complexity without risk overfitting In infinite dimension limit approaches true Bayesian posterior The issues prior selection overfitting also discussed showing commonly held beliefs misleading The practical implementation summarised Simulations using popular publicly available data sets used demonstrate method highlight important issues concerning choice priors',\n",
              " 'This report deals efficient mapping sparse neural networks CNS We develop parallel vector code idealized sparse network determine performance three memory systems We use code evaluate memory systems one implemented prototype pinpoint bottlenecks current CNS design',\n",
              " 'In nature genotype many organisms exhibits diploidy ie includes two copies every gene In paper describe results simulations comparing behavior haploid diploid populations ecological neural networks living fixed changing environments We show diploid genotypes create variability fitness population haploid genotypes buffer better environmental change consequence one wants obtain good results average peak fitness single population one choose diploid population appropriate mutation rate Some results simulations parallel biological findings',\n",
              " 'The problem belief changehow agent revise beliefs upon learning new informationhas active area research philosophy artificial intelligence Many approaches belief change proposed literature Our goal introduce yet another approach examine carefully rationale underlying approaches already taken literature highlight view methodological problems literature The main message study belief change carefully must quite explicit ontology scenario underlying belief change process This something missing previous work focus postulates Our analysis shows must pay particular attention two issues often taken granted The first model agents epistemic state Do use set beliefs richer structure ordering worlds And use set beliefs language beliefs expressed The second status observations Are observations known true believed In latter case firm belief For example argue even postulates called beyond controversy unreasonable agents beliefs include beliefs epistemic state well external world Issues status observations arise particularly consider iterated belief revision must confront possibility revising',\n",
              " 'The study belief change active area philosophy AI In recent years two special cases belief change belief revision belief update studied detail Roughly speaking revision treats surprising observation sign previous beliefs wrong update treats surprising observation indication world changed In general would expect agent making observation may want revise earlier beliefs assume change occurred world We define novel approach belief change allows us applying ideas probability theory qualitative settings The key idea use qualitative Markov assumption says state transitions independent We show recent approach modeling qualitative uncertainty using plausibility measures allows us make qualitative Markov assumption relatively straightforward way show Markov assumption used provide attractive beliefchange model',\n",
              " 'In reinforcement learning frequently necessary resort approximation true optimal value function Here investigate benefits online search cases We examine local searches agent performs finitedepth lookahead search global searches agent performs search trajectory way current state goal state The key success methods lies taking value function gives rough solution hard problem finding good trajectories every single state combining online search gives accurate solution easier problem finding good trajectory specifically current state',\n",
              " 'Probabilistic contextfree grammars PCFGs provide simple way represent particular class distributions sentences contextfree language Efficient parsing algorithms answering particular queries PCFG ie calculating probability given sentence finding likely parse applied variety patternrecognition problems We extend class queries answered several ways allowing missing tokens sentence sentence fragment supporting queries intermediate structure presence particular nonterminals flexible conditioning variety types evidence Our method works constructing Bayesian network represent distribution parse trees induced given PCFG The network structure mirrors chart standard parser generated using similar dynamicprogramming approach We present algorithm constructing Bayesian networks PCFGs show queries patterns queries network correspond interesting queries PCFGs',\n",
              " 'This paper presents recent developments toward formalism combines useful properties logic probabilities Like logic formalism admits qualitative sentences provides symbolic machinery deriving deductively closed beliefs like probability permits us express ifthen rules different levels firmness retract beliefs response changing observations Rules interpreted orderofmagnitude approximations conditional probabilities impose constraints rankings worlds Inferences supported unique priority ordering rules syntactically derived knowledge base This ordering accounts rule interactions respects specificity considerations facilitates construction coherent states beliefs Practical algorithms developed analyzed testing consistency computing rule ordering answering queries Imprecise observations incorporated using qualitative versions Jeffreys Rule Bayesian updating result coherent belief revision embodied naturally tractably Finally causal rules interpreted imposing Markovian conditions constrain world rankings reflect modularity causal organizations These constraints shown facilitate reasoning causal projections explanations actions change',\n",
              " 'Clay evolutionary architecture autonomous robots integrates motor schemabased control reinforcement learning Robots utilizing Clay benefit realtime performance motor schemas continuous dynamic environments taking advantage adaptive reinforcement learning Clay coordinates assemblages groups motor schemas using embedded reinforcement learning modules The coordination modules activate specific assemblages based presently perceived situation Learning occurs robot selects assemblages samples reinforcement signal time Experiments robot soccer simulation illustrate performance utility system',\n",
              " 'Most known learning algorithms dynamic neural networks nonstationary environments need global computations perform credit assignment These algorithms either local time local space Those algorithms local time space usually deal sensibly hidden units In contrast far judge learning rules biological systems many hidden units local space time In paper propose parallel online learning algorithm performs local computations yet still designed deal hidden units units whose past activations hidden time The approach inspired Hollands idea bucket brigade classifier systems transformed run neural network fixed topology The result feedforward recurrent neural dissipative system consuming weightsubstance permanently trying distribute substance onto connections appropriate way Simple experiments demonstrating feasability algorithm reported',\n",
              " 'Although creativity largely studied problem solving contexts creativity consists generative component comprehension component In particular creativity essential part reading understanding natural language stories We formalized understanding process developed algorithm capable producing creative understanding behavior We also created novel knowledge organization scheme assist process Our model creativity implemented portion ISAAC Integrated Story Analysis And Creativity reading system system models creative reading science fiction stories',\n",
              " 'Creative designers often see solutions pending design problems everyday objects surrounding This often lead innovation insight sometimes revealing new functions purposes common design pieces process We interested modeling serendipitous recognition solutions pending problems context creative mechanical design This paper characterizes ability analyzing observations made placing context forms recognition We propose computational model capture explore serendipitous recognition based ideas reconstructive dynamic memory situation assessment casebased reasoning',\n",
              " 'In paper analyze two wellknown measures attribute selection decision tree induction informativity gini index In particular interested influence different methods estimating probabilities two measures The results experiments show different measures obtained different probability estimation methods determine preferential order attributes given node Therefore determine structure constructed decision tree This feature beneficial especially realworld applications several different trees often required',\n",
              " 'We consider learning situations function used classify examples may switch back forth small number different concepts course learning We examine several models situations oblivious models switches made independent selection examples adversarial models single adversary controls concept switches example selection We show relationships benign models pconcepts Kearns Schapire present polynomialtime algorithms learning switches two kDNF formulas For adversarial model present model success patterned popular competitive analysis used studying online algorithms We describe randomized query algorithm adversarial switches two monotone disjunctions competitive total number mistakes plus queries high probability bounded number switches plus fixed polynomial n number variables We also use notions described provide sufficient conditions learning pconcept class decision rule implies able learn class model probability',\n",
              " 'Case based systems typically retrieve cases case base applying similarity measures The measures usually constructed ad hoc manner This report presents toolbox systematic construction similarity measures In addition paving way design methodology similarity measures systematic approach facilitates identification opportunities parallelisation case base retrieval',\n",
              " 'In real world applications software engineers recognise use memory must organised via data structures software using data must independant data structures implementation details They achieve using abstract data structures records files buffers We demonstrate genetic programming automatically implement simple abstract data structures considering detail task evolving list We show general reasonably efficient implementations automatically generated simple primitives A model maintaining evolved code demonstrated using list problem Much published work genetic programming GP evolves functions without sideeffects learn patterns test data In contrast human written programs often make extensive explicit use memory Indeed memory form required programming system Turing Complete ie possible write computable program system However inclusion memory make interactions parts programs much complex make harder produce programs Despite shown GP automatically create programs explicitly use memory Teller In normal genetic programming considerable benefits found adopting structured approach For example Koza shows introduction evolvable code modules automatically defined functions ADFs greatly help GP reach solution We suggest corresponding structured approach use data similarly significant advantage GP Earlier work demonstrated genetic programming automatically generate simple abstract data structures namely stacks queues Langdon That GP evolve programs organise memory accessed via simple read write primitives data structures used external software without needing know implemented This chapter shows possible evolve list data structure basic primitives Aho Hopcroft Ullman suggest three different ways implement list experiments show GP evolve implementation This requires list components agree one implementation coevolve together Section describes GP architecture including use Pareto multiple component fitness scoring measures aimed speeding GP search The evolved solutions described Section Section presents candidate model maintaining evolved software This followed discussion learned conclusions drawn',\n",
              " 'Report SYCON ABSTRACT We pursue particular approach analog computation based dynamical systems type used neural networks research Our systems fixed structure invariant time corresponding unchanging number neurons If allowed exponential time computation turn unbounded power However polynomialtime constraints limits capabilities though powerful Turing Machines A similar restricted model shown polynomialtime equivalent classical digital computation previous work Moreover precise correspondence nets standard nonuniform circuits equivalent resources consequence one lower bound constraints compute This relationship perhaps surprising since analog devices change manner input size We note networks likely solve polynomially NPhard problems equality p np model implies almost complete collapse standard polynomial hierarchy',\n",
              " 'We introduce convergence diagnostic procedure MCMC operates estimating total variation distances distribution algorithm certain numbers iterations The method advantages many existing methods terms applicability utility computational expense interpretability It used assess convergence marginal joint posterior densities show applied two commonly used MCMC samplers Gibbs Sampler Metropolis Hastings algorithm Illustrative examples highlight utility interpretability proposed diagnostic also highlight limitations',\n",
              " 'Because distance skull brain different resistivities electroencephalographic EEG data collected point human scalp includes activity generated within large brain area This spatial smearing EEG data volume conduction involve significant time delays however suggesting Independent Component Analysis ICA algorithm Bell Sejnowski suitable performing blind source separation EEG data The ICA algorithm separates problem source identification source localization First results applying ICA algorithm EEG eventrelated potential ERP data collected sustained auditory detection task show ICA training insensitive different random seeds ICA may used segregate obvious artifactual EEG components line muscle noise eye movements sources ICA capable isolating overlapping EEG phenomena including alpha theta bursts spatiallyseparable ERP components separate ICA channels Nonstationarities EEG behavioral state tracked using ICA via changes amount residual correlation ICAfiltered output channels',\n",
              " 'Miller G The magical number seven plus minus two Some limits capacity processing information The Psychological Review Schmidhuber J b Towards compositional learning dynamic neural networks Technical Report FKI Technische Universitat Munchen Institut fu Informatik ServanSchreiber D Cleermans A McClelland J Encoding sequential structure simple recurrent networks Technical Report CMUCS Carnegie Mellon University Computer Science Department',\n",
              " 'The standard approach decision tree induction topdown greedy algorithm makes locally optimal irrevocable decisions node tree In paper study alternative approach algorithms use limited lookahead decide test use node We systematically compare using large number decision trees quality decision trees induced greedy approach trees induced using lookahead The main results experiments greedy approach produces trees accurate trees produced much expensive lookahead step ii decision tree induction exhibits pathology sense lookahead produce trees larger less accurate trees produced without',\n",
              " 'This thesis presents machine learning model capable extracting discrete classes continuous valued input features This done using neurally inspired novel competitive classifier CC feeds discrete classifications forward supervised machine learning model The supervised learning model uses discrete classifications perhaps information available solve problem The supervised learner generates feedback guide CC potentially useful classifications continuous valued input features Two supervised learning models combined CC creating ASOCSAFE IDAFE Both models simulated results analyzed Based results several areas future research proposed',\n",
              " 'We frequently called upon perform multiple tasks compete attention resource Often know optimal solution task isolation paper describe knowledge exploited efficiently find good solutions tasks parallel We formulate problem dynamically merging multiple Markov decision processes MDPs composite MDP present new theoreticallysound dynamic programming algorithm finding optimal policy composite MDP We analyze various aspects algorithm Every day faced problem multiple tasks parallel competes attention resource If running job shop must decide machines allocate jobs order jobs miss deadlines If mail delivery robot must find intended recipients mail simultaneously avoiding fixed obstacles walls mobile obstacles people still manage keep sufficiently charged Frequently know perform task isolation paper considers take information individual tasks combine efficiently find optimal solution entire set tasks parallel More importantly describe theoreticallysound algorithm merging dynamically new tasks new job arrival job shop assimilated online solution found ongoing set simultaneous tasks illustrate use simple merging problem',\n",
              " 'We consider problem fitting n fi n distance matrix D tree metric T Let distance closest tree metric min T fk T D k g First present On algorithm finding additive tree T k T D k giving first algorithm problem performance guarantee Second show N Phard find tree T k T D k lt',\n",
              " 'CaseBased Planning CBP provides way scaling domainindependent planning solve large problems complex domains It replaces detailed lengthy search solution retrieval adaptation previous planning experiences In general CBP demonstrated improve performance generative fromscratch planning However performance improvements provides dependent adequate judgements problem similarity In particular although CBP may substantially reduce planning effort overall subject misretrieval problem The success CBP depends retrieval errors relatively rare This paper describes design implementation replay framework casebased planner dersnlpebl dersnlpebl extends current CBP methodology incorporating explanationbased learning techniques allow explain learn retrieval failures encounters These techniques used refine judgements case similarity response feedback wrong decision made The failure analysis used building case library addition repairing cases Large problems split stored single goal subproblems Multigoal problems stored smaller cases fail merged full solution An empirical evaluation approach demonstrates advantage learning experienced retrieval failure',\n",
              " 'Modern processors improve instruction level parallelism speculation The outcome data control decisions predicted operations speculatively executed committed original predictions correct There number ways processor resources could used threading eager execution As use speculation increases believe processors need form speculation control balance benefits speculation possible activities Confidence estimation one technique exploited architects speculation control In paper introduce performance metrics compare confidence estimation mechanisms argue metrics appropriate speculation control We compare number confidence estimation mechanisms focusing mechanisms small implementation cost gain benefit exploiting characteristics branch predictors clustering mispredicted branches We compare performance different confidence estimation methods using detailed pipeline simulations Using simulations show improve confidence estimators providing better insight future investigations comparing applying confidence estimators',\n",
              " 'Relational learning algorithms special interest members machine learning community offer practical methods extending representations used algorithms solve supervised learning tasks Five approaches currently explored address issues involved using relational representations This paper surveys algorithms embodying approaches summarizes empirical evaluations highlights commonalities suggests potential directions future research',\n",
              " 'The learning process Boltzmann Machines computationally expensive The computational complexity exact algorithm exponential number neurons We present new approximate learning algorithm Boltzmann Machines based mean field theory linear response theorem The computational complexity algorithm cubic number neurons In absence hidden units show weights directly computed fixed point equation learning rules Thus case need use gradient descent procedure learning process We show solutions method close optimal solutions give significant improvement correlations play significant role Finally apply method pattern completion task show good performance networks neurons',\n",
              " 'This paper introduces methodology solving combinatorial optimization problems application reinforcement learning methods The approach applied cases several similar instances combinatorial optimization problem must solved The key idea analyze set training problem instances learn search control policy solving new problem instances The search control policy twin goals finding highquality solutions finding quickly Results applying methodology NASA scheduling problem show learned search control policy much effective best known nonlearning search procedurea method based simulated annealing',\n",
              " 'Markov decision processes MDPs undiscounted rewards represent important class problems decision control The goal learning MDPs find policy yields maximum expected return per unit time In large state spaces computing averages directly feasible instead agent must estimate stochastic exploration state space In case longer exploration times enable accurate estimates informed decisionmaking The learning curve MDP measures agents performance depends allowed exploration time T In paper analyze learning curves simple control problem undiscounted rewards In particular methods statistical mechanics used calculate lower bounds agents performance thermodynamic limit T N ff T N finite T number time steps allotted per policy evaluation N size state space In limit provide lower bound return policies appear optimal based imperfect statistics',\n",
              " 'One effectively utilize predicated execution improve branch handling instructionlevel parallel processors Although potential benefits predicated execution high tradeoffs involved design instruction set support predicated execution difficult On one end design spectrum architectural support full predicated execution requires increasing number source operands instructions Full predicate support provides flexibility largest potential performance improvements On end partial predicated execution support conditional moves requires little change existing architectures This paper presents preliminary study qualitatively quantitatively address benefit full partial predicated execution support With current compiler technology show compiler use partial full predication achieve speedup large controlintensive programs Some details code generation techniques shown provide insight benefit going partial full predication Preliminary experimental results encouraging partial predication provides average performance improvement issue processor predicate support full predication provides additional improvement',\n",
              " 'This paper studies selfdirected learning variant online learning model learner selects presentation order instances We give tight bounds complexity selfdirected learning concept classes monomials kterm DNF formulas orthogonal rectangles f ng These results demonstrate number mistakes selfdirected learning surprisingly small We prove model selfdirected learning powerful commonly used online query learning models Next explore relationship complexity selfdirected learning VapnikChervonenkis dimension Finally explore relationship Mitchells version space algorithm existence selfdirected learning algorithms make mistakes fl Supported part GE Foundation Junior Faculty Grant NSF Grant CCR Part research conducted author MIT Laboratory Computer Science supported NSF grant DCR grant Siemens Corporation Net address sgcswustledu',\n",
              " 'A lowerbound result power Abstract This paper presents lowerbound result computational power genetic algorithm context combinatorial optimization We describe new genetic algorithm merged genetic algorithm prove class monotonic functions algorithm finds optimal solution exponential convergence rate The analysis pertains ideal behavior algorithm main task reduces showing convergence probability distributions search space combinatorial structures optimal one We take exponential convergence indicative efficient solvability samplebounded algorithm although sampling theory needed better relate limit behavior actual behavior The paper concludes discussion immediate problems lie ahead genetic algorithm',\n",
              " 'In paper study forecasting model based mixture experts predicting French electric daily consumption energy We split task two parts Using mixture experts first model predicts electricity demand exogenous variables temperature degree cloud cover viewed nonlinear regression model mixture Gaussians Using single neural network second model predicts evolution residual error first one viewed nonlinear autoregression model We analyze splitting input space generated mixture experts model compare performance models presently used',\n",
              " 'Suttons TD metho aims provide represen tation cost function absorbing Mark ov chain transition costs A simple example given represen tation obtained dep ends For represen tation optimal resp ect least squares error criterion decreases towards represen tation becomes progressiv ely worse cases poor The example suggests need understand better circumstances TD Qlearning obtain satisfactory neural net workbased compact represen tations cost function A variation TD also prop osed performs b etter example',\n",
              " 'Casebased reasoning involves reasoning cases specific pieces experience reasoners anothers used solve problems We use term graphstructured representations capable expressing relations two objects case allow set relations used vary case case allow set possible relations expanded necessary describe new cases Such representations implemented example semantic networks lists concrete propositions logic We believe graphstructured representations offer significant advantages thus investigating ways implement representations efficiently We make casebased argument using examples two systems chiron caper show graphstructured representation supports two different kinds casebased planning two different domains We discuss costs associated graphstructured representations describe approach reducing costs imple mented caper',\n",
              " 'The advantage using linear regression leaves regression tree analysed paper It carried modification affects construction pruning interpretation regression tree The modification tested artificial reallife domains impact classification error stability induced trees considered The results show modification beneficial leads smaller classification errors induced regression trees The Bayesian approach estimation class distributions used experiments',\n",
              " 'General Theory Quantitative Results Abstract The human genotype represents ten billion binary informations whereas human brain contains million times billion synapses So differentiated brain structure essentially due selforganization Such selforganization relevant areas ranging medicine design intelligent complex systems Many brain structures emerge collective phenomenon microscopic neurosynaptic dynamics stochastic dynamics mimics neuronal action potentials synaptic dynamics modeled local coupling dynamics type Hebbrule synaptic efficiency increases coincident spiking pre postsynaptic neuron The microscopic dynamics transformed collective dynamics reminiscent hydrodynamics The theory models empirical findings quantitatively Topology preserving neuronal maps assumed Descartes selforganization suggested Weiss empirical observation reported Marshall shown neurosynaptically stable due ubiquitous infinitesimal short range electrical chemical leakage In visual cortex neuronal stimulus orientation preference emerges empirically measured orientation patterns determined Poisson equation electrostatics Poisson equation orientation pattern emergence derived Complex cognitive abilities emerge basic local synaptic changes regulated valuation emergent valuation attention attention focus combination subnetworks Altogether general theory presented emergence functionality synaptic growth neurobiological systems The theory provides transformation collective dynamics used quantitative modeling empirical data',\n",
              " 'A Methodology Evaluating Theory Revision Systems Results Abstract Theory revision systems learning systems goal making small changes original theory account new data A measure distance two theories proposed This measure corresponds minimum number edit operations literal level required transform one theory another By computing distance original theory revised theory claim theory revision system makes revisions theory may quantitatively evaluated We present data using accuracy distance metric Audrey II Audrey II fl',\n",
              " 'We present novel data mining approach based decomposition In order analyze given dataset method decomposes hierarchy smaller less complex datasets analyzed independently The method experimentally evaluated realworld housing loans allocation dataset showing decomposition discover meaningful intermediate concepts decompose relatively complex dataset datasets easy analyze comprehend derive classifier high classification accuracy We also show human interaction positive effect comprehensibility classification accuracy',\n",
              " 'Most empirical evaluations machine learning algorithms case studies evaluations multiple algorithms multiple databases Authors case studies implicitly explicitly hypothesize pattern results often suggests one algorithm performs significantly better others limited small number databases investigated instead holds general class learning problems However hypotheses rarely supported additional evidence leaves suspect This paper describes empirical method generalizing results case studies example application This method yields rules describing algorithms significantly outperform others dependent measures Advantages generalizing case studies limitations particular approach also described',\n",
              " 'Learning multiple descriptions class data shown reduce generalization error amount error reduction varies greatly domain domain This paper presents novel empirical analysis helps understand variation Our hypothesis amount error reduction linked degree descriptions class make errors correlated manner We present precise novel definition notion use twentynine data sets show amount observed error reduction negatively correlated degree descriptions make errors correlated manner We empirically show possible learn descriptions make less correlated errors domains many ties search evaluation measure eg information gain experienced learning The paper also presents results help understand multiple descriptions help irrelevant attributes much help large amounts class noise',\n",
              " 'This paper presents Plannett system combines artificial neural networks achieve expert level accuracy difficult scientific task recognizing volcanos radar images surface planet Venus Plannett uses ANNs vary along two dimensions set input features used train number hidden units The ANNs combined simply averaging output activations When Plannett used classification module threestage image analysis system called JAR tool endtoend accuracy sensitivity specificity good human planetary geologist fourimage test suite JARtoolPlannett also achieves best algorithmic accuracy images date',\n",
              " 'Planning learning multiple levels temporal abstraction key problem artificial intelligence In paper summarize approach problem based mathematical framework Markov decision processes reinforcement learning Conventional modelbased reinforcement learning uses primitive actions last one time step modeled independently learning agent These generalized macro actions multistep actions specified arbitrary policy way completing Macro actions generalize classical notion macro operator closed loop uncertain variable duration Macro actions needed represent commonsense higherlevel actions going lunch grasping object traveling distant city This paper generalizes prior work temporally abstract models Sutton extends prediction setting include actions control planning We define semantics models macro actions guarantees validity planning using models This paper present new results theory planning macro actions illustrates potential advantages gridworld task',\n",
              " 'This paper reviews five approximate statistical tests determining whether one learning algorithm outperforms another particular learning task These tests compared experimentally determine probability incorrectly detecting difference difference exists type I error Two widelyused statistical tests shown high probability Type I error certain situations never used These tests test difference two proportions b paireddifferences test based taking several random traintest splits A third test paireddifferences test based fold crossvalidation exhibits somewhat elevated probability Type I error A fourth test McNemars test shown low Type I error The fifth test new test xcv based iterations fold crossvalidation Experiments show test also acceptable Type I error The paper also measures power ability detect algorithm differences exist tests The crossvalidated test powerful The xcv test shown slightly powerful McNemars test The choice best test determined computational cost running learning algorithm For algorithms executed McNemars test test acceptable Type I error For algorithms executed ten times xcv test recommended slightly powerful directly measures variation due choice training set',\n",
              " 'Many classification algorithms passive assign classlabel instance based description given even description incomplete In contrast active classifier cost obtain values missing attributes deciding upon class label The expected utility using active classifier depends cost required obtain additional attribute values penalty incurred outputs wrong classification This paper considers problem learning nearoptimal active classifiers using variant probablyapproximatelycorrect PAC model After defining framework perhaps main contribution paper describe situation task achieved efficiently show task often intractable',\n",
              " 'Probabilistic inference algorithms finding probable explanation maximum aposteriori hypothesis maximum expected utility updating belief reformulated eliminationtype algorithm called bucket elimination This emphasizes principle common many algorithms appearing literature clarifies relationship nonserial dynamic programming algorithms We also present general way combining conditioning elimination within framework Bounds complexity given algorithms function problems struc ture',\n",
              " 'This article published Sociological Methodology edited Peter V Marsden Cambridge Mass Blackwells Adrian E Raftery Professor Statistics Sociology Department Sociology DK University Washington Seattle WA This research supported NIH grant RHD I would like thank Robert Hauser Michael Hout Steven Lewis Scott Long Diane Lye Peter Marsden Bruce Western Yu Xie two anonymous reviewers detailed comments earlier version I also grateful Clem Brooks Sir David Cox Tom DiPrete John Goldthorpe David Grusky Jennifer Hoeting Robert Kass David Madigan Michael Sobel Chris Volinsky helpful discussions correspondence',\n",
              " 'In paper propose family algorithms combining treeclustering conditioning trade space time Such algorithms useful reasoning probabilistic deterministic networks well accomplishing optimization tasks By analyzing problem structure possible select spectrum algorithm best meets given timespace specifica tion',\n",
              " 'In paper propose new approach probabilistic inference belief networks global conditioning simple generalization Pearls b method loopcutset conditioning We show global conditioning well loopcutset conditioning thought special case method Lauritzen Spiegelhalter refined Jensen et al b Nonetheless approach provides new opportunities parallel processing case sequential processing tradeoff time memory We also show hybrid method Suermondt others combining loopcutset conditioning Jensens method viewed within framework By exploring relationships methods develop unifying framework advantages approach combined successfully',\n",
              " 'The dynamics collective properties feedback networks spiking neurons investigated Special emphasis given potential computational role subthreshold oscillations It shown model systems integrateandfire neurons function associative memories two distinct levels On first level binary patterns represented spike activity fire fire On second level analog patterns encoded relative firing times individual spikes spikes underlying subthreshold oscillation Both coding schemes may coexist within network The results suggest cortical neurons may perform broad spectrum associative computations far beyond scope traditional firingrate picture',\n",
              " 'This paper considers new method maintaining diversity creating subpopulations standard generational evolutionary algorithm Unlike methods replaces concept distance individuals tag bits identify subpopulation individual belongs Two variations method presented illustrating feasibility approach',\n",
              " 'Ideally pattern recognition machines provide constant output inputs transformed group G desired invariances These invariances achieved enhancing training data include examples inputs transformed elements G leaving corresponding targets unchanged Alternatively cost function training include regularization term penalizes changes output input transformed group This paper relates two approaches showing precisely sense regularized cost function approximates result adding transformed distorted examples training data The cost function enhanced training set equivalent sum original cost function plus regularizer For unbiased models regularizer reduces intuitively obvious choice term penalizes changes output inputs transformed group For infinitesimal transformations coefficient regularization term reduces variance distortions introduced training data This correspondence provides simple bridge two approaches',\n",
              " 'A new method proposed exploiting causal independencies exact Bayesian network inference A Bayesian network viewed representing factorization joint probability multiplication set conditional probabilities We present notion causal independence enables one factorize conditional probabilities combination even smaller factors consequently obtain finergrain factorization joint probability The new formulation causal independence lets us specify conditional probability variable given parents terms associative commutative operator sum max contribution parent We start simple algorithm VE Bayesian network inference given evidence query variable uses factorization find posterior distribution query We show algorithm extended exploit causal independence Empirical studies based CPCS networks medical diagnosis show method efficient previous methods allows inference larger networks previous algorithms',\n",
              " 'Our goal develop hybrid cognitive model humans acquire skills complex cognitive tasks We pursuing goal designing hybrid computational architectures NRL Navigation task requires competent sensorimotor coordination In paper describe results directly fitting human execution data task We next present empirically compare two methods modeling control knowledge acquisition reinforcement learning novel variant action models human learning task The paper concludes experimental demonstration impact background knowledge system performance Our results indicate performance action models approach closely approximates rate human learning task reinforcement learning',\n",
              " 'The statistical query learning model viewed tool creating demonstrating existence noisetolerant learning algorithms PAC model The complexity statistical query algorithm conjunction complexity simulating SQ algorithms PAC model noise determine complexity noisetolerant PAC algorithms produced Although roughly optimal upper bounds shown complexity statistical query learning corresponding noisetolerant PAC algorithms optimal due inefficient simulations In paper provide improved simulations new variant statistical query model order overcome inefficiencies We improve time complexity classification noise simulation statistical query algorithms Our new simulation roughly optimal dependence noise rate We also derive simpler proof statistical queries simulated presence classification noise This proof makes fewer assumptions queries therefore allows one simulate general types queries We also define new variant statistical query model based relative error show variant natural strictly powerful standard additive error model We demonstrate efficient PAC simulations algorithms new model give general upper bounds learning relative error statistical queries PAC simulation We show statistical query algorithm simulated PAC model malicious errors way resultant PAC algorithm roughly optimal tolerable malicious error rate sample complexity Finally generalize types queries allowed statistical query model We discuss advantages allowing generalized queries show results improved simulations also hold queries This paper available Center Research Computing Technology Division Applied Sciences Harvard University technical report TR',\n",
              " 'This paper outlines problems may occur Reduced Error Pruning relational learning algorithms notably efficiency Thereafter new method Incremental Reduced Error Pruning proposed attempts address problems Experiments show many noisy domains method much efficient alternative algorithms along slight gain accuracy However experiments show well use algorithm recommended domains require specific concept description',\n",
              " 'One kind prosodic structure apparently underlies music language meter Yet detailed measurements music speech show nested periodicities define metrical structure noisy sense What kind system could produce perceive variable metrical timing And would take store particular metrical patterns longterm memory system We developed network coupled oscillators produces perceives metrical patterns pulses In addition beginning initial state biases learns prefer beat patterns like waltzes beat patterns Models general class could learn entrain musical patterns And given way process speech extract appropriate pulses model applicable metrical structure speech well Is language metrical Meter refers particular sorts patterns time abstract description patterns potentially cognitive representation In cases two hierarchical levels equally spaced events occur periods characterizing levels integral multiples usually The hierarchy implied standard Western musical notation different levels indicated kinds notes quarter notes half notes etc bars separating measures For example basic waltztime meter individual beats spacing grouped sets three every third one receiving stronger accent In meter hierarchy consisting faster periodic cycle beat level slower one measure level fast onset zero phase angle coinciding zero phase angle every third beat Metrical systems like seem underlie forms music around world often said underlie human speech well Jones Martin However awkward difficulty definition employs notion integer since data music speech show clearly perfect temporal ratios predicted definition observed performance In music performance various kinds systematic temporal deviations timing specified musical notation known',\n",
              " 'We propose model abduction based revision epistemic state agent Explanations must sufficient induce belief sentence explained instance observation ensure consistency beliefs manner adequately accounts factual hypothetical sentences Our model generate explanations nonmonotonically predict observation thus generalizing current accounts require deductive relationship explanation observation It also provides natural preference ordering explanations defined terms normality plausibility To illustrate generality approach reconstruct two key paradigms modelbased diagnosis abductive consistencybased diagnosis within framework This reconstruction provides alternative semantics extends systems accommodate predictive explanations semantic preferences explanations It also illustrates general information incorporated principled manner fl Some parts paper appeared preliminary form Abduction Belief Revision A Model Preferred Explanations Proc Eleventh National Conf Artificial Intelligence AAAI Washington DC pp',\n",
              " 'Report R ISRN SICSRSE ISSN Abstract The optimal probability activation corresponding performance studied three designs Sparse Distributed Memory namely Kanervas original design Jaeckels selectedcoordinates design Karlssons modifi cation Jaeckels design We assume hard locations Karlssons case masks storage addresses stored data randomly chosen consider different levels random noise reading address',\n",
              " 'Report R ISRN SICSRSE ISSN Abstract We consider sparse distributed memory randomly chosen hard locations unknown number T random data vectors stored A method given estimate T content memory high accuracy In fact estimate unbiased coefficient variation roughly inversely proportional p MU M number hard locations memory U length data accuracy made arbitrarily high making memory big enough A consequence good reading methods used without need special extra location introduced',\n",
              " 'We describe rankedmodel semantics ifthen rules admitting exceptions provides coherent framework many facets evidential causal reasoning Rule priorities automatically extracted form knowledge base facilitate construction retraction plausible beliefs To represent causation formalism incorporates principle Markov shielding imposes stratified set independence constraints rankings interpretations We show formalism resolves classical problems associated specificity prediction abduction offers natural way unifying belief revision belief update reasoning actions',\n",
              " 'We build mathematical connection ExpectationMaximization EM algorithm gradientbased approaches maximum likelihood learning finite Gaussian mixtures We show EM step parameter space obtained gradient via projection matrix P provide explicit expression matrix We analyze convergence EM terms special properties P provide new results analyzing effect P likelihood surface Based mathematical results present comparative discussion advantages disadvantages EM algorithms learning Gaussian mixture models',\n",
              " 'A first order regression algorithm capable handling realvalued continuous variables introduced applications presented Regressional learning assumes realvalued class discrete realvalued variables The algorithm combines regressional learning standard ILP concepts first order concept description background knowledge A clause generated successively refining initial clause adding literals form A v discrete attributes A v A v realvalued attributes background knowledge literals clause body The algorithm employs covering approach beam search heuristic impurity function stopping criteria based local improvement minimum number examples maximum clause length minimum local improvement minimum description length allowed error variable depth An outline algorithm results systems application artificial realworld domains presented The realworld domains comprise modelling water behavior surge tank modelling workpiece roughness steel grinding process modelling operators behavior process electrical discharge machining Special emphasis given evaluation obtained models domain experts comments aspects practical use induced knowledge The results obtained knowledge acquisition process show several important guidelines knowledge acquisition concerning mainly process interaction domain experts exposing primarily importance comprehensibility induced knowledge',\n",
              " 'We address problem measuring degree hemispheric organization asymmetry organization computational model bihemispheric cerebral cortex A theoretical framework measures developed used produce algorithms measuring degree organization symmetry lateralization topographic map formation The performance resulting measures tested several topographic maps obtained selforganization initially random network results compared subjective assessments made humans It found closest agreement human assessments obtained using organization measures based sigmoidtype error averaging Measures developed correct large constant displacements well curving hemispheric topographic maps',\n",
              " 'Learning structure temporallyextended sequences difficult computational problem fraction relevant information available instant Although variants back propagation principle used find structure sequences practice sufficiently powerful discover arbitrary contingencies especially spanning long temporal intervals involving high order statistics For example designing connectionist network music composition encountered problem net able learn musical structure occurs locally timeeg relations among notes within musical phrasebut structure occurs longer time periodseg relations among phrases To address problem require means constructing reduced description sequence makes global aspects explicit readily detectable I propose achieve using hidden units operate different time constants Simulation experiments indicate slower timescale hidden units able pick global structure structure simply learned standard Many patterns world intrinsically temporal eg speech music unfolding events Recurrent neural net architectures devised accommodate timevarying sequences For example architecture shown Figure map sequence inputs sequence outputs Learning structure temporallyextended sequences difficult computational problem input pattern may contain taskrelevant information instant Thus back propagation',\n",
              " 'An incremental higherorder nonrecurrent neuralnetwork combines two properties found useful sequence learning neuralnetworks higherorder connections incremental introduction new units The incremental higherorder neuralnetwork adds higher orders needed adding new units dynamically modify connection weights The new units modify weights next timestep information previous step Since theoretically unlimited number units added network information arbitrarily distant past brought bear prediction Temporal tasks thereby learned without use feedback contrast recurrent neuralnetworks Because recurrent connections training simple fast Experiments demonstrated speedups two orders magnitude recurrent networks',\n",
              " 'In complex models like hidden Markov chains convergence MCMC algorithms used approximate posterior distribution Bayes estimates parameters interest must controlled robust manner We propose paper series online controls rely classical nonparametric tests evaluate independence startup distribution stability Markov chain asymptotic normality These tests lead graphical control spreadsheets presented setup normal mixture hidden Markov chains compare full Gibbs sampler aggregated Gibbs sampler based forwardbackward formulae',\n",
              " 'Three different methods investigated determine ability detect classify various categories diffuse liver disease A statistical method ie discriminant analysis supervised neural network called backpropagation nonsupervised selforganizing feature map examined The investigation performed basis previously selected set acoustic image texture parameters The limited number patients successfully extended generating additional independent data identical statistical properties The generated data used training test sets The final test made original patient data validation set It concluded neural networks attractive alternative traditional statistical techniques dealing medical detection classification tasks Moreover use generated data training networks discriminant classifier shown justified profitable',\n",
              " 'Nonlinear extensions oneunit multiunit Principal Component Analysis PCA neural networks introduced earlier authors reviewed The networks nonlinear Hebbian learning rules related signal expansions like Projection Pursuit PP Independent Component Analysis ICA Separation results mixtures real world signals im ages given',\n",
              " 'Many hormones physiological processes vary circadian pattern Although sinecosine function used model patterns functional form appropriate asymmetry peak nadir phases In paper describe semiparametric periodic spline function fit circadian rhythms The model includes phase amplitude time magnitude peak nadir estimated We also describe tests fit components model Data experiment study immunological responses humans used demonstrate methods',\n",
              " 'We present highlevel decompositionbased algorithms largescale blockangular optimization problems containing integer variables demonstrate effectiveness solution largescale graph partitioning problems These algorithms combine subproblemcoordination paradigm lower bounds pricedirective decomposition methods knapsack genetic approaches utilization building blocks partial solutions Even graph partitioning problems requiring billions variables standard formulation approach produces highquality solutions measured deviations easily computed lower bound substantially outperforms widelyused graph partitioning techniques based heuristics spectral methods',\n",
              " 'Maps regional morbidity mortality rates useful tools determining spatial patterns disease Combined sociodemographic census information also permit assessment environmental justice ie whether certain subgroups suffer disproportionately certain diseases adverse effects harmful environmental exposures Bayes empirical Bayes methods proven useful smoothing crude maps disease risk eliminating instability estimates lowpopulation areas maintaining geographic resolution In paper extend existing hierarchical spatial models account temporal effects spatiotemporal interactions Fitting resulting highlyparametrized models requires careful implementation Markov chain Monte Carlo MCMC methods well novel techniques model evaluation selection We illustrate approach using dataset countyspecific lung cancer rates state Ohio period',\n",
              " 'A novel unsupervised neural network dimensionality reduction seeks directions emphasizing multimodality presented connection exploratory projection pursuit methods discussed This leads new statistical insight synaptic modification equations governing learning Bienenstock Cooper Munro BCM neurons The importance dimensionality reduction principle based solely distinguishing features demonstrated using phoneme recognition experiment The extracted features compared features extracted using backpropagation network',\n",
              " 'This paper reprinted Computational Learning Theory Natural Learning Systems vol T Petsche S Hanson J Shavlik eds Copyrighted MIT Press Abstract The ability inductive learning system find good solution given problem dependent upon representation used features problem A number factors including trainingset size ability learning algorithm perform constructive induction mediate effect input representation accuracy learned concept description We present experiments evaluate effect input representation generalization performance realworld problem finding genes DNA Our experiments demonstrate two different input representations task result significantly different generalization performance neural networks decision trees neural symbolic methods constructive induction fail bridge gap two representations We believe realworld domain provides interesting challenge problem machine learning subfield constructive induction relationship two representations well known conceptually representational shift involved constructing better representation imposing',\n",
              " 'In paper emphasize role selection evolutionary algorithms We briefly review common selection schemes fields Genetic Algorithms Evolution Strategies Genetic Programming However classify selection schemes according group evolutionary algorithm belong rather distinguish parent selection schemes global competition replacement schemes local competition replacement schemes This paper intend fully review analyse presented selection schemes tries short reference standard advanced selection schemes',\n",
              " 'Selfsupervised backpropagation unsupervised learning procedure feedforward networks desired output vector identical input vector For backpropagation able use powerful simulators running parallel machines Topologypreserving maps hand developed variant competitive learning procedure However degenerate case selfsupervised backpropagation version competitive learning A simple extension cost function backpropagation leads competitive version selfsupervised backpropagation used produce topographic maps We demonstrate approach applied Traveling Salesman Problem TSP The algorithm implemented using backpropagation simulator CLONES parallel machine RAP',\n",
              " 'This paper describes evolving computational model perception production simple rhythmic patterns The model consists network oscillators different resting frequencies couple input patterns Oscillators whose frequencies match periodicities input tend become activated Metrical structure represented explicitly network form clusters oscillators whose frequencies phase angles constrained maintain harmonic relationships characterize meter Rests rhythmic patterns represented explicit rest oscillators network become activated expected beat pattern fails appear The model makes predictions relative difficulty The nested periodicity defines musical probably also linguistic meter appears fundamental way people perceive produce patterns time Meter however sufficient describe patterns interesting memorable deviate metrical hierarchy The simplest deviations rests gaps one levels hierarchy would normally beat When beats removed regular intervals match period level metrical hierarchy call simple rhythmic pattern Figure shows example simple rhythmic pattern Below grid representation meter behind pattern patterns effect deviations periodicity input',\n",
              " 'In paper generalize several results uniform approximation orders radial basis functions Buhmann Dyn Levin Dyn Ron L p approximation orders These results apply particular approximants spaces spanned translates radial basis functions scattered centres Examples results apply include quasiinterpolation leastsquares approximation radial function spaces',\n",
              " 'The paper studies L IR norm approximations space spanned discrete set translates basis function Attention restricted functions whose Fourier transform smooth IR n singularity origin Examples basis functions thinplate splines multiquadrics well types radial basis functions employed Approximation Theory The approximation problem wellunderstood case set points ffi used translating forms lattice IR many optimal quasioptimal approximation schemes already found literature In contrast mostly specific results known set ffi scattered points The main objective paper provide general tool extending approximation schemes use integer translates basis function nonuniform case We introduce single relatively simple conversion method preserves approximation orders provided large number schemes presently literature precisely almost stationary schemes In anticipation future introduction new schemes uniform grids effort made impose mild conditions function still allow unified error analysis hold In course discussion recent results BuDL scattered center approximation reproduced improved upon',\n",
              " 'An upper bound L p approximation power p provided principal shiftinvariant spaces derived mild assumptions generator It applies stationary nonstationary ladders shown apply spaces generated exponential box splines polyharmonic splines multiquadrics Gauss kernel',\n",
              " 'In speeduplearning problems full descriptions operators always known explanationbased learning EBL reinforcement learning RL applied This paper shows methods involve fundamentally process propagating information backward goal toward starting state RL performs propagation statebystate basis EBL computes weakest preconditions operators hence performs propagation regionbyregion basis Based observation RL form asynchronous dynamic programming paper shows develop dynamic programming version EBL call ExplanationBased Reinforcement Learning EBRL The paper compares batch online versions EBRL batch online versions RL standard EBL The results show EBRL combines strengths EBL fast learning ability scale large state spaces strengths RL learning optimal policies Results shown chess endgames synthetic maze tasks',\n",
              " 'In paper present extensions kmeans algorithm vector quantization permit efficient use image segmentation pattern classification tasks It shown introducing state variables correspond certain statistics dynamic behavior algorithm possible find representative centers lower dimensional manifolds define boundaries classes clouds multidimensional multiclass data permits one example find class boundaries directly sparse data eg image segmentation tasks efficiently place centers pattern classification eg local Gaussian classifiers The state variables used define algorithms determining adaptively optimal number centers clouds data spacevarying density Some examples application extensions also given This report describes research done within CIMAT Guanajuato Mexico Center Biological Computational Learning Department Brain Cognitive Sciences Artificial Intelligence Laboratory This research sponsored grants Office Naval Research contracts NJ NJ grant National Science Foundation contract ASC grant National Institutes Health contract NIH SRR Additional support provided North Atlantic Treaty Organization ATR Audio Visual Perception Research Laboratories Mitsubishi Electric Corporation Sumitomo Metal Industries Siemens AG Support AI Laboratorys artificial intelligence research provided ONR contract NJ JL Marroquin supported part grant Consejo Nacional de Ciencia Tecnologia Mexico',\n",
              " 'The limitations using selforganizing maps SOM either clusteringvector quantization VQ multidimensional scaling MDS discussed reviewing recent empirical findings relevant theory SOMs remaining ability VQ MDS time challenged new combined technique online Kmeans clustering plus Sammon mapping cluster centroids SOM shown perform significantly worse terms quantization error recovering structure clusters preserving topology comprehensive empirical study using series multivariate normal clustering problems',\n",
              " 'While exploring find better solutions agent performing online reinforcement learning RL perform worse acceptable In cases exploration might unsafe even catastrophic results often modeled terms reaching failure states agents environment This paper presents method uses domain knowledge reduce number failures exploration This method formulates set actions RL agent composes control policy ensure exploration conducted policy space excludes unacceptable policies The resulting action set abstract relationship task solved common many applications RL Although cost added safety learning may result suboptimal solution argue appropriate tradeoff many problems We illustrate method domain motion planning',\n",
              " 'In learning problems connectionist network trained finite sized training set better generalization performance often obtained unneeded weights network eliminated One source unneeded weights comes inclusion input variables provide little information output variables We propose method identifying eliminating input variables The method first determines relationship input output variables using nonparametric density estimation measures relevance input variables using information theoretic concept mutual information We present results method simple toy problem nonlinear time series',\n",
              " 'In work applying genetic algorithms populations neural networks real distinction genotype phenotype In nature information contained genotype mapping genetic information phenotype usually much complex The genotypes many organisms exhibit diploidy ie include two copies gene two copies identical sequences therefore functional difference products usually proteins expressed phenotypic feature termed dominant one one recessive expressed In paper review literature use diploidy dominance operators genetic algorithms present new results obtained simulations changing environments finally discuss results simulations parallel biological findings',\n",
              " 'The Multiscalar architecture advocates distributed processor organization tasklevel speculation exploit high degrees instruction level parallelism ILP sequential programs without impeding improvements clock speeds The main goal paper understand key implications architectural features distributed processor organization tasklevel speculation compiler task selection point view performance We identify fundamental performance issues control ow speculation data communication data dependence speculation load imbalance task overhead We show issues intimately related key characteristics tasks task size intertask control ow intertask data dependence We describe compiler heuristics select tasks favorable characteristics We report experimental results show heuristics successful boosting overall performance establishing larger ILP windows',\n",
              " 'Technical Report January Abstract This paper introduces Introspection Approach method learning agent employing reinforcement learning decide ask training agent instruction When using approach find number trainers responses produced significantly faster learners learner ask aid randomly Guidance received via approach informative random guidance Thus reduce interaction training agent learning agent without reducing speed learner develops policy In fact intelligent learner asks help even increase learning speed level trainer interaction',\n",
              " 'We present method feature construction selection finds minimal set conjunctive features appropriate perform classification task For problems bias appropriate method outperforms constructive induction algorithms able achieve higher classification accuracy The application method search minimal multilevel boolean expressions presented analyzed help examples',\n",
              " 'In paper discuss Bayesian approach finding latent classes data In approach use finite mixture models describe underlying structure data demonstrate possibility use full joint probability models raises interesting new prospects exploratory data analysis The concepts methods discussed illustrated case study using data set recent educational study The Bayesian classification approach described implemented presents appealing addition standard toolbox exploratory data analysis educational data',\n",
              " 'We present two additions hierarchical mixture experts HME architecture We view HME tree structured classifier Firstly applying likelihood splitting criteria expert HME grow tree adaptively training Secondly considering probable path tree may prune branches away either temporarily permanently become redundant We demonstrate results growing pruning algorithms show significant speed ups efficient use parameters conventional algorithms discriminating two interlocking spirals classifying bit parity patterns',\n",
              " 'Systems interacting realworld data must address issues raised possible presence errors observations makes In paper first present framework discussing imperfect data resulting problems may cause We distinguish two categories errors data random errors noise systematic errors examine relationship task describing observations way also useful helping future problemsolving learning tasks Secondly proceed examine techniques currently used AI research recognising errors',\n",
              " 'Genetic Programming applied task evolving general iterative sorting algorithms A connection size generality discovered Adding inverse size fitness measure along correctness decreases size resulting evolved algorithms also dramatically increases generality thus effectiveness evolution process In addition variety differing problem formulations investigated relative probability success reported An example evolved sort problem formulation presented initial attempt made understand variations difficulty resulting differing problem formulations',\n",
              " 'Irrelevant redundant features may reduce predictive accuracy comprehensibility induced concepts Most common Machine Learning approaches selecting good subset relevant features rely crossvalidation As alternative present application particular Minimum Description Length MDL measure task feature subset selection Using MDL principle allows taking account available data The new measure informationtheoretically plausible yet still simple therefore efficiently computable We show empirically new method judging value feature subsets efficient performs least well methods based crossvalidation Domains large number training examples large number possible features yield biggest gains efficiency Thus new approach seems scale better large learning problems previous methods',\n",
              " 'rules Rivest Inductive algorithms AQ CN learn decision lists incrementally one rule time Such algorithms face rule overlap problem classification accuracy decision list depends overlap learned rules Thus even though rules learned isolation evaluated concert Existing algorithms solve problem adopting greedy iterative structure Once rule learned training examples match rule removed training set We propose novel solution problem composing decision lists homogeneous rules rules whose classification accuracy change position decision list We prove problem finding maximally accurate decision list reduced problem finding maximally accurate homogeneous rules We report performance algorithm data sets UCI repository MONKs problems',\n",
              " 'Methods build function approximators example data gained considerable interest past Especially methodologies build models allow interpretation attracted attention Most existing algorithms however either complicated use infeasible highdimensional problems This article presents efficient easy use algorithm construct fuzzy graphs example data The resulting fuzzy graphs based locally independent fuzzy rules operate solely selected important attributes This enables application fuzzy graphs also problems high dimensional spaces Using illustrative examples real world data set demonstrated resulting fuzzy graphs offer quick insights structure example data underlying model',\n",
              " 'We describe methodology enabling intelligent teaching system make high level strategy decisions basis low level student modeling information This framework less costly construct superior hand coding teaching strategies responsive learners needs In order accomplish reinforcement learning used learn associate superior teaching actions certain states students knowledge Reinforcement learning RL shown flexible handling noisy data need expert domain knowledge A drawback RL often needs significant number trials learning We propose offline learning methodology using sample data simulated students small amounts expert knowledge bypass problem',\n",
              " 'Any intelligent system whether human robotic must capable dealing patterns time Temporal pattern processing achieved system shortterm memory capacity STM different representations maintained time In work propose neural model wherein STM realized leaky integrators selforganizing system The model exhibits compositionality ability extract construct progressively complex structured associations hierarchical manner starting basic primitive temporal elements An important feature proposed model use temporal correlations express dynamic bindings',\n",
              " 'In tasks requiring sustained attention human alertness varies minute time scale This serious consequences occupations ranging air traffic control monitoring nuclear power plants Changes electroencephalographic EEG power spectrum accompany fluctuations level alertness assessed measuring simultaneous changes EEG performance auditory monitoring task By combining power spectrum estimation principal component analysis artificial neural networks show continuous accurate noninvasive near realtime estimation operators global level alertness feasible using EEG measures recorded two central scalp sites This demonstration could lead practical system noninvasive monitoring cognitive state human operators attentioncritical settings',\n",
              " 'This paper presents exact solutions convergent approximations inferences Bayesian networks associated finitely generated convex sets distributions Robust Bayesian inference calculation bounds posterior values given perturbations probabilistic model The paper presents exact inference algorithms analyzes circumstances exact inference becomes intractable Two classes algorithms numeric approximations developed transformations original model The first transformation reduces robust inference problem estimation probabilistic parameters Bayesian network The second transformation uses Lavines bracketing algorithm generate sequence maximization problems Bayesian network The analysis extended contaminated lower density bounded belief function subsigma density bounded total variation density ratio classes distributions c fl Carnegie Mellon University',\n",
              " 'One fundamental problems learning identifying members two different classes For example diagnose cancer one must learn discriminate benign malignant tumors Through examination tumors previously determined diagnosis one learns function distinguishing benign malignant tumors Then acquired knowledge used diagnose new tumors The perceptron simple biologically inspired model twoclass learning problem The perceptron trained constructed using examples two classes Then perceptron used classify new examples We describe geometrically perceptron capable learning Using duality develop framework investigating different methods training perceptron Depending define best perceptron different minimization problems developed training perceptron The effectiveness methods evaluated empirically four practical applications breast cancer diagnosis detection heart disease political voting habits sonar recognition This paper assume prior knowledge machine learning pattern recognition',\n",
              " 'I define latent variable model form neural network target outputs specified inputs unspecified Although inputs missing still possible train model placing simple probability distribution unknown inputs maximizing probability data given parameters The model discover description data terms underlying latent variable space lower dimensionality I present preliminary results application models protein data',\n",
              " 'This paper studies aspects two categories usually differ like relevance generalization role loss function presents unifying formalism types information identified answers generalized questions shows kind generalized information necessary enable learning aims put usual training data prior information equal footing discussing possibilities variants measurement control generalized questions including examples smoothness symmetries reviews shortly measurement linguistic concepts based fuzzy priors principles combine preprocessors uses Bayesian decision theoretic framework contrasting parallel inverse decision problems proposes problems nonapproximation aspects Bayesian two step approximation consisting posterior maximization subsequent risk minimization analyses empirical risk minimization aspect nonlocal information compares Bayesian two step approximation empirical risk minimization including interpretations Occams razor formulates examples stationarity conditions maximum posterior approximation nonlocal nonconvex priors leading inhomogeneous nonlinear equations similar example equations scattering theory physics In summary paper focuses dependencies answers different questions Because training examples alone dependencies enable generalization emphasizes need empirical measurement control explicit treatment theory This report describes research done within Center Biological Computational Learning Department Brain Cognitive Sciences Massachusetts Institute Technology This research sponsored grant National Science Foundation contract ASC grant ONRARPA contract NJ The author supported Postdoctoral Fellowship Le Deutsche Forschungsgemeinschaft NSFCISE Postdoctoral Fellowship',\n",
              " 'We present alternative cellular encoding technique Gruau evolving graph network structures via genetic programming The new technique called edge encoding uses edge operators rather node operators cellular encoding While cellular encoding edge encoding produce possible graphs two encodings bias genetic search process different ways may therefore useful different set problems The problems techniques may used think edge encoding may particularly useful include evolution recurrent neural networks finite automata graphbased queries symbolic knowledge bases In preliminary report present technical description edge encoding initial comparison cellular encoding Experimental investigation relative merits encoding schemes currently progress',\n",
              " 'We present technique evaluating classifications geometric comparison rule sets Rules represented objects ndimensional hyperspace The similarity classes computed overlap geometric class descriptions The system produces correlation matrix indicates degree similarity pair classes The technique applied classifications generated different algorithms different numbers classes different attribute sets Experimental results case study medical domain included',\n",
              " 'As natural resources become less abundant naturally become interested adept utilisation waste materials In bringing bear ploy key importance learning I argue paper In Truth Trash model learning viewed process uses environmental feedback assemble fortuitous sensory predispositions sensory trash useful information vehicles ie truthful indicators salient phenomena The main aim show computer implementation model used enhance learning strategic abilities simulated football playing mobot',\n",
              " 'This paper concerns probabilistic evaluation effects actions presence unmeasured variables We show identification causal effect singleton variable X set variables Y accomplished systematically time polynomial number variables graph When causal effect identifiable closedform expression obtained probability action achieve specified goal set goals',\n",
              " 'VISOR large connectionist system shows visual schemas learned represented used mechanisms natural neural networks Processing VISOR based cooperation competition parallel bottomup topdown activation schema representations Simulations show VISOR robust noise variations inputs parameters It indicate confidence analysis pay attention important minor differences use context recognize ambiguous objects Experiments also suggest representation learning stable behavior consistent human processes priming perceptual reversal circular reaction learning The schema mechanisms VISOR serve starting point building robust highlevel vision systems perhaps schemabased motor control natural language processing systems well',\n",
              " 'We present framework characterizing Bayesian classification methods This framework thought spectrum allowable dependence given probabilistic model Naive Bayes algorithm restrictive end learning full Bayesian networks general extreme While much work carried along two ends spectrum surprising little done along middle We analyze assumptions made one moves along spectrum show tradeoffs model accuracy learning speed become critical consider variety data mining domains We present general induction algorithm allows traversal spectrum depending available computational power carrying induction show application number domains different properties',\n",
              " 'Traits acquired members evolving population lifetime adaptive processes learning become genetically specified later generations Thus change level learning population evolutionary time This paper explores idea well benefits gained learning may also costs paid ability learn It costs supply selection pressure genetic assimilation acquired traits Two models presented attempt illustrate assertion The first uses Kauffmans NK fitness landscapes show effect explicit implicit costs assimilation learnt traits A characteristic hump observed graph level plasticity population showing learning first selected evolution progresses The second model practical example neural network controllers evolved small mobile robot Results experiment also show hump',\n",
              " 'The evolution population guided phenotypic traits acquired members population lifetime This phenomenon known Baldwin Effect speed evolutionary process traits initially acquired become genetically specified later generations This paper presents conditions genetic assimilation take place As well benefits lifetime adaptation give population may cost paid adaptive ability It evolutionary tradeoff costs benefits provides selection pressure acquired traits become genetically specified It also noted genotypic space evolution operates phenotypic space adaptive processes learning operate general different nature To guarantee acquired characteristic become genetically specified spaces must property neighbourhood correlation means small distance two individuals phenotypic space implies small distance two individuals genotypic space',\n",
              " 'Decision Trees widely used classificationregression tasks They relatively much faster build compared Neural Networks understandable humans In normal decision trees based input vector one branch followed In Probabilistic OPtion trees based input vector follow subtrees probability These probabilities learned system Probabilistic decisions likely useful boundary classes submerge noise input data In addition provide us confidence measure We allow option nodes trees Again instead uniform voting learn weightage every subtree',\n",
              " 'The fundamental backpropagation BP algorithm training artificial neural networks cast deterministic nonmonotone perturbed gradient method Under certain natural assumptions series learning rates diverging series squares converging established every accumulation point online BP iterates stationary point BP error function The results presented cover serial parallel online BP modified BP momentum term BP weight decay',\n",
              " 'Recurrent neural networks trained behave like deterministic finitestate automata DFAs show deteriorating performance tested long strings This deteriorating performance attributed instability internal representation learned DFA states The use sigmoidal discriminant function together recurrent structure contribute instability We prove simple algorithm construct secondorder recurrent neural networks sparse interconnection topology sigmoidal discriminant function internal DFA state representations stable ie constructed network correctly classifies strings arbitrary length The algorithm based encoding strengths weights directly neural network We derive relationship weight strength number DFA states robust string classification For DFA n states input alphabet symbols constructive algorithm generates programmed neural network On neurons Omn weights We compare algorithm methods proposed literature',\n",
              " 'Report SYCON Recent Results Lyapunovtheoretic Techniques Nonlinear Stability ABSTRACT This paper presents Converse Lyapunov Function Theorem motivated robust control analysis design Our result based upon generalizes various aspects wellknown classical theorems In unified natural manner includes arbitrary bounded disturbances acting system deals global asymptotic stability results smooth infinitely differentiable Lyapunov functions applies stability respect necessarily compact invariant sets As corollary obtained Converse Theorem show wellknown Lyapunov sufficient condition inputtostate stability also necessary settling positively open question raised several authors past years',\n",
              " 'Technical Report CSTR UMIACSTR University Maryland College Park MD Abstract The extraction symbolic knowledge trained neural networks direct encoding partial knowledge networks prior training important issues They allow exchange information symbolic connectionist knowledge representations The focus paper quality rules extracted recurrent neural networks Discretetime recurrent neural networks trained correctly classify strings regular language Rules defining learned grammar extracted networks form deterministic finitestate automata DFAs applying clustering algorithms output space recurrent state neurons Our algorithm extract different finitestate automata consistent training set network We compare generalization performances different models trained network introduce heuristic permits us choose among consistent DFAs model best approximates learned regular grammar',\n",
              " 'Jobshop scheduling important task manufacturing industries We interested particular task scheduling payload processing NASAs space shuttle program This paper summarizes previous work formulating task solution reinforcement learning algorithm T D A shortcoming previous work reliance handengineered input features This paper shows extend timedelay neural network TDNN architecture apply irregularlength schedules Experimental tests show TDNNT D network match performance previous handengineered system The tests also show neural network approaches significantly outperform best previous nonlearning solution problem terms quality resulting schedules number search steps required construct',\n",
              " 'Report SYCON ABSTRACT This paper deals simulation Turing machines neural networks Such networks made interconnections synchronously evolving processors updates state according sigmoidal linear combination previous states units The main result states one may simulate Turing machines nets linear time In particular possible give net made processors computes universal partialrecursive function This update Report SYCON new results include simulation linear time binarytape machines opposed unary alphabets used previous version',\n",
              " 'In paper develop new LRTAbased algorithms variety tasks analyze complexity The LRTA algorithm realtime search algorithm developed Korf It used reach stationary moving goal state identify shortest paths given start state stationary goal state algorithm reset start state reaches goal state Our algorithms search horizon one require internal memory must able store information states For example bidirectional LRTS algorithm determines optimal universal plans ie finds optimal paths states set stationary goal states even reset actions available We show tasks studied paper solved LRTAbased algorithms On action executions state spaces size n',\n",
              " 'In paper consider problem approximating function belonging function space linear combination n translates given function G Using lemma Jones Barron show possible define function spaces functions G rate convergence zero error O p n number dimensions The apparent avoidance curse dimensionality due fact function spaces constrained dimension increases Examples include spaces Sobolev type number weak derivatives required larger number dimensions We give results approximation L norm L norm The interesting feature results thanks constructive nature Jones Barrons lemma iterative procedure defined achieve rate This paper describes research done within Center Biological Information Processing Department Brain Cognitive Sciences Artificial Intelligence Laboratory Department Mathematics University Trento Italy Gabriele Anzellotti Department Mathematics University Trento Italy This research sponsored grant Office Naval Research ONR Cognitive Neural Sciences Division Artificial Intelligence Center Hughes Aircraft Corporation S Support A I Laboratorys artificial intelligence research provided Advanced Research Projects Agency Department Defense Army contract DACAC part ONR contract NK c fl Massachusetts Institute Technology',\n",
              " 'University Wisconsin Computer Sciences Technical Report September Abstract In explanationbased learning specific problems solution generalized form later used solve conceptually similar problems Most research explanationbased learning involves relaxing constraints variables explanation specific example rather generalizing graphical structure explanation However precludes acquisition concepts iterative recursive process implicitly represented explanation fixed number applications This paper presents algorithm generalizes explanation structures reports empirical results demonstrate value acquiring recursive iterative concepts The BAGGER algorithm learns recursive iterative concepts integrates results multiple examples extracts useful subconcepts generalization On problems learning recursive rule appropriate system produces result standard explanationbased methods Applying learned recursive rules requires minor extension PROLOGlike problem solver namely ability explicitly call specific rule Empirical studies demonstrate generalizing structure explanations helps avoid recently reported negative effects learning',\n",
              " 'We consider Gibbs sampler applied uniform distribution bounded region R R We show convergence properties Gibbs sampler depend greatly smoothness boundary R Indeed sufficiently smooth boundaries sampler uniformly ergodic jagged boundaries sampler could fail even geometrically ergodic',\n",
              " 'In learning examples often useful expand attributevector representation intermediate concepts The usual advantage structuring learning problem makes learning easier improves comprehensibility induced descriptions In paper develop technique discovering useful intermediate concepts class attributes realvalued The technique based decomposition method originally developed design switching circuits recently extended handle incompletely specified multivalued functions It also applied machine learning tasks In paper introduce modifications needed decompose real functions present symbolic form The method evaluated number test functions The results show method correctly decomposes fairly complex functions The decomposition hierarchy depend given repertoir basic functions background knowledge',\n",
              " 'Uncertainty sampling methods iteratively request class labels training instances whose classes uncertain despite previous labeled instances These methods greatly reduce number instances expert need label One problem approach classifier best suited application may expensive train use selection instances We test use one classifier highly efficient probabilistic one select examples training another C rule induction program Despite chosen heterogeneous approach uncertainty samples yielded classifiers lower error rates random samples ten times larger',\n",
              " 'Certain causal models involving unmeasured variables induce independence constraints among observed variables imply nevertheless inequality constraints observed distribution This paper derives general formula inequality constraints induced instrumental variables exogenous variables directly affect variables With help formula possible test whether model involving instrumental variables may account data conversely whether given vari able deemed instrumental',\n",
              " 'Bayesian confidence intervals smoothing spline often used distinguish two curves In paper provide asymptotic formula sample size calculations based Bayesian confidence intervals Approximations simulations special functions indicate asymptotic formula reasonably accurate Key Words Bayesian confidence intervals sample size smoothing spline fl Address Department Statistics Applied Probability University California Santa Barbara CA Tel Fax Email yuedongpstatucsbedu Supported National Institute Health Grants R EY P DK P HD',\n",
              " 'We describe several improvements Freund Schapires AdaBoost boosting algorithm particularly setting hypotheses may assign confidences predictions We give simplified analysis AdaBoost setting show analysis used find improved parameter settings well refined criterion training weak hypotheses We give specific method assigning confidences predictions decision trees method closely related one used Quinlan This method also suggests technique growing decision trees turns identical one proposed Kearns Mansour We focus next apply new boosting algorithms multiclass classification problems particularly multilabel case example may belong one class We give two boosting methods problem One leads new method handling singlelabel case simpler effective techniques suggested Freund Schapire Finally give experimental results comparing algorithms discussed paper',\n",
              " 'Evolutionary Algorithms direct random search algorithms imitate principles natural evolution method solve adaptation learning tasks general As several features common observed genetic phenotypic level living species In paper algorithms capability adaptation learning wider sense demonstrated focused Genetic Algorithms illustrate learning process population level first level learning Evolution Strategies demonstrate learning process metalevel strategy parameters second level learning',\n",
              " 'We examine novel addition known methods learning Bayesian networks data improves quality learned networks Our approach explicitly represents learns local structure conditional probability distributions CPDs quantify networks This increases space possible models enabling representation CPDs variable number parameters The resulting learning procedure induces models better emulate interactions present data We describe theoretical foundations practical aspects learning local structures provide empirical evaluation proposed learning procedure This evaluation indicates learning curves characterizing procedure converge faster number training instances standard procedure ignores local structure CPDs Our results also show networks learned local structures tend complex terms arcs yet require fewer parameters',\n",
              " 'This paper contains method bound test errors voting committees members chosen pool trained classifiers There many prospective committees validating directly achieve useful error bounds Because fewer classifiers prospective committees better validate classifiers individually use linear programming infer committee error bounds We test method using credit card data Also extend method infer bounds classifiers general',\n",
              " 'An accurate simulation heating coil used compare performance PI controller neural network trained predict steadystate output PI controller neural network trained minimize nstep ahead error coil output set point reinforcement learning agent trained minimize sum squared error time Although PI controller works well task neural networks result improved performance',\n",
              " 'The CN algorithm induces ordered list classification rules examples using entropy search heuristic In short paper describe two improvements algorithm Firstly present use Laplacian error estimate alternative evaluation function secondly show unordered well ordered rules generated We experimentally demonstrate significantly improved performances resulting changes thus enhancing usefulness CN inductive tool Comparisons Quinlans C also made',\n",
              " 'Neural computation also called connectionism parallel distributed processing neural network modeling brainstyle computation grown rapidly last decade Despite explosion ultimately impressive applications dire need concise introduction theoretical perspective analyzing strengths weaknesses connectionist approaches establishing links disciplines statistics control theory The Introduction Theory Neural Computation Hertz Krogh Palmer subsequently referred HKP written perspective physics home discipline authors The book fulfills mission introduction neural network novices provided background calculus linear algebra statistics It covers number models often viewed disjoint Critical analyses fruitful comparisons models',\n",
              " 'Controlflow misprediction penalties major impediment high performance wideissue superscalar processors In paper present Selective Eager Execution SEE execution model overcome misspeculation penalties executing paths diffident branches We present microarchitecture PolyPath processor extension aggressive superscalar outoforder architecture The PolyPath architecture uses novel instruction tagging register renaming mechanism execute instructions multiple paths simultaneously processor pipeline retaining maximum resource availability singlepath code sequences Results executiondriven pipelinelevel simulations show SEE improve performance much go benchmark average SPECint compared normal superscalar outoforder speculative execution monopath processor Moreover architectural model elegant practical implement using small amount additional state control logic',\n",
              " 'This paper describes competitive tree learning algorithm derived first principles The algorithm approximates Bayesian decision theoretic solution learning task Comparative experiments algorithm several mature AI statistical families tree learning algorithms currently use show derived Bayesian algorithm consistently good better although sometimes computational cost Using strategy design algorithms many supervised model learning tasks given probabilistic representation kind knowledge learned As illustration second learning algorithm derived learning Bayesian networks data Implications incremental learning use multiple models also discussed',\n",
              " 'We address problem finding subset features allows supervised induction algorithm induce small highaccuracy concepts We examine notions relevance irrelevance show definitions used machine learning literature adequately partition features useful categories relevance We present definitions irrelevance two degrees relevance These definitions improve understanding behavior previous subset selection algorithms help define subset features sought The features selected depend features target concept also induction algorithm We describe method feature subset selection using crossvalidation applicable induction algorithm discuss experiments conducted ID C artificial real datasets',\n",
              " 'We describe machine learning method predicting value realvalued function given values multiple input variables The method induces solutions samples form ordered disjunctive normal form DNF decision rules A central objective method representation induction compact easily interpretable solutions This rulebased decision model extended search efficiently similar cases prior approximating function values Experimental results realworld data demonstrate new techniques competitive existing machine learning statistical methods sometimes yield superior regression performance',\n",
              " 'This work presents hybrid branch predictor scheme uses limited form dual path execution along dynamic branch prediction improve execution times The ability execute paths conditional branch enables branch penalty minimized however relying exclusively dual path execution infeasible due instruction fetch rates far exceed capability pipeline retire single branch others must processed By using confidence information available dynamic branch prediction state tables limited form dual path execution becomes feasible This reduces burden branch predictor allowing predictions low confidence avoided In study present new approach gather branch prediction confidence little overhead use confidence mechanism determine whether dual path execution branch prediction used Comparing hybrid predictor model dynamic branch predictor shows dramatic decrease misprediction rate translates reduction runtime These results imply dual path execution often thought excessively resource consuming method may worthy approach restricted appropriate predicting set',\n",
              " 'This paper presents Threaded MultiPath Execution TME exploits existing hardware Simultaneous Multithreading SMT processor speculatively execute multiple paths execution When fewer threads SMT processor hardware contexts threaded multipath execution uses spare contexts fetch execute code along less likely path hardtopredict branches This paper describes hardware mechanisms needed enable SMT processor efficiently spawn speculative threads threaded multipath execution The Mapping Synchronization Bus described enables spawning multiple paths Policies examined deciding branches fork managing competition primary alternate path threads critical resources Our results show TME increases single program performance SMT eight thread contexts average depending misprediction penalty programs high misprediction rate',\n",
              " 'In paper review research machine learning relation computational models human learning We focus initially concept induction examining five main approaches problem consider complex issue learning sequential behaviors After compare rhetoric sometimes appears machine learning psychological literature growing evidence different theoretical paradigms typically produce similar results In response suggest concrete computational models currently dominate field may less useful simulations operate abstract level We illustrate point abstract simulation explains challenging phenomenon area category learning conclude general observations abstract models',\n",
              " 'The function unknown biological sequence often accurately inferred identifying sequences homologous original sequence Given query set known homologs exist least three general classes techniques finding additional homologs pairwise sequence comparisons motif analysis hidden Markov modeling Pair wise sequence comparisons typically employed single query sequence known Hidden Markov models HMMs hand usually trained sets sequences Motif based methods fall two extremes',\n",
              " 'Future research directions Knowledge Discovery Databases KDD include ability extract overlying concept relating useful data Current limitations involve search complexity find concept means useful The Pattern Theory research crosses natural way aforementioned domain The goal paper threefold First present new approach problem learning Discovery robust pattern finding Second explore current limitations Pattern Theoretic approach applied general KDD problem Third exhibit performance experimental results binary functions compare results C This new approach learning demonstrates powerful method finding patterns robust manner',\n",
              " 'Prerequisites An understanding dynamic programming edit distance approach pairwise sequence alignment useful parts Also familiarity use Internet resources would helpful part For former see Chapters latter see Chapter Hypertext Book GNAVSNS Biocomputing Course httpwwwtechfakunibielefelddebcdCurricwelcomehtml General Rationale You understand Multiple Alignment considered challenging problem study approaches try reduce number steps needed calculate optimal solution study fast heuristics In case study involving immunoglobulin sequences study multiple alignments obtained WWW servers recapitulating results original paper Revision History Version Sep Expanded Ex Updated Ex Revised Solution Sheet Ex Marked Exercises A submitted Instructor Various minor clarifications content',\n",
              " 'This article describes new system induction oblique decision trees This system OC combines deterministic hillclimbing two forms randomization find good oblique split form hyperplane node decision tree Oblique decision tree methods tuned especially domains attributes numeric although adapted symbolic mixed symbolicnumeric attributes We present extensive empirical studies using real artificial data analyze OCs ability construct oblique trees smaller accurate axisparallel counterparts We also examine benefits randomization construction oblique decision trees',\n",
              " 'ExplanationBased Reinforcement Learning EBRL introduced Dietterich Flann way combining ability Reinforcement Learning RL learn optimal plans generalization ability ExplanationBased Learning EBL Dietterich Flann We extend work domains agent must order achieve sequence subgoals optimal fashion Hierarchical EBRL effectively learn optimal policies sequential task domains even subgoals weakly interact We also show planner achieve individual subgoals available method converges even faster',\n",
              " 'Discretization continuously valued data useful necessary tool many learning paradigms assume nominal data A list objectives efficient effective discretization presented A paradigm called BRACE Boundary Ranking And Classification Evaluation attempts meet objectives presented along algorithm follows paradigm The paradigm meets many objectives potential extension meet remainder Empirical results promising For reasons BRACE potential effective efficient method discretization continuously valued data A advantage BRACE general enough extended types clusteringunsupervised learning',\n",
              " 'Naive Bayesian classifiers make independence assumptions perform remarkably well data sets poorly others We explore ways improve Bayesian classifier searching dependencies among attributes We propose evaluate two algorithms detecting dependencies among attributes show backward sequential elimination joining algorithm provides improvement naive Bayesian classifier The domains improvement occurs domains naive Bayesian classifier significantly less accurate decision tree learner This suggests attributes used common databases independent conditioned class violations independence assumption affect accuracy classifier The Bayesian classifier Duda Hart probabilistic method classification It used determine probability example j belongs class C given values attributes example represented set n nominallyvalued attributevalue pairs form A V j P A k V k j jC may estimated training data To determine likely class test example probability class computed Equation A classifier created manner sometimes called simple Langley naive Kononenko Bayesian classifier One important evaluation metric machine learning methods predictive accuracy unseen examples This measured randomly selecting subset examples database use training examples reserving remainder used test examples In case simple Bayesian classifier training examples used estimate probabilities Equation used detected training data',\n",
              " 'Multiple sequence alignment distantly related viral proteins remains challenge currently available alignment methods The hidden Markov model approach offers new flexible method generation multiple sequence alignments The results studies attempting infer appropriate parameter constraints generation de novo HMMs globin kinase aspartic acid protease ribonuclease H sequences SAM HMMER methods described',\n",
              " 'Several recurrent networks proposed representations task formal language learning After training recurrent network next step understand information processing carried network Some researchers Giles et al Watrous Kuhn Cleeremans et al resorted extracting finite state machines internal state trajectories recurrent networks This paper describes two conditions sensitivity initial conditions frivolous computational explanations due discrete measurements Kolen Pollack allow extraction methods return illusionary finite state descriptions',\n",
              " 'In order useful learning algorithm must able generalize well faced inputs previously presented system A bias necessary generalization shown several researchers recent years bias lead strictly better generalization summed possible functions applications This paper provides examples illustrate fact also explains bias learning algorithm better another practice probability occurrence functions taken account It shows domain knowledge understanding conditions learning algorithm performs well used increase probability accurate generalization identifies several conditions considered attempting select appropriate bias particular problem',\n",
              " 'In paper introduce modelbased reinforcement learning method called Hlearning optimizes undiscounted average reward We compare three reinforcement learning methods domain scheduling Automatic Guided Vehicles transportation robots used modern manufacturing plants facilities The four methods differ along two dimensions They either modelbased modelfree optimize discounted total reward undiscounted average reward Our experimental results indicate Hlearning robust respect changes domain parameters many cases converges fewer steps better average reward per time step methods An added advantage unlike methods parameters tune',\n",
              " 'This paper presents Converse Lyapunov Function Theorem motivated robust control analysis design Our result based upon generalizes various aspects wellknown classical theorems In unified natural manner allows arbitrary bounded timevarying parameters system description deals global asymptotic stability results smooth infinitely differentiable Lyapunov functions applies stability respect necessarily compact invariant sets Introduction This work motivated problems robust nonlinear stabilization One main',\n",
              " 'Technical Report AI May Abstract An important often neglected problem field Artificial Intelligence grounding systems environment representations manipulate inherent meaning system Since humans rely heavily semantics seems likely grounding crucial development truly intelligent behavior This study investigates use simulated robotic agents neural network processors part method ensure grounding Both topology weights neural networks optimized genetic algorithms Although comprehensive optimization difficult empirical evidence gathered shows method tractable quite fruitful In experiments agents evolved wallfollowing control strategy able transfer novel environments Their behavior suggests also learning build cognitive maps',\n",
              " 'ExplanationBased Learning Mitchell et al DeJong Mooney shown promise powerful analytical learning technique However EBL severely hampered requirement complete correct domain theory successful learning occur Clearly nontrivial domains developing domain theory nearly impossible task Therefore much research devoted understanding imperfect domain theory corrected extended system performance In paper present characterization problem use analyze past research area Past characterizations problem eg Mitchell et al Rajamoney DeJong viewed types performance errors caused faulty domain theory primary In contrast focus primarily types knowledge deficiencies present theory derive types performance errors result Correcting theory viewed search space possible domain theories variety knowledge sources used guide search We examine types knowledge used variety past systems purpose The hope analysis indicate need universal weak method domain theory correction different sources knowledge theory correction freely flexibly combined',\n",
              " 'We study task tnding maximal posteriori MAP instantiation Bayesian network variables given partial value assignment initial constraint This problem known NPhard concentrate stochastic approximation algorithm simulated annealing This stochastic algorithm realized sequential process set Bayesian network variables one variable allowed change time Consequently method become impractically slow number variables increases We present method mapping given Bayesian network massively parallel Bolztmann machine neural network architecture sense instead using normal sequential simulated annealing algorithm use massively parallel stochastic process Boltzmann machine architecture The neural network updating process provably converges state solves given MAP task',\n",
              " 'Parameterized heuristics offers elegant powerful theoretical framework design analysis autonomous adaptive communication networks Routing messages networks presents realtime instance multicriterion optimization problem dynamic uncertain environment This paper describes framework heuristic routing large networks The effectiveness heuristic routing mechanism upon Quo Vadis based described part simulation study within network grid topology A formal analysis underlying principles presented incremental design set heuristic decision functions used guide messages along nearoptimal eg minimum delay path large network This paper carefully derives properties heuristics set simplifying assumptions network topology load dynamics identify conditions guaranteed route messages along optimal path The paper concludes discussion relevance theoretical results presented paper design intelligent autonomous adaptive communication networks outline directions future research',\n",
              " 'Technical Report Department Statistics University Washington Derek Stanford Graduate Research Assistant Adrian E Raftery Professor Statistics Sociology Department Statistics University Washington Box Seattle WA USA Email stanfordstatwashingtonedu rafterystatwashingtonedu Web httpwwwstatwashingtoneduraftery This research supported ONR grants N N The authors grateful Simon Byers Gilles Celeux Christian Posse helpful discussions',\n",
              " 'We analyze algorithms predict binary value combining predictions several prediction strategies called experts Our analysis worstcase situations ie make assumptions way sequence bits predicted generated We measure performance algorithm difference expected number mistakes makes bit sequence expected number mistakes made best expert sequence expectation taken respect randomization predictions We show minimum achievable difference order square root number mistakes best expert give efficient algorithms achieve Our upper lower bounds matching leading constants cases We show leads certain kinds pattern recognitionlearning algorithms performance bounds improve best results currently known context We also compare analysis case log loss used instead expected number mistakes',\n",
              " 'This paper presents formalization novel approach structural similarity assessment adaptation casebased reasoning Cbr synthesis The approach informally presented exemplified implemented domain industrial building design Borner By relating approach existing theories provide foundation systematic evaluation appropriate usage Cases primary repository knowledge represented structurally using algebraic approach Similarity relations provide structure preserving case modifications modulo underlying algebra equational theory algebra available This representation modeled universe discourse enables theorybased inference adapted solutions The approach enables us incorporate formally generalization abstraction geometrical transformation combinations Cbr',\n",
              " 'A learning agent employing reinforcement learning hindered receives critics sparse weakly informative training information We present approach automated training agent may also provide occasional instruction learner form actions learner perform The learner access critics feedback trainers instruction In experiments vary level trainers interaction learner allowing trainer instruct learner almost every time step allowing trainer respond We also vary parameter controls learner incorporates trainers actions The results show significant reductions average number training trials necessary learn perform task',\n",
              " 'We present algorithm improving accuracy algorithms learning binary concepts The improvement achieved combining large number hypotheses generated training given learning algorithm different set examples Our algorithm based ideas presented Schapire paper The strength weak learnability represents improvement results The analysis algorithm provides general upper bounds resources required learning Valiants polynomial PAC learning framework best general upper bounds known today We show number hypotheses combined algorithm smallest number possible Other outcomes analysis results regarding representational power threshold circuits relation learnability compression method parallelizing PAC learning algorithms We provide extensions algorithms cases concepts binary case accuracy learning algorithm depends distribution instances',\n",
              " 'This paper proposes model ratio decidendi justification structure consisting series reasoning steps relate abstract predicates abstract predicates relate abstract predicates specific facts This model satisfies important set characteristics ratio decidendi identified jurisprudential literature In particular model shows theory case decided controls precedential effect By contrast purely exemplarbased model ratio decidendi fails account dependency precedential effect theory decision',\n",
              " 'In paper abstract computational principles underlying topographic maps discussed We give definition perfectly neighbourhood preserving map call topographic homeomorphism prove certain desirable properties It argued topographic homeomorphism exist usual case many equally valid choices available quantifying quality map We introduce particular measure encompasses several previous proposals discuss relation work This formulation problem sets within wellknown class quadratic assignment problems',\n",
              " 'This paper studies robustness pac learning algorithms instance space f g n examples corrupted purely random noise affecting instances labels In past conflicting results subject obtainedthe best agreement rule tolerate small amounts noise yet cases large amounts noise tolerated We show truth lies somewhere two alternatives For uniform attribute noise attribute flipped independently random probability present algorithm pac learns monomials unknown noise rate less Contrasting positive result show product random attribute noise attribute flipped randomly independently probability p nearly harmful malicious noiseno algorithm tolerate small amount noise fl Supported part GE Foundation Junior Faculty Grant NSF grant CCR Part research conducted author MIT Laboratory Computer Science supported NSF grant DCR grant Siemens Corporation Net address sgcswustledu',\n",
              " 'This paper describes research investigating behavioral specialization learning robot teams Each agent provided common set skills motor schemabased behavioral assemblages builds taskachieving strategy using reinforcement learning The agents learn individually activate particular behavioral assemblages given current situation reward signal The experiments conducted robot soccer simulations evaluate agents terms performance policy convergence behavioral diversity The results show many cases robots automatically diversify choosing heterogeneous behaviors The degree diversification performance team depend reward structure When entire team jointly rewarded penalized global reinforcement teams tend towards heterogeneous behavior When agents provided feedback individually local reinforcement converge identical policies',\n",
              " 'Product units provide method automatically learning higherorder input combinations required efficient synthesis Boolean logic functions neural networks Product units also higher information capacity sigmoidal networks However activation function received much attention literature A possible reason one encounters problems using standard backpropagation train networks containing units This report examines problems evaluates performance three training algorithms networks type Empirical results indicate error surface networks containing product units local minima corresponding networks summation units For reason combination local global training algorithms found provide reliable convergence We investigate hints added training algorithm By extracting common frequency input weights training frequency separately show convergence accelerated In order compare performance transfer functions product units implemented candidate units Cascade Correlation CC system Using candidate units resulted smaller networks trained faster standard three sigmoidal types one Gaussian transfer functions used This superiority confirmed pool candidate units four different nonlinear activation functions used compete addition network Extensive simulations showed problem implementing random Boolean logic functions product units always chosen transfer functions',\n",
              " 'Our goal develop cognitive model humans acquire skills complex cognitive tasks We pursuing goal designing computational architectures NRL Navigation task requires competent sensorimotor coordination In paper analyze NRL Navigation task depth We use data experiments human subjects learning task guide us constructing cognitive model skill acquisition task Verbal protocol data augments black box view provided execution traces inputs outputs Computational experiments allow us explore space alternative architectures task guided quality fit human performance data',\n",
              " 'We show paper AGM postulates week ensure rational preservation conditional beliefs belief revision thus permitting improper responses sequences observations We remedy weakness proposing four additional postulates sound relative qualitative version probabilistic conditioning Contrary AGM framework proposed postulates characterize belief revision process may depend elements epistemic state necessarily captured belief set We also show simple modification AGM framework allow belief revision function epistemic states We establish modelbased representation theorem characterizes proposed postulates constrains turn way entrenchment orderings may transformed iterated belief revision',\n",
              " 'Results presented demonstrate learning finetuning search strategies using connectionist mechanisms Previous studies strategy learning within symbolic productionrule formalism addressed finetuning behavior Here twolayer connectionist system presented develops search weak taskspecific strategy finetunes performance The system applied simulated realtime balancecontrol task We compare performance onelayer twolayer networks showing ability twolayer network discover new features thus enhance original representation critical solving balancing task',\n",
              " 'Following terminology used adaptive control distinguish indirect learning methods learn explicit models dynamic structure system controlled direct learning methods We compare existing indirect method uses conventional dynamic programming algorithm closely related direct reinforcement learning method applying methods infinite horizon Markov decision problem unknown statetransition probabilities The simulations show although direct method requires much less space dramatically less computation per control action learning ability task superior compares favorably complex indirect method Although results address methods performances compare problems become difficult suggest given fixed amount computational power available per control action may better use direct reinforcement learning method augmented indirect techniques devote available resources computationally costly indirect method Comprehensive answers questions raised study depend many factors making eco nomic context computation',\n",
              " 'We propose general framework study belief change We begin defining belief terms knowledge plausibility agent believes knows true worlds considers plausible We consider properties defining interaction knowledge plausibility show properties affect properties belief In particular show assuming two natural properties belief becomes KD operator Finally add time picture This gives us framework talk knowledge plausibility hence belief time extends framework Halpern Fagin HF modeling knowledge multiagent systems We show framework quite expressive lets us model natural way number different scenarios belief change For example show capture analogue prior probabilities updated conditioning In related paper show two best studied scenarios belief revision belief update fit framework',\n",
              " 'Markov chain Monte Carlo MCMC used evaluating expectations functions interest target distribution This done calculating averages sample path Markov chain stationary distribution For computational efficiency Markov chain rapidly mixing This sometimes achieved careful design transition kernel chain basis detailed preliminary exploratory analysis An alternative approach might allow transition kernel adapt whenever new features encountered MCMC run However adaptation occurs infinitely often stationary distribution chain may disturbed We describe framework based concept Markov chain regeneration allows adaptation occur infinitely often disturb stationary distribution chain consistency samplepath averages Key Words Adaptive method Bayesian inference Gibbs sampling Markov chain Monte Carlo',\n",
              " 'A traditional interpolation model characterized choice regularizer applied interpolant choice noise model Typically regularizer single regularization constant ff noise model single parameter fi The ratio fffi alone responsible determining globally attributes interpolant complexity flexibility smoothness characteristic scale length characteristic amplitude We suggest interpolation models able capture one flavour simplicity complexity We describe Bayesian models interpolant smoothness varies spatially We emphasize importance practical implementation concept conditional convexity designing models many hyperparameters We apply new models interpolation neuronal spike data demonstrate substantial improvement generalization error',\n",
              " 'Author paper coordinator Machine Learning project StatLog This project supported financially European Community The main aim StatLog evaluate different learning algorithms using real industrial commercial applications As industrial partner contributor DaimlerBenz introduced different applications StatLog among fault diagnosis letter digit recognition creditscoring prediction number registered trucks We learned lot lessons project effected application oriented research field Machine Learning ML DaimlerBenz We distinguished especially research necessary prepare MLalgorithms handle real industrial commercial applications In paper describe shortly DaimlerBenz applications StatLog discuss shortcomings applied MLalgorithms finally outline fields think research necessary',\n",
              " 'This paper describes application reinforcement learning RL difficult real world problem elevator dispatching The elevator domain poses combination challenges seen RL research date Elevator systems operate continuous state spaces continuous time discrete event dynamic systems Their states fully observable nonstationary due changing passenger arrival rates In addition use team RL agents responsible controlling one elevator car The team receives global reinforcement signal appears noisy agent due effects actions agents random nature arrivals incomplete observation state In spite complications show results simulation surpass best heuristic elevator control algorithms aware These results demonstrate power RL large scale stochastic dynamic optimization problem practical utility',\n",
              " 'This paper presents Fringe Exploration technique efficient exploration partially observable domains The key idea applicable many exploration techniques keep statistics space possible shortterm memories instead agents current state space Experimental results partially observable maze difficult driving task visual routines show dramatic performance improvements',\n",
              " 'Performing policy iteration dynamic programming require knowledge relative rather absolute measures utility actions Baird calls advantages actions states Nevertheless existing methods dynamic programming including Bairds compute form absolute utility function For smooth problems advantages satisfy two differential consistency conditions including requirement free curl show enforcing lead appropriate policy improvement solely terms advantages',\n",
              " 'We introduce parallel approach DTSelect selecting features used inductive learning algorithms predict protein secondary structure DTSelect able rapidly choose small nonredundant feature sets pools containing hundreds thousands potentially useful features It building decision tree using features pool classifies set training examples The features included tree provide compact description training data thus suitable use inputs inductive learning algorithms Empirical experiments protein secondarystructure task sets complex features chosen DTSelect used augment standard artificial neural network representation yield surprisingly little performance gain even though features selected large feature pools We discuss possible reasons result',\n",
              " 'This paper presents extension package developed author Faculty Sciences Technology New University Lisbon designed experimentation CoarseGrained Distributed Genetic Algorithms DGA The package implemented extension Basic Sugal system developed Andrew Hunter University Sunderland UK primarily intended used research Sequential Serial Genetic Algorithms SGA',\n",
              " 'We explore representation D objects several distinct D views stored object We demonstrate ability twolayer network thresholded summation units support representations Using unsupervised Hebbian relaxation network learned recognize ten objects different viewpoints The training process led emergence compact representations specific input views When tested novel views objects network exhibited substantial generalization capability In simulated psychophysical experiments networks behavior qualitatively similar human subjects',\n",
              " 'Internal models environment important role play adaptive systems general particular importance supervised learning paradigm In paper demonstrate certain classical problems associated notion teacher supervised learning solved judicious use learned internal models components adaptive system In particular show supervised learning algorithms utilized cases unknown dynamical system intervenes actions desired outcomes Our approach applies supervised learning algorithm capable learning multilayer networks This paper revised version MIT Center Cognitive Science Occasional Paper We wish thank Michael Mozer Andrew Barto Robert Jacobs Eric Loeb James McClelland helpful comments manuscript This project supported part BRSG S RR awarded Biomedical Research Support Grant Program Division Research Resources National Institutes Health grant ATR Auditory Visual Perception Research Laboratories grant Siemens Corporation grant Human Frontier Science Program grant NJ awarded Office Naval Research',\n",
              " 'Technical Report February updated April This paper appear Proceedings Eleventh International Conference Machine Learning Abstract This paper presents algorithm incremental induction decision trees able handle numeric symbolic variables In order handle numeric variables new tree revision operator called slewing introduced Finally nonincremental method given finding decision tree based direct metric candidate tree',\n",
              " 'fl This research primarily conducted author University Calif Santa Cruz support ONR grant NK Harvard University supported ONR grant NK DARPA grant AFOSR Current address NEC Research Institute Independence Way Princeton NJ Email address nicklresearchnjneccom Supported ONR grants NK NJ Part research done author sabbatical Aiken Computation Laboratory Harvard partial support ONR grants NK NK Address Department Computer Science University California Santa Cruz Email address manfredcsucscedu',\n",
              " 'Many recent approaches avoiding utility problem speedup learning rely sophisticated utility measures significant numbers training data accurately estimate utility control knowledge Empirical results presented elsewhere indicate simple selection strategy retaining control rules derived training problem explanation quickly defines efficient set control knowledge training problems This simple selection strategy provides lowcost alternative exampleintensive approaches improving speed problem solver',\n",
              " 'Partigame new algorithm learning feasible trajectories goal regions high dimensional continuous statespaces In high dimensions essential learning plan uniformly statespace Partigame maintains decisiontree partitioning statespace applies techniques gametheory computational geometry efficiently adaptively concentrate high resolution critical areas The current version algorithm designed find feasible paths trajectories goal regions high dimensional spaces Future versions designed find solution optimizes realvalued criterion Many simulated problems tested ranging twodimensional ninedimensional statespaces including mazes path planning nonlinear dynamics planar snake robots restricted spaces In cases good solution found less ten trials minutes',\n",
              " 'Predictive inference seen process determining predictive distribution discrete variable given data set training examples values problem domain variables We consider three approaches computing predictive distribution assume joint probability distribution variables belongs set distributions determined set parametric models In simplest case predictive distribution computed using model maximum posteriori MAP posterior probability In evidence approach predictive distribution obtained averaging individual models model family In third case define predictive distribution using Rissanens new definition stochastic complexity Our experiments performed family Naive Bayes models suggest using data available stochastic complexity approach produces accurate predictions logscore sense However amount available training data decreased evidence approach clearly outperforms two approaches The MAP predictive distribution clearly inferior logscore sense two sophisticated approaches score MAP approach may still cases produce best results',\n",
              " 'Given problem casebased reasoning CBR system search case memory use stored cases find solution possibly modifying retrieved cases adapt required input specifications In paper introduce neural network architecture efficient casebased reasoning We show rigorous Bayesian probability propagation algorithm implemented feedforward neural network adapted CBR In approach efficient indexing problem CBR naturally implemented parallel architecture heuristic matching replaced probability metric This allows CBR perform theoretically sound Bayesian reasoning We also show probability propagation actually offers solution adaptation problem natural way',\n",
              " 'We present new generalpurpose algorithm learning classes valued functions generalization prediction model prove general upper bound expected absolute error algorithm terms scalesensitive generalization Vapnik dimension proposed Alon BenDavid CesaBianchi Haussler We give lower bounds implying upper bounds improved constant factor general We apply result together techniques due Haussler Benedek Itai obtain new upper bounds packing numbers terms scalesensitive notion dimension Using different technique obtain new bounds packing numbers terms Kearns Schapires fatshattering function We show apply packing bounds obtain improved general bounds sample complexity agnostic learning For gt establish weaker sufficient stronger necessary conditions class valued functions agnostically learnable within uniform GlivenkoCantelli class',\n",
              " 'It widely considered ultimate connectionist objective incorporate neural networks intelligent systems These systems intended possess varied repertoire functions enabling adaptable interaction nonstatic environment The first step direction develop various neural network algorithms models second step combine networks modular structure might incorporated workable system In paper consider one aspect second point namely processing reliability hiding wetware details Pre sented architecture type neural expert module named Authority An Authority consists number Minos modules Each Minos modules Authority processing capabilities varies respect particular specialization aspects problem domain The Authority employs collection Minoses like panel experts The expert highest confidence believed answer confidence quotient transmitted levels system hierarchy',\n",
              " 'Partially observable Markov decision processes pomdps model decision problems agent tries maximize reward face limited andor noisy sensor feedback While study pomdps motivated need address realistic problems existing techniques finding optimal behavior appear scale well unable find satisfactory policies problems dozen states After brief review pomdps paper discusses several simple solution methods shows capable finding nearoptimal policies selection extremely small pomdps taken learning literature In contrast show none able solve slightly larger noisier problem based robot navigation We find combination two novel approaches performs well problems suggest methods scaling even larger complicated domains',\n",
              " 'We propose new method construction Markov chains given stationary distribution This method based construction auxiliary chain stationary distribution picking elements auxiliary chain suitable number times The proposed method many advantages rivals It easy implement provides simple analysis faster efficient currently available techniques also adapted course simulation We make theoretical numerical comparisons characteristics proposed algorithm MCMC techniques',\n",
              " 'The problem making optimal decisions uncertain conditions central Artificial Intelligence If state world known times world modeled Markov Decision Process MDP MDPs studied extensively many methods known determining optimal courses action policies The realistic case state information partially observable Partially Observable Markov Decision Processes POMDPs received much less attention The best exact algorithms problems inefficient space time We introduce Smooth Partially Observable Value Approximation SPOVA new approximation method quickly yield good approximations improve time This method combined reinforcement learning methods combination effective test cases',\n",
              " 'The Katsuno Mendelzon KM theory belief update proposed reasonable model revising beliefs changing world However semantics update relies information readily available We describe alternative semantical view update observations incorporated belief set explaining observation terms set plausible events might caused observation b predicting consequences explanations We also allow possibility conditional explanations We show picture naturally induces update operator conforming KM postulates certain assumptions However argue assumptions always reasonable restrict ability integrate update forms revision reasoning action fl Some parts report appeared preliminary form An EventBased Abductive Model Update Proc Tenth Canadian Conf AI Banff Alta',\n",
              " 'This paper specifies main features Brainlike Neuronal Connectionist models argues need usefulness appropriate successively larger brainlike structures examines parallelhierarchical Recognition Cone models perception perspective examples structures The anatomy physiology behavior development visual system briefly summarized motivate architecture brainstructured networks perceptual recognition Results presented simulations carefully predesigned Recognition Cone structures perceive objects eg houses digitized photographs A framework perceptual learning introduced including mechanisms generationdiscovery feedbackguided growth new links nodes subject brainlike constraints eg local receptive fields global convergencedivergence The information processing transforms discovered generation finetuned feedbackguided reweighting links Some preliminary results presented brainstructured networks learn recognize simple objects eg letters alphabet cups apples bananas feedbackguided generation reweighting These show large improvements networks either lack brainlike structure orand learn reweighting links alone',\n",
              " 'The ability restructure decision tree efficiently enables variety approaches decision tree induction would otherwise prohibitively expensive Two approaches described one incremental tree induction ITI nonincremental tree induction using measure tree quality instead test quality DMTI These approaches several variants offer new computational classifier characteristics lend particular applications',\n",
              " 'We consider logistic regression model Gaussian prior distribution parameters We show accurate variational techniques used obtain closed form posterior distribution parameters given data thereby yielding posterior predictive model The results readily extended binary belief networks For belief networks also derive closed form posteriors presence missing values Finally show dual regression problem gives latent variable density model variational formulation leads exactly solvable EM updates',\n",
              " 'Mean field methods provide computationally efficient approximations posterior probability distributions graphical models Simple mean field methods make completely factorized approximation posterior unlikely accurate posterior multimodal Indeed posterior multimodal one modes captured To improve mean field approximation cases employ mixture models posterior approximations mixture component factorized distribution We describe efficient methods optimizing parameters models',\n",
              " 'The success evolutionary methods standard control learning tasks created need new benchmarks The classic pole balancing problem longer difficult enough serve viable yardstick measuring learning efficiency systems In paper present difficult version classic problem cart pole move plane We demonstrate neuroevolution system Enforced SubPopulations ESP solve difficult problem without velocity information',\n",
              " 'This paper introduces explores representational biases efficient learning spatial temporal spatiotemporal patterns connectionist networks CN massively parallel networks simple computing elements It examines learning mechanisms constructively build network structures encode information environmental stimuli successively higher resolutions needed tasks eg perceptual recognition network perform Some simple examples presented illustrate basic structures processes used networks ensure parsimony learned representations guiding system focus efforts minimal adequate resolution Several extensions basic algorithm efficient learning using multiresolution representations spatial temporal spatiotemporal patterns discussed',\n",
              " 'Qlearning uses TDmethods accelerate Qlearning The update complexity previous online Q implementations based lookuptables bounded size stateaction space Our faster algorithms update complexity bounded number actions The method based observation Qvalue updates may postponed needed',\n",
              " 'Massively parallel networks relatively simple computing elements offer attractive versatile framework exploring variety learning structures processes intelligent systems This paper briefly summarizes popular learning structures processes used networks It outlines range potentially powerful alternatives patterndirected inductive learning systems It motivates develops class new learning algorithms massively parallel networks simple computing elements We call class learning processes generative offer set mechanisms constructive adaptive determination network architecture number processing elements connectivity among function experience Generative learning algorithms attempt overcome limitations approaches learning networks rely modification weights links within otherwise fixed network topology eg rather slow learning need apriori choice network architecture Several alternative designs well range control structures processes used regulate form content internal representations learned networks examined Empirical results study generative learning algorithms briefly summarized several extensions refinements algorithms directions future research outlined',\n",
              " 'The use artificial neural networks domain autonomous vehicle navigation produced promising results ALVINN Pomerleau shown neural system drive vehicle reliably safely many different types roads ranging paved paths interstate highways Even impressive results several areas within neural paradigm autonomous road following still need addressed These include transparent navigation roads different type simultaneous use different sensors generalization road types neural system never seen The system presented addresses issue modular neural architecture uses pretrained ALVINN networks connectionist superstructure robustly drive many dif ferent types roads',\n",
              " 'We introduce constructive incremental learning system regression problems models data means locally linear experts In contrast approaches experts trained independently compete data learning Only prediction query required experts cooperate blending individual predictions Each expert trained minimizing penalized local cross val dation error using second order methods In way expert able find local distance metric adjusting size shape rece p tive field predictions valid also detect relevant n put features adjusting bias importance individual input dimensions We derive asymptotic results method In variety simulations properties algorithm demonstrated respect interference learning speed prediction accuracy feature detection task oriented incremental learning',\n",
              " 'The model nonBayesian agent faces repeated game incomplete information Nature appropriate tool modeling general agentenvironment interactions In model environment state controlled Nature may change arbitrarily feedbackreward function initially unknown The agent Bayesian form prior probability neither state selection strategy Nature reward function A policy agent function assigns action every history observations actions Two basic feedback structures considered In one perfect monitoring case agent able observe previous environment state part feedback imperfect monitoring case available agent reward obtained Both settings refer partially observable processes current environment state unknown Our main result refers competitive ratio criterion perfect monitoring case We prove existence efficient stochastic policy ensures competitive ratio obtained almost stages arbitrarily high probability efficiency measured terms rate convergence It shown optimal policy exist imperfect monitoring case Moreover proved perfect monitoring case exist deterministic policy satisfies long run optimality criterion In addition discuss maxmin criterion prove deterministic efficient optimal strategy exist imperfect monitoring case criterion Finally show approach longrun optimality viewed qualitative distinguishes previous work area',\n",
              " 'We describe polynomialtime algorithm learning axisaligned rectangles Q respect product distributions multipleinstance examples PAC model Here example consists n elements Q together label indicating whether n points rectangle learned We assume unknown product distribution D Q instances independently drawn according D The accuracy hypothesis measured probability would incorrectly predict whether one n points drawn D rectangle learned Our algorithm achieves accuracy probability ffi',\n",
              " 'We present new machine learning method given set training examples induces definition target concept terms hierarchy intermediate concepts definitions This effectively decomposes problem smaller less complex problems The method inspired Boolean function decomposition approach design digital circuits To cope high time complexity finding optimal decomposition propose suboptimal heuristic algorithm The method implemented program HINT HIerarchy Induction Tool experimentally evaluated using set artificial realworld learning problems It shown method performs well terms classification accuracy discovery meaningful concept hierarchies',\n",
              " 'In context inductive learning Bayesian approach turned successful estimating probabilities events learning examples The mprobability estimate developed handle situations In paper present mdistribution estimate extension mprobability estimate besides estimation probabilities covers also estimation probability distributions We focus application construction regression trees The theoretical results incorporated system automatic induction regression trees The results applying upgraded system several domains presented compared previous results',\n",
              " 'Realworld learning tasks often involve highdimensional data sets complex patterns missing features In paper review problem learning incomplete data two statistical perspectivesthe likelihoodbased Bayesian The goal twofold place current neural network approaches missing data within statistical framework describe set algorithms derived likelihoodbased framework handle clustering classification function approximation incomplete data principled efficient manner These algorithms based mixture modeling make two distinct appeals ExpectationMaximization EM principle Dempster et al estimation mixture components coping missing data This report describes research done Center Biological Computational Learning Artificial Intelligence Laboratory Massachusetts Institute Technology Support Center provided part grant National Science Foundation contract ASC Support laboratorys artificial intelligence research provided part Advanced Research Projects Agency Department Defense The authors supported part grant ATR Auditory Visual Perception Research Laboratories grant Siemens Corporation grant IRI National Science Foundation grant NJ Office Naval Research Zoubin Ghahramani supported grant McDonnellPew Foundation Michael I Jordan NSF Presidential Young Investigator',\n",
              " 'Recently proven dynamics deterministic finitestate automata DFA n states input symbols implemented sparse secondorder recurrent neural network SORNN n state neurons Omn secondorder weights sigmoidal discriminant functions We investigate constructive algorithm extended faulttolerant neural DFA implementations faults analog implementation neurons weights affect desired network performance We show tolerance weight perturbation achieved easily tolerance weight andor neuron stuckatzero faults however requires duplication network resources This result impact construction neural DFAs dense internal representation DFA states',\n",
              " 'Technical Report No Department Statistics University Washington October Abhijit Dasgupta graduate student Department Biostatistics University Washington Box Seattle WA email address dasguptabiostatwashingtonedu Adrian E Raftery Professor Statistics Sociology Department Statistics University Washington Box Seattle WA email address rafterystatwashingtonedu This research supported Office Naval Research Grant NJ The authors grateful Peter Guttorp Girardeau Henderson Robert Muise helpful discussions',\n",
              " 'In multiarmed bandit problem gambler must decide arm K nonidentical slot machines play sequence trials maximize reward This classical problem received much attention simple model provides tradeoff exploration trying arm find best one exploitation playing arm believed give best payoff Past solutions bandit problem almost always relied assumptions statistics slot machines In work make statistical assumptions whatsoever nature process generating payoffs slot machines We give solution bandit problem adversary rather wellbehaved stochastic process complete control payoffs In sequence T plays prove expected perround payoff algorithm approaches best arm rate OT give improved rate convergence best arm fairly low payoff We also prove general matching lower bound best possible performance algorithm setting In addition consider setting player team experts advising arm play give strategy guarantee expected payoff close best expert Finally apply result problem learning play unknown repeated matrix game allpowerful adversary',\n",
              " 'We show alternative way representing Bayesian belief network sensitivities probability distributions This representation equivalent traditional representation conditional probabilities makes dependencies nodes apparent intuitively easy understand We also propose QR matrix representation sensitivities andor conditional probabilities efficient memory requirements computational speed traditional representation computerbased implementations probabilistic inference We use sensitivities show certain class binary networks computation time approximate probabilistic inference positive upper bound error result independent size network Finally alternative traditional algorithms use conditional probabilities describe exact algorithm probabilistic inference uses QRrepresentation sensitivities updates probability distributions nodes network according messages neigh bors',\n",
              " 'The requirement train large neural networks quickly prompted design new massively parallel supercomputer using custom VLSI This design features processing nodes communicating mesh network connected directly processor chip Studies show peak performance range billion arithmetic operations per second This paper presents case custom hardware combines neural networkspecific features general programmable machine architecture briefly describes design progress',\n",
              " 'In many realworld domains like text categorization supervised learning requires large number training examples In paper describe active learning method uses committee learners reduce number training examples required learning Our approach similar Query Committee framework disagreement among committee members predicted label input part example used signal need knowing actual value label Our experiments text categorization using committee Winnowbased learners demonstrate approach reduce number labeled training examples required used single Winnow learner orders magnitude This paper review accepted publication another conference journal Acknowledgements The availability Reuters corpus Reuters STAT Data Manipulation Analysis Programs Perlman greatly assisted research date',\n",
              " 'covering formalized used extensively In work divideandconquer technique formalized well compared covering technique logic programming framework Covering works repeatedly specializing overly general hypothesis iteration focusing finding clause high coverage positive examples Divideandconquer works specializing overly general hypothesis focusing discriminating positive negative examples Experimental results presented demonstrating cases accurate hypotheses found divideandconquer covering Moreover since covering considers alternatives repeatedly tends less efficient divideandconquer never considers alternative twice On hand covering searches larger hypothesis space may result compact hypotheses found technique divideandconquer Furthermore divideandconquer contrast covering applicable learn ing recursive definitions',\n",
              " 'This paper introduces Recurrence Surface Approximation inductive learning method based linear programming predicts recurrence times using censored training examples examples available training output may lower bound right answer This approach augmented feature selection method chooses appropriate feature set within context linear programming generalizer Computational results field breast cancer prognosis shown A straightforward translation prediction method artificial neural network model also proposed',\n",
              " 'Minimum Message Length MML invariant Bayesian point estimation technique also consistent efficient We provide brief overview MML inductive inference Wallace Boulton Wallace Freeman informationtheoretic Bayesian interpretation We outline MML used statistical parameter estimation MML mixture modelling program Snob Wallace Boulton Wallace Wallace Dowe uses message lengths various parameter estimates enable combine parameter estimation selection number components The message length within constant logarithm posterior probability theory So MML theory also regarded theory highest posterior probability Snob currently assumes variables uncorrelated permits multivariate data Gaussian discrete multistate Poisson von Mises circular distributions',\n",
              " 'One challenges models cognitive phenomena development efficient exible interfaces low level sensory information high level processes For visual processing researchers long argued attentional mechanism required perform many tasks required high level vision This thesis presents VISIT connectionist model covert visual attention used vehicle studying interface The model efficient exible biologically plausible The complexity network linear number pixels Effective parallel strategies used minimize number iterations required The resulting system able efficiently solve two tasks particularly difficult standard bottomup models vision computing spatial relations visual search Simulations show networks behavior matches much known psychophysical data human visual attention The general architecture model also closely matches known physiological data human attention system Various extensions VISIT discussed including methods learning component modules',\n",
              " 'A Lyapunov function excitatoryinhibitory networks constructed The construction assumes symmetric interactions within excitatory inhibitory populations neurons antisymmetric interactions populations The Lyapunov function yields sufficient conditions global asymptotic stability fixed points If conditions violated limit cycles may stable The relations Lyapunov function optimization theory classical mechanics revealed The dynamics neural network symmetric interactions provably converges fixed points general assumptions This mathematical result helped establish paradigm neural computation fixed point attractors But reality interactions neurons brain asymmetric Furthermore dynamical behaviors seen brain confined fixed point attractors also include oscillations complex nonperiodic behavior These types dynamics realized asymmetric networks may useful neural computation For reasons important understand global behavior asymmetric neural networks The interaction excitatory neuron inhibitory neuron clearly asymmetric Here consider class networks incorporates fundamental asymmetry brains microcircuitry Networks class distinct populations excitatory inhibitory neurons antisymmetric interactions minimax dissipative Hamiltonian forms network dynamics',\n",
              " 'In Bayesian inference Bayes factor defined ratio posterior odds versus prior odds posterior odds simply ratio normalizing constants two posterior densities In many practical problems two posteriors different dimensions For cases current Monte Carlo methods bridge sampling method Meng Wong path sampling method Gelman Meng ratio importance sampling method Chen Shao directly applied In article extend importance sampling bridge sampling ratio importance sampling problems different dimensions Then find global optimal importance sampling bridge sampling ratio importance sampling sense minimizing asymptotic relative meansquare errors estimators Implementation algorithms asymptotically achieve optimal simulation errors developed two illustrative examples also provided',\n",
              " 'As knowledge bases used AI systems increase size access relevant information dominant factor cost inference This especially true analogical casebased reasoning ability system perform inference dependent efficient flexible access large base exemplars cases judged likely relevant solving problem hand In chapter discuss novel algorithm efficient associative matching relational structures large semantic networks The structure matching algorithm uses massively parallel hardware search memory knowledge structures matching given probe structure The algorithm built top PARKA massively parallel knowledge representation system runs Connection Machine We currently exploring utility algorithm CaPER casebased planning system',\n",
              " 'We consider use online stopping rules reduce number training examples needed paclearn Rather collect large training sample proved sufficient eliminate bad hypotheses priori idea instead observe training examples oneatatime decide online whether stop return hypothesis continue training The primary benefit approach detect hypothesizer actually converged halt training standard fixedsamplesize bounds This paper presents series sequential learning procedures distributionfree paclearning mistakebounded pac conversion distributionspecific paclearning respectively We analyze worst case expected training sample size procedures show often smaller existing fixed sample size bounds still providing exact worst case pacguarantees We also provide lower bounds show reductions best involve constant possibly log factors However empirical studies show sequential learning procedures actually use many times fewer training examples practice',\n",
              " 'This paper presents novel approach determine structural similarity guidance adaptation casebased reasoning Cbr We advance structural similarity assessment provides single numeric value specific structure two cases common inclusive modification rules needed obtain structure two cases Our approach treats retrieval matching adaptation group dependent processes This guarantees retrieval matching similar adaptable cases Both together enlarge overall problem solving performance Cbr explainability case selection adaptation considerably Although approach theoretical nature restricted specific domain give example taken domain industrial building design Additionally sketch two prototypical implementations approach',\n",
              " 'We analyze blameassignment task context experiencebased design redesign physical devices We identify three types blameassignment tasks differ types information take input design achieve desired behavior device design results undesirable behavior specific structural element design misbehaves We describe modelbased approach solving blameassignment task This approach uses structurebehaviorfunction models capture designers comprehension way device works terms causal explanations structure results behaviors We also address issue indexing models memory We discuss three types blameassignment tasks require different types indices accessing models Finally describe KRITIK system implements evaluates modelbased approach blame assignment',\n",
              " 'We present framework taskdriven knowledge acquisition development design support systems Different types knowledge enter knowledge base design support system defined illustrated formal knowledge acquisition vantage point Special emphasis placed taskstructure used guide acquisition application knowledge Starting knowledge planning steps design augmenting problemsolving knowledge supports design formal integrated model knowledge design constructed Based notion knowledge acquisition incremental process give account possibilities problem solving depending knowledge disposal system Finally depict different kinds knowledge interact design support system This research supported German Ministry Research Technology BMFT within joint project FABEL contract IW Project partners FABEL German National Research Center Computer Science GMD Sankt Augustin BSR Consulting GmbH Munchen Technical University Dresden HTWK Leipzig University Freiburg University Karlsruhe',\n",
              " 'The activity sorting like objects classes without help omniscient supervisor known unsupervised classification In AI symbolic connectionist camps study classification The statistical classifiers Autoclass Snob search theory best explain distribution given data whereas neural network classifiers Kohonens networks ART use vector quantization principle classifying data Previously many studies compared supervised classification algorithms challenging problem comparing unsupervised classifiers largely ignored We performed empirical comparison ART Autoclass Snob We highlight strengths weaknesses various classifiers Overall statistical classifiers especially Snob perform better neural network counterpart ART',\n",
              " 'AI research casebased reasoning led development many laboratory casebased systems As move towards introducing systems work environments explaining processes casebased reasoning becoming increasingly important issue In paper describe notion metacase illustrating explaining justifying casebased reasoning A metacase contains trace processing problemsolving episode provides explanation problemsolving decisions partial justification solution The language representing problemsolving trace depends model problem solving We describe taskmethod knowledge TMK model problemsolving describe representation metacases TMK language We illustrate explanatory scheme examples Interactive Kritik computerbased de',\n",
              " 'Statistical decision theory provides principled way estimate amino acid frequencies conserved positions protein family The goal minimize risk function expected squarederror distance estimates true population frequencies The minimumrisk estimates obtained adding optimal number pseudocounts observed data Two formulas presented one pseudocounts based marginal amino acid frequencies one pseudocounts based observed data Experimental results show profiles constructed using minimalrisk estimates discriminating constructed using existing methods',\n",
              " 'The purpose paper propose refinement notion innateness If merely identify innateness bias obtain poor characterisation notion since learning device relies bias makes choose given hypothesis instead another We show intuition innateness better captured characteristic bias related isotropy Generalist models learning shown rely isotropic bias whereas bias specialised models include specific priori knowledge learned necessarily anisotropic The socalled generalist models however turn specialised way learn symmetrical forms preferentially strictly deficiencies learning ability Because learning beings always show two properties generalist models may sometimes ruled bad candidates cognitive modelling',\n",
              " 'Reliable visionbased control autonomous vehicle requires ability focus attention important features input scene Previous work autonomous lane following system ALVINN Pomerleau yielded good results uncluttered conditions This paper presents artificial neural network based learning approach handling difficult scenes confuse ALVINN system This work presents mechanism achieving taskspecific focus attention exploiting temporal coherence A saliency map based upon computed expectation contents inputs next time step indicates regions input retina important performing task The saliency map used accentuate features important task deemphasize',\n",
              " 'Production scheduling problem sequentially configuring factory meet forecasted demands critical problem throughout manufacturing industry The requirement maintaining product inventories face unpredictable demand stochastic factory output makes standard scheduling models jobshop inadequate Currently applied algorithms simulated annealing constraint propagation must employ adhoc methods frequent replanning cope uncertainty In paper describe Markov Decision Process MDP formulation production scheduling captures stochasticity production demands The solution MDP value function used generate optimal scheduling decisions online A simple example illustrates theoretical superiority approach replanningbased methods We describe industrial application two reinforcement learning methods generating approximate value function domain Our results demonstrate deterministic noisy scenarios value function approximation effective technique',\n",
              " 'In paper investigate new formal model machine learning concept boolean function learned may exhibit uncertain probabilistic behaviorthus input may sometimes classified positive example sometimes negative example Such probabilistic concepts pconcepts may arise situations weather prediction measured variables accuracy insufficient determine outcome certainty We adopt Valiant model learning demands learning algorithms efficient general sense perform well wide class pconcepts distribution domain In addition giving many efficient algorithms learning natural classes pconcepts study develop detail underlying theory learning pconcepts',\n",
              " 'This paper highlights phenomenon causes deductively learned knowledge harmful used problem solving The problem occurs deductive problem solvers encounter failure branch search tree The backtracking mechanism problem solvers force program traverse whole subtree thus visiting many nodes twice using deductively learned rule using rules generated learned rule first place We suggest approach called utilization filtering solve problem Learners use approach submit problem solver filter function together knowledge acquired The function decides problem whether use learned knowledge part use We tested idea context lemma learning system filter uses probability subgoal failing decide whether turn lemma usage Experiments show improvement performance factor This paper concerned particular type harmful redundancy occurs deductive problem solvers employ backtracking search procedure use deductively learned knowledge accelerate search The problem failure branches search tree backtracking mechanism problem solver forces exploration whole subtree Thus search procedure visit many states twice using deductively learned rule using search path produced rule first place',\n",
              " 'fl The authors thank Rich Yee Vijay Gullapalli Brian Pinette Jonathan Bachrach helping clarify relationships heuristic search control We thank Rich Sutton Chris Watkins Paul Werbos Ron Williams sharing fundamental insights subject numerous discussions thank Rich Sutton first making us aware Korfs research thoughtful comments manuscript We grateful Dimitri Bertsekas Steven Sullivan independently pointing error earlier version article Finally thank Harry Klopf whose insight persistence encouraged interest class learning problems This research supported grants AG Barto National Science Foundation ECS ECS Air Force Office Scientific Research Bolling AFB AFOSR',\n",
              " 'Technical Report OSUCISRC TR Abstract One classical topics neural networks winnertakeall WTA widely used unsupervised competitive learning cortical processing attentional control Because global connectivity WTA networks however encode spatial relations input thus support sensory perceptual processing spatial relations important We propose new architecture maintains spatial relations input features This selection network builds LEGION Locally Excitatory Globally Inhibitory Oscillator Networks dynamics slow inhibition In input scene many objects patterns network selects largest object This system easily adjusted select several largest objects alternate time We show twostage selection network gains efficiency combining selection parallel removal noisy regions The network applied select salient object real images As special case selection network without local excitation gives rise new form oscillatory WTA',\n",
              " 'Reinforcement learning RL become central paradigm solving learningcontrol problems robotics artificial intelligence RL researchers focussed almost exclusively problems controller maximize discounted sum payoffs However emphasized Schwartz many problems eg optimal behavior limit cycle natural computationally advantageous formulate tasks controllers objective maximize average payoff received per time step In paper I derive new averagepayoff RL algorithms stochastic approximation methods solving system equations associated policy evaluation optimal control questions averagepayoff RL tasks These algorithms analogous popular TD Qlearning algorithms already developed discountedpayoff case One algorithms derived significant variation Schwartzs Rlearning algorithm Preliminary empirical results presented validate new algorithms',\n",
              " 'We present algorithms exactly learning unknown environments described deterministic finite automata The learner performs walk target automaton step observes output state chooses labeled edge traverse next state The learner means reset access teacher answers equivalence queries gives learner counterexamples hypotheses We present two algorithms The first case outputs observed learner always correct second case outputs might corrupted random noise The running times algorithms polynomial cover time underlying graph target automaton',\n",
              " 'Exploring mapping unknown environment fundamental problem studied variety contexts Many works focused finding efficient solutions restricted versions problem In paper consider model makes limited assumptions environment solve mapping problem general setting We model environment unknown directed graph G consider problem robot exploring mapping G We assume vertices G labeled thus robot hope succeeding unless given means distinguishing vertices For reason provide robot pebble device place vertex use identify vertex later In paper show If robot knows upper bound number vertices learn graph efficiently one pebble If robot know upper bound number vertices n filog log n pebbles necessary sufficient In cases algorithms deterministic',\n",
              " 'In recent years increasing interest learning Bayesian networks data One effective methods learning networks based minimum description length MDL principle Previous work shown learning procedure asymptotically successful probability one converge target distribution given sufficient number samples However rate convergence hitherto unknown In work examine sample complexity MDL based learning procedures Bayesian networks We show number samples needed learn close approximation terms entropy distance confidence ffi O log ffi log log This means sample complexity loworder polynomial error threshold sublinear confidence bound We also discuss constants term depend complexity target distribution Finally address questions asymptotic minimality propose method using sample complexity results speed learning process',\n",
              " 'Almost work Averagereward Reinforcement Learning ARL far focused tablebased methods scale domains large state spaces In paper propose two extensions modelbased ARL method called Hlearning address scaleup problem We extend Hlearning learn action models reward functions form Bayesian networks approximate value function using local linear regression We test algorithms several scheduling tasks simulated Automatic Guided Vehicle AGV show effective significantly reducing space requirement Hlearning making converge faster To best knowledge results first apply ing function approximation ARL',\n",
              " 'Understanding highdimensional real world data usually requires learning structure data space The structure may contain highdimensional clusters related complex ways Methods merge clustering selforganizing maps designed aid visualization interpretation data However methods often fail capture critical structural properties input Although selforganizing maps capture highdimensional topology represent cluster boundaries discontinuities Merge clustering extracts clusters capture local global topology This paper proposes algorithm combines topologypreserving characteristics selforganizing maps flexible adaptive structure learns cluster bound aries data',\n",
              " 'Although building sophisticated learning agents operate complex environments require learning perform multiple tasks applications reinforcement learning focussed single tasks In paper I consider class sequential decision tasks SDTs called composite sequential decision tasks formed temporally concatenating number elemental sequential decision tasks Elemental SDTs decomposed simpler SDTs I consider learning agent learn solve set elemental composite SDTs I assume structure composite tasks unknown learning agent The straightforward application reinforcement learning multiple tasks requires learning tasks separately waste computational resources memory time I present new learning algorithm modular architecture learns decomposition composite SDTs achieves transfer learning sharing solutions elemental SDTs across multiple composite SDTs The solution composite SDT constructed computationally inexpensive modifications solutions constituent elemental SDTs I provide proof one aspect learning algorithm',\n",
              " 'Existing approaches learning control robot arm rely supervised methods correct behavior explicitly given It difficult learn avoid obstacles using methods however examples obstacle avoidance behavior hard generate This paper presents alternative approach evolves neural network controllers genetic algorithms No inputoutput examples necessary since neuroevolution learns single performance measurement entire task grasping object The approach tested simulation OSCAR robot arm receives visual sensory input Neural networks evolved effectively avoid obstacles various locations reach random target locations',\n",
              " 'It widely accepted use compact representations lookup tables crucial scaling reinforcement learning RL algorithms realworld problems Unfortunately almost theory reinforcement learning assumes lookup table representations In paper address pressing issue combining function approximation RL present function approximator based simple extension state aggregation commonly used form compact representation namely soft state aggregation theory convergence RL arbitrary fixed soft state aggregation novel intuitive understanding effect state aggregation online RL new heuristic adaptive state aggregation algorithm finds improved compact representations exploiting nondiscrete nature soft state aggregation Preliminary empirical results also presented',\n",
              " 'This article introduces class incremental learning procedures specialized predictionthat using past experience incompletely known system predict future behavior Whereas conventional predictionlearning methods assign credit means difference predicted actual outcomes new methods assign credit means difference temporally successive predictions Although temporaldifference methods used Samuels checker player Hollands bucket brigade authors Adaptive Heuristic Critic remained poorly understood Here prove convergence optimality special cases relate supervisedlearning methods For realworld prediction problems temporaldifference methods require less memory less peak computation conventional methods produce accurate predictions We argue problems supervised learning currently applied really prediction problems sort temporaldifference methods applied advantage',\n",
              " 'This paper extends previous work Dyna class architectures intelligent systems based approximating dynamic programming methods Dyna architectures integrate trialanderror reinforcement learning executiontime planning single process operating alternately world learned model world In paper I present show results two Dyna architectures The DynaPI architecture based dynamic programmings policy iteration method related existing AI ideas evaluation functions universal plans reactive systems Using navigation task results shown simple DynaPI system simultaneously learns trial error learns world model plans optimal routes using evolving world model The DynaQ architecture based Watkinss Qlearning new kind reinforcement learning DynaQ uses less familiar set data structures DynaPI arguably simpler implement use We show DynaQ architectures easy adapt use changing environments',\n",
              " 'On large problems reinforcement learning systems must use parameterized function approximators neural networks order generalize similar situations actions In cases strong theoretical results accuracy convergence computational results mixed In particular Boyan Moore reported last years meeting series negative results attempting apply dynamic programming together function approximation simple control problems continuous state spaces In paper present positive results control tasks attempted one significantly larger The important differences used sparsecoarsecoded function approximators CMACs whereas used mostly global function approximators learned online whereas learned oine Boyan Moore others suggested problems encountered could solved using actual outcomes rollouts classical Monte Carlo methods TD algorithm However experiments always resulted substantially poorer performance We conclude reinforcement learning work robustly conjunction function approximators little justification present avoiding case general',\n",
              " 'We consider requirements online learninglearning must done incrementally realtime results learning available soon new example acquired Despite abundance methods learning examples used effectively online learning eg components reinforcement learning systems Most including radial basis functions CMACs Kohonens selforganizing maps developed paper share structure All expand original input representation higher dimensional representation unsupervised way map representation final answer using relatively simple supervised learner perceptron LMS rule Such structures learn rapidly reliably thought either scale poorly require extensive domain knowledge To contrary researchers Rosenblatt Gallant Smith Kanerva Prager Fallside argued expanded representation chosen largely random good results The main contribution paper develop test hypothesis We show simple randomrepresentation methods perform well nearestneighbor methods suited online learning significantly better backpropagation We find size random representation increase dimensionality problem unreasonably required size reduced substantially using unsupervisedlearning techniques Our results suggest randomness useful role play online supervised learning constructive induction',\n",
              " 'We consider problem dynamically apportioning resources among set options worstcase online framework The model study interpreted broad abstract extension wellstudied online prediction model general decisiontheoretic setting We show multiplicative weightupdate rule Littlestone Warmuth adapted model yielding bounds slightly weaker cases applicable considerably general class learning problems We show resulting learning algorithm applied variety problems including gambling multipleoutcome prediction repeated games prediction points R n',\n",
              " 'A new online learning algorithm minimizes statistical dependency among outputs derived blind separation mixed signals The dependency measured average mutual information MI outputs The source signals mixing matrix unknown except number sources The GramCharlier expansion instead Edgeworth expansion used evaluating MI The natural gradient approach used minimize MI A novel activation function proposed online learning algorithm equivariant property easily implemented neural network like model The validity new learning algorithm verified computer simulations',\n",
              " 'Overfitting wellknown problem fields symbolic connectionist machine learning It describes deterioration generalisation performance trained model In paper investigate ability novel artificial neural network bpsom avoid overfitting bpsom hybrid neural network combines multilayered feedforward network mfn Kohonens selforganising maps soms During training supervised backpropagation learning unsupervised som learning cooperate finding adequate hiddenlayer representations We show bpsom outperforms standard backpropagation also backpropagation weight decay dealing problem overfitting In addition show bpsom succeeds preserving generalisation performance hiddenunit pruning methods fail',\n",
              " 'We describe model iterated belief revision extends AGM theory revision account effect revision conditional beliefs agent In particular model ensures agent makes changes possible conditional component belief set Adopting Ramsey test minimal conditional revision provides acceptance conditions arbitrary rightnested conditionals We show problem determining acceptance nested conditional reduced acceptance tests unnested conditionals Thus iterated revision accomplished virtual manner using uniterated revision',\n",
              " 'Reinforcement learning techniques address problem learning select actions unknown dynamic environments It widely acknowledged use complex domains reinforcement learning techniques must combined generalizing function approximation methods artificial neural networks Little however understood theoretical properties combinations many researchers encountered failures practice In paper identify prime source failuresnamely systematic overestimation utility values Using Watkins QLearning example give theoretical account phenomenon deriving conditions one may expected cause learning fail Employing popular function approximators present experimental results support theoretical findings',\n",
              " 'We derive new selforganising learning algorithm maximises information transferred network nonlinear units The algorithm assume knowledge input distributions defined zeronoise limit Under conditions information maximisation extra properties found linear case Linsker The nonlinearities transfer function able pick higherorder moments input distributions perform something akin true redundancy reduction units output representation This enables network separate statistically independent components inputs higherorder generalisation Principal Components Analysis We apply network source separation cocktail party problem successfully separating unknown mixtures ten speakers We also show variant network architecture able perform blind deconvolution cancellation unknown echoes reverberation speech signal Finally derive dependencies information transfer time delays We suggest information maximisation provides unifying framework problems blind signal processing fl Please send comments tonysalkedu This paper appear Neural Computation The reference version Technical Report INC February Institute Neural Computation UCSD San Diego CA',\n",
              " 'This paper multidisciplinary review empirical statistical learning graphical model perspective Wellknown examples graphical models include Bayesian networks directed graphs representing Markov chain undirected networks representing Markov field These graphical models extended model data analysis empirical learning using notation plates Graphical operations simplifying manipulating problem provided including decomposition differentiation manipulation probability models exponential family Two standard algorithm schemas learning reviewed graphical framework Gibbs sampling expectation maximization algorithm Using operations schemas popular algorithms synthesized graphical specification This includes versions linear regression techniques feedforward networks learning Gaussian discrete Bayesian networks data The paper concludes sketching implications data analysis summarizing popular algorithms fall within framework presented',\n",
              " 'The utility problem speedup learning describes common behavior machine learning methods eventual degradation performance due increasing amounts learned knowledge The shape learning curve cost using learning method vs number training examples several domains suggests parameterized model relating performance amount learned knowledge mechanism limit amount learned knowledge optimal performance Many recent approaches avoiding utility problem speedup learning rely sophisticated utility measures significant numbers training data accurately estimate utility control knowledge Empirical results presented elsewhere indicate simple selection strategy retaining control rules derived training problem explanation quickly defines efficient set control knowledge training problems This simple selection strategy provides lowcost alternative exampleintensive approaches improving speed problem solver Experimentation illustrates existence minimum representing least cost learning curve reached training examples Stress placed controlling amount learned knowledge opposed knowledge An attempt also made relate domain characteristics shape learning curve',\n",
              " 'We compare kernel estimators single multilayered perceptrons radialbasis functions problems classification handwritten digits speech phonemes By taking two different applications employing many techniques report twodimensional study whereby domainindependent assessment learning methods possible We consider feedforward network one hidden layer As examples local methods use kernel estimators like knearest neighbor knn Parzen windows generalized knn Grow Learn Condensed Nearest Neighbor We also considered fuzzy knn due similarity As distributed networks use linear perceptron pairwise separating linear perceptron multilayer perceptrons sigmoidal hidden units We also tested radialbasis function network combination local distributed networks Four criteria taken comparison Correct classification test set network size learning time operational complexity We found perceptrons architecture suitable generalize better local memorybased kernel estimators require longer training precise computation Local networks simple learn quickly acceptably use memory',\n",
              " 'In current CBR systems case adaptation usually performed rulebased methods use taskspecific rules handcoded system developer The ability define rules depends knowledge task domain may available priori presenting serious impediment endowing CBR systems needed adaptation knowledge This paper describes ongoing research method address problem acquiring adaptation knowledge experience The method uses reasoning scratch based introspective reasoning requirements successful adaptation build library adaptation cases stored future reuse We describe tenets approach types knowledge requires We sketch initial computer implementation lessons learned open questions study',\n",
              " 'This position paper sketches framework modeling introspective reasoning discusses relevance framework modeling introspective reasoning memory search It argues effective flexible memory processing rich memories built five types explicitly represented selfknowledge knowledge information needs relationships different types information expectations actual behavior information search process desires ideal behavior representations expectations desires relate actual performance This approach modeling memory search illustration general principles modeling introspective reasoning step towards addressing problem reasoner human machinecan acquire knowledge properties knowledge base',\n",
              " 'Machine learning techniques perceived great potential means acquisition knowledge nevertheless use complex engineering domains still rare Most machine learning techniques studied context knowledge acquisition well defined tasks classification Learning tasks handled relatively simple algorithms Complex domains present difficulties approached combining strengths several complementing learning techniques overcoming weaknesses providing alternative learning strategies This study presents two perspectives macro micro viewing issue multistrategy learning The macro perspective deals decomposition overall complex learning task relatively welldefined learning tasks micro perspective deals designing multistrategy learning techniques supporting acquisition knowledge task The two perspectives discussed context',\n",
              " 'In order learn effectively reasoner must possess knowledge world able improve knowledge also must introspectively reason performs given task particular pieces knowledge needs improve performance current task Introspection requires declarative representations metaknowledge reasoning performed system performance task systems knowledge organization knowledge This chapter presents taxonomy possible reasoning failures occur performance task declarative representations failures associations failures particular learning strategies The theory based MetaXPs explanation structures help system identify failure types formulate learning goals choose appropriate learning strategies order avoid similar mistakes future The theory implemented computer model introspective reasoner performs multistrategy learning story understanding task',\n",
              " 'We introduce learning algorithm unsupervised neural networks based ideas statistical mechanics The algorithm derived mean field approximation large layered sigmoid belief networks We show approximately infer statistics networks without resort sampling This done solving mean field equations relate statistics unit Markov blanket Using statistics target values weights network adapted local delta rule We evaluate strengths weaknesses networks problems statistical pattern recognition',\n",
              " 'The paper describes selflearning control system mobile robot Based sensor information control system provide steering signal way collisions avoided Since case examples available system learns basis external reinforcement signal negative case collision zero otherwise We describe adaptive algorithm used discrete coding state space adaptive algorithm learning correct mapping input state vector output steering signal',\n",
              " 'fl Partially supported Advanced Research Projects Agency AFOSR Partially supported Air Force Office Scientific Research AFOSR FJ Advanced Research Projects Agency ONR NJ Office Naval Research ONR NJ z Partially funded Air Force Office Scientific Research AFOSR FJ Office Naval Research ONR NJ ONR N',\n",
              " 'The problem approximating smooth L p functions spaces spanned integer translates radially symmetric function well understood In case points translation ffi scattered throughout R approximation problem well understood stationary setting In work treat nonstationary setting assumption ffi small perturbation Z Our results similar many respects known results case ffi Z apply specifically examples Gauss kernel Generalized Multiquadric',\n",
              " 'In paper initiate investigation generalizations Probably Approximately Correct PAC learning model attempt significantly weaken target function assumptions The ultimate goal direction informally termed agnostic learning make virtually assumptions target function The name derives fact designers learning algorithms give belief Nature represented target function simple succinct explanation We give number positive negative results provide initial outline possibilities agnostic learning Our results include hardness results obvious generalization PAC model agnostic setting efficient general agnostic learning method based dynamic programming relationships loss functions agnostic learning algorithm learning problem involves hidden variables',\n",
              " 'In paper describe design implementation derivation replay framework dersnlpebl Derivational snlpebl based within partial order planner dersnlpebl replays previous plan derivations first repeating earlier decisions context new problem situation extending replayed path obtain complete solution new problem When replayed path extended new solution explanationbased learning ebl techniques employed identify features new problem prevent extension These features added censors retrieval stored case To keep retrieval costs low dersnlpebl normally stores plan derivations individual goals replays one derivations solving multigoal problems Cases covering multiple goals stored subplans individual goals successfully merged The aim constructing case library predict goal interactions store multigoal case set negatively interacting goals We provide empirical results demonstrating effectiveness dersnlpebl improving planning performance randomlygenerated problems drawn complex domain',\n",
              " 'Previous algorithms supervised sequence learning based dynamic recurrent networks This paper describes alternative class gradientbased systems consisting two feedforward nets learn deal temporal sequences using fast weights The first net learns produce context dependent weight changes second net whose weights may vary quickly The method offers potential STM storage efficiency A single weight instead fullfledged unit may sufficient storing temporal information Various learning methods derived Two experiments unknown time delays illustrate approach One experiment shows system used adaptive temporary variable binding',\n",
              " 'Evolutionary tree reconstruction important step many biological research problems yet extremely difficult variety computational statistical scientific reasons In particular reconstruction large trees containing significant amounts divergence especially challenging We present paper new tree reconstruction method call DiskCovering Method used recover accurate estimations evolutionary tree otherwise intractable datasets DCM obtains decomposition input dataset small overlapping sets closely related taxa reconstructs trees subsets using base phylogenetic method choice combines subtrees one tree entire set taxa Because subproblems analyzed DCM smaller computationally expensive methods maximum likelihood estimation used without incurring much cost At time taxa within subset closely related even simple methods neighborjoining much likely highly accurate The result DCMboosted methods typically faster accurate compared naive use method In paper describe basic ideas techniques DCM demonstrate advantages DCM experimentally simulating sequence evolution variety trees',\n",
              " 'Automating construction semantic grammars difficult interesting problem machine learning This paper shows semanticgrammar acquisition problem viewed learning searchcontrol heuristics logic program Appropriate control rules learned using new firstorder induction algorithm automatically invents useful syntactic semantic categories Empirical results show learned parsers generalize well novel sentences outperform previous approaches based connectionist techniques',\n",
              " 'Conventional speculative architectures use branch prediction evaluate likely execution path program execution However certain branches difficult predict One solution problem evaluate paths following conditional branch Predicated execution used implement form multipath execution Predicated architectures fetch issue instructions associated predicates These predicates indicate instruction commit result Predicating branch reduces number branches executed eliminating chance branch misprediction cost executing additional instructions In paper propose restricted form multipath execution called Dynamic Predication architectures little support predicated instructions instruction set Dynamic predication dynamically predicates instruction sequences form branch hammock concurrently executing paths branch A branch hammock short forward branch spans instructions form ifthen ifthenelse construct We mark constructs executable When decode stage detects sequence passes predicated instruction sequence dynamically scheduled execution core Our results show dynamic predication accrue speedups',\n",
              " 'In barn owl selforganization auditory map space external nucleus inferior colliculus ICx strongly influenced vision nature interaction unknown In paper biologically plausible minimalistic model ICx selforganization proposed ICx receives learn signal based owls visual attention When visual attention focused spatial location auditory input learn signal turned map allowed adapt A twodimensional Kohonen map used model ICx simulations performed evaluate learn signal would affect auditory map When primary area visual attention shifted different spatial locations auditory map shifted corresponding location The shift complete done early development partial done later Similar results observed barn owl visual field modified prisms Therefore simulations suggest learn signal based visual attention possible explanation auditory plasticity',\n",
              " 'The place fields hippocampal cells old animals sometimes change animal removed returned environment Barnes et al The ensemble correlation two sequential visits environment shows strong bimodality old animals near indicative remapping greater indicative similar representation experiences strong unimodality young animals greater indicative similar representation experiences One explanation multimap hypothesis multiple maps encoded hippocampus old animals may sometimes returning wrong map A theory proposed Samsonovich McNaughton suggests Barnes et al experiment implies maps prewired CA region hippocampus Here offer alternative explanation orthogonalization properties dentate gyrus DG region hippocampus interact errors selflocalization reset path integrator reentry environment produce bimodality',\n",
              " 'MIT Media Laboratory Perceptual Computing Section Technical Report No Appeared th IEEE Intl Conference Pattern Recognition ICPR Vienna Austria Abstract We present foveated gesture recognition system guides active camera foveate salient features based reinforcement learning paradigm Using vision routines previously implemented interactive environment determine spatial location salient body parts user guide active camera obtain images gestures expressions A hiddenstate reinforcement learning paradigm based Partially Observable Markov Decision Process POMDP used implement visual attention The attention module selects targets foveate based goal successful recognition uses new multiplemodel Qlearning formulation Given set target distractor gestures system learn foveate maximally discriminate particular gesture',\n",
              " 'Various extensions Genetic Algorithm GA attempt find optima search space containing several optima Many emulate natural speciation For coevolutionary learning succeed range management control problems learning game strategies methods must find optima However suitable comparison studies rare We compare two similar GA speciation methods fitness sharing implicit sharing Using realistic letter classification problem find advantages different circumstances Implicit sharing covers optima comprehensively population large enough species form optimum With population large enough fitness sharing find optima larger basins attraction ignore peaks narrow bases implicit sharing easily distracted This indicates speciated GA trying find many nearglobal optima possible implicit sharing works well population large enough This requires prior knowledge many peaks exist',\n",
              " 'Modern knowledge systems design typically employ multiple problemsolving methods turn use different kinds knowledge The construction heterogeneous knowledge system support practical design thus raises two fundamental questions accumulate huge volumes design information support heterogeneous design processing Fortunately partial answers questions exist separately Legacy databases already contain huge amounts generalpurpose design information In addition modern knowledge systems typically characterize kinds knowledge needed specific problemsolving methods quite precisely This leads us hypothesize methodspecific datatoknowledge compilation potential mechanism integrating heterogeneous knowledge systems legacy databases design In paper first outline general computational architecture called HIPED integration Then focus specific issue convert data accessed legacy database form appropriate problemsolving method used heterogeneous knowledge system We describe experiment legacy knowledge system called Interactive Kritik integrated ORACLE database using IDI communication tool The limited experiment indicates computational feasibility methodspecific datatoknowledge compilation also raises additional research issues',\n",
              " 'This paper investigates advantages disadvantages mixture experts ME model introduced connectionist community JJNH applied time series analysis WM two time series dynamics well understood The first series computergenerated series consisting mixture noisefree process quadratic map noisy process composition noisy linear autoregressive hyperbolic tangent There three main results ME model produces significantly better results single networks discovers regimes correctly also allows us characterize subprocesses variances due correct matching noise level model data avoids overfitting The second series laser series used Santa Fe competition ME model also obtains excellent outofsample predictions allows analysis shows overfitting',\n",
              " 'In natural visual experience different views object tend appear close temporal proximity animal manipulates object navigates around We investigated ability attractor network acquire view invariant visual representations associating first neighbors pattern sequence The pattern sequence contains successive views faces ten individuals change pose Under network dynamics developed Griniasty Tsodyks Amit multiple views given subject fall basin attraction We use independent component ICA representation faces input patterns Bell Sejnowski The ICA representation advantages principal component representation PCA viewpointinvariant recognition without attractor network suggesting ICA better representation PCA object recognition',\n",
              " 'This paper examines effects relaxed synchronization numerical parallel efficiency parallel genetic algorithms GAs We describe coarsegrain geographically structured parallel genetic algorithm Our experiments provide preliminary evidence asynchronous versions algorithms lower run time synchronous GAs Our analysis shows improvement due decreased synchronization costs high numerical efficiency eg fewer function evaluations asynchronous GAs This analysis includes critique utility traditional parallel performance measures parallel GAs',\n",
              " 'Key ideas statistical learning theory support vector machines generalized decision trees A support vector machine used decision tree The optimal decision tree characterized primal dual space formulation constructing tree proposed The result method generating logically simple decision trees multivariate linear nonlinear decisions The preliminary results indicate method produces simple trees generalize well respect decision tree algorithms single support vector machines',\n",
              " 'We previously shown regularization principles lead approximation schemes equivalent networks one layer hidden units called Regularization Networks In particular standard smoothness functionals lead subclass regularization networks well known Radial Basis Functions approximation schemes This paper shows regularization networks encompass much broader range approximation schemes including many popular general additive models neural networks In particular introduce new classes smoothness functionals lead different classes basis functions Additive splines well tensor product splines obtained appropriate classes smoothness functionals Furthermore generalization extends Radial Basis Functions RBF Hyper Basis Functions HBF also leads additive models ridge approximation models containing special cases Breimans hinge functions forms Projection Pursuit Regression several types neural networks We propose use term Generalized Regularization Networks broad class approximation schemes follow extension regularization In probabilistic interpretation regularization different classes basis functions correspond different classes prior probabilities approximating function spaces therefore different types smoothness assumptions In summary different multilayer networks one hidden layer collectively call Generalized Regularization Networks correspond different classes priors associated smoothness functionals classical regularization principle Three broad classes Radial Basis Functions generalized Hyper Basis Functions b tensor product splines c additive splines generalized schemes type ridge approximation hinge functions several perceptronlike neural networks onehidden layer This paper appear Neural Computation vol pages An earlier version',\n",
              " 'Learning inputoutput mapping set examples type many neural networks constructed perform regarded synthesizing approximation multidimensional function solving problem hypersurface reconstruction From point view form learning closely related classical approximation techniques generalized splines regularization theory This paper considers problems exact representation detail approximation linear nonlinear mappings terms simpler functions fewer variables Kolmogorovs theorem concerning representation functions several variables terms functions one variable turns almost irrelevant context networks learning We develop theoretical framework approximation based regularization techniques leads class threelayer networks call Generalized Radial Basis Functions GRBF since mathematically related wellknown Radial Basis Functions mainly used strict interpolation tasks GRBF networks equivalent generalized splines also closely related pattern recognition methods Parzen windows potential functions several neural network algorithms Kanervas associative memory backpropagation Kohonens topology preserving map They also interesting interpretation terms prototypes synthesized optimally combined learning stage The paper introduces several extensions applications technique discusses intriguing analogies neurobiological data c fl Massachusetts Institute Technology This paper describes research done within Center Biological Information Processing Department Brain Cognitive Sciences Artificial Intelligence Laboratory This research sponsored grant Office Naval Research ONR Cognitive Neural Sciences Division Artificial Intelligence Center Hughes Aircraft Corporation Alfred P Sloan Foundation National Science Foundation Support A I Laboratorys artificial intelligence research provided Advanced Research Projects Agency Department Defense Army contract DACAC part ONR contract NK',\n",
              " 'This article describes reasoner improve understanding incompletely understood domain application already knows novel problems domain Casebased reasoning process using past experiences stored reasoners memory understand novel situations solve novel problems However process assumes past experiences well understood provide good lessons used future situations This assumption usually false one learning novel domain since situations encountered previously domain might understood completely Furthermore reasoner may even case adequately deals new situation may able access case using existing indices We present theory incremental learning based revision previously existing case knowledge response experiences situations The theory implemented casebased story understanding program learn new case situations case already exists b learn index case memory c incrementally refine understanding case using reason new situations thus evolving better understanding domain experience This research complements work casebased reasoning providing mechanisms case library automatically built use casebased reasoning program',\n",
              " 'We present statistical model genes DNA A Generalized Hidden Markov Model GHMM provides framework describing grammar legal parse DNA sequence Stormo Haussler Probabilities assigned transitions states GHMM generation nucleotide base given particular state Machine learning techniques applied optimize probabilities using standardized training set Given new candidate sequence best parse deduced model using dynamic programming algorithm identify path model maximum probability The GHMM flexible modular new sensors additional states inserted easily In addition provides simple solutions integrating cardinality constraints reading frame constraints indels homology searching The description results implementation genefinding model called Genie presented The exon sensor codon frequency model conditioned windowed nucleotide frequency preceding codon Two neural networks used Brunak Engelbrecht Knudsen splice site prediction We show simple model performs quite well For crossvalidated standard test set genes ftpwwwhgclblgovpubgenesets human DNA genefinding system identified proteincoding bases correctly specificity exons exactly identified specificity Genie shown perform favorably compared several genefinding systems',\n",
              " 'We examine questions optimality domination repeated stage games one players may draw strategies perhaps different computationally bounded sets We also consider optimality domination bounded convergence rates infinite payoff We develop notion grace period handle problem vengeful strategies',\n",
              " 'We study problem efficiently learning play game optimally unknown adversary chosen computationally bounded class We contribute line research playing games finite automata expand scope research considering new classes adversaries We introduce natural notions games recent history adversaries whose current action determined simple boolean formula recent history play games statistical adversaries whose current action determined simple function statistics entire history play In cases give efficient algorithms learning play pennymatching difficult game called contract We also give powerful positive result date learning play finite automata efficient algorithm learning play game finite automata probabilistic actions low cover time',\n",
              " 'MORGAN integrated system finding genes vertebrate DNA sequences MORGAN uses variety techniques accomplish task distinctive decision tree classifier The decision tree system combined new methods identifying start codons donor sites acceptor sites brought together framesensitive dynamic programming algorithm finds optimal segmentation DNA sequence coding noncoding regions exons introns The optimal segmentation dependent separate scoring function takes subsequence assigns score reflecting probability sequence exon The scoring functions MORGAN sets decision trees combined give probability estimate Experimental results database vertebrate DNA sequences show MORGAN excellent performance many different measures On separate test set achieves overall accuracy correlation coefficient sensitivity specificity coding bases In addition MORGAN identifies coding exons exactly ie beginning end coding regions predicted correctly This paper describes MORGAN system including decision tree routines algorithms site recognition performance benchmark database vertebrate DNA',\n",
              " 'In paper report use backpropagation based neural networks implement phase computational intelligence process PYTHIA expert system supporting numerical simulation applications modelled partial differential equations PDEs PYTHIA exemplar based reasoning system provides advice method parameters use simulation specified PDE based application When advice requested characteristics given model matched characteristics previously seen classes models The performance various solution methods previously seen similar classes models used basis predicting method use Thus major step reasoning process PYTHIA involves analysis categorization models classes models based characteristics In study demonstrate use neural networks identify class predefined models whose characteristics match ones specified PDE based application',\n",
              " 'A method described reduces hypotheses space efficient easily interpretable reduction criteria called reduction A learning algorithm described based reduction analyzed using probability approximate correct learning results The results obtained reducing rule set equivalent set kDNF formulas The goal learning algorithm induce compact rule set describing basic dependencies within set data The reduction based criterion exible gives semantic interpretation rules fulfill criteria Comparison syntactical hypotheses reduction show reduction improves search smaller probability missclassification',\n",
              " 'We identify three principle factors affecting performance learning networks localized units unit noise sample density structure target function We analyze effect unit receptive field parameters factors use analysis propose new learning algorithm dynamically alters receptive field properties learning',\n",
              " 'SemiMarkov Decision Problems continuous time generalizations discrete time Markov Decision Problems A number reinforcement learning algorithms developed recently solution Markov Decision Problems based ideas asynchronous dynamic programming stochastic approximation Among TD Qlearning Realtime Dynamic Programming After reviewing semiMarkov Decision Problems Bellmans optimality equation context propose algorithms similar named adapted solution semiMarkov Decision Problems We demonstrate algorithms applying problem determining optimal control simple queueing system We conclude discussion circumstances algorithms may usefully ap plied',\n",
              " 'There recently widespread interest use multiple models classification regression statistics neural networks communities The Hierarchical Mixture Experts HME successful number regression problems yielding significantly faster training use Expectation Maximisation algorithm In paper extend HME classification results reported three common classification benchmark tests ExclusiveOr Ninput Parity Two Spirals',\n",
              " 'One important factor determining computa tional complexity evaluating probabilistic network cardinality state spaces nodes By varying granularity state spaces one trade accuracy result computational efficiency We present time procedure approximate evaluation probabilistic networks based idea On application simple networks proce dure exhibits smooth improvement approxi mation quality computation time increases This suggests statespace abstraction one useful control parameter designing real time probabilistic reasoners',\n",
              " 'Existing complexity measures contemporary learning theory conveniently applied specific learning problems eg training sets Moreover typically nongeneric ie necessitate making assumptions way learner operate The lack satisfactory generic complexity measure learning problems poses difficulties researchers various areas present paper puts forward idea may help alleviate It shows supervised learning problems fall two generic complexity classes one associated computational tractability By determining class particular problem belongs thus effectively evaluate degree generic difficulty',\n",
              " 'The paper investigates statistical effects may need exploited supervised learning It notes effects classified according conditionality order proposes learning algorithms typically form bias towards particular classes effect It presents results empirical study statistical bias backpropagation The study involved applying algorithm wide range learning problems using variety different internal architectures The results study revealed backpropagation specific bias general direction statistical rather relational effects The paper shows existence bias effectively constitutes weakness algorithms ability discount noise',\n",
              " 'segmentation Preliminary results Abstract Scatterpartitioning Radial Basis Function RBF networks increase number degrees freedom complexity inputoutput mapping estimated basis supervised training data set Due superior expressive power scatterpartitioning Gaussian RBF GRBF model termed Supervised Growing Neural Gas SGNG selected literature SGNG employs onestage errordriven learning strategy capable generating removing hidden units synaptic connections A slightly modified SGNG version tested function estimator training surface fitted image ie D signal whose size finite The relationship generation learning system disjointed maps hidden units presence image pictorially homogeneous subsets segments investigated Unfortunately examined SGNG version performs poorly function estimator image segmenter This may due intrinsic inadequacy onestage errordriven learning strategy adjust structural parameters output weights simultaneously consistently In framework RBF networks studies investigate combination twostage errordriven learning strategies synapse generation removal criteria Internal report paper entitled Image segmentation scatterpartitioning RBF networks A feasibility study presented conference Applications Science Neural Networks Fuzzy Systems Evolutionary Computation part SPIEs International Symposium Optical Science Engineering Instrumentation July San Diego CA',\n",
              " 'A distinct advantage symbolic learning algorithms artificial neural networks typically concept representations form easily understood humans One approach understanding representations formed neural networks extract symbolic rules trained networks In paper describe investigate approach extracting rules networks uses NofM extraction algorithm network training method soft weightsharing Previously NofM algorithm successfully applied knowledgebased neural networks Our experiments demonstrate extracted rules generalize better rules learned using C system In addition accurate extracted rules also reasonably comprehensible',\n",
              " 'Our experience showed us exibility expressing parallel algorithm simulating neural networks desirable even possible obtain efficient solution single training algorithm We believe advantages clear easy understand program predominates disadvantages approaches allowing specific machine neural network algorithm We currently investigate neural network models worth parallelized resulting parallel algorithms composed common basic building blocks logarithmic tree efficient communication structure connections connections D Ackley G Hinton T Sejnowski A Learning Algorithm Boltzmann Machines Cognitive Science pp B M Forrest et al Implementing Neural Network Models Parallel Computers The computer Journal vol W Giloi Latency Hiding Message Passing Architectures International Parallel Processing Symposium April Cancun Mexico IEEE Computer Society Press T Nordstrm B Svensson Using And Designing Massively Parallel Computers Artificial Neural Networks Journal Of Parallel And Distributed Computing vol pp A Kramer A Vincentelli Efficient parallel learning algorithms neural networks Advances Neural Information Processing Systems I D Touretzky ed pp T Kohonen SelfOrganization Associative Memory SpringerVerlag Berlin D A Pomerleau G L Gusciora D L Touretzky H T Kung Neural Network Simulation Warp Speed How We Got Million Connections Per Second IEEE Intern Conf Neural Networks July A Rbel Dynamic selection training patterns neural networks A new method control generalization Technical Report Technical University Berlin D E Rumelhart D E Hinton R J Williams Learning internal representations error propagation Rumelhart McClelland eds Parallel Distributed Processing Explorations Microstructure Cognition vol I pp Bradford BooksMIT Press Cambridge MA W Schiffmann M Joost R Werner Comparison optimized backpropagation algorithms Proc European Symposium Artificial Neural Networks ESANN Brussels pp J Schmidhuber Accelerated Learning BackPropagation Nets Connectionism perspective Elsevier Science Publishers BV NorthHolland pp M Taylor P Lisboa eds Techniques Applications Neural Networks Ellis Horwood M Witbrock M Zagha An implementation backpropagation learning GF large SIMD parallel computer Parallel Computing vol pp X Zhang M Mckenna J P Mesirov D L Waltz The backpropagation algorithm grid hypercube architectures Parallel Computing vol pp',\n",
              " 'In order learn effectively system must possess knowledge world able improve knowledge also must introspectively reason performs given task particular pieces knowledge needs improve performance current task Introspection requires declaratflive representation reasoning performed system performance task This paper presents taxonomy possible reasoning failures occur task declarative representations associations particular learning strategies We propose theory MetaXPs explanation structures help system identify failure types choose appropriate learning strategies order avoid similar mistakes future A program called MetaAQUA embodies theory processes examples domain drug smuggling',\n",
              " 'Although artificial neural networks applied variety realworld scenarios remarkable success often criticized exhibiting low degree human comprehensibility Techniques compile compact sets symbolic rules artificial neural networks offer promising perspective overcome obvious deficiency neural network representations This paper presents approach extraction ifthen rules artificial neural networks Its key mechanism validity interval analysis generic tool extracting symbolic knowledge propagating rulelike knowledge Backpropagationstyle neural networks Empirical studies robot arm domain illustrate appropriateness proposed method extracting rules networks realvalued distributed representations',\n",
              " 'In paper examine method feature subset selection based Information Theory Initially framework defining theoretically optimal computationally intractable method feature subset selection presented We show goal eliminate feature gives us little additional information beyond subsumed remaining features In particular case irrelevant redundant features We give efficient algorithm feature selection computes approximation optimal feature selection criterion The conditions approximate algorithm successful examined Empirical results given number data sets showing algorithm effectively han dles datasets large numbers features',\n",
              " 'In paper address problem casebased learning presence irrelevant features We review previous work attribute selection present new algorithm Oblivion carries greedy pruning oblivious decision trees effectively store set abstract cases memory We hypothesize approach efficiently identify relevant features even interact parity concepts We report experimental results artificial domains support hypothesis experiments natural domains show improvement cases others In closing discuss implications experiments consider additional work irrelevant features outline directions future research',\n",
              " 'Learning plays vital role development situated agents In paper explore use reinforcement learning shape robot perform predefined target behavior We connect simulated real robots A LECSYS parallel implementation learning classifier system extended genetic algorithm After classifying different kinds Animatlike behaviors explore effects learning different types agents architecture monolithic flat hierarchical training strategies In particular hierarchical architecture requires agent learn coordinate basic learned responses We show best results achieved agents architecture training strategy match structure behavior pattern learned We report results number experiments carried simulated real environments show results simulations carry smoothly real robots While experiments deal simple reactive behavior one demonstrate use simple general memory mechanism As whole experimental activity demonstrates classifier systems genetic algorithms practically employed develop autonomous agents',\n",
              " 'Although probabilistic inference general Bayesian belief network NPhard problem inference computation time reduced practical cases exploiting domain knowledge making appropriate approximations knowledge representation In paper introduce property similarity states new method approximate knowledge representation based property We define two states node similar likelihood ratio probabilities depend instantiations nodes network We show similarity states exposes redundancies joint probability distribution exploited reduce computational complexity probabilistic inference networks multiple similar states For example show BNO networka two layer networks often used diagnostic problemscan reduced close network multiple similar states Probabilistic inference new network done polynomial time respect size network results queries practical importance close results obtained exponential time original network The error introduced reduction converges zero faster exponentially respect degree polynomial describing resulting computational complexity',\n",
              " 'Multilayer architectures used Bayesian belief networks Helmholtz machines provide powerful framework representing learning higher order statistical relations among inputs Because exact probability calculations models often intractable much interest finding approximate algorithms We present algorithm efficiently discovers higher order structure using EM Gibbs sampling The model interpreted stochastic recurrent network ambiguity lowerlevel states resolved feedback higher levels We demonstrate performance algorithm bench mark problems',\n",
              " 'In paper study extension distributionfree model learning introduced Valiant also known probably approximately correct PAC model allows presence malicious errors examples given learning algorithm Such errors generated adversary unbounded computational power access entire history learning algorithms computation Thus study worstcase model errors Our results include general methods bounding rate error tolerable learning algorithm efficient algorithms tolerating nontrivial rates malicious errors equivalences problems learning errors standard combinatorial optimization problems',\n",
              " 'We investigate problem computing posterior probability model class given data sample prior distribution possible parameter settings By model class mean group models share parametric form In general posterior may hard compute highdimensional parameter spaces usually case realworld applications In literature several methods computing posterior approximately proposed quality approximations may depend heavily size available data sample In work interested testing well approximative methods perform realworld problem domains In order conduct study chosen model family finite mixture distributions With certain assumptions able derive model class posterior analytically model family We report series model class selection experiments realworld data sets true posterior approximations compared The empirical results support hypothesis approximative techniques provide good estimates true posterior especially sample size grows large',\n",
              " 'Email FirstnameLastnamecsHelsinkiFI Report C University Helsinki Department Computer Science Abstract In paper explore use finite mixture models building decision support systems capable sound probabilistic inference Finite mixture models many appealing properties computationally efficient prediction reasoning phase universal sense approximate problem domain distribution handle multimodality well We present formulation model construction problem Bayesian framework finite mixture models describe Bayesian inference performed given model The model construction problem seen missing data estimation describe realization ExpectationMaximization EM algorithm finding good models To prove feasibility approach report crossvalidated empirical results several publicly available classification problem datasets compare results corresponding results obtained alternative techniques neural networks decision trees The comparison based best results reported literature datasets question It appears using theoretically sound Bayesian framework suggested reported results outperformed relatively small effort',\n",
              " 'One application models reasoning behavior allow reasoner introspectively detect repair failures reasoning process We address issues transferability models versus specificity knowledge kinds knowledge needed selfmodeling knowledge structured evaluation introspective reasoning systems We present ROBBIE system implements model planning processes improve planner response reasoning failures We show ROBBIEs hierarchical model balances model generality access implementationspecific details discuss qualitative quantitative measures used evaluating introspective component',\n",
              " 'We consider multicriteria sequential decision making problems criteria ordered according importance Structural properties problems touched reinforcement learning algorithms learn asymptotically optimal decisions derived Computer experiments confirm theoretical results provide insight learning processes',\n",
              " 'Acyclic digraphs ADGs widely used describe dependences among variables multivariate distributions In particular likelihood functions ADG models admit convenient recursive factorizations often allow explicit maximum likelihood estimates well suited building Bayesian networks expert systems There may however many ADGs determine dependence Markov model Thus family ADGs given set vertices naturally partitioned Markovequivalence classes class associated unique statistical model Statistical procedures model selection model averaging fail take account equivalence classes may incur substantial computational inefficiencies Recent results shown Markovequivalence class uniquely determined single chain graph essential graph Markovequivalent simultaneously ADGs equivalence class Here propose two stochastic Bayesian model averaging selection algorithms essential graphs apply analysis three discretevariable data sets',\n",
              " 'Given set samples unknown probability distribution study problem constructing good approximative Bayesian network model probability distribution question This task viewed search problem goal find maximal probability network model given data In work make attempt learn arbitrarily complex multiconnected Bayesian network structures since resulting models unsuitable practical purposes due exponential amount time required reasoning task Instead restrict special class simple treestructured Bayesian networks called Bayesian prototype trees polynomial time algorithm Bayesian reasoning exists We show probability given Bayesian prototype tree model evaluated given data evaluation criterion used stochastic simulated annealing algorithm searching model space The simulated annealing algorithm provably finds maximal probability model provided sufficient amount time used',\n",
              " 'We use simple illustrative example expose main ideas Evidential Probability Specifically show use acceptance rule naturally leads use intervals represent probabilities change opinion due experience facilitated probabilities concerning compound experiments events computed given proper knowledge underlying distributions',\n",
              " 'This paper presents UTree reinforcement learning algorithm uses selective attention shortterm memory simultaneously address intertwined problems large perceptual state spaces hidden state By combining advantages work instancebased memorybased learning work robust statistical tests separating noise task structure method learns quickly creates taskrelevant state distinctions handles noise well UTree uses treestructured representation related work Prediction Suffix Trees Ron et al Partigame Moore Galgorithm Chapman Kaelbling Variable Resolution Dynamic Programming Moore It builds Utile Suffix Memory McCallum c used shortterm memory selective perception The algorithm demonstrated solving highway driving task agent weaves around slower faster traffic The agent uses active perception simulated eye movements The environment hidden state time pressure stochasticity world states percepts From environment sensory system agent uses utile distinction test build tree represents depththree memory necessary internal statesfar fewer states would resulted fixedsized historywindow ap proach',\n",
              " 'Feature selection problem choosing subset relevant features In general exhaustive search bring optimal subset With monotonic measure exhaustive search avoided without sacrificing optimality Unfortunately error distancebased measures monotonic A new measure employed work monotonic fast compute The search relevant features according measure guaranteed complete exhaustive Experiments conducted verification',\n",
              " 'This paper describes novel method dialogue agent learn choose optimal dialogue strategy While widely agreed dialogue strategies formulated terms communicative intentions little work automatically optimizing agents choices multiple ways realize communicative intention Our method based combination learning algorithms empirical evaluation techniques The learning component method based algorithms reinforcement learning dynamic programming Qlearning The empirical component uses PARADISE evaluation framework Walker et al identify important performance factors provide performance function needed learning algorithm We illustrate method dialogue agent named ELVIS EmaiL Voice Interactive System supports access email phone We show ELVIS learn choose among alternate strategies agent initiative reading messages summarizing email folders',\n",
              " 'This paper outlines problems may occur Reduced Error Pruning Inductive Logic Programming notably efficiency Thereafter new method Incremental Reduced Error Pruning proposed attempts address problems Experiments show many noisy domains method much efficient alternative algorithms along slight gain accuracy However experiments show well use algorithm recommended domains specific concept description',\n",
              " 'EEG analysis played key role modeling brains cortical dynamics relatively little effort devoted developing EEG limited means communication If several mental states reliably distinguished recognizing patterns EEG paralyzed person could communicate device like wheelchair composing sequences mental states EEG pattern recognition difficult problem hinges success finding representations EEG signals patterns distinguished In article report study comparing three EEG representations unprocessed signals reduceddimensional representation using KarhunenLoeve transform frequencybased representation Classification performed twolayer neural network implemented CNAPS server processor SIMD architecture Adaptive Solutions Inc Execution time comparisons show hundredfold speed Sun Sparc The best classification accuracy untrained samples using frequencybased representation',\n",
              " 'This paper surveys field reinforcement learning computerscience perspective It written accessible researchers familiar machine learning Both historical basis field broad selection current work summarized Reinforcement learning problem faced agent learns behavior trialanderror interactions dynamic environment The work described resemblance work psychology differs considerably details use word reinforcement The paper discusses central issues reinforcement learning including trading exploration exploitation establishing foundations field via Markov decision theory learning delayed reinforcement constructing empirical models accelerate learning making use generalization hierarchy coping hidden state It concludes survey implemented systems assessment practical utility current methods reinforcement learning',\n",
              " 'We add internal memory XCS classifier system We test XCS internal memory named XCSM nonMarkovian environments two four aliasing states Experimental results show XCSM easily converge optimal solutions simple environments moreover XCSMs performance stable respect size internal memory involved learning However results present evidence complex nonMarkovian environments XCSM may fail evolve optimal solution Our results suggest happens exploration strategies currently employed XCS adequate guarantee convergence optimal policy XCSM complex nonMarkovian environments',\n",
              " 'Simple modification standard hill climbing optimization algorithm taking account learning features discussed Basic concept approach socalled probability vector single entries determine probabilities appearance entries nbit vectors This vector used random generation nbit vectors form neighborhood specified given probability vector Within neighborhood best solutions smallest functional values minimized function recorded The feature learning introduced probability vector updated formal analogue Hebbian learning rule wellknown theory artificial neural networks The process repeated probability vector entries close either zero one The resulting probability vector unambiguously determines nbit vector may interpreted optimal solution given optimization task Resemblance genetic algorithms discussed Effectiveness proposed method illustrated example looking global minima highly multimodal function',\n",
              " 'This paper describes efficient methods exact approximate implementation MINFEATURES bias prefers consistent hypotheses definable features possible This bias useful learning domains many irrelevant features present training data We first introduce FOCUS new algorithm exactly implements MINFEATURES bias This algorithm empirically shown substantially faster FOCUS algorithm previously given Almuallim Dietterich We introduce MutualInformationGreedy SimpleGreedy WeightedGreedy algorithms apply efficient heuristics approximating MINFEATURES bias These algorithms employ greedy heuristics trade optimality computational efficiency Experimental studies show learning performance ID greatly improved algorithms used preprocess training data eliminating irrelevant features IDs consideration In particular WeightedGreedy algorithm provides excellent efficient approximation MIN',\n",
              " 'A statistical approach decision tree modeling described In approach decision tree modeled parametrically process output generated input sequence decisions The resulting model yields likelihood measure goodness fit allowing ML MAP estimation techniques utilized An efficient algorithm presented estimate parameters tree The model selection problem presented several alternative proposals considered A hidden Markov version tree described data sequences temporal dependencies',\n",
              " 'A binary matrix Our task infer given z A given assumptions statistical properties n This problem arises decoding noisy communication z transmitted using errorcorrecting code based parity checks original signal inference sequence linear feedback shift register LFSR noisy observation sequence P zjA I assume decoders aim find probable For large N exhaustive search N possible sequences feasible One way attack combinatorial problem create related continuous optimization problem discrete variables replaced real variables Here I derive continuous representation terms free energy approximation awkward posterior distribution',\n",
              " 'An intelligent system capable adapting constantly changing environment It therefore ought capable learning perceptual interactions surroundings This requires certain amount plasticity structure Any attempt model perceptual capabilities living system matter construct synthetic system comparable abilities must therefore account plasticity variety developmental learning mechanisms This paper examines results neuroanatomical morphological well behavioral studies development visual perception integrates computational framework suggests several interesting experiments computational models yield insights development visual perception In order understand development information processing structures brain one needs knowledge changes undergoes birth maturity context normal environment However knowledge development aberrant settings also extremely useful reveals extent development function environmental experience opposed genetically determined prewiring Accordingly consider development visual system normal restricted rearing conditions The role experience early development sensory systems general visual system particular widely studied variety experiments involving carefully controlled manipulation environment presented animal Extensive reviews results found Mitchell Movshon Hirsch Boothe Singer Some examples manipulation visual experience total pattern deprivation eg dark rearing selective deprivation certain class patterns eg vertical lines monocular deprivation animals binocular vision etc Extensive studies involving behavioral deficits resulting total visual pattern deprivation indicate deficits arise primarily result impairment visual information processing brain The results experiments suggest specific developmental learning mechanisms may operating various stages development different levels system We discuss hhhhhhhhhhhhhhh This working draft All comments especially constructive criticism suggestions improvement appreciated I indebted Prof James Dannemiller introducing literature infant development Prof Leonard Uhr helpful comments initial draft paper numerous researchers whose experimental work provided basis model outlined paper This research partially supported grants National Science Foundation University Wisconsin Graduate School',\n",
              " 'This paper studies problem ergodicity transition probability matrices Markovian models hidden Markov models HMMs makes difficult task learning represent longterm context sequential data This phenomenon hurts forward propagation longterm context information well learning hidden state representation represent longterm context depends propagating credit information backwards time Using results Markov chain theory show problem diffusion context credit reduced transition probabilities approach ie transition probability matrices sparse model essentially deterministic The results found paper apply learning approaches based continuous optimization gradient descent BaumWelch algorithm',\n",
              " 'Modern industry today needs flexible adaptive faulttolerant methods information processing Several applications shown neural networks fulfill requirements In paper application areas neural networks successfully used presented Then kind check list described mentioned different steps applying neural networks The paper finished discussion neural networks projects done research group Interactive Planning Research Center Computer Science FZI',\n",
              " 'Gas oil pipelines need inspected corrosion defects regular intervals For application Pipetronix GmbH PTX Karlsruhe developed special ultrasonic based probe Based recorded wall thicknesses called pipe pig Research center computer science FZI developed cooperation PTX automatic inspection system called NeuroPipe NeuroPipe task detect defects like metal loss The kernel inspection tool neural classifier trained using manually collected defect examples The following paper focus aspects successfull use learning methods industrial application',\n",
              " 'We construct mixture locally linear generative models collection pixelbased images digits use recognition Different models given digit used capture different styles writing new images classified evaluating loglikelihoods model We use EMbased algorithm Mstep computationally straightforward principal components analysis PCA Incorporating tangentplane information expected local deformations requires adding tangent vectors sample covariance matrices PCA demonstrably improves performance',\n",
              " 'In International Journal Neural Systems p URL paper ftpftpcscoloradoedupubTimeSeriesMyPapersexpertspsZ httpwwwcscoloradoeduandreasTimeSeriesMyPapersexpertspsZ University Colorado Computer Science Technical Report CUCS In analysis prediction realworld systems two key problems nonstationarityoften form switching regimes overfitting particularly serious noisy processes This article addresses problems using gated experts consisting nonlinear gating network several also nonlinear competing experts Each expert learns predict conditional mean expert adapts width match noise level regime The gating network learns predict probability expert given input This article focuses case gating network bases decision information inputs This contrasted hidden Markov models decision based previous states ie output gating network previous time step well averaging several predictors In contrast gated experts softpartition input space This article discusses underlying statistical assumptions derives weight update rules compares performance gated experts standard methods three time series computergenerated series obtained randomly switching two nonlinear processes time series Santa Fe Time Series Competition light intensity laser chaotic state daily electricity demand France realworld multivariate problem structure several time scales The main results gating network correctly discovers different regimes process widths associated expert important segmentation task used characterize subprocesses less overfitting compared single networks homogeneous multilayer perceptrons since experts learn match variances local noise levels This viewed matching local complexity model local complexity data',\n",
              " 'This paper describes approach modelling drug activity using machine learning tools Some experiments modelling quantitative structureactivity relationship QSAR using standard Hansch method machine learning system Golem already reported literature The paper describes results applying two machine learning systems Magnus Assistant Retis data The results achieved machine learning systems better results Hansch method therefore machine learning tools considered promising solving kind problems The given results also illustrate variations performance different machine learning systems applied drug design problem',\n",
              " 'In paper describe one aspect research project called HIPED addressed problem performing design engineering devices accessing heterogeneous databases The front end HIPED system consisted interactive KRITIK multimodal reasoning system combined case based model based reasoning solve design problem This paper focuses backend processing five types queries received front end evaluated mapping appropriately using facts schemas underlying databases rules establish correspondance among data databases terms relationships equivalence overlap set containment The uniqueness approach stems fact mapping process forgiving query received front end evaluated respect large number possibilities These possibilities encoded form rules consider various ways tokens given query may match relation names attrribute names values underlying tables The approach implemented using CORAL deductive database system rule processing engine',\n",
              " 'Temporal difference methods solve temporal credit assignment problem reinforcement learning An important subproblem general reinforcement learning learning achieve dynamic goals Although existing temporal difference methods Q learning applied problem take advantage special structure This paper presents DGlearning algorithm learns efficiently achieve dynamically changing goals exhibits good knowledge transfer goals In addition paper shows traditional relaxation techniques applied problem Finally experimental results given demonstrate superiority DG learning Q learning moderately large synthetic nondeterministic domain',\n",
              " 'In paper prove intractability learning several classes Boolean functions distributionfree model also called Probably Approximately Correct PAC model learning examples These results representation independent hold regardless syntactic form learner chooses represent hypotheses Our methods reduce problems cracking number wellknown publickey cryptosys tems learning problems We prove polynomialtime learning algorithm Boolean formulae deterministic finite automata constantdepth threshold circuits would dramatic consequences cryptography number theory particular algorithm could used break RSA cryptosystem factor Blum integers composite numbers equivalent modulo detect quadratic residues The results hold even learning algorithm required obtain slight advantage prediction random guessing The techniques used demonstrate interesting duality learning cryptography We also apply results obtain strong intractability results approximating gener alization graph coloring fl This research conducted author Harvard University supported AT T Bell Laboratories scholarship Supported grants ONRNK NSFDCR NSFCCR DAALK DARPA AFOSR SERC',\n",
              " 'We present new method determining consensus sequence DNA fragment assemblies The new method TraceEvidence directly incorporates aligned ABI trace information consensus calculations via previously described representation TraceData Classifications The new method extracts sums evidence indicated representation determine consensus calls Using TraceEvidence method results automatically produced consensus sequences accurate less ambiguous produced standard majority voting methods Additionally improvements achieved less coverage required standard methods using TraceEvidence coverage three error rates low coverage ten sequences',\n",
              " 'To learned morphology natural language capacity recognize produce words consisting novel combinations familiar morphemes Most recent work acquisition morphology takes perspective production receptive morphology comes first child This paper presents connectionist model acquisition capacity recognize morphologically complex words The model takes sequences phonetic segments inputs maps onto output units representing meanings lexical grammatical morphemes It consists simple recurrent network separate hiddenlayer modules tasks recognizing root grammatical morphemes input word Experiments artificial language stimuli demonstrate model generalizes novel words morphological rules one major types found natural languages version network unassigned hiddenlayer modules learn assign output recognition tasks efficient manner I also argue rules involving reduplication copying portions root network requires separate recurrent subnetworks sequences larger units syllables The network learn develop syllable representations support recognition reduplication also provide basis learning produce well recognize morphologically complex words The model makes many detailed predictions learning difficulty particular morphological rules',\n",
              " 'This paper presents algorithm combines traditional EBL techniques recent developments inductive logic programming learn effective clause selection rules Prolog programs When control rules incorporated original program significant speedup may achieved The algorithm shown improvement competing EBL approaches several domains Additionally algorithm capable automatically transforming intractable algorithms ones run polynomial time',\n",
              " 'Neurons ventral stream primate visual system exhibit responses images objects invariant respect natural transformations translation size view Anatomical neurophysiological evidence suggests achieved series hierarchical processing areas In attempt elucidate manner representations established constructed model cortical visual processing seeks parallel many features system specifically multistage hierarchy topologically constrained convergent connectivity Each stage constructed competitive network utilising modified Hebblike learning rule called trace rule incorporates previous well current neuronal activity The trace rule enables neurons learn whatever invariant short time periods eg representation objects objects transform real world The trace rule enables neurons learn statistical invariances objects transformations associating together representations occur close together time We show using trace rule training algorithm model indeed learn produce transformation invariant responses natural stimuli faces',\n",
              " 'In paper propose recurrent neural networks feedback input units handling two types data analysis problems On one hand scheme used static data input variables missing On hand also used sequential data input variables missing available different frequencies Unlike case probabilistic models eg Gaussian missing variables network attempt model distribution missing variables given observed variables Instead discriminant approach fills missing variables sole purpose minimizing learning criterion eg minimize output error',\n",
              " 'Many neural networks derived optimization dynamics suitable objective functions We show networks designed repeated transformations one objective another fixpoints We exhibit collection algebraic transformations reduce network cost increase set objective functions neurally implementable The transformations include simplification products expressions functions one two expressions sparse matrix products may interpreted Legendre transformations also minimum maximum set expressions These transformations introduce new interneurons force network seek saddle point rather minimum Other transformations allow control network dynamics reconciling Lagrangian formalism need fixpoints We apply transformations simplify number structured neural networks beginning standard reduction winnertakeall network ON connections ON Also susceptible inexact graphmatching random dot matching convolutions coordinate transformations sorting Simulations show fixpointpreserving transformations may applied repeatedly elaborately example networks still robustly converge',\n",
              " 'The use casebased reasoning process model design involves subtasks recalling previously known designs memory adapting design cases subcases fit current design context The development process model particular design domain proceeds parallel development representation cases case memory organisation design knowledge needed addition specific designs The selection particular representational paradigm types information details use particular problemsolving domain depend intended use information represented project information available well nature domain In paper describe development implementation four casebased design systems CASECAD CADSYN WIN DEMEX Each system described terms content organisation source case memory implementation case recall case adaptation A comparison systems considers relative advantages disadvantages implementations',\n",
              " 'We describe biologically plausible model dynamic recognition learning visual cortex based statistical theory Kalman filtering optimal control theory The model utilizes hierarchical network whose successive levels implement Kalman filters operating successively larger spatial temporal scales Each hierarchical level network predicts current visual recognition state lower level adapts recognition state using residual error prediction actual lowerlevel state Simultaneously network also learns internal model spatiotemporal dynamics input stream adapting synaptic weights hierarchical level order minimize prediction errors The Kalman filter model respects key neuroanatomical data reciprocity connections visual cortical areas assigns specific computational roles interlaminar connections known exist neurons visual cortex Previous work elucidated usefulness model explaining neurophysiological phenomena endstopping related extraclassical receptive field effects In paper addition providing detailed exposition model present variety experimental results demonstrating ability model perform robust spatiotemporal segmentation recognition objects image sequences presence varying amounts occlusion background clutter noise',\n",
              " 'Individual lifetime learning guide evolving population areas high fitness genotype space evolutionary phenomenon known Baldwin effect Baldwin Hinton Nowlan It accepted wisdom guiding speeds rate evolution By highlighting another interaction learning evolution termed Hiding effect argued depends measure evolutionary speed one adopts The Hiding effect shows learning reduce selection pressure individuals hiding genetic differences There thus tradeoff Baldwin effect Hiding effect determine learnings influence evolution two factors contribute tradeoff cost learning landscape epis tasis investigated experimentally',\n",
              " 'This paper focuses optimization hyperparameters function approximators We describe kind racing algorithm continuous optimization problems spends less time evaluating poor parameter settings time honing estimates promising regions parameter space The algorithm able automatically optimize parameters function approximator less computation time We demonstrate algorithm problem finding good parameters memory based learner show tradeoffs involved choosing right amount computation spend evaluation',\n",
              " 'Based analysis experiments using realworld datasets find greediness forward feature selection algorithms severely corrupt accuracy function approximation using selected input features improves efficiency significantly Hence propose three greedier algorithms order enhance efficiency feature selection processing We provide empirical results linear regression locally weighted regression knearestneighbor models We also propose use algorithms develop offline Chinese Japanese handwriting recognition system auto matically configured local models',\n",
              " 'This paper considers aspect mixture modelling Significantly overlapping distributions require data parameters accurately estimated well separated distributions For example two Gaussian distributions considered significantly overlap means within three standard deviations If insufficient data available single component distribution estimated although data originates two component distributions We consider much data required distinguish two component distributions one distribution mixture modelling using minimum message length MML criterion First perform experiments show MML criterion performs well relative Bayesian criteria Second make two improvements existing MML estimates improve performance overlapping distributions',\n",
              " 'In paper present performance prediction model indicating performance range MIMD parallel processor systems neural network simulations The model expresses total execution time simulation function execution times small number kernel functions measured one processor one physical communication link The functions depend type neural network geometry decomposition connection structure MIMD machine Using model execution time speedup scalability efficiency large MIMD systems predicted The model validated quantitatively applying two popular neural networks backpropagation Kohonen selforganizing feature map decomposed GCel transputer system Measurements taken network simulations decomposed via dataset network decomposition techniques Agreement model measurements within Estimates given performances expected new T transputer systems The presented method also used application areas image processing',\n",
              " 'With goal reducing computational costs without sacrificing accuracy describe two algorithms find sets prototypes nearest neighbor classification Here term prototypes refers reference instances used nearest neighbor computation instances respect similarity assessed order assign class new data item Both algorithms rely stochastic techniques search space sets prototypes simple implement The first Monte Carlo sampling algorithm second applies random mutation hill climbing On four datasets show three four prototypes sufficed give predictive accuracy equal superior basic nearest neighbor algorithm whose runtime storage costs approximately times greater We briefly investigate random mutation hill climbing may applied select features prototypes simultaneously Finally explain performance sampling algorithm datasets terms statistical measure extent clustering displayed target classes',\n",
              " 'We present new selforganizing neural network model two variants The first variant performs unsupervised learning used data visualization clustering vector quantization The main advantage existing approaches eg Kohonen feature map ability model automatically find suitable network structure size This achieved controlled growth process also includes occasional removal units The second variant model supervised learning method results combination abovementioned selforganizing network radial basis function RBF approach In model possible contrast earlier approaches toperform positioning RBF units supervised training weights parallel Therefore current classification error used determine insert new RBF units This leads small networks generalize well Results twospirals benchmark vowel classification problem presented better results previously published fl submitted publication',\n",
              " 'I present first results COLUMBUS autonomous mobile robot COLUMBUS operates initially unknown structured environments Its task explore model environment efficiently avoiding collisions obstacles COLUMBUS uses instancebased learning technique modeling environment Realworld experiences generalized via two artificial neural networks encode characteristics robots sensors well characteristics typical environments robot assumed face Once trained networks allow knowledge transfer across different environments robot face lifetime COLUMBUS models represent expected reward confidence expectations Exploration achieved navigating low confidence regions An efficient dynamic programming method employed background find minimalcost paths executed robot maximize exploration COLUMBUS operates realtime It operating successfully office building environment periods hours',\n",
              " 'We analyze performance Genetic Algorithm GA call Culling variety algorithms problem refer Additive Search Problem ASP ASP closely related several previously well studied problems game Mastermind additive fitness functions We show problem learning Ising perceptron reducible noisy version ASP Culling efficient ASP highly noise tolerant best known approach regimes Noisy ASP first problem aware Genetic Type Algorithm bests known competitors Standard GAs contrast perform much poorly ASP hillclimbing approaches even though Schema theorem holds ASP We generalize ASP kASP study whether GAs achieve implicit parallelism problem many schemata GAs fail achieve implicit parallelism describe algorithm call Explicitly Parallel Search succeeds We also compute optimal culling point selective breeding turns independent fitness function population distribution We also analyze Mean Field Theoretic algorithm performing similarly Culling many problems These results provide insight GAs beat competing methods',\n",
              " 'Many extensions proposed help instancebased learning algorithms perform better wide variety realworld applications However trivial decide parameters options use applying instancebased learning algorithm particular problem Traditionally crossvalidation used choose parameters k k nearest neighbor classifier This paper points cross validation often provide enough information allow finetuning classifier confidence levels used break ties common crossvalidation used It proposes Fuzzy Instance Based Learning FIBL algorithm uses distanceweighted voting parameters set via combination crossvalidation confidence levels In experiments datasets FIBL higher average generalization accuracy using majority voting using crossvalidation alone determine parameters',\n",
              " 'This paper describes formulation reinforcement learning enables learning noisy dynamic environemnts complex concurrent multirobot learning domain The methodology involves minimizing learning space use behaviors conditions dealing credit assignment problem shaped reinforcement form heterogeneous reinforcement functions progress estimators We experimentally validate ap proach group four mobile robots learning foraging task',\n",
              " 'Most existing decision tree systems use greedy approach induce trees locally optimal splits induced every node tree Although greedy approach suboptimal believed produce reasonably good trees In current work attempt verify belief We quantify goodness greedy tree induction empirically using popular decision tree algorithms C CART We induce decision trees thousands synthetic data sets compare corresponding optimal trees turn found using novel map coloring idea We measure effect greedy induction variables underlying concept complexity training set size noise dimensionality Our experiments show among things expected classification cost greedily induced tree consistently close optimal tree',\n",
              " 'Report SYCON ABSTRACT Previous results input state stabilizability shown hold even systems linear controls provided general type feedback allowed Applications certain stabilization problems coprime factorizations well comparisons results input state stability also briefly discussed',\n",
              " 'Attractor networks map continuous input space discrete output space useful pattern completion cleaning noisy missing features input However designing net given set attractors notoriously tricky training procedures CPU intensive often produce spurious attractors illconditioned attractor basins These difficulties occur connection network participates encoding multiple attractors We describe alternative formulation attractor networks encoding knowledge local distributed Although localist attractor nets similar dynamics distributed counterparts much easier work interpret We propose statistical formulation localist attractor net dynamics yields convergence proof mathematical interpretation model parameters We present simulation experiments explore behavior localist attractor nets showing produce gang effectthe presence attractor enhances attractor basins neighboring attractorsand spurious attractors occur points symmetry state space',\n",
              " 'According Wolperts nofreelunch NFL theorems generalisation absence domain knowledge necessarily zerosum enterprise Good generalisation performance one situation always offset bad performance another Wolpert notes theorems demonstrate effective generalisation logical impossibility merely learners bias assumption set key importance',\n",
              " 'Learning limited modification parameters limited scope capability modify system structure also needed get wider range learnable In case artificial neural networks learning iterative adjustment synaptic weights succeed network designer predefines appropriate network structure ie number hidden layers units size shape receptive projective fields This paper advocates view network structure usually done determined trialanderror computed learning algorithm Incremental learning algorithms modify network structure addition andor removal units andor links A survey current connectionist literature given line thought Grow Learn GAL new algorithm learns association oneshot due incremental using local representation During socalled sleep phase units previously stored longer necessary due recent modifications removed minimize network complexity The incrementally constructed network later finetuned offline improve performance Another method proposed greatly increases recognition accuracy train number networks vote responses The algorithm variants tested recognition handwritten numerals seem promising especially terms learning speed This makes algorithm attractive online learning tasks eg robotics The biological plausibility incremental learning also discussed briefly Earlier part work realized Laboratoire de Microinformatique Ecole Polytechnique Federale de Lausanne supported Fonds National Suisse de la Recherche Scientifique Later part realized supported International Computer Science Institute A number people helped guiding stimulating discussions questions Subutai Ahmad Peter Clarke Jerry Feldman Christian Jutten Pierre Marchal Jean Daniel Nicoud Steve Omohondro Leon Personnaz',\n",
              " 'This paper introduces probability model mixture trees account sparse dynamically changing dependence relationships We present family efficient algorithms use EM Minimum Spanning Tree algorithm find ML MAP mixture trees variety priors including Dirichlet MDL priors',\n",
              " 'Two fundamental problems analyzing DNA sequences locating regions DNA sequence encode proteins determining reading frame region We investigate using artificial neural networks ANNs find coding regions determine reading frames detect frameshift errors E coli DNA sequences We describe adaptation approach used Uberbacher Mural identify coding regions human DNA compare performance ANNs several conventional methods predicting reading frames Our experiments demonstrate ANNs outperform conventional approaches',\n",
              " 'The paper describes selflearning control system mobile robot Based sensor information control system provide steering signal way collisions avoided Since case examples available system learns basis external reinforcement signal negative case collision zero otherwise Rules Temporal Difference learning used find correct mapping discrete sensor input space steering signal We describe algorithm learning correct mapping input state vector output steering signal algorithm used discrete coding input state space',\n",
              " 'Work currently underway devise learning methods better able transfer knowledge one task another The process knowledge transfer usually viewed logically separate inductive procedures ordinary learning However paper argues seperatist view leads number conceptual difficulties It offers task analysis situates transfer process inside generalised inductive protocol It argues transfer viewed subprocess within induction independent procedure transporting knowledge learning trials',\n",
              " 'This chapter describes three studies address question neural network learning improved via incorporation information extracted networks This general problem call network transfer encompasses many types relationships source target networks Our focus utilization weights source networks solve subproblem target network task goal speeding learning target task We demonstrate approach described improve learning speed ten times learning starting random weights',\n",
              " 'ALVINN Autonomous Land Vehicle Neural Net Backpropagation trained neural network capable autonomously steering vehicle road highway environments Although ALVINN fairly robust one problems time takes train As vehicle capable online learning driver drive car minutes network capable autonomous operation One reason use Backprop In report describe original ALVINN system look three alternative training methods Quickprop Cascade Correlation Cascade We run series trials using Quickprop Cascade Correlation Cascade compare BackProp baseline Finally hidden unit analysis performed determine network learning Applying Advanced Learning Algorithms ALVINN',\n",
              " 'The work discussed paper motivated need building decision support systems realworld problem domains Our goal use systems tool supporting Bayes optimal decision making action maximizing expected utility respect predicted probabilities possible outcomes selected For reason models used need probabilistic nature output model probability distribution set numbers For model family chosen set simple discrete finite mixture models advantage computationally efficient In work describe Bayesian approach constructing finite mixture models sample data Our approach based twophase unsupervised learning process used exploratory analysis model construction In first phase selection model class ie number parameters performed calculating CheesemanStutz approximation model class evidence In second phase MAP parameters selected class estimated EM algorithm In framework overfitting problem common many traditional learning approaches avoided learning process automatically regulates complexity model This paper focuses model class selection phase approach validated presenting empirical results natural synthetic data',\n",
              " 'We introduce analyze new algorithm linear classification combines Rosenblatts perceptron algorithm Helmbold Warmuths leaveoneout method Like Vapniks maximalmargin classifier algorithm takes advantage data linearly separable large margins Compared Vapniks algorithm however much simpler implement much efficient terms computation time We also show algorithm efficiently used high dimensional spaces using kernel functions We performed experiments using algorithm variants classifying images handwritten digits The performance algorithm close good performance maximalmargin classifiers problem',\n",
              " 'A version paper appear ACM Transactions Computer Systems August Permission make digital copies part work personal classroom use grantedwithout fee provided copies made distributed profit commercial advantage copies bear notice full citation first page Copyrights components work owned others ACM must honored Abstracting credit permitted To copy otherwise republish post servers redistribute lists requires prior specific permission andor fee Abstract To achieve high performance contemporary computer systems rely two forms parallelism instructionlevel parallelism ILP threadlevel parallelism TLP Wideissue superscalar processors exploit ILP executing multiple instructions single program single cycle Multiprocessors MP exploit TLP executing different threads parallel different processors Unfortunately parallelprocessing styles statically partition processor resources thus preventing adapting dynamicallychanging levels ILP TLP program With insufficient TLP processors MP idle insufficient ILP multipleissue hardware superscalar wasted This paper explores parallel processing alternative architecture simultaneous multithreading SMT allows multiple threads compete share processors resources every cycle The compelling reason running parallel applications SMT processor ability use threadlevel parallelism instructionlevel parallelism interchangeably By permitting multiple threads share processors functional units simultaneously processor use ILP TLP accommodate variations parallelism When program single thread SMT processors resources dedicated thread TLP exists parallelism compensate lack',\n",
              " 'In paper present framework building probabilistic automata parameterized contextdependent probabilities Gibbs distributions used model state transitions output generation parameter estimation carried using EM algorithm Mstep uses generalized iterative scaling procedure We discuss relations certain classes stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model constructed using methodology',\n",
              " 'In regression context boosting bagging techniques build committee regressors may superior single regressor We use regression trees fundamental building blocks bagging committee machines boosting committee machines Performance analyzed three nonlinear functions Boston housing database In cases boosting least equivalent cases better bagging terms prediction error',\n",
              " 'Current expert systems properly handle imprecise incomplete information On hand neural networks perform pattern recognition operations even noisy environments Against background implemented neural expert system shell NEULA whose computational mechanism processes imprecisely incompletely given information means approximate probabilistic reasoning',\n",
              " 'Coevolution give rise Red Queen effect interacting populations alter others fitness landscapes The Red Queen effect significantly complicates measurement coevolutionary progress introducing fitness ambiguities improvements performance coevolved individuals appear decline stasis usual measures evolutionary progress Unfortunately appropriate measures fitness given Red Queen effect developed artificial life theoretical biology population dynamics evolutionary genetics We propose set appropriate performance measures based genetic behavioral data illustrate use simulation coevolution genetically specified continuoustime noisy recurrent neural networks generate pursuit evasion behaviors autonomous agents',\n",
              " 'Inferences measurement error models sensitive modeling assumptions Specifically model incorrect estimates inconsistent To reduce sensitivity modeling assumptions yet still retain efficiency parametric inference propose use flexible parametric models accommodate departures standard parametric models We use mixtures normals purpose We study two cases detail linear errorsinvariables model changepoint Berkson model fl Raymond J Carroll Professor Statistics Nutrition Toxicology Department Statistics Texas AM University College Station TX Kathryn Roeder Associate Professor Larry Wasserman Professor Department Statistics CarnegieMellon University Pittsburgh PA Carrolls research supported grant National Cancer Institute CA Roeders research supported NSF grant DMS Wassermans research supported NIH grant ROCA NSF grants DMS DMS',\n",
              " 'In paper investigate phenomenon multiparent reproduction ie study recombination mechanisms arbitrary n gt number parents participate creating children In particular discuss scanning crossover generalizes standard uniform crossover diagonal crossover generalizes point crossover study effects different number parents GA behavior We conduct experiments tough function optimization problems observe multiparent operators performance GAs enhanced significantly We also give theoretical foundation showing operators work distributions',\n",
              " 'TECHNICAL REPORT No Department Statistics GN University Washington Seattle Washington USA Susan L Rosenkranz Pew Health Policy Postdoctoral Fellow Institute Health Policy Studies Box University California San Francisco San Francisco CA Adrian E Raftery Professor Statistics Sociology Department Statistics GN University Washington Seattle WA Rosenkranzs research supported National Research Service Award TCA National Cancer Institute The authors grateful Paula Diehr Kevin Cain helpful discussions',\n",
              " 'Draft A Brief Introduction Neural Networks Richard D De Veaux Lyle H Ungar Williams College University Pennsylvania Abstract Artificial neural networks used increasing frequency high dimensional problems regression classification This article provides tutorial overview neural networks focusing back propagation networks method approximating nonlinear multivariable functions We explain statisticians vantage point neural networks might attractive compare modern regression techniques KEYWORDS nonparametric regression function approximation backpropagation Introduction Networks mimic way brain works computer programs actually LEARN patterns forecasting without know statistics These many claims attractions artificial neural networks Neural networks henceforth drop term artificial unless need distinguish biological neural networks seem everywhere days least advertising able statistics without fuss bother anything except buy piece software Neural networks successfully used many different applications including robotics chemical process control speech recognition optical character recognition credit card fraud detection interpretation chemical spectra vision autonomous navigation vehicles Pointers literature given end article In article attempt explain one particular type neural network feedforward networks sigmoidal activation functions backpropagation networks actually works trained compares well known statistical techniques As example someone would want use neural network consider problem recognizing hand written ZIP codes letters This classification problem',\n",
              " 'To apply algorithm classification assign class separate set codebook Gaussians Each set trained patterns single class After trained codebook Gaussians set provides estimate probability function one class Parzen window estimation take estimate pattern distribution average Gaussians set Classification pattern may done calculating probability class respective sample point assigning pattern class highest probability Hence whole codebook plays role classification patterns This case regular classification schemes using codebooks We tested classification scheme several classification tasks including two spiral problem We compared algorithm various classification algorithms came second best algorithm applications Parzen window estimation However computing time memory Parzen window estimation excessive compared algorithm hence practical situations algorithm preferred We developed fast algorithm combines attractive properties Parzen window estimation vector quantization The scale parameter tuned adaptively therefore set ad hoc manner It allows classification strategy codebook vectors taken account This yields better results standard vector quantization techniques An interesting topic research use radially nonsymmetric Gaussians',\n",
              " 'Predictions lifetimes dynamically allocated objects used improve time space efficiency dynamic memory management computer programs Barrett Zorn used simple lifetime predictor demonstrated improvement variety computer programs In paper use decision trees lifetime prediction programs show significantly better prediction Our method also advantage training use large number features let decision tree automatically choose relevant subset',\n",
              " 'Evolutionary systems used variety applications turbine design scheduling problems The basic algorithms similar applications representation always problem specific Unfortunately search time evolutionary systems much depends efficient codings using problem specific domain knowledge reduce size search space This paper describes approach user specifies general basic coding used larger variety problems The system learns efficient problem specific coding To evolutionary system variable length coding used While system optimizes example problem meta process identifies successful combinations genes population combines higher level evolved genes The extraction repeated iteratively allowing genes evolve high level complexity encode high number original basic genes This results continuous restructuring search space allowing potentially successful solutions found much shorter search time The evolved coding used solve related problems While excluding potentially desirable solutions evolved coding makes knowledge example problem available new problem',\n",
              " 'The coverage learning algorithm number concepts learned algorithm samples given size This paper asks whether good learning algorithms designed maximizing coverage The paper extends previous upper bound coverage Boolean concept learning algorithm describes two algorithmsMultiBalls LargeBallwhose coverage approaches upper bound Experimental measurement coverage ID FRINGE algorithms shows coverage far bound Further analysis LargeBall shows although learns many concepts seem interesting concepts Hence coverage maximization alone appear yield practicallyuseful learning algorithms The paper concludes definition coverage within bias suggests way coverage maximization could applied strengthen weak preference biases',\n",
              " 'Markov decision processes MDPs recently applied problem modeling decisiontheoretic planning While traditional methods solving MDPs often practical small states spaces effectiveness large AI planning problems questionable We present algorithm called structured policy iteration SPI constructs optimal policies without explicit enumeration state space The algorithm retains fundamental computational steps commonly used modified policy iteration algorithm exploits variable propositional independencies reflected temporal Bayesian network representation MDPs The principles behind SPI applied structured representation stochastic actions policies value functions algorithm used conjunction cent approximation methods',\n",
              " 'This paper reviews features new class multilayer connectionist architectures known ASOCS Adaptive SelfOrganizing Concurrent Systems ASOCS similar decisionmaking neural network models attempts learn adaptive set arbitrary vector mappings However differs dramatically mechanisms ASOCS based networks adaptive digital elements selfmodify using local information Function specification entered incrementally use rules rather complete inputoutput vectors processing network able extract critical features large environment give output parallel fashion Learning also uses parallelism selforganization new rule completely learned time linear depth network The model guarantees learning arbitrary mapping boolean inputoutput vectors The model also stable learning erase previously learned mappings except explicitly contradicted',\n",
              " 'Maximum working likelihood MWL inference presence missing data quite challenging intractability associated marginal likelihood This problem exacerbated number parameters involved large We propose using Markov chain Monte Carlo MCMC first obtain MWL estimator working Fisher information matrix second using Monte Carlo quadrature obtain remaining components correct asymptotic MWL variance Evaluation marginal likelihood needed We demonstrate consistency asymptotic normality number independent identically distributed data clusters large likelihood may incorrectly specified An analysis longitudinal ordinal data given example KEY WORDS Convergence posterior distributions Maximum likelihood Metropolis',\n",
              " 'Natural images contain characteristic statistical regularities set apart purely random images Understanding regularities enable natural images coded efficiently In paper describe forms structure contained natural images show related response properties neurons early stages visual system Many important forms structure require higherorder ie linear pairwise statistics characterize makes models based linear Hebbian learning principal components analysis inappropriate finding efficient codes natural images We suggest good objective efficient coding natural scenes maximize sparseness representation show network learns sparse codes natural scenes succeeds developing localized oriented bandpass receptive fields similar primate striate cortex',\n",
              " 'In paper develop empirical methodology studying behavior evolutionary algorithms based problem generators We describe three generators used study effects epistasis performance EAs Finally illustrate use ideas preliminary exploration effects epistasis simple GAs',\n",
              " 'Traditionally genetic algorithms relied upon point crossover operators Many recent empirical studies however shown benefits higher numbers crossover points Some intriguing recent work focused uniform crossover involves average L crossover points strings length L Theoretical results suggest view hyperplane sampling disruption uniform crossover redeeming features However growing body experimental evidence suggests otherwise In paper attempt reconcile opposing views uniform crossover present framework understanding virtues',\n",
              " 'Conditional logics introduced Lewis Stalnaker utilized artificial intelligence capture broad range phenomena In paper examine complexity several variants discussed literature We show general deciding satisfiability PSPACEcomplete formulas arbitrary conditional nesting NPcomplete formulas bounded nesting conditionals However provide several exceptions rule Of particular note results showing assuming uniformity ie worlds agree worlds possible decision problem becomes EXPTIMEcomplete even formulas bounded nesting b assuming absoluteness ie worlds agree conditional statements decision problem NPcomplete mulas arbitrary nesting',\n",
              " 'An incremental higherorder nonrecurrent network combines two properties found useful learning sequential tasks higherorder connections incremental introduction new units The network adds higher orders needed adding new units dynamically modify connection weights Since new units modify weights next timestep information previous step temporal tasks learned without use feedback thereby greatly simplifying training Furthermore theoretically unlimited number units added reach arbitrarily distant past Experiments Reber grammar demonstrated speedups two orders magnitude recurrent networks',\n",
              " 'I propose novel general principle unsupervised learning distributed nonredundant internal representations input patterns The principle based two opposing forces For representational unit adaptive predictor tries predict unit remaining units In turn unit tries react environment minimizes predictability This encourages unit filter abstract concepts environmental input concepts statistically independent upon units focus I discuss various simple yet potentially powerful implementations principle aim finding binary factorial codes Barlow et al ie codes probability occurrence particular input simply product probabilities corresponding code symbols Such codes potentially relevant segmentation tasks speeding supervised learning novelty detection Methods finding factorial codes automatically implement Occams razor finding codes using minimal number units Unlike previous methods novel principle potential removing linear also nonlinear output redundancy Illustrative experiments show algorithms based principle predictability minimization practically feasible The final part paper describes entirely local algorithm potential learning unique representations extended input sequences',\n",
              " 'In paper study learning PAC model Valiant example oracle used learning may faulty one two ways either misclassifying example distorting distribution examples We first consider models examples misclassified Kearns recently showed efficient learning new model using statistical queries sufficient condition PAC learning classification noise We show efficient learning statistical queries sufficient learning PAC model malicious error rate proportional required statistical query accuracy One application result new lower bound tolerable malicious error learning monomials k literals This first bound independent number irrelevant attributes n We also use statistical query model give sufficient conditions using distribution specific algorithms distributions outside prescribed domains A corollary result expands class distributions weakly learn monotone Boolean formulae We also consider new models learning examples chosen according distribution learner tested We examine three variations distribution noise give necessary sufficient conditions polynomial time learning noise We show containments separations various models faulty oracles Finally examine hypothesis boosting algorithms context learning distribution noise show Schapires result regarding strength weak learnability sense tight requiring weak learner nearly distribution free',\n",
              " 'This paper describes first stage study evolution learning abilities We use simple maze exploration problem designed R Sutton task individual encode inherent learning parameters genome The learning architecture use one step Qlearning using lookup table inherent parameters initial Qvalues learning rate discount rate rewards exploration rate Under fitness measure proportioning number times achieves goal later half life learners evolve genetic algorithm The results computer simulation indicated learning ability emerge environment changes every generation inherent map optimal path acquired environment doesnt change These results suggest emergence learning ability needs environmental change faster alternate generation',\n",
              " 'We examine problem performing exact dynamicprogramming updates partially observable Markov decision processes pomdps computational complexity viewpoint Dynamicprogramming updates crucial operation wide range pomdp solution methods find intractable perform updates piecewiselinear convex value functions general pomdps We offer new algorithm called witness algorithm compute updated value functions efficiently restricted class pomdps number linear facets great We compare witness algorithm existing algorithms analytically empirically find fastest algorithm wide range pomdp sizes',\n",
              " 'This paper examines limits instruction level parallelism found programs particular SPEC benchmark suite Apart using recent version SPEC benchmark suite differs earlier studies removing nonessential true dependencies occur result compiler employing stack subroutine linkage This subtle limitation parallelism readily evident appears true dependency stack pointer Other methods used employ stack remove dependency In paper show removal exposes far parallelism seen previously We refer type parallelism parallelism distance requires impossibly large instruction windows detection We conclude two observations single instruction window characteristic superscalar machines inadequate detecting parallelism distance order take advantage parallelism compiler must involved separate threads must explicitly programmed',\n",
              " 'In paper present framework building probabilistic automata parameterized contextdependent probabilities Gibbs distributions used model state transitions output generation parameter estimation carried using EM algorithm Mstep uses generalized iterative scaling procedure We discuss relations certain classes stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model constructed using methodology',\n",
              " 'Models unsupervised correlationbased Hebbian synaptic plasticity typically unstable either synapses grow reaches maximum allowed strength synapses decay zero strength A common method avoiding outcomes use constraint conserves limits total synaptic strength cell We study dynamical effects constraints Two methods enforcing constraint distinguished multiplicative subtractive For otherwise linear learning rules multiplicative enforcement constraint results dynamics converge principal eigenvector operator determining unconstrained synaptic development Subtractive enforcement contrast typically leads final state almost synaptic strengths reach either maximum minimum allowed value This final state often dominated weight configurations principal eigenvector unconstrained operator Multiplicative enforcement yields graded receptive field mutually correlated inputs represented whereas subtractive enforcement yields receptive field sharpened subset maximallycorrelated inputs If two equivalent input populations eg two eyes innervate common target multiplicative enforcement prevents segregation ocular dominance segregation two populations weakly correlated whereas subtractive enforcement allows segregation circumstances These results may used understand constraints output cells input cells A variety rules implement constrained dynamics discussed',\n",
              " 'This project supported part grant McDonnellPew Foundation grant ATR Human Information Processing Research Laboratories grant Siemens Corporation grant NJ Office Naval Research The project also supported NSF grant ASC support Center Biological Computational Learning MIT including funds provided DARPA HPCC program Michael I Jordan NSF Presidential Young Investigator',\n",
              " 'Learning made efficient actively select particularly salient data points Within Bayesian learning framework objective functions discussed measure expected informativeness candidate measurements Three alternative specifications want gain information lead three different criteria data selection All criteria depend assumption hypothesis space correct may prove main weakness',\n",
              " 'Knowledge clusters relations important understanding highdimensional input data unknown distribution Ordinary feature maps fully connected fixed grid topology properly reflect structure clusters input spacethere cluster boundaries map Incremental feature map algorithms nodes connections added deleted map according input distribution overcome problem However far algorithms limited maps drawn D case dimensional input space In approach proposed paper nodes added incrementally regular dimensional grid drawable times irrespective dimensionality input space The process results map explicitly represents cluster structure highdimensional input',\n",
              " 'Lattice conditional independence LCI models multivariate normal data recently introduced analysis nonmonotone missing data patterns nonnested dependent linear regression models seemingly unrelated regressions It shown class LCI models coincides subclass class graphical Markov models determined acyclic digraphs ADGs namely subclass transitive ADG models An explicit graph theoretic characterization ADGs Markov equivalent transitive ADG obtained This characterization allows one determine whether specific ADG D Markov equivalent transitive ADG hence LCI model polynomial time without exhaustive search exponentially large equivalence class D These results require existence positivity joint densities',\n",
              " 'In paper describe method improving geneticalgorithmbased optimization using casebased learning The idea utilize sequence points explored search guide exploration The proposed method particularly suitable continuous spaces expensive evaluation functions arise engineering design Empirical results two engineering design domains across different representations demonstrate proposed method significantly improve efficiency reliability GA optimizer Moreover results suggest modification makes genetic algorithm less sensitive poor choices tuning parameters muta tion rate',\n",
              " 'Genetic algorithms GAs extensively used means performing global optimization simple yet reliable manner However realistic engineering design optimization domains simple classical implementation GA based binary encoding bit mutation crossover often inefficient unable reach global optimum In paper describe GA continuous designspace optimization uses new GA operators strategies tailored structure properties engineering design domains Empirical results domains supersonic transport aircraft supersonic missile inlets demonstrate newly formulated GA significantly better classical GA efficiency reliability',\n",
              " 'D E Rumelhart G E Hinton R J Williams Learning Internal Representations Error Propagation D E Rumelhart J L McClelland eds Parallel Distributed Processing Explorations Microstructure Cognition Vol MIT Press',\n",
              " 'Evolutionary trees frequently used underlying model design algorithms optimization criteria software packages multiple sequence alignment MSA In paper reexamine suitability trees universal model MSA light broad range biological questions MSAs used address A tree model consists tree topology model accepted mutations along branches After surveying major applications MSA examples molecular biology literature used illustrate situations tree model fails This occurs relationship residues column described tree example structural functional applications MSA It also occurs situations lateral gene transfer entire gene modeled unique tree In cases nonparsimonous data convergent evolution may difficult find consistent mutational model We hope survey promote dialogue biologists computer scientists leading biologically realistic research MSA',\n",
              " 'Selective suppression transmission feedback synapses learning proposed mechanism combining associative feedback selforganization feedforward synapses Experimental data demonstrates cholinergic suppression synaptic transmission layer I feedback synapses lack suppression layer IV feedforward synapses A network feature uses local rules learn mappings linearly separable During learning sensory stimuli desired response simultaneously presented input Feedforward connections form selforganized representations input suppressed feedback connections learn transpose feedforward connectivity During recall suppression removed sensory input activates selforganized representation activity generates learned response',\n",
              " 'Technical Report No Department Statistics University Toronto Abstract One way sample distribution sample uniformly region plot density function A Markov chain converges uniform distribution constructed alternating uniform sampling vertical direction uniform sampling horizontal slice defined current vertical position Variations slice sampling methods easily implemented univariate distributions used sample multivariate distribution updating variable turn This approach often easier implement Gibbs sampling may efficient easilyconstructed versions Metropolis algorithm Slice sampling therefore attractive routine Markov chain Monte Carlo applications use software automatically generates Markov chain sampler model specification One also easily devise overrelaxed versions slice sampling sometimes greatly improve sampling efficiency suppressing random walk behaviour Random walks also avoided slice sampling schemes simultaneously update variables',\n",
              " 'Markov decision problems MDPs provide foundations number problems interest AI researchers studying automated planning reinforcement learning In paper summarize results regarding complexity solving MDPs running time MDP solution algorithms We argue although MDPs solved efficiently theory study needed reveal practical algorithms solving large problems quickly To encourage future research sketch alternative methods analysis rely struc ture MDPs',\n",
              " 'Learning reinforcements promising approach creating intelligent agents However reinforcement learning usually requires large number training episodes We present evaluate design addresses shortcoming allowing connectionist Qlearner accept advice given time natural manner external observer In approach advicegiver watches learner occasionally makes suggestions expressed instructions simple imperative programming language Based techniques knowledgebased neural networks insert programs directly agents utility function Subsequent reinforcement learning integrates refines advice We present empirical evidence investigates several aspects approach show given good advice learner achieve statistically significant gains expected reward A second experiment shows advice improves expected reward regardless stage training given another study demonstrates subsequent advice result gains reward Finally present experimental results indicate method powerful naive technique making use advice',\n",
              " 'This paper presents mathematical foundations Dirichlet mixtures used improve database search results homologous sequences variable number sequences protein family domain known We present method condensing information protein database mixture Dirichlet densities These mixtures designed combined observed amino acid frequencies form estimates expected amino acid probabilities position profile hidden Markov model statistical model These estimates give statistical model greater generalization capacity remotely related family members reliably recognized model Dirichlet mixtures shown outperform substitution matrices methods computing expected amino acid distributions database search resulting fewer false positives false negatives families tested This paper corrects previously published formula estimating expected probabilities contains complete derivations Dirichlet mixture formulas methods optimizing mixtures match particular databases suggestions efficient implementation',\n",
              " 'Derivational analogy technique reusing problem solving experience improve problem solving performance This research addresses issue common problem solvers use derivational analogy overcoming mismatches past experiences new problems impede reuse First research describes variety mismatches arise proposes new approach derivational analogy uses appropriate adaptation strategies Second compares approach seven others common domain This empirical study shows derivational analogy almost always efficient problem solving scratch amount contributes depends ability overcome mismatches',\n",
              " 'Pollack demonstrated secondorder recurrent neural networks act dynamical recognizers formal languages trained positive negative examples observed phase transitions learning IFSlike fractal state sets Followon work focused mainly extraction minimization finite state automaton FSA trained network However networks capable inducing languages regular therefore equivalent FSA Indeed may simpler small network fit training data inducing nonregular language But networks language regular In paper using low dimensional network capable learning Tomita data sets present empirical method testing whether language induced network regular We also provide detailed machine analysis trained networks regular nonregular languages',\n",
              " 'COINS Technical Report January Abstract This article presents algorithm inducing multiclass decision trees multivariate tests internal decision nodes Each test constructed training linear machine eliminating variables controlled manner Empirical results demonstrate algorithm builds small accurate trees across variety tasks',\n",
              " 'Funes P Pollack J Computer Evolution Buildable Objects Fourth European Conference Artificial Life P Husbands I Harvey eds MIT Press pp knowledge program would result familiar structures provided algorithm model physical reality purely utilitarian fitness function thus supplying measures feasibility functionality In way evolutionary process runs environment unnecessarily constrained We added however requirement computability reject overly complex structures took long simulations evaluate The results encouraging The evolved structures surprisingly alien look based common knowledge build brick toys instead computer found ways evolutionary search process We able assemble final designs manually confirm accomplish objectives introduced fitness functions After background related problems describe physical simulation model twodimensional Lego structures representation encoding applying evolution We demonstrate feasibility work photos actual objects result particular optimizations Finally discuss future work draw conclusions In order evolve morphology behavior autonomous mechanical devices manufactured one must simulator operates several constraints resultant controller adaptive enough cover gap simulated real world eral space mechanisms Conservative simulation never perfect preserve margin safety Efficient quicker test simulation physical production test Buildable results convertible simula tion real object Computer Evolution Buildable Objects Abstract The idea coevolution bodies brains becoming popular little work done evolution physical structure lack general framework Evolution creatures simulation constrained reality gap implies resultant objects usually buildable The work present takes step problem body evolution applying evolutionary techniques design structures assembled parts Evolution takes place simulator designed computes forces stresses predicts failure dimensional Lego structures The final printout program schematic assembly built physically We demonstrate functionality several different evolved entities',\n",
              " 'In paper concerned problem acquiring knowledge integration Our aim construct integrated knowledge base several separate sources The need merge knowledge bases arise example knowledge bases acquired independently interactions several domain experts As opinions different domain experts may differ knowledge bases constructed way normally differ A similar problem also arise whenever separate knowledge bases generated learning algorithms The objective integration construct one system exploits knowledge available good performance The aim paper discuss methodology knowledge integration describe implemented system INTEG present concrete results demonstrate advantages method',\n",
              " 'Many arthropods particularly insects exhibit sophisticated visually guided behaviours Yet cases behaviours guided input hundreds thousands pixels ie ommatidia compound eye Inspired observation several years exploring possibilities visually guided robots lowbandwidth vision Rather design robot controllers hand use artificial evolution form extended genetic algorithm automatically generate architectures artificial neural networks generate effective sensorymotor coordination controlling mobile robots Analytic techniques drawn neuroethology dynamical systems theory allow us understand evolved robot controllers function predict behaviour environments used evolutionary process Initial experiments performed simulation techniques successfully transferred work variety real physical robot platforms This chapter reviews past work concentrating analysis evolved controllers gives overview current research We conclude discussion application evolutionary techniques problems biological vision',\n",
              " 'The major implementational problem reversible jump MCMC commonly natural way choose jump proposals since Euclidean structure guide choice In paper consider mechanism guiding proposal choice analysis acceptance probabilities jumps Essentially method involves approximation acceptance probability around certain canonical jumps We illustrate procedure using example reversible jump MCMC application involving Bayesian analysis graphical gaussian models',\n",
              " 'Instancebased learning methods explicitly remember data receive They usually training phase prediction time perform computation Then take query search database similar datapoints build online local model local average local regression predict output value In paper review advantages instance based methods autonomous systems also note ensuing cost hopelessly slow computation database grows large We present evaluate new way structuring database new algorithm accessing maintains advantages instancebased learning Earlier attempts combat cost instancebased learning sacrificed explicit retention data applicable instancebased predictions based small number near neighbors reintroduce explicit training phase form interpolative data structure Our approach builds multiresolution data structure summarize database experiences resolutions interest simultaneously This permits us query database exibility conventional linear search greatly reduced computational cost',\n",
              " 'In standard online model learning algorithm tries minimize total number mistakes made series trials On trial learner sees instance either accepts rejects instance told appropriate response We define natural variant model apple tasting learner gets feedback instance accepted We use two transformations relate apple tasting model enhanced standard model false acceptances counted separately false rejections We present strategy trading false acceptances false rejections standard model From one perspective strategy exactly optimal including constants We apply results obtain good general purpose apple tasting algorithm well nearly optimal apple tasting algorithms variety standard classes conjunctions disjunctions n boolean variables We also present analyze simpler transformation useful instances drawn random rather selected adversary',\n",
              " 'In paper describe algorithm exploits error distribution generated learning algorithm order break domain approximated piecewise learnable partitions Traditionally error distribution neglected favor lump error measure RMS By however lose lot important information The error distribution tells us algorithm badly exists ridge errors also tells us partition space one part space interfere learning another The algorithm builds variable arity kd tree whose leaves contain partitions Using tree new points predicted using correct partition traversing tree We instantiate algorithm using memory based learners crossvalidation',\n",
              " 'PREENS Parallel Research Execution Environment Neural Systems distributed neurosimulator targeted networks workstations transputer systems As current applications neural networks often contain large amounts data neural networks involved tasks vision large high requirements memory computational resources imposed target execution platforms PREENS executed distributed environment ie tools neural network simulation programs running machine connectable via TCPIP Using approach larger tasks data examined using efficient coarse grained parallelism Furthermore design PREENS allows neural networks running high performance MIMD machine transputer system In paper different features design concepts PREENS discussed These also used applications like image processing',\n",
              " 'It well known standard learning classifier systems applied many different domains exhibit number problems payoff oscillation difficult regulate interplay reward system background genetic algorithm GA rule chains instability default hierarchies instability ALECSYS parallel version standard learning classifier system CS suffers problems In paper propose innovative solutions problems We introduce following original features Mutespec new genetic operator used specialize potentially useful classifiers Energy quantity introduced measure global convergence order apply genetic algorithm system close steady state Dynamical adjustment classifiers set cardinality order speed performance phase algorithm We present simulation results experiments run simulated twodimensional world simple agent learns follow light source',\n",
              " 'Supervised neural networks generalize well much less information weights output vectors training cases So learning important keep weights simple penalizing amount information contain The amount information weight controlled adding Gaussian noise noise level adapted learning optimize tradeoff expected squared error network amount information weights We describe method computing derivatives expected squared error amount information noisy weights network contains layer nonlinear hidden units Provided output units linear exact derivatives computed efficiently without timeconsuming Monte Carlo simulations The idea minimizing amount information required communicate weights neural network leads number interesting schemes encoding weights',\n",
              " 'There many applications desirable order rather classify instances Here consider problem learning order given feedback form preference judgments ie statements effect one instance ranked ahead another We outline twostage approach one first learns conventional means preference function form PREFu v indicates whether advisable rank u v New instances ordered maximize agreements learned preference function We show problem finding ordering agrees best preference function NPcomplete even restrictive assumptions Nevertheless describe simple greedy algorithm guaranteed find good approximation We discuss online learning algorithm based Hedge algorithm finding good linear combination ranking experts We use ordering algorithm combined online learning algorithm find combination search experts domainspecific query expansion strategy WWW search engine present experimental results demonstrate merits approach',\n",
              " 'Technical Report CSRP March Abstract Evolutionary algorithms powerful techniques optimisation whose operation principles inspired natural selection genetics In paper discuss relation evolutionary techniques numerical classical search methods show methods instances single general search strategy call evolutionary computation cookbook By combining features classical evolutionary methods different ways new instances general strategy generated ie new evolutionary classical algorithms designed One algorithm GA fl described',\n",
              " 'We present neural net architecture discover hierarchical recursive structure symbol strings To detect structure multiple levels architecture capability reducing symbols substrings single symbols makes use external stack memory In terms formal languages architecture learn parse strings LR contextfree grammar Given training sets positive negative exemplars architecture trained recognize many different grammars The architecture one layer modifiable weights allowing Many cognitive domains involve complex sequences contain hierarchical recursive structure eg music natural language parsing event perception To illustrate spider ate hairy fly noun phrase containing embedded noun phrase hairy fly Understanding multilevel structures requires forming reduced descriptions Hinton string symbols states hairy fly reduced single symbolic entity noun phrase We present neural net architecture learns encode structure symbol strings via reduction transformations The difficult problem extracting multilevel structure complex extended sequences studied Mozer Ring Rohwer Schmidhuber among others While previous efforts made straightforward interpretation behavior',\n",
              " 'Selforganizing feature maps usually implemented abstracting lowlevel neural parallel distributed processes An external supervisor finds unit whose weight vector closest Euclidian distance input vector determines neighborhood weight adaptation The weights changed proportional Euclidian distance In biologically plausible implementation similarity measured scalar product neighborhood selected lateral inhibition weights changed redistributing synaptic resources The resulting selforganizing process quite similar abstract case However process somewhat hampered boundary effects parameters need carefully evolved It also necessary add redundant dimension input vectors',\n",
              " 'The application decision making learning algorithms multiagent systems presents many interestingresearch challenges opportunities Among ability agents learn act observing imitating agents We describe algorithm IQalgorithm integrates imitation Qlearning Roughly Qlearner uses observations made expert agent bias exploration promising directions This algorithm goes beyond previous work direction relaxing oftmade assumptions learner observer expert observed agent share objectives abilities Our preliminary experiments demonstrate significant transfer agents using IQmodel many cases reductions training time',\n",
              " 'Faces represent complex multidimensional meaningful visual stimuli developing computational model face recognition difficult We present hybrid neural network solution compares favorably methods The system combines local image sampling selforganizing map neural network convolutional neural network The selforganizing map provides quantization image samples topological space inputs nearby original space also nearby output space thereby providing dimensionality reduction invariance minor changes image sample convolutional neural network provides partial invariance translation rotation scale deformation The convolutional network extracts successively larger features hierarchical set layers We present results using KarhunenLoeve transform place selforganizing map multilayer perceptron place convolutional network The KarhunenLoeve transform performs almost well error versus The multilayer perceptron performs poorly error versus The method capable rapid classification requires fast approximate normalization preprocessing consistently exhibits better classification performance eigenfaces approach database considered number images per person training database varied With images per person proposed method eigenfaces result error respectively The recognizer provides measure confidence output classification error approaches zero rejecting examples We use database images individuals contains quite high degree variability expression pose facial details We analyze computational complexity discuss new classes could added trained recognizer',\n",
              " 'We present new algorithm solving Markov decision problems extends modified policy iteration algorithm Puterman Shin two important ways The new algorithm asynchronous allows values states updated arbitrary order need consider actions state updating policy The new algorithm converges general initial conditions required modified policy iteration Specifically set initial policyvalue function pairs algorithm guarantees convergence strict superset set modified policy iteration converges This generalization obtained making simple easily implementable change policy evaluation operator used updating value function Both asynchronous nature algorithm convergence general conditions expand range problems algorithm applied',\n",
              " 'Recently Markov chain Monte Carlo MCMC sampling methods become widely used determining properties posterior distribution Alternative Gibbs sampler elaborate HitandRun sampler generalization blackbox sampling scheme generate timereversible Markov chain posterior distribution The proof convergence applications Bayesian computation constrained parameter spaces provided comparisons MCMC samplers made In addition propose importance weighted marginal density estimation IWMDE method An IWMDE obtained averaging many dependent observations ratio full joint posterior densities multiplied weighting conditional density w The asymptotic properties IWMDE guidelines choosing weighting conditional density w also considered The generalized version IWMDE estimating marginal posterior densities full joint posterior density contains analytically intractable normalizing constants developed Furthermore develop Monte Carlo methods based KullbackLeibler divergences comparing marginal posterior density estimators This article summary authors PhD thesis presented Savage Award session',\n",
              " 'In paper characterize complexity noisetolerant learning PAC model Specifically show general lower bound logffi number examples required PAC learning presence classification noise Combined result Simon effectively show sample complexity PAC learning presence classification noise VCF Furthermore demonstrate optimality general lower bound providing noisetolerant learning algorithm class symmetric Boolean functions uses sample size within constant factor bound Finally note general lower bound compares favorably various general upper bounds PAC learning presence classification noise',\n",
              " 'It recently realized parasite virulence harm caused parasites hosts adaptive trait Selection particular level virulence happen either level betweenhost tradeoffs result shortsighted withinhost competition This paper describes simulations study effect modifier genes changes mutation rate suppressing shortsighted development virulence investigates interaction simplified model im mune clearance',\n",
              " 'Much work qualitative physics involves constructing models physical systems using functional descriptions flow monotonically increases pressure Semiquantitative methods improve model precision adding numerical envelopes monotonic functions Ad hoc methods normally used determine envelopes This paper describes systematic method computing bounding envelope multivariate monotonic function given stream data The derived envelope computed determining simultaneous confidence band special neural network guaranteed produce monotonic functions By composing envelopes complex systems simulated using semiquantitative methods',\n",
              " 'In paper describe application MemoryBased Learning problem Prepositional Phrase attachment disambiguation We compare MemoryBased Learning stores examples memory generalizes using intelligent similarity metrics number recently proposed statistical methods well suited large numbers features We evaluate methods common benchmark dataset show method compares favorably previous methods wellsuited incorporating various unconventional representations word patterns value difference metrics Lexical Space',\n",
              " 'Hierarchically structured mixture models studied context data analysis inference neural synaptic transmission characteristics mammalian central nervous systems Mixture structures arise due uncertainties stochastic mechanisms governing responses electrochemical stimulation individual neurotransmitter release sites nerve junctions Models attempt capture scientific features sensitivity individual synaptic transmission sites electrochemical stimuli extent electrochemical responses stimulated This done via suitably structured classes prior distributions parameters describing features Such priors may structured permit assessment currently topical scientific hypotheses fundamental neural function Posterior analysis implemented via stochastic simulation Several data analyses described illustrate approach resulting neurophysiological insights recently generated experimental contexts Further developments open questions neurophysiological statistical noted Research partially supported NSF grants DMS DMS DMS This work represents part collaborative project Dr Dennis A Turner Duke University Medical Center Durham VA Data provided Dr Turner Dr Howard V Wheal Southampton University A slightly revised version paper published Journal American Statistical Association vol pp modified title Hierarchical Mixture Models Neurological Transmission Analysis The author recipient Mitchell Prize Bayesian analysis substantive concrete problem based work reported paper',\n",
              " 'The need software modules performing natural language processing NLP tasks growing These modules perform efficiently accurately time rapid development often mandatory Recent work indicated machine learning techniques general memorybased learning MBL particular offer tools meet ends We present examples modules trained MBL three NLP tasks texttospeech conversion ii partofspeech tagging iii phrase chunking We demonstrate three modules display high generalization accuracy argue MBL applicable similarly well large class NLP tasks',\n",
              " 'We present membership query ie interpolation algorithm exactly identifying class readonce formulas basis boolean threshold functions Using generic transformation Angluin Hellerstein Karpinski gives algorithm using membership equivalence queries exactly identifying class readonce formulas basis boolean threshold functions negation We also present series generic transformations used convert algorithm one learning model algorithm different model',\n",
              " 'We study time series model viewed decision tree Markov temporal structure The model intractable exact calculations thus utilize variational approximations We consider three different distributions approximation one Markov calculations performed exactly layers decision tree decoupled one decision tree calculations performed exactly time steps Markov chain decoupled one Viterbilike assumption made pick single likely state sequence We present simulation results artificial data Bach chorales Accepted oral presentation NIPS',\n",
              " 'Stochastic simulation algorithms likelihood weighting often give fast accurate approximations posterior probabilities probabilistic networks methods choice large networks Unfortunately special characteristics dynamic probabilistic networks DPNs used represent stochastic temporal processes mean standard simulation algorithms perform poorly In essence simulation trials diverge reality process observed time In paper present simulation algorithms use evidence observed time step push set trials back towards reality The first algorithm evidence reversal ER restructures time slice DPN evidence nodes slice become ancestors state variables The second algorithm called survival fittest sampling SOF repopulates set trials time step using stochastic reproduction rate weighted likelihood evidence according trial We compare performance algorithm likelihood weighting original network also investigate benefits combining ER SOF methods The ERSOF combination appears maintain bounded error independent number time steps simulation',\n",
              " 'Simulated Annealing Search technique single trial solution modified random An energy defined represents good solution The goal find best solution minimising energy Changes lead lower energy always accepted increase probabilistically accepted The probability given expEk B T Where E change energy k B constant T Temperature Initially temperature high corresponding liquid molten state large changes possible progressively reduced using cooling schedule allowing smaller changes system solidifies low energy solution',\n",
              " 'Systems learn examples often create disjunctive concept definition The disjuncts concept definition cover training examples referred small disjuncts The problem small disjuncts error prone large disjuncts may necessary achieve high level predictive accuracy Holte Acker Porter This paper extends previous work done problem small disjuncts investigating reasons small disjuncts error prone large disjuncts evaluating impact small disjuncts inductive learning This paper shows attribute noise missing attributes class noise training set size cause small disjuncts error prone large disjuncts This paper also evaluates impact factors learning small disjuncts ie error rate It shows two artificial domains low levels attribute noise applied training set ability learn correct noisefree concept evaluated small disjuncts primarily responsible making learning difficult',\n",
              " 'A number efficient learning algorithms achieve exact identification unknown function class using membership equivalence queries Using standard transformation algorithms easily converted online learning algorithms use membership queries Under transformation number equivalence queries made query algorithm directly corresponds number mistakes made online algorithm In paper consider several natural classes known learnable setting investigate minimum number equivalence queries accompanying counterexamples equivalently minimum number mistakes online model made learning algorithm makes polynomial number membership queries uses polynomial computation time We able reduce number equivalence queries used previous algorithms often prove matching lower bounds As example consider class DNF formulas n variables k Olog n terms Previously algorithm Blum Rudich BR provided best known upper bound Ok log n minimum number equivalence queries needed exact identification We greatly improve upper bound showing exactly k counterexamples needed learner knows k priori exactly k counterexamples needed learner know k priori This exactly matches known lower bounds BC For many results obtain complete characterization tradeoff number membership equivalence queries needed exact identification The classes consider monotone DNF formulas Horn sentences Olog nterm DNF formulas readk satj DNF formulas readonce formulas various bases deterministic finite automata',\n",
              " 'We present learning algorithm rulebased concept representations called rippledown rule sets Rippledown rule sets allow us deal exceptions rule separately introducing exception rules exception rules exception rule etc constant depth These local exception rules contrast decision lists exception rules must placed global ordering rules The localization exceptions makes possible represent concepts decision list representation On hand decision lists constant number alternations rules different classes represented constant depth rippledown rule sets polynomial increase size Our algorithm Occam algorithm constant depth rippledown rule sets hence PAC learning algorithm It based repeatedly applying greedy approximation method weighted set cover problem find good exception rule sets',\n",
              " 'We present algorithm learning sets rules organized k levels Each level contain arbitrary number rules c l l class associated level c concept given class basic concepts The rules higher levels precedence rules lower levels used represent exceptions As basic concepts use Boolean attributes infinite attribute space model certain concepts defined terms substrings Given sample examples algorithm runs polynomial time produces consistent concept representation size Olog k n k n size smallest consistent representation k levels rules This implies algorithm learns PAC model The algorithm repeatedly applies greedy heuristics weighted set cover The weights obtained approximate solutions previous set cover problems',\n",
              " 'In paper investigate representational methodological issues attractor network model mapping orthography semantics based Plaut We find contrary psycholinguistic studies response time concrete words represented bits output pattern slower abstract words This model also predicts response times words dense semantic neighborhood faster words semantically similar neighbors language This conceptually consistent neighborhood effect seen mapping orthography phonology Seidenberg McClelland Plaut et al patterns many neighbors faster pathways since regularity random mapping used clear cause effect different previous experiments We also report rather distressing finding Reaction time model measured time takes network settle presented new input When criterion used determine network settled changed include testing hidden units results reported change direction effect abstract words slower words dense semantic neighborhoods Since independent reasons exclude hidden units stopping criterion done common practice believe phenomenon interest mostly neural network practitioners However provide insight interaction hidden output units settling',\n",
              " 'Casebased reasoning CBR used form caching solved problems speedup later problem solving Using cached cases brings additional costs due retrieval time case adaptation time also storage space Simply storing cases result situation retrieving trying adapt old cases take time average caching This means caching must applied selectively build case memory actually useful This form utility problem The approach taken construct cost model system used predict effect changes system In paper describe utility problem associated caching cases construction cost model We present experimental results demonstrate model used predict effect certain changes case memory',\n",
              " 'A Genetic Algorithmic GA approach vector quantizer design combines conventional Generalized Lloyd Algorithm GLA presented We refer hybrid Genetic Generalized Lloyd Algorithm GGLA It works briefly follows A finite number codebooks called chromosomes selected Each codebook undergoes iterative cycles reproduction We perform experiments various alternative design choices using GaussianMarkov processes speech image source data signaltonoise ratio SNR performance measure In cases GGLA showed performance improvements respect GLA We also compare results ZadorGersho formula',\n",
              " 'In casebased planning CBP previously generated plans stored cases memory reused solve similar planning problems future CBP save considerable time planning scratch generative planning thus offering potential heuristic mechanism handling intractable problems One drawback CBP systems need highly structured memory requires significant domain engineering complex memory indexing schemes enable efficient case retrieval In contrast CBP system CaPER based massively parallel framebased AI language extremely fast retrieval complex cases large unindexed memory The ability fast frequent retrievals many advantages indexing unnecessary large casebases used memory probed numerous alternate ways allowing specific retrieval stored plans better fit target problem less adaptation fl Preliminary version article appearing IEEE Expert February pp This paper extended version',\n",
              " 'We present efficient method assigning number processors tasks associated cells rectangular uniform grid Load balancing equipartition constraints observed approximately minimizing total perimeter partition corresponds amount interprocessor communication This method based upon decomposition grid stripes optimal height We prove mild assumptions problem size grows large parameters error bound associated feasible solution approaches zero We also present computational results high level parallel Genetic Algorithm utilizes method make comparisons methods On network workstations algorithm solves within minutes instances problem would require one billion binary variables Quadratic Assignment formulation',\n",
              " 'Finding Bayesian balance exploration exploitation adaptive optimal control general intractable This paper shows compute suboptimal estimates based certainty equivalence approximation arising form dual control This systematizes extends existing uses exploration bonuses reinforcement learning Sutton The approach two components statistical model uncertainty world way turning exploratory behaviour',\n",
              " 'This paper deals nonlinear leastsquares problems involving fitting data parameterized analytic functions For generic regression data general result establishes countability stronger assumptions finiteness set functions giving rise critical points quadratic loss function In special case usually called singlehidden layer neural networks built upon standard sigmoidal activation tanhx equivalently e x rough upper bound cardinality provided well',\n",
              " 'This research funded part NSF Grant No IRI part ONR Grant No NJ We thank John Clement use protocol transcript James Greeno contribution developing constructive modeling interpretation Ryan Tweney helpful comments Todd W Griffith Nancy J Nersessian Ashok Goel Abstract We hypothesize generic models central conceptual change science This hypothesis origins two theoretical sources The first source constructive modeling derives philosophical theory synthesizes analyses historical conceptual changes science investigations reasoning representation cognitive psychology The theory constructive modeling posits generic mental models productive conceptual change The second source adaptive modeling derives computational theory creative design Both theories posit situation independent domain abstractions ie generic models Using constructive modeling interpretation reasoning exhibited protocols collected John Clement problem solving session involving conceptual change employ resources theory adaptive modeling develop new computational model ToRQUE Here describe piece analysis protocol illustrate synthesis two theories used develop system articulating testing ToRQUE The results research show generic modeling plays central role conceptual change They also demonstrate interdisciplinary synthesis provide significant insights scientific reasoning',\n",
              " 'This paper discusses design neural networks solve specific problems adaptive control In particular investigates influence typical problems arising realworld control tasks well techniques solution exist framework neurocontrol Based investigation systematic design method developed The method exemplified development adaptive force controller robot manipulator',\n",
              " 'We present informationtheoretic derivation learning algorithm clusters unlabelled data linear discriminants In contrast methods try preserve information input patterns maximize information gained observing output robust binary discriminators implemented sigmoid nodes We derive local weight adaptation rule via gradient ascent objective demonstrate dynamics simple data sets relate approach previous work suggest directions may extended',\n",
              " 'This paper presents ASOCS Adaptive SelfOrganizing Concurrent System model massively parallel processing incrementally defined rule systems areas adaptive logic robotics logical inference dynamic control An ASOCS adaptive network composed many simple computing elements operating asynchronously parallel This paper focuses Adaptive Algorithm AA details architecture learning algorithm AA significant memory knowledge maintenance advantages previous ASOCS models An ASOCS operate either data processing mode learning mode During learning mode ASOCS given new rule expressed boolean conjunction The AA learning algorithm incorporates new rule distributed fashion short bounded time During data processing mode ASOCS acts parallel hardware circuit',\n",
              " 'This paper presents method analyzing coupled time series using Markov models domain state space immense To make parameter estimation tractable large state space represented Cartesian product smaller state spaces paradigm known factorial Markov models The transition matrix model represented mixture transition matrices underlying dynamical processes This formulation know mixed memory Markov models Using framework analyze daily exchange rates five currencies British pound Canadian dollar Deutsch mark Japanese yen Swiss franc measured US dollar',\n",
              " 'This work explores use machine learning methods extracting knowledge simulations complex systems In particular use genetic algorithms learn rulebased strategies used autonomous robots The evaluation given strategy may require several executions simulation produce meaningful estimate quality strategy As consequence evaluation single individual genetic algorithm requires fairly substantial amount computation Such system suggests sort largegrained parallelism available network workstations We describe implementation parallel genetic algorithm present case studies resulting speedup two robot learning tasks',\n",
              " 'Most Artificial Neural Networks ANNs fixed topology learning often suffer number shortcomings result Variations ANNs use dynamic topologies shown ability overcome many problems This paper introduces LocationIndependent Transformations LITs general strategy implementing distributed feedforward networks use dynamic topologies dynamic ANNs efficiently parallel hardware A LIT creates set locationindependent nodes node computes part network output independent nodes using local information This type transformation allows efficient support adding deleting nodes dynamically learning In particular paper presents LIT dynamic Backpropagation networks single hidden layer The complexity learning execution algorithms Onplogm single pattern nis number inputs p number outputs number hidden nodes original network Keywords Neural Networks Backpropagation Implementation Design Dynamic Topologies Reconfigurable Architectures',\n",
              " 'Hard combinatorial problems sequencing scheduling led recently research genetic algorithms Canonical coding symmetric TSP modified coding njob mmachine flowshop problem configurates solution space different way We show well known genetic operators act intelligently coding scheme They implecitely prefer subset solutions contain probably best solutions respect objective We conjecture every new problem needs determination necessary condition genetic algorithm work e proof experiment We implemented asynchronous parallel genetic algorithm UNIXbased computer network Computational results new heuristic discussed',\n",
              " 'This paper presents VLSI implementation Priority Adaptive SelfOrganizing Concurrent System PASOCS learning model built using multichip module MCM substrate Many current hardware implementations neural network learning models direct implementations classical neural network structuresa large number simple computing nodes connected dense number weighted links PASOCS one class ASOCS Adaptive SelfOrganizing Concurrent System connectionist models whose overall goal classical neural networks models whose functional mechanisms differ significantly This model potential application areas pattern recognition robotics logical inference dynamic control',\n",
              " 'The application adaptive optimization strategies scheduling manufacturing systems recently become research topic broad interest Population based approaches scheduling predominantly treat static data models whereas realworld scheduling tends dynamic problem This paper briefly outlines application genetic algorithm dynamic job shop problem arising production scheduling First sketch genetic algorithm handle release times jobs In second step preceding simulation method used improve performance algorithm Finally job shop regarded nondeterministic optimization problem arising occurrence job releases Temporal Decomposition leads scheduling control interweaves simulation time genetic search',\n",
              " 'Neural network pruning methods level individual network parameters eg connection weights improve generalization shown empirical study However open problem pruning methods known today OBD OBS autoprune epsiprune selection number parameters removed pruning step pruning strength This work presents pruning method lprune automatically adapts pruning strength evolution weights loss generalization training The method requires algorithm parameter adjustment user Results statistical significance tests comparing autoprune lprune static networks early stopping given based extensive experimentation different problems The results indicate training pruning often significantly better rarely significantly worse training early stopping without pruning Furthermore lprune often superior autoprune superior OBD diagnosis tasks unless severe pruning early training process required',\n",
              " 'Casebased problemsolving systems rely similarity assessment select stored cases whose solutions easily adaptable fit current problems However widelyused similarity assessment strategies evaluation semantic similarity poor predictors adaptability As result systems may select cases difficult impossible adapt even easily adaptable cases available memory This paper presents new similarity assessment approach couples similarity judgments directly case library containing systems adaptation knowledge It examines approach context casebased planning system learns new plans new adaptations Empirical tests alternative similarity assessment strategies show approach enables better case selection increases benefits accrued learned adaptations',\n",
              " 'The casebased reasoning process depends multiple overlapping knowledge sources provides opportunity learning Exploiting opportunities requires determining learning mechanisms use individual knowledge source also different learning mechanisms interact combined utility This paper presents case study examining relative contributions costs involved learning processes three different knowledge sourcescases case adaptation knowledge similarity informationin casebased planner It demonstrates importance interactions different learning processes identifies promising method integrating multiple learning methods improve casebased reasoning',\n",
              " 'Casebased reasoning depends multiple knowledge sources beyond case library including knowledge case adaptation criteria similarity assessment Because hand coding knowledge accounts large part knowledge acquisition burden developing CBR systems appealing acquire learning CBR promising learning method apply This observation suggests developing casebased CBR systems CBR systems whose components use CBR However despite early interest casebased approaches CBR method received comparatively little attention Open questions include casebased components CBR system designed amount knowledge acquisition effort require effectiveness This paper investigates questions case study issues addressed methods used results achieved casebased planning system uses CBR guide case adaptation similarity assessment The paper discusses design considerations presents empirical results support usefulness casebased CBR point potential problems tradeoffs directly demonstrate overlapping roles different CBR knowledge sources The paper closes general lessons casebased CBR areas future research',\n",
              " 'A linear support vector machine formulation used generate fast finitelyterminating linearprogramming algorithm discriminating two massive sets ndimensional space number points orders magnitude larger n The algorithm creates succession sufficiently small linear programs separate chunks data time The key idea small number support vectors corresponding linear programming constraints positive dual variables carried successive small linear programs containing chunk data We prove procedure monotonic terminates finite number steps exact solution leads globally optimal separating plane entire dataset Numerical results fully dense publicly available datasets numbering million points dimensional space confirm theoretical results demonstrate ability handle large problems',\n",
              " 'In Sejnowski Rosenberg developed famous NETtalk system English texttospeech This chapter describes machine learning approach texttospeech builds upon extends initial NETtalk work Among many extensions NETtalk system following different learning algorithm wider input window errorcorrecting output coding righttoleft scan word pronounced results decision influencing subsequent decisions addition several useful input features These changes yielded system performs much better original NETtalk system After training words system achieves correct pronunciation individual phonemes correct pronunciation whole words pronunciation must exactly match dictionary pronunciation correct Based judgements three human participants blind assessment study system estimated serious error rate whole words compared error rate DECTalk rulebase',\n",
              " 'The problem minimizing number misclassified points plane attempting separate two point sets intersecting convex hulls ndimensional real space formulated linear program equilibrium constraints LPEC This general LPEC converted exact penalty problem quadratic objective linear constraints A FrankWolfetype algorithm proposed penalty problem terminates stationary point global solution Novel aspects approach include A linear complementarity formulation step function counts misclassifications ii Exact penalty formulation without boundedness nondegeneracy constraint qualification assumptions iii An exact solution extraction sequence minimizers penalty function finite value penalty parameter general LPEC explicitly exact solution LPEC uncoupled constraints iv A parametric quadratic programming formulation LPEC associated misclassification minimization problem',\n",
              " 'Planning analogical reasoning learning method consists storage retrieval replay planning episodes Planning performance improves accumulation reuse library planning cases Retrieval driven domaindependent similarity metrics based planning goals scenarios In complex situations multiple goals retrieval may find multiple past planning cases jointly similar new planning situation This paper presents issues implications involved replay multiple planning cases opposed single one Multiple case plan replay involves adaptation merging annotated derivations planning cases Several merge strategies replay introduced process various forms eagerness differences past new situations annotated justifications planning cases In particular introduce effective merging strategy considers plan step choices especially appropriate interleaving planning plan execution We illustrate discuss effectiveness merging strategies specific domains',\n",
              " 'Mixedinitiative planning envisions framework automated human planners interact jointly construct plans satisfy specific objectives In paper report work engineering robust mixedinitiative planning system Human planners rely strongly past planning experience generate new plans ForMAT casebased system supports human planning accumulation userbuilt plans querydriven browsing past plans several plan functionality analysis primitives ProdigyAnalogy automated AI planner combines generative casebased planning Stored plans annotated plan rationale reuse involves adaptation driven rationale Our system MICBP integrates ForMAT ProdigyAnalogy realtime messagepassing mixedinitiative planning system The main technical approach consists allowing user specify link objectives enable system capture reuse plan rationale We present MICBP concrete application domain military force deployment planning This synergistic system increases planning efficiency human planners automated suggestion similar past plans plausible plan modifications',\n",
              " 'The primary goal inductive learning generalize well induce function accurately produces correct output future inputs Hansen Salamon showed certain assumptions combining predictions several separately trained neural networks improve generalization One key assumptions individual networks independent errors produce In standard way performing backpropagation assumption may violated standard procedure initialize network weights region weight space near origin This means backpropagations gradientdescent search may reach small subset possible local minima In paper present approach initializing neural networks uses competitive learning intelligently create networks originally located far origin weight space thereby potentially increasing set reachable local minima We report experiments two realworld datasets combinations networks initialized method generalize better combina tions networks initialized traditional way',\n",
              " 'We present two algorithms inducing structural equation models data Assuming latent variables models causal interpretation parameters may estimated linear multiple regression Our algorithms comparable PC IC rely conditional independence We present algorithms empirical comparisons PC IC',\n",
              " 'We investigate neural network based approximation methods These methods depend locality basis functions After discussing local global basis functions propose multiresolution hierarchical method The various resolutions stored various levels tree At root tree global approximation kept leafs store learning samples Intermediate nodes store intermediate representations In order find optimal partitioning input space selforganising maps SOMs used The proposed method implementational problems reminiscent encountered manyparticle simulations We investigate parallel implementation method using parallel hierarchical meth ods manyparticle simulations starting point',\n",
              " 'Orthogonal incremental learning OIL new approach incremental training feedforward network single hidden layer OIL based idea describe output weights hidden nodes set orthogonal basis functions Hidden nodes treated orthogonal representation network output weights domain We proved separate training hidden nodes conflict previously optimized nodes described special relationship orthogonal backpropagation OBP rule An advantage OIL existing algorithms extremely fast learning This approach also easily extended buildup incrementally arbitrary function linear composition adjustable functions necessarily orthogonal OIL tested twospirals Net Talk benchmark problems',\n",
              " 'Todays potential users machine learning technology faced nontrivial problem choosing large everincreasing number available tools one appropriate particular task To assist often noninitiated users desirable model selection process automated Using experience base level learning researchers proposed metalearning possible solution Historically predictive accuracy de facto criterion work metalearning focusing discovery rules match applications models based accuracy Although predictive accuracy clearly important criterion also case number criteria could often ought considered learning model selection This paper presents number criteria discusses impact metalevel approaches model selection',\n",
              " 'One approach invariant object recognition employs recurrent neural network associative memory In standard depiction networks state space memories objects stored attractive fixed points dynamics I argue modification picture object continuous family instantiations represented continuous attractor This idea illustrated network learns complete patterns To perform task filling missing information network develops continuous attractor models manifold patterns drawn From statistical viewpoint pattern completion task allows formulation unsupervised A classic approach invariant object recognition use recurrent neural network associative memory In spite intuitive appeal biological plausibility approach largely abandoned practical applications This paper introduces two new concepts could help resurrect object representation continuous attractors learning attractors pattern completion In models associative memory memories stored attractive fixed points discrete locations state space Discrete attractors may appropriate patterns continuous variability like images threedimensional object different viewpoints When instantiations object lie continuous pattern manifold appropriate represent objects attractive manifolds fixed points continuous attractors To make idea practical important find methods learning attractors examples A naive method train network retain examples shortterm memory This method deficient prevent network storing spurious fixed points unrelated examples A superior method train network restore examples corrupted learns complete patterns filling missing information learning terms regression rather density estimation',\n",
              " 'In paper consider problem independent constraint handling mechanism Stepwise Adaptation Weights SAW show working graph coloring problems SAWing technically belongs penalty function based approaches amounts modifying penalty function search We show twofold benefit First proves rather insensitive technical parameters thereby providing general problem independent way handle constrained problems Second leads superior EA performance In extensive series comparative experiments show SAWing EA outperforms powerful graph coloring heuristic algorithm DSatur hardest graph instances linear scaleup behaviour',\n",
              " 'Recently several neural algorithms introduced Independent Component Analysis Here approach problem point view single neuron First simple Hebbianlike learning rules introduced estimating one independent components sphered data Some learning rules used estimate independent component negative kurtosis others estimate component positive kurtosis Next twounit system introduced estimate independent component kurtosis The results generalized estimate independent components nonsphered raw mixtures To separate several independent components system several neurons linear negative feedback used The convergence learning rules rigorously proven without unnecessary hypotheses distributions independent components',\n",
              " 'In paper define task place learning describe one approach problem The framework represents distinct places using evidence grids probabilistic description occupancy Place recognition relies casebased classification augmented registration process correct translations The learning mechanism also similar casebased systems involving simple storage inferred evidence grids Experimental studies physical simulated robots suggest approach improves place recognition experience handle significant sensor noise scales well increasing numbers places Previous researchers studied evidence grids place learning combined two powerful concepts used experimental methods machine learning evaluate methods abilities',\n",
              " 'In constructive induction CI learners problem representation modified normal part learning process This useful initial representation inadequate inappropriate In paper I argue distinction constructive nonconstructive methods unclear I propose theoretical model allows clean distinction made b process CI properly motivated I also show although constructive induction used almost exclusively context supervised learning reason form part unsupervised regime',\n",
              " 'When designing deductive database designer decide predicate relation whether defined extensionally intensionally definition look like An intelligent system presented assist designer task It starts example database predicates defined extensionally It tries compact database transforming extensionally defined predicates intensionally defined ones The intelligent system employs techniques area inductive logic programming',\n",
              " 'When work information multiple sources formalism employs handle uncertainty may uniform In order able combine knowledge bases different formats need first establish common basis characterizing evaluating different formalisms provide semantics combined mechanism A common framework provide infrastructure building integrated system essential understand behavior We present unifying framework based ordered partition possible worlds called partition sequences corresponds intuitive notion biasing towards certain possible scenarios uncertain actual situation We show existing formalisms namely default logic autoepistemic logic probabilistic conditioning thresholding generalized conditioning possibility theory incorporated general framework',\n",
              " 'This paper investigates technique creating sparsely connected feedforward neural networks may capable producing networks large input output layers The architecture appears particularly suited tasks involve sparse training data able take advantage sparseness reduce training time Some initial results presented based tests bit compression problem',\n",
              " 'In paper propose method calculate posterior probability nondecomposable graphical Gaussian model Our proposal based new device sample Wishart distributions conditional graphical constraints As result methodology allows Bayesian model selection within whole class graphical Gaussian models including nondecomposable ones',\n",
              " 'For absorbing Markov chain reinforcement transition Bertsekas gives simple example function learned TD depends Bertsekas showed approximation optimal respect leastsquares error value function approximation obtained TD method poor respect metric With respect error values TD approximates function better TD However respect error differences values TD approximates function better TD TD better TD respect former metric rather latter In addition direct TD weights errors unequally residual gradient methods Baird Harmon Baird Klopf weight errors equally For case control simple Markov decision process presented direct TD residual gradient TD learn optimal policy TD learns suboptimal policy These results suggest example differences state values significant state values TD preferable TD',\n",
              " 'Lazy learning methods provide useful representations training algorithms learning complex phenomena autonomous adaptive control complex systems This paper surveys ways locally weighted learning type lazy learning applied us control tasks We explain various forms control tasks take affects choice learning paradigm The discussion section explores interesting impact explicitly remembering previous experiences problem learning control',\n",
              " 'Genetic programming GP variant genetic algorithms data structures handled trees This makes GP especially useful evolving functional relationships computer programs represented trees Symbolic regression determination function dependence gx approximates set data points x In paper feasibility symbolic regression GP demonstrated two examples taken different domains Furthermore several suggested methods literature compared intended improve GP performance readability solutions taking account introns redundancy occurs trees keeping size trees small The experiments show GP elegant useful tool derive complex functional dependencies numerical data',\n",
              " 'We report study mixture modeling problems arising assessment chemical structureactivity relationships drug design discovery Pharmaceutical research laboratories developing test compounds screening synthesize many related candidate compounds linking together collections basic molecular building blocks known monomers These compounds tested biological activity feeding screening analysis drug design The tests also provide data relating compound activity chemical properties aspects structure associated monomers focus studying relationships aid future monomer selection The level chemical activity compounds based geometry chemical binding test compounds target binding sites receptor compounds screening tests unable identify binding configurations Hence potentially critical covariate information missing natural latent variable Resulting statistical models mixed respect missing information complicating data analysis inference This paper reports study twomonomer twobinding site framework associated data We build structured mixture models mix linear regression models predicting chemical effectiveness respect sitebinding selection mechanisms We discuss aspects modeling analysis including problems pitfalls describe results analyses simulated real data set In modeling real data led critical model extensions introduce hierarchical random effects components adequately capture heterogeneities site binding mechanisms resulting levels effectiveness compounds bound Comments current potential future directions conclude report',\n",
              " 'We give analysis generalization error cross validation terms two natural measures difficulty problem consideration approximation rate accuracy target function ideally approximated function number hypothesis parameters estimation rate deviation training generalization errors function number hypothesis parameters The approximation rate captures complexity target function respect hypothesis model estimation rate captures extent hypothesis model suffers overfitting Using two measures give rigorous general bound error cross validation The bound clearly shows tradeoffs involved making fl fraction data saved testing large small By optimizing bound respect fl argue combination formal analysis plotting controlled experimentation following qualitative properties cross validation behavior quite robust significant changes underlying model selection problem',\n",
              " 'Model selection eg considered problem choosing hypothesis language provides optimal balance low empirical error high structural complexity In Abstract discuss intuition new efficient approach model selection Our approach inherently Bayesian eg instead using priors target functions hypotheses talk priors error values leads us new mathematical characterization expected true error In setting classification learning learner given sample drawn according unknown distribution labeled instances returns empirical minimizer hypothesis least empirical error certain unknown true error If process carried repeatedly true error empirical minimizer vary run run empirical minimizer depends randomly drawn sample This induces distribution true errors empirical minimizers possible samples drawn according unknown distribution If distribution would known one could easily derive expected true error empirical minimizer model integrating distribution This would immediately lead optimal model selection algorithm Enumerate models calculate expected error model integrating error distribution select model least expected error PAC theory VC framework provide worstcase bounds chance drawing sample true error minimizer exceeds worstcase meaning hold distribution instances concept given class By contrast focus determine distribution fixed given learning problem specified assumptions Unlike worstcase bound depends size VCdimension hypothesis space actual error distribution depends hypothesis space unknown distribution labeled instances However prove certain assumption independence hypotheses distribution true errors hence expected true error expressed function distribution empirical errors uniformly drawn hypotheses thought prior error values The latter distribution always onedimensional estimated fixedsized initial portion training data fixedsized set randomly drawn hypotheses This estimate distribution leads us estimate expected true error empirical minimizer model turn leads highly efficient model selection algorithm We study behavior approach several controlled experiments Our results show accuracy error estimate least comparable accuracy estimate obtained fold crossvalidation provided prior error values estimated using least examples But CV requires ten invocations learner per model time algorithm requires assess model constant size model We also study robustness algorithm violations independence assumptions We observe bias predictions hypotheses space size four less When hypothesis space size dependencies diluted violations assumptions negligible incur significant error The full paper available httpkicstuberlindeschefferpaperseedreportps',\n",
              " 'In area inductive learning generalization main operation usual definition induction based logical implication Recently rising interest clausal representation knowledge machine learning Almost inductive learning systems perform generalization clauses use relation subsumption instead implication The main reason wellknown simple technique compute least general generalizations subsumption implication However generalization subsumption inappropriate learning recursive clauses crucial problem since recursion basic program structure logic programs We note implication clauses undecidable therefore introduce stronger form implication called Timplication decidable clauses We show every finite set clauses exists least general generalization Timplication We describe technique reduce generalizations implication clause generalizations subsumption call expansion original clause Moreover show every nontautological clause exists Tcomplete expansion means every generalization Timplication clause reduced generalization subsumption expansion',\n",
              " 'This paper argues Bayesian probability theory general method machine learning From two wellfounded axioms theory capable accomplishing learning tasks incremental nonincremental supervised unsupervised It learn different types data regardless whether noisy perfect independent facts behaviors unknown machine These capabilities partially demonstrated paper uniform application theory two typical types machine learning incremental concept learning unsupervised data classification The generality theory suggests process learning may many different types currently held method oldest may best',\n",
              " 'This paper focuses bias variance decomposition analysis local learning algorithm nearest neighbor classifier extended error correcting output codes This extended algorithm often considerably reduces ie classification error comparison nearest neighbor Ricci Aha The analysis presented reveals performance improvement obtained drastically reducing bias cost increasing variance We also show even classification problems classes extending codeword length beyond limit assures column separation yields error reduction This error reduction variance due voting mechanism used errorcorrecting output codes also bias',\n",
              " 'We integrated distributed search genetic programming GP based systems collective memory form collective adaptation search method Such system significantly improves search problem complexity increased Since pure GP approach scale well problem complexity natural question two components actually contributing search process We investigate collective memory search utilizes random search engine find significantly outperforms GP based search engine We examine solution space show problem complexity search space grow collective adaptive system perform better collective memory search employing random search engine',\n",
              " 'The document presents approach judging relevance retrieved information based novel approach similarity assessment Contrary systems define relevance measures context similarity query time This necessary since without context similarity one guarantee similar items also relevant',\n",
              " 'This paper presents selfimproving reactive control system autonomous robotic navigation The navigation module uses schemabased reactive control system perform navigation task The learning module combines casebased reasoning reinforcement learning continuously tune navigation system experience The casebased reasoning component perceives characterizes systems environment retrieves appropriate case uses recommendations case tune parameters reactive control system The reinforcement learning component refines content cases based current experience Together learning components perform online adaptation resulting improved performance reactive control system tunes environment well online learning resulting improved library cases capture environmental regularities necessary perform online adaptation The system extensively evaluated simulation studies using several performance metrics system configurations',\n",
              " 'A model onsite learning presented The system learns querying hard patterns classifying easy ones This model related querybased filtering methods takes account addition labelling filtering data cost A simple policies introduced analyzed simple problem D high low game In addition QuerybyCommittee algorithm Seung et al suggested good approximator model space realworld domains Results using algorithm synthesized problem realworld OCR task using backpropagation network nearest neighbor classifier show onsite learner perform well classifier trained offsite achieving significant cost reduction',\n",
              " 'The standard method obtaining response treebased genetic programming take value returned root node In nontree representations alternate methods explored One alternative treat specific location indexed memory response value program terminates The purpose paper explore applicability technique treestructured programs explore intron effects studies bring light This papers experimental results support finding memorybased program response technique improvement problems In addition papers experimental results support finding contrary past research speculation addition even facilitation introns seriously degrade search performance genetic programming',\n",
              " 'We discuss implications Holtes recentlypublished article demonstrated commonly used data simple classification rules almost accurate decision trees produced Quinlans C We consider particular significance Holtes results future topdown induction decision trees To extent Holte questioned sense research multilevel decision tree learning We go detail parts Holtes study We try put results perspective We argue absolute terms small difference accuracy R C witnessed Holte still significant We claim C possesses additional accuracyrelated advantages R In addition discuss representativeness databases used Holte We compare empirically optimal accuracies multilevel onelevel decision trees observe significant differences We point several deficien cies limitedcomplexity classifiers',\n",
              " 'We describe approach graphemetophoneme conversion languageindependent dataoriented Given set examples spelling words associated phonetic representation language graphemetophoneme conversion system automatically produced language takes input spelling words produces output phonetic transcription according rules implicit training data We describe design system compare performance knowledgebased alternative dataoriented approaches',\n",
              " 'No finite sample sufficient determine density therefore entropy signal directly Some assumption either functional form density smoothness necessary Both amount prior space possible density functions By far common approach assume density parametric form By contrast derive differential learning rule called EMMA optimizes entropy way kernel density estimation Entropy derivative calculated sampling density estimate The resulting parameter update rule surprisingly simple efficient We show EMMA used detect correct corruption magnetic resonance images MRI This application beyond scope existing parametric entropy models',\n",
              " 'A satisficing search problem consists set probabilistic experiments performed order without repetitions satisfying configuration successes failures reached The cost performing experiments depends order chosen Earlier work concentrated finding optimal search strategies special cases model search trees andor graphs cost function success probabilities experiments given In contrast study complexity learning approximately optimal search strategy success probabilities known outset Working fully general model show n number unknown probabilities C maximum cost performing experiments',\n",
              " 'We present method calculating phase diagrams highdimensional variant SelfOrganizing Map SOM The method requires ansatz tesselation data space induced map explicit state map Using method analyze two recently proposed models development orientation ocular dominance column maps The phase transition condition orientation map turns different form corresponding lowdimensional map',\n",
              " 'We study process multiagent reinforcement learning context load balancing distributed system without use either central coordination explicit communication We first define precise framework study adaptive load balancing important features stochastic nature purely local information available individual agents Given framework show illuminating results interplay basic adaptive behavior parameters effect system efficiency We investigate properties adaptive load balancing heterogeneous populations address issue exploration vs exploitation context Finally show naive use communication may improve might even harm system efficiency',\n",
              " 'Brendan J Frey Geoffrey E Hinton Efficient stochastic source coding application Bayesian network source model The Computer Journal In paper introduce new algorithm called bitsback coding makes stochastic source codes efficient For given onetomany source code show algorithm actually efficient algorithm always picks shortest codeword Optimal efficiency achieved codewords chosen according Boltzmann distribution based codeword lengths It turns commonly used technique determining parameters maximum likelihood estimation actually minimizes bitsback coding cost codewords chosen according Boltzmann distribution A tractable approximation maximum likelihood estimation generalized expectation maximization algorithm minimizes bitsback coding cost After presenting binary Bayesian network model assigns exponentially many codewords symbol show tractable approximation Boltzmann distribution used bitsback coding We illustrate performance bitsback coding using using nonsynthetic data binary Bayesian network source model produces possible codewords input symbol The rate bitsback coding nearly one half obtained picking shortest codeword symbol',\n",
              " 'Agents learn agents exploit information possess distinct advantage competitive situations Games provide stylized adversarial environments study agent learning strategies Researchers developed game playing programs learn play better experience We developed learning program learn play better learns identify exploit weaknesses particular opponent repeatedly playing several games We propose scheme learning opponent action probabilities utility maximization framework exploits learned opponent model We show proposed expected utility maximization strategy generalizes traditional maximin strategy allows players benefit taking calculated risks avoided maximin strategy Experiments popular board game Connect show learning player consistently outperforms nonlearning player pitted another automated player using weaker heuristic Though proposed mechanism improve skill level computer player improve ability play effectively weaker opponent',\n",
              " 'Many real world learning problems best characterized interaction multiple independent causes factors Discovering causal structure data focus paper Based Zemel Hintons cooperative vector quantizer CVQ architecture unsupervised learning algorithm derived ExpectationMaximization EM framework Due combinatorial nature data generation process exact Estep computationally intractable Two alternative methods computing Estep proposed Gibbs sampling meanfield approximation promising empirical results presented',\n",
              " 'This paper deals problem blind identification source separation consists estimation mixing matrix andor separation mixture stochastically independent sources without priori knowledge mixing matrix The method propose estimates mixture matrix recurrent InputOutput IO Identification using inputs nonlinear transformation estimated sources Herein nonlinear transformation distortion consists constraining modulus inputs IOIdentification device constant In contrast existing approaches covariance additive noise need modeled estimated regular parameter needed The proposed approach implemented using multilayer neural networks order improve performance separation New associated online unsupervised adaptive learning rules also developed The effectiveness proposed method illustrated computer simulations',\n",
              " 'Source separation consists recovering set n independent signals n observed instantaneous mixtures signals possibly corrupted additive noise Many source separation algorithms use second order information whitening operation reduces non trivial part separation determining unitary matrix Most show kind invariance property exploited predict general results performance Our first contribution exhibit lower bound performance terms accuracy separation This bound independent algorithm iid case distribution source signals Second show performance invariant algorithms depends mixing matrix noise level specific way A consequence low noise levels performance depend mixture distribution sources via function characteristic given source separation algorithm',\n",
              " 'In paper neural network approach reconstruction natural highly correlated images linear additive mixture proposed A multilayer architecture local online learning rules developed solve problem blind separation sources The main motivation using multilayer network instead singlelayer one improve performance robustness separation applying simple local learning rule biologically plausible Moreover architecture onchip learning relatively easy implementable using VLSI electronic circuits Furthermore enables extraction source signals sequentially one starting strongest signal finishing weakest one The experimental part focuses separating highly correlated human faces mixture additive noise unknown number sources',\n",
              " 'We study online learning algorithms predict combining predictions several subordinate prediction algorithms sometimes called experts These simple algorithms belong multiplicative weights family algorithms The performance algorithms degrades logarithmically number experts making particularly useful applications number experts large However applications text categorization often natural experts abstain making predictions instances We show transform algorithms assume experts always awake algorithms require assumption We also show derive corresponding loss bounds Our method general applied large family online learning algorithms We also give applications various prediction models including decision graphs switching experts',\n",
              " 'When dealing classification problems current ILP systems often lag behind stateoftheart attributional learners Part blame ascribed much larger hypothesis space therefore thoroughly explored However sometimes due fact ILP systems take account probabilistic aspects hypotheses classifying unseen examples This paper proposes We developed naive Bayesian classifier within ILPR first order learner The learner uses clever RELIEF based heuristic able detect strong dependencies within literal space dependencies exist We conducted series experiments artificial realworld data sets The results show combination ILPR together naive Bayesian classifier sometimes significantly improves classification unseen instances measured classification accuracy average information score',\n",
              " 'Process simulation emerged valuable tool process design analysis operation In work extend capabilities iterated linear programming LP dealing problems encountered dynamic nonsmooth process simulation A previously developed LP method refined addition new descent strategy combines line search trust region approach This adds stability efficiency method The LP method advantage naturally dealing profile bounds well This demonstrated avoid computational difficulties arise iterates going physically unrealistic regions A new method treatment discontinuities occurring dynamic simulation problems also presented paper The method ensures event occurred within time interval consideration detected one event occurs detected one indeed earliest one A specific class implicitly discontinuous process simulation problems phase equilibrium calculations also looked A new formulation introduced solve multiphase problems fl To correspondence addressed emailbieglercmuedu',\n",
              " 'A frequently observed difficulty application genetic algorithms domain optimization arises premature convergence In order preserve genotype diversity develop new model autoadaptive behavior individuals In model population member active individual assumes sociallike behavior patterns Different individuals living population assume different patterns By moving hierarchy social states individuals change behavior Changes social state controlled arguments plausibility These arguments implemented rule set massivelyparallel genetic algorithm Computational experiments largescale job shop benchmark problems show results new approach dominate ordinary genetic algorithm significantly',\n",
              " 'Proben collection problems neural network learning realm pattern classification function approximation plus set rules conventions carrying benchmark tests similar problems Proben contains data sets different domains All datasets represent realistic problems could called diagnosis tasks one consist real world data The datasets presented simple format using attribute representation directly used neural network training Along datasets Proben defines set rules conduct document neural network benchmarking The purpose problem rule collection give researchers easy access data evaluation algorithms networks make direct comparison published results feasible This report describes datasets benchmarking rules It also gives basic performance measures indicating difficulty various problems These measures used baselines comparison',\n",
              " 'This paper presents NeuroChess program learns play chess final outcome games NeuroChess learns chess board evaluation functions represented artificial neural networks It integrates inductive neural network learning temporal differencing variant explanationbased learning Performance results illustrate strengths weaknesses approach',\n",
              " 'Some important factors play major role determining performances CBR CaseBased Reasoning system complexity accuracy retrieval phase Both flat memory inductive approaches suffer serious drawbacks In first approach search time increases dealing large scale memory base second one modification case memory becomes complex sophisticated architecture In paper show construct simple efficient indexing system structure The idea construct case hierarchy two levels memory lower level contains cases organised groups similar cases upper level contains prototypes prototype represents one group cases This smaller memory used retrieval phase Prototype construction achieved means incremental prototypebased NN Neural Network We show mode CBRNN coupling preprocessing one neural network serves indexing system',\n",
              " 'Developing ability recognize landmark visual image robots current location fundamental problem robotics We consider problem PAClearning concept class geometric patterns target geometric pattern configuration k points real line Each instance configuration n points real line labeled according whether visually resembles target pattern To capture notion visual resemblance use Hausdorff metric Informally two geometric patterns P Q resemble Hausdorff metric every point one pattern close point pattern We relate concept class geometric patterns landmark recognition problem present polynomialtime algorithm PAClearns class onedimensional geometric patterns We also present experimental results algorithm performs',\n",
              " 'The concept measure functions generalization performance suggested This concept provides alternative way selecting evaluating learned models classifiers In addition makes possible state learning problem computational problem The known prior metaknowledge problem domain captured measure function possible combination training set classifier assigns value describing good classifier The computational problem find classifier maximizing measure function We argue measure functions great value practical applications Besides tool model selection force us make explicit relevant prior knowledge learning problem hand ii provide deeper understanding existing algorithms iii help us construction problemspecific algorithms We illustrate last point suggesting novel algorithm based incremental search classifier optimizes given measure function',\n",
              " 'Recurrent attractor networks offer many advantages feedforward networks modeling psychological phenomena Their dynamic nature allows capture time course cognitive processing learned weights may often easily interpreted soft constraints representational components Perhaps significant feature networks however ability facilitate generalization enforcing well formedness constraints intermediate output representations Attractor networks learn systematic regularities well formed representations exposure small number examples said possess articulated attractors This paper investigates conditions articulated attractors arise recurrent networks trained using variants backpropagation The results computational experiments demonstrate structured attractors spontaneously appear emergence systematicity appropriate error signal presented directly recurrent processing elements We show however distal error signals backpropagated intervening weights pose serious problems networks kind We present simulation results discuss reasons difficulty suggest directions future attempts surmount',\n",
              " 'Induced decision trees extensivelyresearched solution classification tasks For many practical tasks trees produced treegeneration algorithms comprehensible users due size complexity Although many tree induction algorithms shown produce simpler comprehensible trees data structures derived trees good classification accuracy tree simplification usually secondary concern relative accuracy attempt made survey literature perspective simplification We present framework organizes approaches tree simplification summarize critique approaches within framework The purpose survey provide researchers practitioners concise overview treesimplification approaches insight relative capabilities In final discussion briefly describe empirical findings discuss application tree induction algorithms case retrieval casebased reasoning systems',\n",
              " 'In paper propose monitor Markov chain sampler using cusum path plot chosen dimensional summary statistic We argue cusum path plot bring effectively sequential plot aspects Markov sampler tell user quickly slowly sampler moving around sample space direction summary statistic The proposal illustrated four examples represent situations cusum path plot works well well Moreover rigorous analysis given one examples We conclude cusum path plot effective tool convergence diagnostics Markov sampler comparing different Markov samplers',\n",
              " 'This paper gives precise easy compute bounds convergence time Gibbs sampler used Bayesian image reconstruction For sampling Gibbs distribution without presence external field bounds N number pixels obtained proportionality constant easy calculate Some key words Bayesian image restoration Convergence Gibbs sampler Ising model Markov chain Monte Carlo',\n",
              " 'c flMIT Media Lab Perceptual Computing Learning Common Sense Technical Report nov revised jun Abstract We present methods coupling hidden Markov models hmms model systems multiple interacting processes The resulting models multiple state variables temporally coupled via matrices conditional probabilities We introduce deterministic OT CN approximation maximum posterior MAP state estimation enables fast classification parameter estimation via expectation maximization An Nheads dynamic programming algorithm samples highest probability paths compact state trellis minimizing upper bound cross entropy full combinatoric dynamic programming problem The complexity OT CN C chains N states apiece observing T data points compared OT N C naive Cartesian product exact state clustering stochastic Monte Carlo methods applied inference problem In several experiments examining training time model likelihoods classification accuracy robustness initial conditions coupled hmms compared favorably conventional hmms energybased approaches coupled inference chains We demonstrate compare algorithms synthetic real data including interpretation video',\n",
              " 'SUMMARY The paper describes Bayesian analysis agricultural field experiments topic received little previous attention despite vast frequentist literature Adoption Bayesian paradigm simplifies interpretation results especially ranking selection Also complex formulations analyzed comparative ease using Markov chain Monte Carlo methods A key ingredient approach need spatial representations unobserved fertility patterns This discussed detail Problems caused outliers jumps fertility tackled via hierarchicalt formulations may find use contexts The paper includes three analyses variety trials yield one example involving binary data none entirely straightforward Some comparisons frequentist analyses made The datasets available httpwwwstatdukeeduhigdontrialsdatahtml',\n",
              " 'We show paper continuous state space Markov chains rigorously discretized finite Markov chains The idea subsample continuous chain renewal times related small sets control discretization Once finite Markov chain derived MCMC output general convergence properties finite state spaces exploited convergence assessment several directions Our choice based divergence criterion derived Kemeny Snell first evaluated parallel chains stopping time implemented efficiently two parallel chains using Birkhoffs pointwise ergodic theorem stopping rules The performance criterion illustrated three standard examples',\n",
              " 'Markov chain Monte Carlo MCMC samplers proved remarkably popular tools Bayesian computation However problems arise application density interest high dimensional strongly correlated In circumstances sampler may slow traverse state space mixing poor In article offer partial solution problem The state space Markov chain augmented accommodate multiple chains parallel Updates individual chains based around genetic style crossover operator acting parent states drawn population chains This process makes efficient use gradient information implicitly encoded within distribution states across population Empirical studies support claim crossover operator acting parallel population chains improves mixing This illustrated example sampling high dimensional posterior probability density complex predictive model By adopting latent variable approach methodology extended deal variable selection model averaging high dimensions This illustrated example knot selection spline interpolant',\n",
              " 'MIT Computational Cognitive Science Technical Report Abstract We describe variational approximation methods efficient probabilistic reasoning applying methods problem diagnostic inference QMRDT database The QMRDT database largescale belief network based statistical expert knowledge internal medicine The size complexity network render exact probabilistic diagnosis infeasible small set cases This hindered development QMR DT network practical diagnostic tool hindered researchers exploring critiquing diagnostic behavior QMR In paper describe variational approximation methods applied QMR network resulting fast diagnostic inference We evaluate accuracy methods set standard diagnostic cases compare stochastic sampling methods',\n",
              " 'The effects neural networks topology performance well known yet question finding optimal configurations automatically remains largely open This paper proposes solution problem RBF networks A self optimising approach driven evolutionary strategy taken The algorithm uses output information computationally efficient approximation RBF networks optimise Kmeans clustering process coevolving two determinant parameters networks layout number centroids centroids positions Empirical results demonstrate promise',\n",
              " 'This paper describes hybrid methodology integrates genetic algorithms decision tree learning order evolve useful subsets discriminatory features recognizing complex visual concepts A genetic algorithm GA used search space possible subsets large set candidate discrimination features Candidate feature subsets evaluated using C decisiontree learning algorithm produce decision tree based given features using limited amount training data The classification performance resulting decision tree unseen testing data used fitness underlying feature subset Experimental results presented show increasing amount learning significantly improves feature set evolution difficult visual recognition problems involving satellite facial image data In addition also report extent subtle aspects Baldwin effect exhibited system',\n",
              " 'In paper examine behavior humancomputer system crisis response As one instance crisis management describe task responding spills fires involving hazardous materials We describe INCA intelligent assistant planning scheduling domain relation human users We focus INCAs strategy retrieving case case library seeding initial schedule helping user adapt seed We also present three hypotheses behavior mixedinitiative system experiments designed test The results suggest approach leads faster response development usergenerated automaticallygenerated schedules without sacrificing solution quality',\n",
              " 'Given adequate simulation model task environment payoff function measures quality partially successful plans competitionbased heuristics genetic algorithms develop high performance reactive rules interesting sequential decision tasks We previously described implemented system called SAMUEL learning reactive plans shown system successfully learn rules laboratory scale tactical problem In paper describe method deriving explanations justify success empirically derived rule sets The method consists inferring plausible subgoals explaining reactive rules trigger sequence actions ie stra tegy satisfy subgoals',\n",
              " 'Machine learning valuable tool improving flexibility efficiency robot applications Many approaches applying machine learning robotics known Some approaches enhance robots highlevel processing planning capabilities Other approaches enhance lowlevel processing control basic actions In contrast approach presented paper uses machine learning enhancing link lowlevel representations sensing action highlevel representation planning The aim facilitate communication robot human user A hierarchy concepts learned route records mobile robot Perception action combined every level ie concepts perceptually anchored The relational learning algorithm grdt developed completely searches hypothesis space restricted rule schemata user defines terms grammars',\n",
              " 'We motivate use convergence diagnostic techniques Markov Chain Monte Carlo algorithms review various methods proposed MCMC literature A common notation established method discussed particular emphasis implementational issues possible extensions The methods compared terms interpretability applicability recommendations provided particular classes problems',\n",
              " 'For target tracking task handheld camera anthropomorphic OSCARrobot manipulator track object moves arbitrarily table The desired camerajoint mapping approximated feedforward neural network Through use time derivatives position object manipulator controller inherently predict next position moving target object In paper several anticipative controllers described successfully applied track moving object',\n",
              " 'Covariance information help algorithm search predictive causal models estimate strengths causal relationships This information discarded conditional independence constraints identified usual contemporary causal induction algorithms Our fbd algorithm combines covariance information effective heuristic build predictive causal models We demonstrate fbd accurate efficient In one experiment assess fbds ability find best predictors variables another compare performance using many measures Pearl Vermas ic algorithm And although fbd based multiple linear regression cite evidence performs well problems difficult regression algorithms',\n",
              " 'The problem learning decision rules sequential tasks addressed focusing problem learning tactical decision rules simple flight simulator The learning method relies notion competition employs genetic algorithms search space decision policies Several experiments presented address issues arising differences simulation model learning occurs target environment decision rules ultimately tested',\n",
              " 'The inductive learning problem consists learning concept given examples nonexamples concept To perform learning task inductive learning algorithms bias learning method Here discuss biasing learning method use previously learned concepts domain These learned concepts highlight useful information concepts domain We describe transference bias present MFOCL Horn clause relational learning algorithm utilizes bias learn multiple concepts We provide preliminary empirical evaluation show effects biasing previous information noisefree noisy data',\n",
              " 'Choosing architecture neural network one important problems making neural networks practically useful accounts applications usually sweep details carpet How many hidden units needed Should weight decay used much What type output units chosen And We address issues within framework statistical theory model This paper principally concerned architecture selection issues feedforward neural networks also known multilayer perceptrons Many issues arise selecting radial basis function networks recurrent networks widely These problems occur much wider context within statistics applied statisticians selecting combining models decades Two recent discussions References discuss neural networks statistical perspective choice provides number workable approximate answers',\n",
              " 'We propose modeltheoretic definition causation show contrary common folklore genuine causal influences distinguished spurious covariations following standard norms inductive reasoning We also establish complete characterization conditions distinction possible Finally provide prooftheoretical procedure inductive causation show large class data structures effective algorithms exist uncover direction causal influences defined',\n",
              " 'This study deals alltoall broadcast CNS We determine lower bound run time present algorithm meeting bound Since study points bottleneck network interface also analyze performance alternative interface designs Our analyses based run time model network',\n",
              " 'Automated decision making often complicated complexity knowledge involved Much complexity arises contextsensitive variations underlying phenomena We propose framework representing descriptive contextsensitive knowledge Our approach attempts integrate categorical uncertain knowledge network formalism This paper outlines basic representation constructs examines expressiveness efficiency discusses potential applications framework',\n",
              " 'We discuss number methods estimating standard error predicted values multilayer perceptron These methods include delta method based Hessian bootstrap estimators sandwich estimator The methods described compared number examples We find bootstrap methods perform best partly capture variability due choice starting weights',\n",
              " 'Discrete mixtures normal distributions widely used modeling amplitude fluctuations electrical potentials synapses human animal nervous systems The usual framework independent data values j arising j j x n j means j come discrete prior G unknown x n j observed x j j n gaussian noise terms A practically important development associated statistical methods issue nonnormality noise terms often norm rather exception neurological context We recently developed models based convolutions Dirichlet process mixtures problems Explicitly model noise data values x j arising Dirichlet process mixture normals addition modeling location prior G Dirichlet process This induces Dirichlet mixture mixtures normals whose analysis may developed using Gibbs sampling techniques We discuss models analysis illustrate context neurological response analysis',\n",
              " 'Neural controllers able position handheld camera DOF anthropomorphic OSCARrobot manipulator object arbitrary placed table The desired camerajoint mapping approximated feedforward neural networks However object moving manipulator lags behind required time preprocess visual information move manipulator Through use time derivatives position object manipulator controller inherently predict next position object In paper several predictive controllers proposed successfully applied track moving object',\n",
              " 'This paper overviews AA Adaptive Algorithm model ASOCS Adaptive Self Organizing Concurrent Systems approach It also presents promising empirical generalization results AA actual data AA topologically dynamic network grows fit problem learned AA generalizes selforganizing fashion network seeks find features discriminate concepts Convergence training set guaranteed bounded linearly time',\n",
              " 'This communication deals source separation problem consists separation noisy mixture independent sources without priori knowledge mixture coefficients In paper consider maximum likelihood ML approach discrete source signals known probability distributions An important feature ML approach Gaussian noise covariance matrix additive noise treated parameter Hence necessary know model spatial structure noise Another striking feature offered case discrete sources mild assumptions possible separate sources sensors In paper consider maximization likelihood via ExpectationMaximization EM algorithm',\n",
              " 'If robust statistical model developed classify health system wellknown Taylor series approximation technique forms basis diagnosticrecovery procedure initiated systems health degrades fails altogether This procedure determines ranked set probable causes degraded health state used prioritized checklist isolating system anomalies quantifying corrective action The diagnosticrecovery procedure applicable classifier known robust applied neural network traditional parametric pattern classifiers generated supervised learning procedure empirical riskbenefit measure optimized We describe procedure mathematically demonstrate ability detect diagnose causes faults NASAs Deep Space Communications Complex Goldstone California',\n",
              " 'Case combination difficult problem Case Based Reasoning subcases often exhibit conflicts merged together In previous work formalized case combination representing case constraint satisfaction problem used minimum conflicts algorithm systematically synthesize global solution However also found instances problem minimum conflicts algorithm perform case combination efficiently In paper describe situations initially retrieved cases easily adaptable propose method improve case adaptability genetic algorithm We introduce fitness function maintains much retrieved case information possible also perturbing subsolution allow subsequent case combination proceed efficiently',\n",
              " 'The Dynamic Constraint Satisfaction Problem DCSP formalism gaining attention valuable often necessary extension static CSP framework Dynamic Constraint Satisfaction enables CSP techniques applied extensively since applied domains set constraints variables involved problem evolves time At time CaseBased Reasoning CBR community working techniques reuse existing solutions solving new problems We observed dynamic constraint satisfaction matches closely casebased reasoning process case adaptation These observations emerged previous work combining CBR CSP achieve constraintbased adaptation This paper summarizes previous results describes similarity challenges facing DCSP case adaptation shows CSP CBR together begin address chal lenges',\n",
              " 'Prior knowledge bias regarding concept speed task learning Probably Approximately Correct PAC learning mathematical model concept learning used quantify speed due different forms bias learning Thus far PAC learning mostly used analyze syntactic bias limiting concepts conjunctions boolean prepositions This paper demonstrates PAC learning also used analyze semantic bias domain theory concept learned The key idea view hypothesis space PAC learning consistent prior knowledge syntactic semantic In particular paper presents PAC analysis determinations type relevance knowledge The results analysis reveal crisp distinctions relations among different determinations illustrate usefulness analysis based PAC model',\n",
              " 'Computational models natural systems often contain free parameters must set optimize predictive accuracy models This process called calibrationcan viewed form supervised learning presence prior knowledge In view fixed aspects model constitute prior knowledge goal learn values free parameters We report series attempts learn parameter values global vegetation model called MAPSS Mapped AtmospherePlantSoil System developed collaborator Ron Neilson Standard machine learning methods work MAPSS constraints introduced structure model create difficult nonlinear optimization problem We developed new divideandconquer approach subsets parameters calibrated others held constant This approach succeeds possible select training examples exercise portions model',\n",
              " 'The paper considers situation learners testing set contains close approximations cases appear training set Such cases considered virtual seens since approximately seen learner Generalisation measures take account frequency virtual seens may misleading The paper shows NN algorithm used derive normalising baseline generalisation statistics The normalisation process demonstrated though application Holtes study generalisation performance R algorithm tested C commonly used datasets',\n",
              " 'Initial Results Abstract Conversational casebased reasoning CBR systems incrementally extract query description userdirected conversation advertised ease use However designing large case libraries good performance ie precision querying efficiency difficult CBR vendors provide guidelines designing libraries manually guidelines difficult apply We describe automated inductive approach revises conversational case libraries increase conformance design guidelines Revision increased performance three conversational case libraries',\n",
              " 'Diagnosis process identifying disorders machine patient considering history symptoms signs Starting possible initial information new information requested sequential manner diagnosis made precise It thus missing data problem since everything known We model joint probability distribution data case database mixture models Model parameters estimated EM algorithm gives additional benefit missing data database also handled correctly Request new information refine diagnosis performed using maximum utility principle decision theory Since system based machine learning domain independent An example using heart disease database presented',\n",
              " 'We give example neural net without hidden layers sigmoid transfer function together training set binary vectors sum squared errors regarded function weights local minimum global minimum The example consists set training instances four weights threshold learnt We know substantially smaller binary examples exist',\n",
              " 'The multiple extension problem arises default theory use different subsets defaults propose different mutually incompatible answers queries This paper presents algorithm uses set observations learn credulous version default theory essentially optimally accurate In detail associate given default theory set related credulous theories R fR g R uses total ordering defaults determine single answer return query Our goal select credulous theory highest expected accuracy R expected accuracy probability answer produces query correspond correctly world Unfortunately theorys expected accuracy depends distribution queries usually known Moreover task identifying optimal R opt R even given distribution information intractable This paper presents method OptAcc sidesteps problems using set samples estimate unknown distribution hillclimbing local optimum In particular given parameters ffi gt OptAcc produces R oa R whose expected accuracy probability least ffi within local optimum Appeared ECAI Workshop Theoretical Foundations Knowledge Representation Reasoning',\n",
              " 'Compression information important concept theory learning We argue hypothesis inherent compression pressure towards short elegant general solutions genetic programming system variable length evolutionary algorithms This pressure becomes visible size complexity solutions measured without noneffective code segments called introns The built parsimony pressure effects complex fitness functions crossover probability generality maximum depth length solutions explicit parsimony granularity fitness function initialization depth length modularization Some effects positive negative In work provide basis analysis effects suggestions overcome negative implications order obtain balance needed successful evolution An empirical investigation supports hypothesis also presented',\n",
              " 'Wilsons recent XCS classifier system forms complete mappings payoff environment reinforcement learning tradition thanks accuracy based fitness According Wilsons Generalization Hypothesis XCS tendency towards generalization With XCS Optimality Hypothesis I suggest XCS systems evolve optimal populations representations populations accurately map inputaction pairs payoff predictions using smallest possible set nonoverlapping classifiers The ability XCS evolve optimal populations boolean multiplexer problems demonstrated using condensation technique evolutionary search suspended setting crossover mutation rates zero Condensation automatically triggered selfmonitoring performance statistics entire learning process terminated autotermination Combined techniques allow classifier system evolve optimal representations boolean functions without form supervision',\n",
              " 'Current rule induction systems eg CN typically rely separate conquer strategy learning rule stilluncovered examples This results dwindling number examples available learning successive rules adversely affecting systems accuracy An alternative learn rules simultaneously using entire training set This approach implemented Rise system Empirical comparison Rise CN suggests conquering without separating performs similarly counterpart simple domains achieves increasingly substantial gains accuracy domain difficulty grows',\n",
              " 'A genetic programming method investigated optimizing architecture connection weights multilayer feedforward neural networks The genotype network represented tree whose depth width dynamically adapted particular application specifically defined genetic operators The weights trained nextascent hillclimbing search A new fitness function proposed quantifies principle Occams razor It makes optimal tradeoff error fitting ability parsimony network We discuss results two problems differing complexity study convergence scaling properties algorithm',\n",
              " 'The performance neural network categorizes facial expressions compared human subjects set experiments using interpolated imagery The experiments human subjects neural networks make use interpolations facial expressions Pictures Facial Affect Database Ekman Friesen The difference materials used human subjects experiments Young et al materials manner interpolated images constructed imagequality morphs versus pixel averages Nevertheless neural network accurately captures categorical nature human responses showing sharp transitions labeling images along interpolated sequence Crucially demonstration categorical perception Harnad model shows highest discrimination transition images crossover point The model also captures shape reaction time curves human subjects along sequences Finally network matches human subjects judgements expressions mixed images The main failing model intrusions neutral responses transitions seen human subjects We attribute difference difference pixel average stimuli image quality morph stimuli These results show simple neural network classifier access biological constraints presumably imposed human emotion processor whose access surrounding culture category labels placed American subjects facial expressions nevertheless simulate fairly well human responses emotional expressions',\n",
              " 'The article hand discusses tool automatic generation structured models complex dynamic processes means genetic programming In contrast techniques use genetic programming find appropriate arithmetic expression order describe inputoutput behaviour process tool based block oriented approach transparent description signal paths A short survey techniques computer based system identification given basic concept SMOG Structured MOdel Generator described Furthermore latest extensions system presented detail including automatically defined submodels quali tative fitness criteria',\n",
              " 'We examine role hyperplane ranking search performed simple genetic algorithm We also develop metric measuring degree ranking exists respect static measurements taken directly function well measurement dynamic ranking hyperplanes genetic search We show degree dynamic ranking induced simple genetic algorithm highly correlated degree static ranking inherent function especially initial genera tions search',\n",
              " 'Genetic algorithms rely two genetic operators crossover mutation Although exists large body conventional wisdom concerning roles crossover mutation roles captured theoretical fashion For example never theoretically shown mutation sense less powerful crossover vice versa This paper provides answers questions theoretically demonstrating important characteristics operator captured',\n",
              " 'In recent paper Friedman Geiger Goldszmidt introduced classifier based Bayesian networks called Tree Augmented Naive Bayes TAN outperforms naive Bayes performs competitively C stateoftheart methods This classifier several advantages including robustness polynomial computational complexity One limitation TAN classifier applies discrete attributes thus continuous attributes must prediscretized In paper extend TAN deal continuous attributes directly via parametric eg Gaussians semiparametric eg mixture Gaussians conditional probabilities The result classifier represent combine discrete continuous attributes In addition propose new method takes advantage modeling language Bayesian networks order represent attributes discrete continuous form simultaneously use versions classification This automates process deciding form attribute relevant classification task It also avoids commitment either discretized semiparametric form since different attributes may correlate better one version Our empirical results show latter method usually achieves classification performance good better either purely discrete purely continuous TAN models',\n",
              " 'This paper considers problem representing complex systems evolve stochastically time Dynamic Bayesian networks provide compact representation stochastic processes Unfortunately often unwieldy since explicitly model complex organizational structure many real life systems fact processes typically composed several interacting subprocesses turn decomposed We propose hierarchically structured representation language extends dynamic Bayesian networks objectoriented Bayesian network framework show language allows us describe systems natural modular way Our language supports natural representation certain system characteristics hard capture using traditional frameworks For example allows us represent systems processes evolve different rate others systems processes interact intermittently We provide simple inference mechanism representation via translation Bayesian networks suggest ways inference algorithm exploit additional structure encoded representation',\n",
              " 'It often difficult predict optimal neural network size particular application Constructive destructive methods add subtract neurons layers connections etc might offer solution problem We prove one method Recurrent Cascade Correlation due topology fundamental limitations representation thus learning capabilities It represent monotone ie sigmoid hardthreshold activation functions certain finite state automata We give preliminary approach get around limitations devising simple constructive training method adds neurons training still preserving powerful fullyrecurrent structure We illustrate approach simulations learn many examples regular grammars',\n",
              " 'Indexing cases important topic MemoryBased ReasoningMBR One key problem assign weights attributes cases Although several weighting methods proposed methods handle numeric attributes directly necessary discretize numeric values classification Furthermore existing methods theoretical background little said optimality We propose new weighting method based statistical technique called Quantification Method II It handle numeric symbolic attributes framework Generated attribute weights optimal sense maximize ratio variance classes variance cases Experiments several benchmark tests show many cases method obtains higher accuracies weighting methods The results also indicate distinguish relevant attributes irrelevant ones tolerate noisy data',\n",
              " 'A General Result Stabilization Linear Systems Using Bounded Controls ABSTRACT We present two constructions controllers globally stabilize linear systems subject control saturation We allow essentially arbitrary saturation functions The conditions imposed system obvious necessary ones namely eigenvalues uncontrolled system positive real part standard stabilizability rank condition hold One constructions terms neuralnetwork type onehidden layer architecture one terms cascades linear maps saturations',\n",
              " 'This paper proposes classification scheme based integration multiple Ensembles ANNs It demonstrated classification problem seismic signals Natural Earthquakes must distinguished seismic signals Artificial Explosions A Redundant Classification Environment consists several Ensembles Neural Networks created trained Bootstrap Sample Sets using various data representations architectures The ANNs within Ensembles aggregated Bagging Ensembles integrated nonlinearly signal adaptive manner using posterior confidence measure based agreement variance within Ensembles The proposed Integrated Classification Machine achieved correct classifications seismic test data Cross Validation evaluations comparisons indicate integration collection ANNs Ensembles robust way handling high dimensional problems complex nonstationary signal space current Seismic Classification problem',\n",
              " 'This first draft chapter Bayesian Biostatistics edited Donald A Berry Darlene K Strangl Adrian E Raftery Professor Statistics Sociology Department Statistics GN University Washington Seattle WA USA Sylvia Richardson Directeur de Recherche INSERM Unite avenue Paul Vaillant Couturier Villejuif CEDEX France Rafterys research supported ONR contract NJ Ministere de la Recherche et de lEspace Paris Universite de Paris VI INRIA Rocquencourt France Raftery thanks latter two institutions Paul Deheuvels Gilles Celeux hearty hospitality Paris sabbatical part chapter written The authors grateful Christine Montfort excellent research assistance Mariette Gerber Michel Chavance David Madigan helpful discussions',\n",
              " 'ProductionManufacturing scheduling typically involves acquisition user optimization preferences The illstructuredness problem space desired objectives make practical scheduling problems difficult formalize costly solve especially problem configurations user optimization preferences change time This paper advocates incremental revision framework improving schedule quality incorporating user dynamically changing preferences CaseBased Reasoning Our implemented system called CABINS records situationdependent tradeoffs consequences result schedule revision guide schedule improvement The preliminary experimental results show CABINS able effectively capture user static dynamic preferences known system exist implicitly extensional manner case base',\n",
              " 'Realization autonomous behavior mobile robots using fuzzy logic control requires formulation rules collectively responsible necessary levels intelligence Such collection rules conveniently decomposed efficiently implemented hierarchy fuzzybehaviors This article describes done using behaviorbased architecture A behavior hierarchy mechanisms control decisionmaking described In addition approach behavior coordination described emphasis evolution fuzzy coordination rules using genetic programming GP paradigm Both conventional GP steadystate GP applied evolve fuzzybehavior sensorbased goalseeking The usefulness behavior hierarchy partial design GP evident performance results simulated autonomous navigation',\n",
              " 'We present distribution model binary vectors called influence combination model show model used basis unsupervised learning algorithms feature selection The model closely related Harmonium model defined Smolensky RMCh In first part paper analyze properties distribution representation scheme We show arbitrary distributions binary vectors approximated combination model We show weight vectors model interpreted high order correlation patterns among input bits We compare combination model mixture model principle component analysis In second part paper present two algorithms learning combination model examples The first algorithm based gradient ascent Here give closed form gradient significantly easier compute corresponding gradient general Boltzmann machine The second learning algorithm greedy method creates hidden units computes weights one time This method variant projection pursuit density estimation In third part paper give experimental results learning methods synthetic data natural data handwritten digit images',\n",
              " 'Complex group behavior arises social insects colonies integration actions simple redundant individual insects Adler Gordon Oster Wilson Furthermore colony act information center expedite foraging Brown We apply lessons natural systems model collective action memory computational agent society Collective action expedite search combinatorial optimization problems Dorigo et al Collective memory improve learning multiagent systems Garland Alterman Our collective adaptation integrates simplicity collective action pattern detection collective memory significantly improve gathering processing knowledge As test role society information center examine ability society distribute task allocation without omnipotent centralized control',\n",
              " 'We study annealed theories learning boolean functions using concept class finite cardinality The naive annealed theory used derive universal learning curve bound zero temperature learning similar inverse square root bound VapnikChervonenkis theory Tighter nonuniversal learning curve bounds also derived A refined annealed theory leads still tighter bounds cases similar results previously obtained using onestep replica symmetry breaking',\n",
              " 'This article describes numerical method may used efficiently locate track underwater sonar targets nearfield bearing range estimation case large passive arrays The approach used requirement priori knowledge source uses limited information receiver array shape The role sensor position uncertainty consequence targets always nearfield analysed problems associated manipulation large matrices inherent conventional eigenvalue type algorithms noted A simpler numerical approach presented reduces problem search optimization When using method location target corresponds finding position maximum weighted sum output sensors Since search procedure dealt using modern stochastic optimization methods genetic algorithm operational requirement acceptable accuracy achieved real time usually met The array studied consists elements positioned along flexible cable towed behind ship sensors giving effective aperture For long array far field assumption used beamforming algorithms longer appropriate The waves emitted targets considered curved rather plane It shown simulated data significant noise',\n",
              " 'This paper introduces new type intelligent agent called constructive inductionbased learning agent CILA This agent differs adaptive agents ability learn assist user task also incrementally adapt knowledge representation space better fit given learning task The agents ability autonomously make problemoriented modifications originally given representation space due constructive induction CI learning method Selective induction SI learning methods agents based methods rely good representation space A good representation space misclassification noise intercorrelated attributes irrelevant attributes Our proposed CILA methods overcoming problems In agent domains poor representations CIbased learning agent learn accurate rules useful SIbased learning agent This paper gives architecture CIbased learning agent gives empirical comparison CI SI set six abstract domains involving DNFtype disjunctive normal form descriptions',\n",
              " 'We propose method decreasing computational complexity selforganising maps The method uses partitioning neurons disjoint clusters Teaching neurons occurs clusterbasis instead neuronbasis For teaching Nneuron network N samples computational complexity decreases ON N ON log N Furthermore introduce measure amount order selforganising map show introduced algorithm behaves well original algorithm',\n",
              " 'Inductive learning relational domains shown intractable general Many approaches task suggested nevertheless way restrict hypothesis space searched They roughly divided two groups datadriven restriction encoded algorithm modelbased restrictions made less explicit form declarative bias This paper describes Incy inductive learner seeks combine aspects approaches Incy initially datadriven using examples background knowledge put forth specialize hypotheses based connectivity data hand It modeldriven hypotheses abstracted rule models used control decisions datadriven phase modelguided induction Key Words Inductive learning relational domains cooperation datadriven modelguided methods implicit declarative bias',\n",
              " 'The problem learning decision rules sequential tasks addressed focusing problem learning tactical plans simple flight simulator plane must avoid missile The learning method relies notion competition employs genetic algorithms search space decision policies Experiments presented address issues arising differences simulation model learning occurs target environment decision rules ultimately tested Specifically either model target environment may contain noise These experiments examine effect learning tactical plans without noise testing plans noisy environment effect learning plans noisy simulator testing plans noisefree environment Empirical results show best result obtained training model closely matches target environment using training environment noisy target environment better using using training environment less noise target environment',\n",
              " 'Navigation obstacles mine fields important capability autonomous underwater vehicles One way produce robust behavior perform projective planning However realtime performance critical requirement navigation What needed truly autonomous vehicle robust reactive rules perform well wide variety situations also achieve realtime performance In work SAMUEL learning system based genetic algorithms used learn highperformance reactive strategies navigation collision avoidance',\n",
              " 'In paper introduce investigate mathematically rigorous theory learning curves based ideas statistical mechanics The advantage theory wellestablished VapnikChervonenkis theory bounds considerably tighter many cases also reflective true behavior functional form learning curves This behavior often exhibit dramatic properties phase transitions well power law asymptotics explained VC theory The disadvantages theory application requires knowledge input distribution limited far finite cardinality function classes We illustrate results many concrete examples learning curve bounds derived theory',\n",
              " 'Although considerable interest shown language inference automata induction using recurrent neural networks success models mostly limited regular languages We previously demonstrated Neural Network Pushdown Automaton NNPDA model capable learning deterministic contextfree languages eg n b n parenthesis languages examples However learning task computationally intensive In paper discuss ways priori knowledge task data could used efficient learning We also observe knowledge often experimental prerequisite learning nontrivial languages eg n b n cb',\n",
              " 'Connectionist learning procedures presented sigmoid noisyOR varieties stochastic feedforward network These networks class belief networks used expert systems They represent probability distribution set visible variables using hidden variables express correlations Conditional probability distributions exhibited stochastic simulation use tasks classification Learning empirical data done via gradientascent method analogous used Boltzmann machines due feedforward nature connections negative phase Boltzmann machine learning unnecessary Experimental results show result learning sigmoid feedforward network faster Boltzmann machine These networks advantages Boltzmann machines pattern classification decision making applications provide link work connectionist learning work representation expert knowledge',\n",
              " 'Genetic Programming GP uses variable size representations programs Size becomes important interesting emergent property structures evolved GP The size programs controlling controlled factor GP search Size influences efficiency search process related generality solutions This paper analyzes size generality issues standard GP GP using subroutines addresses question whether analysis help control search process We relate size generalization modularity issues programs evolved control agent dynamic nondeterministic environment exemplified PacMan game',\n",
              " 'We present definition cause effect terms decisiontheoretic primitives thereby provide principled foundation causal reasoning Our definition departs traditional view causation causal assertions may vary set decisions available We argue approach provides added clarity notion cause Also paper examine encoding causal relationships directed acyclic graphs We describe special class influence diagrams canonical form show relationship Pearls representation cause effect Finally show canonical form facilitates counterfactual reasoning',\n",
              " 'Fuzzy logic evolutionary computation proven convenient tools handling realworld uncertainty designing control systems respectively An approach presented combines attributes paradigms purpose developing intelligent control systems The potential genetic programming paradigm GP learning rules use fuzzy logic controllers FLCs evaluated focussing problem discovering controller mobile robot path tracking Performance results incomplete rulebases compare favorably complete FLC designed usual trialanderror approach A constrained syntactic representation supported structurepreserving genetic operators also introduced',\n",
              " 'We review estimation interval censoring models including nonparametric estimation distribution function estimation regression models In nonparametric setting describe computational procedures asymptotic properties nonparametric maximum likelihood estimators In regression setting focus proportional hazards proportional odds accelerated failure time semiparametric regression models Particular emphasis given calculation Fisher information regression parameters We also discuss computation regression parameter estimators via profile likelihood maximization semiparametric likelihood distributional results maximum likelihood estimators estimation asymptotic variances Some problems open questions also reviewed',\n",
              " 'Genetic programming distinguished evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme important allows underlying structure data discovered automatically One primary difficulty however solutions may grow big without improvement generalization ability In paper investigate fundamental relationship performance complexity evolved structures The essence parsimony problem demonstrated empirically analyzing error landscapes programs evolved neural network synthesis We consider genetic programming statistical inference problem apply Bayesian modelcomparison framework introduce class fitness functions error complexity terms An adaptive learning method presented automatically balances modelcomplexity factor evolve parsimonious programs without losing diversity population needed achieving desired training accuracy The effectiveness approach empirically shown induction sigmapi neural networks solving realworld medical diagnosis problem well benchmark tasks',\n",
              " 'Dynamic probabilistic networks DPNs useful tool modeling complex stochastic processes The simplest inference task DPNs monitoring computing posterior distribution state variables time step given observations time Recursive constantspace algorithms wellknown monitoring DPNs models This paper concerned hindsight computing posterior distribution given past future observations Hindsight essential subtask learning DPN models data Existing algorithms hindsight DPNs use OSN space time N total length observation sequence S state space size time step They therefore impractical hindsight complex models long observation sequences This paper presents OS log N space OSN log N time hindsight algorithm We demonstrates effectiveness algorithm two realworld DPN learning problems We also discuss possibility OSspace OSN time algorithm',\n",
              " 'Learning methods vary optimism pessimism regard informativeness learned knowledge Pessimism implicit hypothesis testing wish draw cautious conclusions experimental evidence However paper demonstrates optimism utility derived rules may preferred bias learning systems We examine continuum naive pessimism naive optimism context decision tree learner prunes rules based stringent ie pessimistic weak ie optimistic tests significance Our experimental results indicate cases optimism preferred particularly cases sparse training data high noise This work generalizes earlier findings Fisher Schlimmer Schaffer discuss relevance unsupervised learning small disjuncts issues',\n",
              " 'We already shown extracting longterm dependencies sequential data difficult deterministic dynamical systems recurrent networks probabilistic models hidden Markov models HMMs inputoutput hidden Markov models IOHMMs In practice avoid problem researchers used domain specific apriori knowledge give meaning hidden state variables representing past context In paper propose use general type apriori knowledge namely temporal dependencies structured hierarchically This implies longterm dependencies represented variables long time scale This principle applied recurrent network includes delays multiple time scales Experiments confirm advantages structures A similar approach proposed HMMs IOHMMs',\n",
              " 'We present new algorithm finding low complexity neural networks high generalization capability The algorithm searches flat minimum error function A flat minimum large connected region weightspace error remains approximately constant An MDLbased Bayesian argument suggests flat minima correspond simple networks low expected overfitting The argument based Gibbs algorithm variant novel way splitting generalization error underfitting overfitting error Unlike many previous approaches require Gaussian assumptions depend good weight prior instead prior inputoutput functions thus taking account net architecture training set Although algorithm requires computation second order derivatives backprops order complexity Automatically effectively prunes units weights input lines Various experiments feedforward recurrent nets described In application stock market prediction flat minimum search outperforms conventional backprop weight decay optimal brain surgeon optimal brain damage We also provide pseudo code algorithm omitted NCversion',\n",
              " 'This paper describes method improving comprehensibility accuracy generality reactive plans A reactive plan set reactive rules Our method involves two phases formulate explanations execution traces generate new reactive rules explanations Since explanation phase previously described primary focus paper rule generation phase This latter phase consists taking subset explanations using explanations generate set new reactive rules add original set The particular subset explanations chosen yields rules provide new domain knowledge handling knowledge gaps original rule set The original rule set complimentary manner provides expertise fill gaps domain knowledge provided new rules incomplete',\n",
              " 'Technical Report AI May Abstract A new method developing good valueordering strategies constraint satisfaction search presented Using evolutionary technique called SANE individual neurons evolve cooperate form neural network problemspecific knowledge discovered results better valueordering decisions based problemgeneral heuristics A neural network evolved chronological backtrack search decide ordering cars resourcelimited assembly line The network required backtracks random ordering backtracks maximization future options heuristic The SANE approach extend well domains heuristic information either difficult discover problemspecific',\n",
              " 'Conversational casebased reasoning CBR shells eg Inferences CBR Express commercially successful tools supporting development help desk related applications In contrast rulebased expert systems capture knowledge cases rather problematic rules incrementally extended However rather eliminate knowledge engineering bottleneck refocus case engineering task carefully authoring cases according library design guidelines ensure good performance Designing complex libraries according guidelines difficult software needed assist users case authoring We describe approach revising case libraries according design guidelines implementation Clire empirical results showing conditions approach improve conversational CBR performance',\n",
              " 'We present computational model movement skill learning The types skills addressed class trajectory following movements involving multiple accelerations decelerations changes direction lasting seconds These skills acquired observation improved practice We also review speedaccuracy tradeoffone robust phenomena human motor behavior We present two speedaccuracy tradeoff experiments models performance fits human behavior quite well',\n",
              " 'Reinforcement Learning class problems autonomous agent acting given environment improves behavior progressively maximizing function calculated basis succession scalar responses received environment Qlearning classifier systems CS two methods among used solve reinforcement learning problems Notwithstanding popularity shared goal past often considered two different models In paper first show classifier system restricted sharp simplification called discounted max simple classifier system D MAX VSCS boils tabular Qlearning It follows D MAX VSCS converges optimal policy proved Watkins Dayan draw profit results experimental theoretical works dedicated improve Qlearning facilitate use concrete applications In second part paper show three restrictions need impose CS deriving equivalence Qlearning internal states dont care symbols structural changes turn essential recently rediscovered reprogrammed Qlearning adepts Eventually sketch similarities among ongoing work within research contexts The main contribution paper therefore make explicit strong similarities existing Qlearning classifier systems show experience gained research within one domain useful direct future research one',\n",
              " 'Some recent work investigated dichotomy compact coding using dimensionality reduction sparse distributed coding context understanding biological information processing We introduce artificial neural network self organises basis simple Hebbian learning negative feedback activation show capable forming compact codings data distributions also identifying filters sensitive sparse distributed codes The network extremely simple biological relevance investigated via response set images typical everyday life However analysis networks identification filter sparse coding reveals coding may globally optimal exists innate limiting factor transcended',\n",
              " 'For classes concepts defined certain classes analytic functions depending n parameters nonempty open sets samples length n shattered A slighly weaker result also proved piecewiseanalytic functions The special case neural networks discussed',\n",
              " 'Two important goals evaluation AI theory model assess merit design decisions performance implemented computer system analyze impact performance system faces problem domains different characteristics This particularly difficult casebased reasoning systems systems typically complex tasks domains operate We present methodology evaluation casebased reasoning systems systematic empirical experimentation range system configurations environmental conditions coupled rigorous statistical analysis results experiments This methodology enables us understand behavior system terms theory design computational model select best system configuration given domain predict system behave response changing domain problem characteristics A case study multistrategy casebased reinforcement learning system performs autonomous robotic navigation presented example',\n",
              " 'For casebased reasoner use knowledge flexibly must equipped powerful case adapter A casebased reasoner cope variation form problems given extent cases memory efficiently adapted fit wide range new situations In paper address task adapting abstract knowledge planning fit specific planning situations First show adapting abstract cases requires reconciling incommensurate representations planning situations Next describe representation system memory organization adaptation process tailored requirement Our approach implemented brainstormer planner takes abstract advice',\n",
              " 'The maximum likelihood estimator MLE proportional hazards model current status data studied It shown MLE regression parameter asymptotically normal p nconvergence rate achieves information bound even though MLE baseline cumulative hazard function converges n rate Estimation asymptotic variance matrix MLE regression parameter also considered To prove main results also establish general theorem showing MLE finite dimensional parameter class semiparametric models asymptotically efficient even though MLE infinite dimensional parameter converges rate slower The results illustrated applying data set tumoriginicity study Introduction In many survival analysis problems interested p',\n",
              " 'PO Box Wellington New Zealand Tel Fax Internet TechReportscompvuwacnz Technical Report CSTR October Abstract People often give advice telling stories Stories recommend course action exemplify general conditions recommendation appropriate A computational model advice taking using stories must address two related problems determining storys recommendations appropriateness conditions showing obtain new situation In paper present efficient solution second problem based caching results first Our proposal implemented brainstormer planner takes abstract advice',\n",
              " 'There increasing need efficient estimation mixture distributions especially following explosion use modelling tools many applied fields We propose paper Bayesian noninformative approach estimation normal mixtures relies reparameterisation secondary components mixture terms divergence main component As well providing intuitively appealing representation modelling stage reparameterisation important bearing prior distribution performance MCMC algorithms We compare two possible reparameterisations extending Mengersen Robert show reparameterisation link secondary components together associated poor convergence properties MCMC algorithms',\n",
              " 'A WorldWide Web WWW server implemented Common LISP order facilitate exploratory programming global hypermedia domain provide access complex research programs particularly artificial intelligence systems The server initially used provide interfaces document retrieval email servers More advanced applications include interfaces systems inductive rule learning naturallanguage question answering Continuing research seeks fully generalize automatic formprocessing techniques developed email servers operate seamlessly Web The conclusions argue presentationbased interfaces sophisticated form processing moved clients order reduce load servers provide advanced interaction models users',\n",
              " 'Survival analysis concerned finding models predict survival patients assess efficacy clinical treatment A key part modelbuilding process selection predictor variables It standard use stepwise procedure guided series significance tests select single model make inference conditionally selected model However ignores model uncertainty substantial We review standard Bayesian model averaging solution problem extend survival analysis introducing partial Bayes factors Cox proportional hazards model In two examples taking account model uncertainty enhances predictive performance extent could clinically useful',\n",
              " 'We propose bootstrapbased method model averaging selection focuses training points left individual bootstrap samples This information used estimate optimal weighting factors combining estimates different bootstrap samples also finding best subsets linear model setting These proposals provide alternatives Bayesian approaches model averaging selection requiring less computation fewer subjective choices',\n",
              " 'Technical Report December Statistics Department University California Berkeley CA Abstract The theory behind success adaptive reweighting combining algorithms arcing Adaboost Freund Schapire others reducing generalization error well understood By formulating prediction classification regression game one player makes selection instances training set convex linear combination predictors finite set existing arcing algorithms shown algorithms finding good game strategies An optimal game strategy finds combined predictor minimizes maximum error training set A bound generalization error combined predictors terms maximum error proven sharper bounds date Arcing algorithms described converge optimal strategy Schapire etal offered explanation Adaboost works terms ability reduce margin Comparing Adaboost optimal arcing algorithm shows explanation valid answer lies elsewhere In situation VCtype bounds misleading Some empirical results given explore situation',\n",
              " 'Conversational casebased reasoning CCBR form interactive casebased reasoning users input partial problem description text The CCBR system responds ranked solution display lists solutions stored cases whose problem descriptions best match users ranked question display lists unanswered questions cases Users interact displays either refining problem description answering selected questions selecting solution apply CCBR systems support dialogue inferencing infer answers questions implied problem description Otherwise questions listed user believes already answered The standard approach dialogue inferencing allows case library designers insert rules define implications problem description unanswered questions However approach imposes substantial knowledge engineering requirements We introduce alternative approach whereby intelligent assistant guides designer defining model case library implication rules derived We detail approach benefits explain supported integration ParkaDB fast relational database system We evaluate approach context CCBR system named NaCoDAE This paper appeared AAAI Spring Symposium Multimodal Reasoning NCARAI TR AIC We introduce integrated reasoning approach modelbased reasoning component performs important inferencing role conversational casebased reasoning CCBR system named NaCoDAE Breslow Aha Figure CCBR form casebased reasoning users enter text queries describing problem system assists eliciting refinements Aha Breslow Cases three components',\n",
              " 'A readonce formula boolean formula variable occurs Such formulas also called formulas boolean trees This paper treats problem exactly identifying unknown readonce formula using specific kinds queries The main results polynomial time algorithm exact identification monotone readonce formulas using membership queries polynomial time algorithm exact identification general readonce formulas using equivalence membership queries protocol based notion minimally adequate teacher Our results improve Valiants previous results readonce formulas We also show polynomial time algorithm using membership queries equivalence queries exactly identify readonce formulas',\n",
              " 'Recursive AutoAssociative Memory RAAM structures show promise general representation vehicle uses distributed patterns However training often difficult explains least part relatively small networks studied We show technique transforming collection hierarchical structures set training patterns sequential RAAM effectively trained using simple Elmanstyle recurrent network Tr aining produces set distributed patterns corresponding structures',\n",
              " 'We propose analyze distribution learning algorithm variable memory length Markov processes These processes described subclass probabilistic finite automata name Probabilistic Finite Suffix Automata The learning algorithm motivated real applications manmachine interaction handwriting speech recognition Conventionally used fixed memory Markov hidden Markov models either severe practical theoretical drawbacks Though general hardness results known learning distributions generated sources similar structure prove algorithm indeed efficiently learn distributions generated restricted sources In Particular show KLdivergence distribution generated target source distribution generated hypothesis made small high confidence polynomial time sample complexity We demonstrate applicability algorithm learning structure natural English text using hy pothesis correction corrupted text',\n",
              " 'The clausal discovery engine claudien presented claudien discovers regularities data representative inductive logic programming paradigm As represents data regularities means first order clausal theories Because search space clausal theories larger attribute value representation claudien also accepts input declarative specification language bias determines set syntactically wellformed regularities Whereas papers claudien focuss semantics logical problem specification claudien discovery algorithm PAClearning aspects paper wants illustrate power resulting technique In order achieve aim show claudien used learn integrity constraints databases functional dependencies determinations properties sequences mixed quantitative qualitative laws reverse engineering classification rules',\n",
              " 'In context machine learning examples paper deals problem estimating quality attributes without dependencies Greedy search prevents current inductive machine learning algorithms detect significant dependencies attributes Recently Kira Rendell developed RELIEF algorithm estimating quality attributes able detect dependencies attributes We show strong relation RELIEFs estimates impurity functions usually used heuristic guidance inductive learning algorithms We propose use RELIEFF extended version RELIEF instead myopic impurity functions We reimplemented Assistant system top induction decision trees using RELIEFF estimator attributes selection step The algorithm tested several artificial several real world problems Results show advantage presented approach inductive learning open wide rang possibilities using RELIEFF',\n",
              " 'An investigation dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques ability perform well many problem domains failing others Because Genetic Programmings flexible tree structure particular problem represented myriad forms These representations variegated effects search performance Therefore aspect fundamental engineering significance find representation acted upon Genetic Programming operators optimizes search performance We discover case chaotic time series prediction representation commonly used domain yield optimal solutions Instead find population converges onto one accurately replicating tree trees explored To correct premature convergence make simple modification crossover operator In paper review previous work GP time series prediction pointing anomalous result related overlearning report improvement effected modified crossover operator',\n",
              " 'Current ILP algorithms typically use variants extensions greedy search This prevents detect significant relationships training objects Instead myopic impurity functions propose use heuristic based RELIEF guidance ILP algorithms At step ILPR system heuristic used determine beam candidate literals The beam used exhaustive search potentially good conjunction literals From efficiency point view introduce interesting declarative bias enables us keep growth training set introducing new variables within linear bounds linear respect clause length This bias prohibits crossreferencing variables variable dependency tree The resulting system tested various artificial problems The advantages deficiencies approach discussed',\n",
              " 'Instead myopic impurity functions propose use ReliefF heuristic guidance inductive learning algorithms The basic algoritm RELIEF developed Kira Rendell Kira Rendell ab able efficiently solve classification problems involving highly dependent attributes parity problems However sensitive noise unable deal incomplete data multiclass regression problems continuous class We extended RELIEF several directions The extended algorithm ReliefF able deal noisy incomplete data used multiclass problems regressional variant RReliefF deal regression problems Another area application inductive logic programming ILP instead myopic measures ReliefF used estimate utility literals theory construction',\n",
              " 'In paper present TDLeaf variation TD algorithm enables used conjunction minimax search We present experiments chess backgammon demonstrate utility provide comparisons TD another less radical variant TDdirected In particular chess program KnightCap used TDLeaf learn evaluation function playing Free Internet Chess Server FICS ficsonenetnet It improved rating rating games We discuss reasons success relationship results Tesauros results backgammon',\n",
              " 'This paper deals asymptotic properties MetropolisHastings algorithm distribution interest unknown approximated sequential estimator density We prove simple conditions rate convergence MetropolisHastings algorithm sequential estimator latter introduced reversible measure MetropolisHastings Kernel This problem natural extension previous work new simulated annealing algorithm sequential estimator energy',\n",
              " 'We explored two approaches recognizing faces across changes pose First developed representation face images based independent component analysis ICA compared principal component analysis PCA representation face recognition The ICA basis vectors data set spatially local PCA basis vectors ICA representation greater invariance changes pose Second present model development viewpoint invariant responses faces visual experience biological system The temporal continuity natural visual experience incorporated attractor network model Hebbian learning following lowpass temporal filter unit activities When combined temporal filter basic Hebbian update rule became generalization Griniasty et al associates temporally proximal input patterns basins attraction The system acquired rep resentations faces largely independent pose',\n",
              " 'Problems regression smoothing curve fitting addressed via predictive inference flexible class mixture models Multidimensional density estimation using Dirichlet mixture models provides theoretical basis semiparametric regression methods fitted regression functions may deduced means conditional predictive distributions These Bayesian regression functions features similar generalised kernel regression estimates formal analysis addresses problems multivariate smoothing parameter estimation assessment uncertainties regression functions naturally Computations based multidimensional versions existing Markov chain simulation analysis univariate Dirichlet mixture models',\n",
              " 'On basis early theoretical empirical studies genetic algorithms typically used point crossover operators standard mechanisms implementing recombination However number recent studies primarily empirical nature shown benefits crossover operators involving higher number crossover points From traditional theoretical point view surprising new results relate uniform crossover involves average L crossover points strings length L In paper extend existing theoretical results attempt provide broader explanatory predictive theory role multipoint crossover genetic algorithms In particular extend traditional disruption analysis include two general forms multipoint crossover npoint crossover uniform crossover We also analyze two aspects multipoint crossover operators namely recombination potential exploratory power The results analysis provide much clearer view role multipoint crossover genetic algorithms The implications results implementation issues performance discussed several directions research suggested',\n",
              " 'In paper discuss methodological issues using class neural networks called Mixture Density Networks MDN discriminant analysis MDN models advantage rigorous probabilistic interpretation proven viable alternative classification procedure discrete domains We address classification interpretive aspects discriminant analysis compare approach traditional method linear discrimin ants implemented standard statistical packages We show MDN approach adopted performs well aspects Many observations made restricted particular case hand applicable applications discriminant analysis educational research fl URL httpwwwcsHelsinkiFIresearchcosco',\n",
              " 'Satisfiability SAT refers task finding truth assignment makes arbitrary boolean expression true This paper compares simulated annealing algorithm SASAT GSAT Selman et al greedy algorithm solving satisfiability problems GSAT solve problem instances extremely difficult traditional satisfiability algorithms Results suggest SASAT scales better number variables increases solving least many hard SAT problems less effort The paper presents ablation study helps explain relative advantage SASAT GSAT Next improvement basic SASAT algorithm examined based random walk implemented GSAT Selman et al Finally examine performance SASAT test suite satisfiability problems produced DIMACS challenge',\n",
              " 'We present comparison errorbased entropybased methods discretization continuous features Our study includes extensive empirical comparison well analysis scenarios error minimization may inappropriate discretization criterion We present discretization method based C decision tree algorithm compare existing entropybased discretization algorithm employs Minimum Description Length Principle recently proposed errorbased technique We evaluate discretization methods respect C NaiveBayesian classifiers datasets UCI repository analyze computational complexity method Our results indicate entropybased MDL heuristic outperforms error minimization average We analyze shortcomings errorbased approaches comparison entropybased methods',\n",
              " 'Here show similar construction multipleoutput systems modifications Let A B C discretetime signlinear system state space IR n p outputs Perform change A n fi n invertible A n fi n nilpotent If A B reachable pair A C observable pair minimal sense signlinear system inputoutput behavior dimension least n But n lt n det A observable hence canonical Let us find another system necessarily signlinear inputoutput behavior canonical Let relative degree ith row Markov sequence A minf pg Let initial state x There difference case smallest relative degree greater equal n case lt n Roughly speaking n outputs signlinear system give us information sign Cx sign CAx sign CA x first outputs sys tem After use inputs outputs learn x first n components x When lt n may able use controls learn x last n components x time n nilpotency A finally Lemma Two states x z indistinguishable x z Proof In case n equations x z equality The first output terms exactly terms So equalities satisfied first output terms coincide x z input Equality everything first n components equivalent first n output terms coinciding x z since jth row qth output initial state x example either sign c j A q x j gt q sign c j A q x A j j u q j j q case may use control u q j identify c j A q x using Remark',\n",
              " 'So applying Corollary second equation conclude From get jgy n k obtain jy n k From see righthand side bounded Since system A k b jyj ev N Now suppose lim sup jytj gt Then jyj ev Since j kyj Ljyj using obtain jyj ev L ffi Note righthand side inequality trivial since know jyj ev From ffi N ffi gt N However see still holds So established cases From get jyj ev Taking lim sup lefthand side N ffi ie N ffi Substituting get jyj ev ffi jyj ev N ffi So take N N L conclusion follows To complete proof need deal general case gt inputs This done induction proof omitted Fuller AT In large stability relay saturated control systems linear controllers Int J Control Gutman PO P Hagander A new design constrained controllers linear systems IEEE Transactions Automat Contr AC Kosut RL Design linear systems saturating linear control bounded states IEEE Trans Autom Control AC Krikelis NJ SK Barkas Design tracking systems subject actuator saturation integrator windup Int J Control Schmitendorf WE BR Barmish Null controllability linear systems constrained controls SIAM J Control Opt Slemrod M Feedback stabilization linear control system Hilbert space Math Control Signals Systems Slotine JJE W Li Applied Nonlinear Control PrenticeHall Englewood Cliffs Sontag ED An algebraic approach bounded controllability linear systems Int J Control Sontag ED Remarks stabilization inputtostate stability Proc IEEE CDC Tampa Dec IEEE Publications pp Sontag ED Mathematical Control Theory Deterministic Finite Dimensional Systems Springer New York Sontag ED HJ Sussmann Nonlinear output feedback design linear systems saturating controls Proc IEEE CDC Honolulu Dec IEEE Publications pp Sussmann H J Y Yang On stabilizability multiple integrators means bounded feedback controls Proc IEEE CDC Brighton UK Dec IEEE Publications Teel AR Global stabilization restricted tracking multiple integrators bounded controls Systems Control Letters Yang Y HJ Sussmann ED Sontag Stabilization linear systems bounded controls Proc June NOLCOS Bordeaux M Fliess Ed IFAC Publications pp Yang Y Global Stabilization Linear Systems Bounded Feedback Ph D Thesis Mathematics Department Rutgers University jyj ev M ffi',\n",
              " 'Gross error detection plays vital role parameter estimation data reconciliation dynamic steady state systems In particular recent advances process optimization allow data reconciliation dynamic systems appropriate problem formulations need considered Data errors due either miscalibrated faulty sensors random events nonrepresentative underlying statistical distribution induce heavy biases parameter estimates reconciled data In paper concentrate robust estimators exploratory statistical methods allow us detect gross errors data reconciliation performed These robust methods property insensitive departures ideal statistical distributions therefore insensitive presence outliers Once regression done outliers detected readily using exploratory statistical techniques An important feature performance optimization algorithm uniqueness reconciled data ability classify variables according observability redundancy properties Here observable variable unmeasured quantity estimated measured variables physical model nonredundant variable measured variable estimated measurements Variable classification used aid design instrumentation schemes In',\n",
              " 'Many significant realworld classification tasks involve large number categories arranged hierarchical structure example classifying documents subject categories library congress scheme classifying worldwideweb documents topic hierarchies We investigate potential benefits using given hierarchy base classes learn accurate multicategory classifiers domains First consider possibility exploiting class hierarchy prior knowledge help one learn accurate classifier We explore benefits learning categorydiscriminants hard topdown fashion compare soft approach shares training data among sibling categories In verify hierarchies potential improve prediction accuracy But argue reasons subtle Sometimes improvement using hierarchy happens constrain expressiveness hypothesis class appropriate manner However various controlled experiments show cases performance advantage associated using hierarchy really seem due prior knowledge encodes',\n",
              " 'Many algorithms inferring decision tree data involve twophase process First large decision tree grown typically ends overfitting data To reduce overfitting second phase tree pruned using one number available methods The final tree output used classification test data In paper suggest alternative approach pruning phase Using given unpruned decision tree present new method making predictions test data prove algorithms performance much worse precise technical sense predictions made best reasonably small pruning given decision tree Thus procedure guaranteed competitive terms quality predictions pruning algorithm We prove procedure efficient highly robust Our method viewed synthesis two previously studied techniques First apply CesaBianchi et als results predicting using expert advice view pruning expert obtain algorithm provably low prediction loss computationally infeasible Next generalize apply method developed Buntine Willems Shtarkov Tjalkens derive efficient implementation procedure',\n",
              " 'We present efficient algorithm PAClearning general class geometric concepts lt fixed More specifically let T set halfspaces Let x x x arbitrary point lt With T associate boolean indicator function I x x halfspace The concept class C study consists concepts formed boolean function I I T This concept class much general geometric concept class known PAClearnable Our results easily extended efficiently learn boolean combination polynomial number concepts selected concept class C lt given VCdimension C dependence thus constant constant polynomial time algorithm determine concept C consistent given set labeled examples We also present statistical query version algorithm tolerate random classification noise noise rate strictly less Finally present generalization standard net result Haussler Welzl apply give alternative noisetolerant algorithm based geometric subdivisions',\n",
              " 'In work develop new criteria perform pessimistic decision tree pruning Our method theoretically sound based theoretical concepts uniform convergence VapnikChervonenkis dimension We show criteria well motivated theory side performs well practice The accuracy new criteria comparable current method used C',\n",
              " 'In paper study performance probabilistic networks context protein sequence analysis molecular biology Specifically report results initial experiments applying framework problem protein secondary structure prediction One main advantages probabilistic approach describe ability perform detailed experiments experiment different models We easily perform local substitutions mutations measure probabilistically effect global structure Windowbased methods support experimentation readily Our method efficient training prediction important order able perform many experiments different networks We believe probabilistic methods comparable methods prediction quality In addition predictions generated methods precise quantitative semantics shared classification methods Specifically causal statistical independence assumptions made explicit networks thereby allowing biologists study experiment different causal models convenient manner',\n",
              " 'In paper prove sanitycheck bounds error leaveoneout crossvalidation estimate generalization error bounds showing worstcase error estimate much worse training error estimate The name sanitycheck refers fact although often expect leaveoneout estimate perform considerably better training error estimate seeking assurance performance considerably worse Perhaps surprisingly assurance given limited cases prior literature crossvalidation Any nontrivial bound error leaveoneout must rely notion algorithmic stability Previous bounds relied rather strong notion hypothesis stability whose application primarily limited nearestneighbor local algorithms Here introduce new weaker notion error stability apply obtain sanitycheck bounds leaveoneout classes learning algorithms including training error minimization procedures Bayesian algorithms We also provide lower bounds demonstrating necessity form error stability proving bounds error leaveoneout estimate fact training error minimization algorithms worst case bounds must still depend VapnikChervonenkis dimension hypothesis class',\n",
              " 'This paper describes program observes behaviour actors simulated world uses observations guides conducting experiments An experiment sequence actions carried actor order support weaken case generalisation concept A generalisation attempted program observes state world similar previous state A partial matching algorithm used find substitutions enable two states unified The generalisation two states unifier',\n",
              " 'Widespread adoption Genetic Programming techniques domainindependent problem solving tool depends good underlying software structure A system presented mirrors conceptual makeup GP system Consisting loose collection software components strict interface definitions roles system maximises flexibility minimises effort applied new problem domain',\n",
              " 'Coevolution competitive species provides interesting testbed study role adaptive behavior provides unpredictable dynamic environments In paper experimentally investigate arguments coevolution different adaptive protean behaviors competing species predators preys Both species implemented simulated mobile robots Kheperas infrared proximity sensors predator additional vision module whereas prey maximum speed set twice predator Different types variability life neurocontrollers architecture genetic length compared It shown simple forms proteanism affect coevolutionary dynamics preys rather exploit noisy controllers generate random trajectories whereas predators benefit directionalchange controllers improve pursuit behavior',\n",
              " 'The calculation second derivatives required recent training analysis techniques connectionist networks elimination superfluous weights estimation confidence intervals weights network outputs We review develop exact approximate algorithms calculating second derivatives For networks jwj weights simply writing full matrix second derivatives requires Ojwj operations For networks radial basis units sigmoid units exact calculation necessary intermediate terms requires order h backwardforwardpropagation passes h number hidden units network We also review compare three approximations ignoring components second derivative numerical differentiation scoring Our algorithms apply arbitrary activation functions networks error functions instance connections skip layers radial basis functions crossentropy error Softmax units etc',\n",
              " 'In paper describe principles problem solving analogy applied domain functional program synthesis For reason treat programs syntactical structures We discuss two different methods handle structures graph metric determining distance two program schemes b Structure Mapping Engine existing system examine analogical processing Furthermore show experimental results discuss',\n",
              " 'There many ways learning system generalize training set data This paper presents several generalization styles using prototypes attempt provide accurate generalization training set data wide variety applications These generalization styles efficient terms time space lend well massively parallel architectures Empirical results generalizing several realworld applications given results indicate prototype styles generalization presented potential provide accurate generalization many applications',\n",
              " 'This paper provides exposition recent research regarding systemtheoretic aspects continuoustime recurrent dynamic neural networks sigmoidal activation functions The class systems introduced discussed result cited regarding universal approximation properties Known characterizations controllability observability parameter identifiability reviewed well result minimality Facts regarding computational power recurrent nets also mentioned fl Supported part US Air Force Grant AFOSR',\n",
              " 'Most Artificial Neural Networks ANNs fixed topology learning often suffer number shortcomings result ANNs use dynamic topologies shown ability overcome many problems Adaptive Self Organizing Concurrent Systems ASOCS class learning models inherently dynamic topologies This paper introduces LocationIndependent Transformations LITs general strategy implementing learning models use dynamic topologies efficiently parallel hardware A LIT creates set locationindependent nodes node computes part network output independent nodes using local information This type transformation allows efficient support adding deleting nodes dynamically learning In particular paper presents Location Independent ASOCS LIA model LIT ASOCS Adaptive Algorithm The description LIA gives formal definitions LIA algorithms Because LIA implements basic ASOCS mechanisms definitions provide formal description basic ASOCS mechanisms general addition LIA',\n",
              " 'Reinforcement learning algorithms often work finding functions satisfy Bellman equation This yields optimal solution prediction Markov chains controlling Markov decision process MDP finite number states actions This approach also frequently applied Markov chains MDPs infinite states We show case Bellman equation may multiple solutions many lead erroneous predictions policies Baird Algorithms conditions presented guarantee single optimal solution Bellman equation',\n",
              " 'A major issue casebasedsystems retrieving appropriate cases memory solve given problem This implies case indexed appropriately stored memory A casebased system dynamic stores cases reuse needs learn indices new knowledge system designers envision knowledge Irrespective type indexing structural functional hierarchical organization case memory raises two distinct related issues index learning learning indexing vocabulary learning right level generalization In paper show structurebehaviorfunction SBF models help learning structural indices design cases domain physical devices The SBF model design provides functional causal explanation structure design delivers function We describe SBF model design provides vocabulary structural indexing design cases inductive biases index generalization We discuss modelbased learning integrated similaritybased learning uses prior design cases learning level index generalization',\n",
              " 'We present representational format observed movements The representation temporal structure relating components single complex movement We also present OXBOW unsupervised learning system constructs classes movements Empirical results indicate system builds abstract movement concepts appropriate component structure allowing predict latter portions partially observed movement',\n",
              " 'Constructive induction divides problem learning inductive hypothesis two intertwined searches onefor best representation space twofor best hypothesis space In datadriven constructive induction DCI learning system searches better representation space analyzing input examples data The presented datadriven constructive induction method combines AQtype learning algorithm two classes representation space improvement operators constructors destructors The implemented system AQDCI experimentally applied GNP prediction problem using World Bank database The results show decision rules learned AQDCI outperformed rules learned original representation space predictive accuracy rule simplicity',\n",
              " 'We report novel possibility extracting small subset data base contains information necessary solve given classification task using Support Vector Algorithm train three different types handwritten digit classifiers observed types classifiers construct decision surface strongly overlapping small subsets data base This finding opens possibility compressing data bases significantly disposing data important solution given task In addition show theory allows us predict classifier best generalization ability based solely performance training set characteristics learning machines This finding important cases amount available data limited',\n",
              " 'Physical variables orientation line visual field location body space coded activity levels populations neurons Reconstruction decoding inverse problem physical variables estimated observed neural activity Reconstruction useful first quantifying much information physical variables present population second providing insight brain might use distributed representations solving related computational problems visual object recognition spatial navigation Two classes reconstruction methods namely probabilistic Bayesian methods basis function methods discussed They include important existing methods special cases population vector coding optimal linear estimation template matching As representative example reconstruction problem different methods applied multielectrode spike train data hippocampal place cells freely moving rats The reconstruction accuracy trajectories rats compared different methods Bayesian methods especially accurate continuity constraint enforced best errors within factor two informationtheoretic limit accurate reconstruction comparable intrinsic experimental errors position tracking In addition reconstruction analysis uncovered interesting aspects place cell activity tendency erratic jumps reconstructed trajectory animal stopped running In general theoretical values minimal achievable reconstruction errors quantify accurately physical variable encoded neuronal population sense mean square error regardless method used reading information One related result theoretical accuracy independent width Gaussian tuning function two dimensions Finally reconstruction methods considered paper implemented unified neural network architecture brain could feasibly use solve related problems',\n",
              " 'The headdirection HD cells found limbic system freely moving rats represent instantaneous head direction animal horizontal plane regardless location animal The internal direction represented cells uses selfmotion information inertially based updating familiar visual landmarks calibration Here model dynamics HD cell ensemble presented The stability localized static activity profile network dynamic shift mechanism explained naturally synaptic weight distribution components even odd symmetry respectively Under symmetric weights symmetric reciprocal connections stable activity profile close known directional tuning curves emerge By adding slight asymmetry weights activity profile shift continuously without disturbances shape shift speed accurately controlled strength oddweight component The generic formulation shift mechanism determined uniquely within current theoretical framework The attractor dynamics system ensures modalityindependence internal representation facilitates correction cumulative error putative localview detectors The model offers specific onedimensional example computational mechanism truly worldcentered representation derived observercentered sensory inputs integrating selfmotion information',\n",
              " 'We present biasvariance decomposition expected misclassification rate commonly used loss function supervised classification learning The biasvariance decomposition quadratic loss functions well known serves important tool analyzing learning algorithms yet decomposition offered commonly used zeroone misclassification loss functions recent work Kong Dietterich Breiman Their decomposition suffers major shortcomings though eg potentially negative variance decomposition avoids We show practice naive frequencybased estimation decomposition terms biased show correct bias We illustrate decomposition various algorithms datasets UCI repository',\n",
              " 'The dominant component computational burden solving n n trivial p r b l e w h evolutionary algorithms task measuring fitness individual generation evolving population The advent r p l r e c n f g u r b l e f e l programmable gate arrays FPGAs idea evolvable hardware opens possiblity e b n g individual evolving population hardware purpose accelerating timeconsuming fitness evaluation task This paper demonstrates massive parallelism rapidly r e c n f g u r b l e X l n x X C FPGA exploited accelerate computationally burdensome fitness evaluation task genetic programming The work done Virtual Computing Corporations lowcost HOTS expansion board PC type computers A step sorter evolved two fewer steps sorting network described OConnor Nelson patent sorting networks number steps minimal sorter devised Floyd Knuth subsequent patent',\n",
              " 'A theoretically justifiable fast finite successive linear approximation algorithm proposed obtaining parsimonious solution corrupted linear system Ax b p corruption p due noise error measurement The proposed linearprogrammingbased algorithm finds solution x parametrically minimizing number nonzero elements x error k Ax b p k Numerical tests signalprocessingbased example indicate proposed method comparable method parametrically minimizes norm solution x error k Ax b p k methods superior orders magnitude solutions obtained least squares well combinatorially choosing optimal solution specific number nonzero elements',\n",
              " 'In natural visual experience different views object face tend appear close temporal proximity A set simulations presented demonstrate viewpoint invariant representations faces developed visual experience capturing temporal relationships among input patterns The simulations explored interaction temporal smoothing activity signals Hebbian learning Foldiak feedforward system recurrent system The recurrent system generalization Hopfield network lowpass temporal filter unit activities Following training sequences graylevel images faces changed pose multiple views given face fell basin attraction system acquired representations faces approximately viewpoint invariant',\n",
              " 'Neural networks successfully applied wide range supervised unsupervised learning applications Neuralnetwork methods commonly used datamining tasks however often produce incomprehensible models require long training times In article describe neuralnetwork learning algorithms able produce comprehensible models require excessive training times Specifically discuss two classes approaches data mining neural networks The first type approach often called rule extraction involves extracting symbolic models trained neural networks The second approach directly learn simple easytounderstand networks We argue given current state art neuralnetwork methods deserve place tool boxes datamining specialists',\n",
              " 'A statistical theory overtraining proposed The analysis treats realizable stochastic neural networks trained KullbackLeibler loss asymptotic case It shown asymptotic gain generalization error small perform early stopping even access optimal stopping time Considering crossvalidation stopping answer question In ratio examples divided training testing sets order obtain optimum performance In nonasymptotic region crossvalidated early stopping always decreases generalization error Our large scale simulations done CM nice agreement analytical findings',\n",
              " 'Mathematical programming approaches three fundamental problems described feature selection clustering robust representation The feature selection problem considered discriminating two sets recognizing irrelevant redundant features suppressing This creates lean model often generalizes better new unseen data Computational results real data confirm improved generalization leaner models Clustering exemplified unsupervised learning patterns clusters may exist given database useful tool knowledge discovery databases KDD A mathematical programming formulation problem proposed theoretically justifiable computationally implementable finite number steps A resulting kMedian Algorithm utilized discover useful survival curves breast cancer patients medical database Robust representation concerned minimizing trained model degradation applied new problems A novel approach proposed purposely tolerates small error training process order avoid overfitting data may contain errors Examples applications concepts given',\n",
              " 'Concept learning viewed search space concept descriptions The hypothesis language determines search space In standard inductive learning algorithms structure search space determined generalizationspecialization operators Algorithms perform locally optimal search using hillclimbing andor beamsearch strategy To overcome limitation concept learning viewed stochastic search space concept descriptions The proposed stochastic search method based simulated annealing known successful means solving combinatorial optimization problems The stochastic search method implemented rule learning system ATRIS based compact efficient representation problem appropriate operators structuring search space Furthermore heuristic pruning search space method enables also handling imperfect data The paper introduces stochastic search method describes ATRIS learning algorithm gives results experiments',\n",
              " 'The increasing availability finelygrained parallel architectures resulted variety evolutionary algorithms EAs population spatially distributed local selection algorithms operate parallel small overlapping neighborhoods The effects design choices regarding particular type local selection algorithm well size shape neighborhood particularly well understood generally tested empirically In paper extend techniques used formally analyze selection methods sequential EAs apply local neighborhood models resulting much clearer understanding effects neighborhood size shape',\n",
              " 'Qualitative probabilistic reasoning Bayesian network often reveals tradeoffs relationships ambiguous due competing qualitative influences We present two techniques combine qualitative numeric probabilistic reasoning resolve tradeoffs inferring qualitative relationship nodes Bayesian network The first approach incrementally marginalizes nodes contribute ambiguous qualitative relationships The second approach evaluates approximate Bayesian networks bounds probability distributions uses bounds determinate qualitative relationships question This approach also incremental algorithm refines state spaces random variables tighter bounds qualitative relationships resolved Both approaches provide systematic methods tradeoff resolution potentially lower computational cost application purely numeric methods',\n",
              " 'A simple powerful modification standard Gaussian distribution studied The variables rectified Gaussian constrained nonnegative enabling use nonconvex energy functions Two multimodal examples competitive cooperative distributions illustrate representational power rectified Gaussian Since cooperative distribution represent translations pattern demonstrates potential rectified Gaussian modeling pattern manifolds',\n",
              " 'This paper appear Neural Computation Abstract We introduce novel fast algorithm Independent Component Analysis used blind source separation feature extraction It shown neural network learning rule transformed txedpoint iteration provides algorithm simple depend userdetned parameters fast converge accurate solution allowed data The algorithm tnds one time nonGaussian independent components regardless probability distributions The computations performed either batch mode semiadaptive manner The convergence algorithm rigorously proven convergence speed shown cubic Some comparisons gradient based algorithms made showing new algorithm usually times faster sometimes giving solution iterations',\n",
              " 'Barlows seminal work minimal entropy codes unsupervised learning reiterated In particular need transmit probability events put practical neuronal framework detecting suspicious events A variant BCM learning rule presented together mathematical results suggesting optimal minimal entropy coding',\n",
              " 'Constructive induction divides problem learning inductive hypothesis two intertwined searches onefor best representation space twofor best hypothesis space In datadriven constructive induction DCI learning system searches better representation space analyzing input examples data The presented datadriven constructive induction method combines AQtype learning algorithm two classes representation space improvement operators constructors destructors The implemented system AQDCI experimentally applied GNP prediction problem using World Bank database The results show decision rules learned AQDCI outperformed rules learned original representation space predictive accuracy rule simplicity',\n",
              " 'Heuristic measures estimating quality attributes mostly assume independence attributes domains strong dependencies attributes performance poor Relief extension ReliefF capable correctly estimating quality attributes classification problems strong dependencies attributes By exploiting local information provided different contexts provide global view We present analysis ReliefF lead us adaptation regression continuous class problems The experiments artificial realworld data sets show Regressional ReliefF correctly estimates quality attributes various conditions used nonmyopic learning regression trees Regressional ReliefF ReliefF provide unified view estimating attribute quality regression classification',\n",
              " 'A new research area Inductive Logic Programming presently emerging While inheriting various positive characteristics parent subjects Logic Programming Machine Learning hoped new area overcome many limitations forebears The background present developments within area discussed various goals aspirations increasing body researchers identified Inductive Logic Programming needs based sound principles Logic Statistics On side statistical justification hypotheses discuss possible relationship Algorithmic Complexity theory ProbablyApproximatelyCorrect PAC Learning In terms logic provide unifying framework Muggleton Buntines Inverse Resolution IR Plotkins Relative Least General Generalisation RLGG rederiving RLGG terms IR This leads discussion feasibility extending RLGG framework allow invention new predicates previously discussed within context IR',\n",
              " 'Bayesian methods applicable complex modeling tasks In review principles Bayesian inference presented applied neural network models Several approximate implementations discussed advantages conventional frequentist model training selection outlined It argued Bayesian methods preferable traditional approaches although empirical evidence still sparse',\n",
              " 'This paper presents efficient algorithm learning Bayesian belief networks databases The algorithm takes database input constructs belief network structure output The construction process based computation mutual information attribute pairs Given data set large enough algorithm generate belief network close underlying model time enjoys time When data set normal DAGFaithful see Section probability distribution algorithm guarantees structure perfect map Pearl underlying dependency model generated To evaluate algorithm present experimental results three versions wellknown ALARM network database attributes records The results show algorithm accurate efficient The proof correctness analysis complexity O N conditional independence CI tests',\n",
              " 'This paper presents efficient algorithm constructing Bayesian belief networks databases The algorithm takes database attributes ordering ie causal attributes attribute appear earlier order input constructs belief network structure output The construction process based computation mutual information attribute pairs Given data set large enough DAGIsomorphic probability distribution algorithm guarantees perfect map underlying dependency tests To evaluate algorithm present experimental results three versions wellknown ALARM network database attributes records The correctness proof analysis computational complexity also presented We also discuss features work relate previous works model generated time enjoys time complexity O N conditional independence CI',\n",
              " 'A novel method regression recently proposed V Vapnik et al The technique called Support Vector Machine SVM well founded mathematical point view seems provide new insight function approximation We implemented SVM tested data base chaotic time series used compare performances different approximation techniques including polynomial rational approximation local polynomial techniques Radial Basis Functions Neural Networks The SVM performs better approaches presented We also study particular time series variability performance respect free parameters SVM',\n",
              " 'The requirement dense interconnect artificial neural network systems led researchers seek highdensity interconnect technologies This paper reports implementation using multichip modules MCMs interconnect medium The specific system described selforganizing parallel dynamic learning model requires dense interconnect technology effective implementation requirement fulfilled exploiting MCM technology The ideas presented paper regarding MCM implementation artificial neural networks versatile adapted apply neural network connectionist models',\n",
              " 'When specializing recursive predicate order exclude set negative examples without excluding set positive examples may possible specialize remove clauses refutation negative example without excluding positive exam ples A previously proposed solution problem apply program transformation order obtain nonrecursive target predicates recursive ones However application method prevents recursive specializations found In work present algorithm spectre ii limited specializing nonrecursive predicates The key idea upon algorithm based enough specialize remove clauses refutations negative examples order obtain correct specializations sometimes necessary specialize clauses appear refutations positive examples In contrast predecessor spectre new algorithm limited specializing clauses defining one predicate may specialize clauses defining multiple predicates Furthermore positive negative examples longer required instances predicate It proven algorithm produces correct specialization positive examples logical consequences original program finite number derivations positive negative examples positive negative examples sequence input clauses refutations',\n",
              " 'program wrt positive negative examples viewed problem pruning SLDtree refutations negative examples refutations positive examples excluded It shown actual pruning performed applying unfolding clause removal The algorithm spectre presented based idea The input algorithm besides logic program positive negative examples computation rule determines shape SLDtree pruned It shown generality resulting specialization dependent computation rule experimental results presented using three different computation rules The experiments indicate computation rule formulated number applications unfolding kept low possible The algorithm uses divideandconquer method also compared covering algorithm The experiments show higher predictive accuracy achieved focus discriminating positive negative examples rather achieving high coverage positive examples',\n",
              " 'Cognitive mapping qualitative decision modeling technique developed twenty years ago political scientists continues see occasional use social science decisionaiding applications In paper I show cognitive maps viewed context recent formalisms qualitative decision modeling latter provide firm semantic foundation facilitate development powerful inference procedures well extensions expressiveness models sort',\n",
              " 'Casebased reasoning systems traditionally used perform highlevel reasoning problem domains adequately described using discrete symbolic representations However many realworld problem domains autonomous robotic navigation better characterized using continuous representations Such problem domains also require continuous performance continuous sensorimotor interaction environment continuous adaptation learning performance task We introduce new method continuous casebased reasoning discuss applied dynamic selection modification acquisition robot behaviors autonomous navigation systems We conclude general discussion casebased reasoning issues addressed work',\n",
              " 'The EastWest Challenge title second international competition machine learning programs organized Fall Donald Michie Stephen Muggleton David Page Ashwin Srinivasan Oxford University The goal competition solve TRAINS problems discover simplest classification rules trainlike structured objects The rule complexity judged Prolog program counted number various components rule expressed Prolog Horn clauses There entries several countries submitted competition The GMU teams entry generated three members AQ family learning programs AQDT INDUCE AQHCI The paper analyses results obtained programs compares obtained learning programs It also presents ideas research inspired competition One ideas challenge machine learning community develop measure knowledge complexity would adequately capture cognitive complexity knowledge A preliminary measure cognitive complexity called Ccomplexity different Prologcomplexity Pcomplexity used competition briefly discussed The authors thank Professors Donald Michie Steve Muggleton David Page Ashwin Srinivasan organizing WestEast Challenge competition machine learning programs provided us stimulating challenge learning programs inspired new ideas improving The authors also thank Nabil Allkharouf Ali Hadjarian help suggestions efforts solve problems posed competition This research conducted Center Machine Learning Inference George Mason University The Centers research supported part Advanced Research Projects Agency Grant No NJ administered Office Naval Research Grant No FJ administered Air Force Office Scientific Research part Office Naval Research Grant No NJ part National Science Foundation Grants No IRI CDA DMI',\n",
              " 'Previous algorithms recovery Bayesianbelief network structures data either highly dependent conditional independence CI tests required ordering nodes supplied user We present algorithm integrates two approaches CI tests used generate ordering nodes database used recover underlying Bayesian network structure using non CI test based method Results evaluation algorithm number databases eg ALARM LED SOYBEAN presented We also discuss algorithm performance issues open problems',\n",
              " 'We propose new criterion model selection prediction problems The covariance inflation criterion adjusts training error average covariance predictions responses prediction rule applied permuted versions dataset This criterion applied general prediction problems example regression classification general prediction rules example stepwise regression treebased models neural nets As byproduct obtain measure effective number parameters used adaptive procedure We relate covariance inflation criterion model selection procedures illustrate use regression classification problems We also revisit conditional bootstrap approach model selection',\n",
              " 'This paper introduces magnetic neural gas MNG algorithm extends unsupervised competitive learning class information improve positioning radial basis functions The basic idea MNG discover heterogeneous clusters ie clusters data different classes migrate additional neurons towards The discovery effected heterogeneity coefficient associated neuron migration guided introducing kind magnetic effect The performance MNG tested number data sets including thyroid data set Results demonstrate promise',\n",
              " 'This research supported National Science Foundation Fellowship awarded Dario Salvucci Office Naval Research grant N awarded John Anderson The views conclusions contained document authors interpreted representing official policies either expressed implied National Science Foundation Office Naval Research United States government',\n",
              " 'Efficient algorithms developed estimating model parameters measured data even presence gross errors In addition point estimates parameters however assessments uncertainty needed Linear approximations provide standard errors misleading applied models substantially nonlinear To overcome difficulty profiling methods developed case regressor variables error free In paper extend profiling methods ErrorinVariableMeasurement EVM models We use Laplaces method integrate incidental parameters associated measurement errors apply profiling methods obtain approximate confidence contours parameters This approach computationally efficient requiring function evaluations applied large scale problems It useful certain measurement errors eg input variables relatively small small ignored',\n",
              " 'A novel architecture set learning rules cortical selforganization proposed The model based idea multiple information channels modulate one anothers plasticity Features learned bottomup information sources thus influenced learned contextual pathways vice versa A maximum likelihood cost function allows scheme implemented biologically feasible hierarchical neural circuit In simulations model first demonstrate utility temporal context modulating plasticity The model learns representation categorizes peoples faces according identity independent viewpoint taking advantage temporal continuity image sequences In second set simulations add plasticity contextual stream explore variations architecture In case model learns twotiered representation starting coarse viewbased clustering proceeding finer clustering specific stimulus features This model provides tenable account people may perform D object recognition hierarchical bottomup fashion',\n",
              " 'The boosting algorithm AdaBoost developed Freund Schapire exhibited outstanding performance several benchmark problems using C weak algorithm boosted Like ensemble learning approaches AdaBoost constructs composite hypothesis voting many individual hypotheses In practice large amount memory required store hypotheses make ensemble methods hard deploy applications This paper shows selecting subset hypotheses possible obtain nearly levels performance entire set The results also provide insight behavior AdaBoost',\n",
              " 'Infusion GABA agonist Reiter Stryker infusion NMDA receptor antagonist Bear et al primary visual cortex kittens monocular deprivation shifts ocular dominance toward closed eye cortical region near infusion site This reverse ocular dominance shift previously modeled variants covariance synaptic plasticity rule Bear et al Clothiaux et al Miller et al Reiter Stryker Kasamatsu et al showed infusion NMDA receptor antagonist adult cat primary visual cortex changes ocular dominance distribution reduces binocularity reduces orientation direction selectivity This paper presents novel account effects pharmacological treatments based EXIN synaptic plasticity rules Marshall include instar afferent excitatory outstar lateral inhibitory rule Functionally EXIN plasticity rules enhance efficiency discrimination contextsensitivity neural networks representation perceptual patterns Marshall Marshall Gupta The EXIN model decreases lateral inhibition neurons outside infusion site control regions neurons inside infusion region monocular deprivation In model plasticity afferent pathways neurons affected pharmacological treatments assumed blocked opposed previous models Bear et al Miller et al Reiter Stryker afferent pathways open eye neurons infusion region weakened The proposed model consistent results suggesting longterm plasticity blocked NMDA antagonists postsynaptic hyperpolarization Bear et al Dudek Bear Goda Stevens Kirkwood et al Since role plasticity lateral inhibitory pathways producing cortical plasticity received much attention several predictions made based EXIN lateral inhibitory plasticity rule',\n",
              " 'We present two algorithms use membership equivalence queries exactly identify concepts given union discretized axisparallel boxes ddimensional discretized Euclidean space coordinate n discrete values The first algorithm receives sd counterexamples uses time membership queries polynomial log n constant Further equivalence queries made formulated union Osd log axisparallel boxes Next introduce new complexity measure better captures complexity union boxes simply number boxes dimensions Our new measure number segments target polyhedron segment maximum portion one sides polyhedron lies entirely inside entirely outside halfspaces defining polyhedron We present improvement first algorithm uses time queries polynomial log n The hypothesis class used decision trees height sd Further show time queries used algorithm polynomial log n constant thus generalizing exact learnability DNF formulas constant number terms In fact single algorithm efficient either constant',\n",
              " 'Approaches combining genetic algorithms neural networks received great deal attention recent years As result much work reported two major areas neural network design training topology optimization This paper focuses key issues associated problem pruning multilayer perceptron using genetic algorithms simulated annealing The study presented considers number aspects associated network training may alter behavior stochastic topology optimizer Enhancements discussed improve topology searches Simulation results two mentioned stochastic optimization methods applied nonlinear system identification presented compared simple random search',\n",
              " 'Local belief propagation rules sort proposed Pearl guaranteed converge optimal beliefs singly connected networks Recently number researchers empirically demonstrated good performance algorithms networks loops theoretical understanding performance yet achieved Here lay foundation understanding belief propagation networks loops For networks single loop derive analytical relationship steady state beliefs loopy network true posterior probability Using relationship show category networks MAP estimate obtained belief update belief revision proven optimal although beliefs incorrect We show nodes use local information messages receive order correct steady state beliefs Furthermore prove networks single loop MAP estimate obtained belief revision convergence guaranteed give globally optimal sequence states The result independent length cycle size state space For networks multiple loops introduce concept balanced network show simulation results comparing belief revision update networks We show Turbo code structure balanced present simulations toy Turbo code problem indicating decoding obtained belief revision convergence significantly likely correct This report describes research done Center Biological Computational Learning Department Brain Cognitive Sciences Massachusetts Institute Technology Support Center provided part grant National Science Foundation contract ASC YW also supported NEI R EY E H Adelson',\n",
              " 'Previous work showed combination Genetic Algorithm using order permutation chromosome combined hand coded Greedy Optimizers readily produce optimal schedule four node test problem Langdon Following GA used find low cost schedules South Wales region UK high voltage power network This paper describes evolution best known schedule base South Wales problem using Genetic Programming starting hand coded heuris tics used GA',\n",
              " 'Search mechanisms artificial intelligence combine two elements representation determines search space search mechanism actually explores space Unfortunately many searches may explore redundant andor invalid solutions Genetic programming refers class evolutionary algorithms based genetic algorithms utilizing parameterized representation form trees These algorithms perform searches based simulation nature They face problems redundantinvalid subspaces These problems recently addressed systematic manner This paper presents methodology devised public domain genetic programming tool lilgp This methodology uses data typing semantic information constrain representation space valid possibly unique solutions explored The user enters problemspecific constraints transformed normal set This set checked feasibility subsequently used limit space explored The constraints determine valid possibly unique space Moreover also used exclude subspaces user considers uninteresting using problemspecific knowledge A simple example followed thoroughly illustrate constraint language transformations normal set Experiments boolean multiplexer illustrate practical applications method limit redundant space exploration utilizing problemspecific knowledge fl Supported grant NASAJSC NAG',\n",
              " 'Knowledge acquisition difficult errorprone timeconsuming task The task automatically improving existing knowledge base using learning methods addressed class systems performing theory refinement This paper presents system Forte FirstOrder Revision Theories Examples refines firstorder Hornclause theories integrating variety different revision techniques coherent whole Forte uses techniques within hillclimbing framework guided global heuristic It identifies possible errors theory calls library operators develop possible revisions The best revision implemented process repeats revisions possible Operators drawn variety sources including propositional theory refinement firstorder induction inverse resolution Forte demonstrated several domains including logic programming qualitative modelling',\n",
              " 'The problem sequence categorization generalize corpus labeled sequences procedures accurately labeling future unlabeled sequences The choice representation sequences major impact task absence background knowledge good representation often known straightforward representations often far optimal We propose feature generation method called FGEN creates Boolean features check presence absence heuristically selected collections subsequences We show empirically representation computed FGEN improves accuracy two commonly used learning systems C Ripper new features added existing representations sequence data We show superiority FGEN across range tasks selected three domains DNA sequences Unix command sequences English text',\n",
              " 'Genetic algorithms one example use random element within algorithm combinatorial optimization We consider application genetic algorithm particular problem Assembly Line Balancing Problem A general description genetic algorithms given specialized use testbed problems discussed We carry extensive computational testing find appropriate values various parameters associated genetic algorithm These experiments underscore importance correct choice scaling parameter mutation rate ensure good performance genetic algorithm We also describe parallel implementation genetic algorithm give comparisons parallel serial implementations Both versions algorithm shown effective producing good solutions problems type appropriately chosen parameters',\n",
              " 'This paper presents application CaseBased Reasoning methods KOSIMO data base international conflicts A CaseBased Reasoning tool VIECBR deveolped used classification various outcome variables like political military territorial outcome solution modalities conflict intensity In addition case retrieval algorithms presented interactive usermodifiable tool intelli gently searching conflict data base precedent cases',\n",
              " 'In order learn behaviour casebased reasoners learning systems formalise simple casebased learner PAC learning algorithm using casebased representation hCB We first consider naive casebased learning algorithm CB H learns collecting available cases casebase calculates similarity counting number features two problem descriptions agree We present results concerning consistency learning algorithm give partial results regarding sample complexity We able characterise CB H weak general learning algorithm We consider sample complexity casebased learning reduced specific classes target concept application inductive bias prior knowledge class target concepts Following recent work demonstrating casebased learning improved choosing similarity measure appropriate concept learnt define second casebased learning algorithm CB learns using best possible similarity measure might inferred chosen target concept While CB executable learning strategy since chosen similarity measure defined terms priori knowledge actual target concept allows us assess limit maximum possible contribution approach casebased learning Also addition illustrating role inductive bias definition CB simplifies general problem establishing functions might represented form hCB Reasoning casebased representation special case therefore little straightforward general case CB H allowing substantial results regarding representable functions sample complexity presented CB In assessing results forced conclude casebased learning best approach learning chosen concept space space monomial functions We discuss however study demonstrated context casebased learning operation concepts well known machine learning inductive bias tradeoff computational complexity sample complexity',\n",
              " 'In past years evolutionary computation landscape rapidly changing result increased levels interaction various research groups injection new ideas challenge old tenets The effect simultaneously exciting invigorating annoying bewildering oldtimers well newcomers field Emerging activity beginnings structure common themes agreement important open issues We attempt summarize emergent properties paper',\n",
              " 'We quantify experimentally analytically performance memorybased reasoning MBR algorithms To start gaining insight capabilities MBR algorithms compare MBR algorithm using value difference metric popular Bayesian classifier These two approaches similar make certain independence assumptions data However whereas MBR uses specific cases perform classification Bayesian methods summarize data probabilistically We demonstrate particular MBR system called Pebls works comparatively well wide range domains using real artificial data With respect artificial data consider distributions concept classes separated functional discriminants well timeseries data generated Markov models varying complexity Finally show formally Pebls learn limit natural concept classes Bayesian classifier learn attain perfect accuracy whenever',\n",
              " 'The Knearestneighbor decision rule assigns object unknown class plurality class among K labeled training objects closest Closeness usually deflned terms metric distance Euclidean space input measurement variables axes The metric chosen deflne distance strongly efiect performance An optimal choice depends problem hand characterized respective class distributions input measurement space within given problem location unknown object space In paper new types Knearestneighbor procedures described estimate local relevance input variable linear combinations individual point classifled This information used separately customize metric used deflne distance object flnding nearest neighbors These procedures hybrid regular Knearestneighbor methods treestructured recursive partitioning techniques popular statistics machine learning',\n",
              " 'Seismic data interpretation problems typically solved using computationally intensive local search methods often result inferior solutions Here traditional hybrid genetic algorithm compared different staged hybrid genetic algorithms geophysical imaging static corrections problem The traditional hybrid genetic algorithm used applied local search every offspring produced genetic search The staged hybrid genetic algorithms designed temporally separate local genetic search components distinct phases minimize interference two search methods The results show staged hybrid genetic algorithms produce higher quality solutions using significantly less computational time problem',\n",
              " 'We describe immune system model based universe binary strings The model directed understanding pattern recognition processes learning take place individual species levels immune system The genetic algorithm GA central component model In paper study behavior GA two pattern recognition problems relevant natural immune systems Finally compare model explicit fitness sharing techniques genetic algorithms show model implements form implicit fitness sharing',\n",
              " 'We present method accurate representation highdimensional unknown functions random samples drawn input space The method builds representations function recursively splitting input space smaller subspaces subspaces linear approximation computed The representations function levels ie depths tree retained learning process good generalisation available well accurate representations subareas Therefore fast accurate learning combined method',\n",
              " 'Several authors made link hidden Markov models time series energybased models Luttrell Williams Saul Jordan Saul Jordan discuss linear Boltzmann chain model statestate transition energies A ii going state state symbol emission energies B ij probability entire state fi l j l g L Whilst HMM written linear Boltzmann chain setting expA ii ii expB ij b ij exp linear Boltzmann chains represented HMMs Saul Jordan However difference two models minimal To precise final hidden state L linear Boltzmann chain constrained particular end state distribution sequences identical hidden Markov model',\n",
              " 'We present coevolutionary approach learning sequential decision rules appears number advantages noncoevolutionary approaches The coevolutionary approach encourages formation stable niches representing simpler subbehaviors The evolutionary direction subbehavior controlled independently providing alternative evolving complex behavior using intermediate training steps Results presented showing significant learning rate speedup noncoevolutionary approach simulated robot domain In addition results suggest coevolutionary approach may lead emer gent problem decompositions',\n",
              " 'Appropriate bias widely viewed key efficient learning generalization I present new algorithm Incremental DeltaBarDelta IDBD algorithm learning appropriate biases based previous learning experience The IDBD algorithm developed case simple linear learning systemthe LMS delta rule separate learningrate parameter input The IDBD algorithm adjusts learningrate parameters important form bias system Because bias approach adapted based previous learning experience appropriate testbeds drifting nonstationary learning tasks For particular tasks type I show IDBD algorithm performs better ordinary LMS fact finds optimal learning rates The IDBD algorithm extends improves prior work Jacobs fully incremental single free parameter This paper also extends previous work presenting derivation IDBD algorithm gradient descent space learningrate parameters Finally I offer novel interpretation IDBD algorithm incremental form holdoneout cross validation',\n",
              " 'Neural network pruning methods level individual network parameters eg connection weights improve generalization An open problem pruning methods known today OBD OBS autoprune epsiprune selection number parameters removed pruning step pruning strength This paper presents pruning method lprune automatically adapts pruning strength evolution weights loss generalization training The method requires algorithm parameter adjustment user The results extensive experimentation indicate lprune often superior autoprune superior OBD diagnosis tasks unless severe pruning early training process required Results statistical significance tests comparing autoprune new method lprune well backpropagation early stopping given different problems',\n",
              " 'ICSIM connectionist net simulator developed ICSI written Sather It objectoriented meet requirements flexibility reuse homogeneous structured connectionist nets allow user encapsulate efficient customized implementations perhaps running dedicated hardware Nets composed combining offtheshelf library classes necessary specializing behaviour General user interface classes allow uniform customized graphic presentation nets modeled',\n",
              " 'In experiencebased casebased reasoning new problems solved retrieving adapting solutions similar problems encountered past An important issue experiencebased reasoning identify different types knowledge reasoning useful different classes caseadaptation tasks In paper examine class nonroutine caseadaptation tasks involve patterned insertions new elements old solutions We describe modelbased method solving task context design physical devices The method uses knowledge generic teleological mechanisms GTMs cascading Old designs adapted meet new functional specifications accessing instantiating appropriate GTM The Kritik system evaluates computational feasibility sufficiency method design adaptation',\n",
              " 'The utility problem learning systems occurs knowledge learned attempt improve systems performance degrades performance instead We present methodology analysis utility problems uses computational models problem solving systems isolate root causes utility problem detect threshold conditions problem arise design strategies eliminate We present models casebased reasoning controlrule learning systems compare performance respect swamping utility problem Our analysis suggests casebased reasoning systems resistant utility problem controlrule learning systems',\n",
              " 'We present model similaritybased retrieval attempts capture three psychological phenomena people extremely good judging similarity analogy given items compare Superficial remindings much frequent structural remindings People sometimes experience use purely structural analogical remindings Our model called MACFAC many called chosen consists two stages The first stage MAC uses computationally cheap nonstructural matcher filter candidates pool memory items That redundantly encode structured representations content vectors whose dot product yields estimate well corresponding structural representations match The second stage FAC uses SME compute true structural match probe output first stage MACFAC fully implemented show capable modeling patterns access found psychological data',\n",
              " 'We present algorithm online learning linear functions optimal within constant factor respect bounds sum squared errors worst case sequence trials The bounds logarithmic number variables Furthermore algorithm shown optimally robust respect noise data within constant factor Key words Machine learning computational learning theory online learning linear functions worstcase loss bounds adaptive filter theory Subject classifications T',\n",
              " 'A fundamental issue casebased reasoning similarity assessment determining similarities differences new retrieved cases Many methods developed comparing input case descriptions cases already memory However success methods depends input case description sufficiently complete reflect important features new situation assured In casebased explanation anomalous events story understanding anomaly arises current situation incompletely understood consequently similarity assessment based matches known current features old cases likely fail gaps current cases description Our solution problem gaps new cases description approach call constructive similarity assessment Constructive similarity assessment treats similarity assessment simple comparison fixed new old cases process deciding types features investigated new situation features borne knowledge added description current case Constructive similarity assessment merely compare new cases old using prior cases guide dynamically carves augmented descriptions new cases memory',\n",
              " 'Much recent research modeling memory processes focused identifying useful indices retrieval strategies support particular memory tasks Another important question concerning memory processes however retrieval criteria learned This paper examines issues involved modeling learning memory search strategies It discusses general requirements appropriate strategy learning presents model memory search strategy learning applied problem retrieving relevant information adapting cases casebased reasoning It discusses implementation model based lessons learned implementation points towards issues directions refining model',\n",
              " 'The problem approximating probability distribution occurs frequently many areas applied mathematics including statistics communication theory machine learning theoretical analysis complex systems neural networks Saul Jordan recently proposed powerful method efficiently approximating probability distributions known structured variational approximations In structured variational approximations exact algorithms probability computation tractable substructures combined variational methods handle interactions substructures make system whole intractable In note I present mathematical result simplify derivation struc tured variational approximations exponential family distributions',\n",
              " 'This paper presents ASOCS adaptive selforganizing concurrent system model massively parallel processing incrementally defined rule systems areas adaptive logic robotics logical inference dynamic control An ASOCS adaptive network composed many simple computing elements operating asynchronously parallel This paper focuses adaptive algorithm AA details architecture learning algorithm It advantages previous ASOCS models simplicity implementability cost An ASOCS operate either data processing mode learning mode During data processing mode ASOCS acts parallel hardware circuit In learning mode rules expressed boolean conjunctions incrementally presented ASOCS All ASOCS learning algorithms incorporate new rule distributed fashion short bounded time',\n",
              " 'This paper describes novel search algorithm called dynamic hill climbing borrows ideas genetic algorithms hill climbing techniques Unlike genetic hill climbing algorithms dynamic hill climbing ability dynamically change coordinate frame course optimization Furthermore algorithm moves coarsegrained search finegrained search function space changing mutation rate uses diversitybased distance metric ensure searches new regions space Dynamic hill climbing empirically compared traditional genetic algorithm using De Jongs wellknown five function test suite shown vastly surpass performance genetic algorithm often finding better solutions using many function evaluations',\n",
              " 'Autonomous vehicles likely require sophisticated software controllers maintain vehicle performance presence vehicle faults The test evaluation complex software controllers expected challenging task The goal e ffort apply machine learning techniques field arti ficial intelligence general problem evaluating intelligent controller autonomous vehicle The approach involves subjecting controller adaptively chosen set fault scenarios within vehicle simulator searching combinations faults produce noteworthy performance vehicle controller The search employs genetic algorithm We illustrate approach evaluating performance subsumptionbased controller autonomous vehicle The preliminary evidence suggests approach e ffective alternative manual testing sophisticated software controllers',\n",
              " 'Speedup learning seeks improve efficiency searchbased problem solvers In paper propose new theoretical model speedup learning captures systems improve problem solving performance solving usergiven set problems We also use model motivate notion batch problem solving argue congenial learning sequential problem solving Our theoretical results applicable serially decomposable domains We empirically validate results domain Eight Puzzle',\n",
              " 'Nonparametric density estimation problem approximating values probability density function given samples associated distribution Nonparametric estimation finds applications discriminant analysis cluster analysis flow calculations based Smoothed Particle Hydrodynamics Usual estimators make use kernel functions require order n arithmetic operations evaluate density n sample points We describe sequence special weight functions requires almost linear number operations n computation',\n",
              " 'In paper consider learning firstorder Horn programs entailment In particular show subclass firstorder acyclic Horn programs constant arity exactly learnable equivalence entailment membership queries provided allows polynomialtime subsumption procedure satisfies closure conditions One consequence firstorder acyclic determinate Horn programs constant arity exactly learnable equiv alence entailment membership queries',\n",
              " 'A strategy using Genetic Algorithms GAs solve NPcomplete problems presented The key aspect approach taken exploit observation although NPcomplete problems equally difficult general computational sense much better GA representations others leading much successful use GAs NPcomplete problems others Since NPcomplete problem mapped one polynomial time strategy described consists identifying canonical NPcomplete problem GAs work well solving NPcomplete problems indirectly mapping onto canonical problem Initial empirical results presented support claim Boolean Satisfiability Problem SAT GAeffective canonical problem NPcomplete problems poor GA representations solved efficiently mapping first onto SAT problems',\n",
              " 'Fully cooperative multiagent systemsthose agents share joint utility modelis special interest AI A key problem ensuring actions individual agents coordinated especially settings agents autonomous decision makers We investigate approaches learning coordinated strategies stochastic domains agents actions directly observable others Much recent work game theory adopted Bayesian learning perspective general problem equilibrium selection tends assume actions observed We discuss special problems arise actions observable including effects rates convergence effect action failure probabilities asymmetries We also use likelihood estimates means generalizing fictitious play learning models setting Finally propose use maximum likelihood means removing strategies consideration aim convergence conventional equilibrium point learning deliberation cease',\n",
              " 'Humans appear often solve problems new domain transferring expertise familiar domain However making crossdomain analogies hard often requires abstractions common source target domains Recent work casebased design suggests generic mechanisms one type abstractions used designers However one important yet unexplored issue generic mechanisms come We hypothesize acquired incrementally problemsolving experiences familiar domains generalization patterns regularity Three important issues generalization experiences generalize experience far generalize methods use In paper show mental models familiar domain provide content together problemsolving context learning occurs also provide constraints learning generic mechanisms design experiences In particular show modelbased learning method integrated similaritybased learning addresses issues generalization experiences',\n",
              " 'The optimization single bit string means iterated mutation selection best Genetic Algorithm discussed respect three simple fitness functions The counting ones problem standard binary encoded integer Gray coded integer optimization problem A mutation rate schedule optimal respect success probability mutation presented objective functions turns standard binary code hamper search process even case unimodal objective functions While normally mutation rate l l denotes bit string length recommendable results indicate variation mutation rate useful cases fitness function multimodal pseudoboolean function multimodality may caused objective function well encoding mechanism',\n",
              " 'Genetic Algorithms used learn navigation collision avoidance behaviors robots The learning performed simulation resulting behaviors used control The approach learning behaviors robots described reflects particular methodology learning via simulation model The motivation making mistakes real systems may costly dangerous In addition time constraints might limit number experiences learning real world many cases simulation model made run faster real time Since learning may require experimenting behaviors might occasionally produce unacceptable results applied real world might require much time real environment assume hypothetical behaviors evaluated simulation model offline system As illustrated Figure current best behavior placed real online system learning continues offline system The learning algorithm designed learn useful behaviors simulations limited fidelity The expectation behaviors learned simulations useful realworld environments Previous studies illustrated knowledge learned simulation robust might applicable real world simulation general ie noise varied conditions etc real world environment Where possible important identify differences simulation world note effect upon learning process The research reported continues examine hypothesis The next section briefly explains learning algorithm gives pointers extensive documentation found After actual robot described Then describe simulation robot The task actual robot',\n",
              " 'Conventional Intelligent Tutoring Systems ITS acknowledge uncertainty students knowledge Yet outcome teaching intervention exact state students knowledge uncertain In recent years researchers made startling progress management uncertainty knowledgebased systems Building developments describe ITS architecture explicitly models uncertainty This facilitate accurate student modeling provide ITSs learn',\n",
              " 'Satisfiability SAT refers task finding truth assignment makes arbitrary boolean expression true This paper compares neural network algorithm NNSAT GSAT greedy algorithm solving satisfiability problems GSAT solve problem instances difficult traditional satisfiability algorithms Results suggest NNSAT scales better number variables increase solving least many hard SAT problems',\n",
              " 'In last years several researchers within Artificial Life Mobile Robotics community used Artificial Neural Networks Explicitly viewing Neural Networks Artificial Life perspective number consequences make research call Artificial Life Neural Networks ALNNs rather different traditional connectionist research The aim paper make differences ALNNs classical neural networks explicit',\n",
              " 'The recognition D objects sequences D views modeled family selforganizing neural architectures called VIEWNET use View Information Encoded With NETworks VIEWNET incorporates preprocessor generates compressed D invariant representation image supervised incremental learning system Fuzzy ARTMAP classifies preprocessed representations D view categories whose outputs combined D invariant object categories working memory makes D object prediction accumulating evidence time D object category nodes multiple D views experienced VIEWNET benchmarked MIT Lincoln Laboratory database x D views aircraft including small frontal views without additive noise A recognition rate achieved one D view correct three D views The properties D view D object category nodes compared cells monkey inferotemporal cortex',\n",
              " 'Recent interest come deriving various neural network architectures modelling timedependent signals A number algorithms published multilayer perceptrons synapses described finite impulse response FIR infinite impulse response IIR filters latter case also known Locally Recurrent Globally Feedforward Networks The derivations algorithms used different approaches calculating gradients note present short unifying account different algorithms compare FIR case derivation performance New algorithms subsequently presented Simulation results performed benchmark algorithms In note results compared MackeyGlass chaotic time series number methods including standard multilayer perceptron local approximation method',\n",
              " 'This paper presents methodology estimate optimal number learning samples number hidden units needed obtain desired accuracy function approximation feedforward network The representation error generalization error components total approximation error analyzed approximation accuracy feedforward network investigated function number hidden units number learning samples Based asymptotical behavior approximation error asymptotical model error function AMEF introduced parameters determined experimentally An alternative model error function include theoretical results general bounds approximation also analyzed In combination knowledge computational complexity learning rule optimal learning set size number hidden units found resulting minimum computation time given desired precision approximation This approach applied optimize learning camerarobot mapping visually guided robot arm complex logarithm function approximation',\n",
              " 'We propose methodology Bayesian model determination decomposable graphical Gaussian models To achieve aim consider hyper inverse Wishart prior distribution concentration matrix given graph To ensure compatibility across models prior distributions obtained marginalisation prior conditional complete graph We explore alternative structures hyperparameters latter consequences model Model determination carried implementing reversible jump MCMC sampler In particular dimensionchanging move propose involves adding dropping edge graph We characterise set moves preserve decomposability graph giving fast algorithm maintaining junction tree representation graph sweep As state variable propose use incomplete variancecovariance matrix containing elements corresponding element inverse nonzero This allows computations performed locally clique level clear advantage analysis large complex datasets Finally statistical computational performance procedure illustrated means artificial real multidimensional datasets',\n",
              " 'An essential component opportunistic behavior opportunity recognition recognition conditions facilitate pursuit suspended goal Opportunity recognition special case situation assessment process sizing novel situation The ability recognize opportunities reinstating suspended problem contexts one way goals manifest design crucial creative design In order deal real world opportunity recognition attribute limited inferential power relevant suspended goals We propose goals suspended working memory monitor internal hidden representations currently recognized objects A suspended goal satisfied current internal representation suspended goal match We propose computational model working memory compare relevant theories opportunistic planning This working memory model implemented part IMPROVISER system',\n",
              " 'Technical Report UMIACSTR CSTR Institute Advanced Computer Studies University Maryland College Park MD Abstract One important aspects machine learning paradigm scales according problem size complexity Using task known optimal training error prespecified maximum number training updates investigate convergence backpropagation algorithm respect complexity required function approximation b size network relation size required optimal solution c degree noise training data In general solution found worse function approximated complex b oversized networks result lower training generalization error certain cases c use committee ensemble techniques beneficial level noise training data increased For experiments performed obtain optimal solution case We support observation larger networks produce better training generalization error using face recognition example network many parameters training points generalizes better smaller networks',\n",
              " 'For many reasons neural networks become popular AI machine learning models Two important aspects machine learning models well model generalizes unseen data well model scales problem complexity Using controlled task known optimal training error investigate convergence backpropagation BP algorithm We find optimal solution typically found Furthermore observe networks larger might expected result lower training generalization error This result supported another real world example We investigate training behavior analyzing weights trained networks excess degrees freedom seen little harm aid convergence contrasting interpolation characteristics multilayer perceptron neural networks MLPs polynomial models overfitting behavior different MLP often biased towards smoother solutions Finally analyze relevant theory outlining reasons significant practical differences These results bring question common beliefs neural network training regarding convergence optimal network size suggest alternate guidelines practical use lower fear excess degrees freedom help direct future work eg methods creation parsimonious solutions importance MLPBP bias possibly worse performance improved training algorithms',\n",
              " 'This paper presents novel induction algorithm Rulearner induces classification rules using Galois lattice explicit map search space rules The Rulearner system shown compare favorably commonly used symbolic learning methods use heuristics rather explicit map guide search rule space Furthermore learning system shown robust presence noisy data The Rulearner system also capable learning decision lists unordered rule sets allowing comparisons different learning paradigms within algorithmic framework',\n",
              " 'Keywords CaseBased Reasoning case retrieval case representation This paper deals retrieval useful cases casebased reasoning It focuses questions useful could mean search useful cases organized We present new search algorithm Fish Shrink able search quickly case base even aspects deflne usefulness spontaneously combined query time We compare Fish Shrink algorithms show make implicit closed world assumption We flnally refer realization presented idea context prototype FABELProject The scenery follows Previously collected cases stored large scaled case base An expert describes problem gives aspects requested case similar The similarity measure thus given spontaneously shall used explore case base within short time shall present required number cases make sure none cases similar The question prepare previously collected cases deflne retrieval algorithm able deal sponta neously userdeflned similarity measures',\n",
              " 'The parallel genetic algorithm PGA uses two major modifications compared genetic algorithm Firstly selection mating distributed Individuals live D world Selection mate done individual independently neighborhood Secondly individual may improve fitness lifetime eg local hillclimbing The PGA totally asynchronous running maximal efficiency MIMD parallel computers The search strategy PGA based small number active intelligent individuals whereas GA uses large population passive individuals We investigate PGA deceptive problems traveling salesman problem We outline PGA succesful Abstractly PGA parallel search information exchange individuals If represent optimization problem fitness landscape certain configuration space see PGA tries jump two local minima third still better local minima using crossover operator This jump probabilistically successful fitness landscape certain correlation We show correlation traveling salesman problem configuration space analysis The PGA explores implicitly correlation',\n",
              " 'The dominant theme casebased research recent ML conferences classifying cases represented feature vectors However useful tasks targeted representations often preferable We review recent literature casebased learning focusing alternative performance tasks expressive case representations We also highlight topics need additional research',\n",
              " 'Current approaches computational lexicology language technology knowledgebased competenceoriented try abstract away specific formalisms domains applications This results severe complexity acquisition reusability bottlenecks As alternative propose particular performanceoriented approach Natural Language Processing based automatic memorybased learning linguistic lexical tasks The consequences approach computational lexicology discussed application approach number lexical acquisition disambiguation tasks phonology morphology syntax described',\n",
              " 'Let H function explicitly defined approximable sequence H n n functional estimators In context propose new sequential algorithm optimise asymptotically H using stepwise estimators H n We prove mild conditions almost sure convergence law algorithm',\n",
              " 'In paper study new informationtheoretically justified approach missing data estimation multivariate categorical data The approach discussed modelbased imputation procedure relative model class ie functional form probability distribution complete data matrix case set multinomial models independence assumptions Based given model class assumption informationtheoretic criterion derived select different complete data matrices Intuitively general criterion called stochastic complexity represents shortest code length needed coding complete data matrix relative model class chosen Using informationtheoretic criteria missing data problem reduced search problem ie finding data completion minimal stochastic complexity In experimental part paper present empirical results approach using two real data sets compare results achived commonly used techniques case deletion imputating sample averages',\n",
              " 'We present paper new evolutionary procedure solving general optimization problems combines efficiently mechanisms genetic algorithms tabu search In order explore solution space properly interaction phases interspersed periods optimization algorithm An adaptation search principle National Hockey League NHL problem discussed The hybrid method developed paper well suited Open Shop Scheduling problems OSSP The results obtained appear quite satisfactory',\n",
              " 'Behavioural observations often described sequence symbols drawn finite alphabet However inductive inference strings automated technique produce models data nontrivial task This paper considers modelling behavioural data using probabilistic finite state automata PFSAs There number informationtheoretic techniques evaluating possible hypotheses The measure used paper Minimum Message Length MML Wallace Although attempts made construct PFSA models incremental addition substrings using heuristic rules MML give lowest information cost resultant models shown globally optimal Fogels Evolutionary Programming produce globally optimal PFSA models evolving data structures arbitrary complexity without requirement encode PFSA binary strings Genetic Algorithms However evaluation PFSAs evolution process MML PFSA alone possible since symbols consumed partially correct solution It suggested addition cant consume symbol symbol alphabet obviates difficulty The addition null symbol alphabet also permits evolution explanatory models need explain data useful property avoid overfitting noisy data Results given test set optimal pfsa model known set eye glance data derived instrument panel simulator',\n",
              " 'Technical Report CUEDFINFENGTR We use reversible jump Markov chain Monte Carlo MCMC methods Green address problem model order uncertainty autoregressive AR time series within Bayesian framework Efficient model jumping achieved proposing model space moves full conditional density AR parameters obtained analytically This compared alternative method moves cheaper compute proposals made new parameters move Results presented synthetic audio time series',\n",
              " 'Learning viewed problem planning series modifications memory We adopt view learning propose applicability casebased planning methodology task planning learn We argue relatively simple finegrained primitive inferential operators needed support flexible planning We show possible obtain benefits casebased reasoning within planning learn framework',\n",
              " 'V SCBR simple instancebased learning algorithm adjusts weighted similarity measure well collecting cases This paper presents PAC analysis V SCBR motivated PAC learning framework demonstrates two main ideas relevant study instancebased learners Firstly hypothesis spaces learner different target concepts compared predict difficulty target concepts learner Secondly helpful consider constituent parts instancebased learner explore separately many examples needed infer good similarity measure many examples needed case base Applying approaches show V SCBR learns quickly variables representation irrelevant target concept slowly relevant variables The paper relates overall behaviour behaviour constituent parts V SCBR',\n",
              " 'Partial determinations interesting form dependency attributes relation They generalize functional dependencies allowing exceptions We modify known MDL formula evaluating partial determinations allow use admissible heuristic exhaustive search Furthermore describe efficient preprocessingbased approach handling numerical attributes An empirical investigation tries evaluate viability presented ideas',\n",
              " 'The induction optimal finite state machine explanation symbol strings known least NPcomplete However satisfactory approximately optimal explanations may found use Evolutionary Programming It shown information theoretic measure finite state machine explanations used fitness function required evaluation candidate explanations search nearoptimal explanation It obvious measure class explanation favoured others search By empirical studies possible gain insight dimensions measure optimising In general probabilistic finite state machines explanations assessed minimum message length estimator minimum number transitions favoured explanations The information measure also favour explanations uneven distributions frequencies transitions node suggesting repeated sequences symbol strings preferred explanation Approximate bounds acceptance explanations length string required induction successful also derived considerations simplest possible random explanations information measure',\n",
              " 'How evolutionary process interact decentralized distributed system order produce globally coordinated behavior Using genetic algorithm GA evolve cellular automata CAs show evolution spontaneous synchronization one type emergent coordination takes advantage underlying mediums potential form embedded particles The particles typically phase defects synchronous regions designed evolutionary process resolve frustrations global phase We describe detail one typical solution discovered GA delineating discovered synchronization algorithm terms embedded particles interactions We also use particlelevel description analyze evolutionary sequence solution discovered Our results implications understanding emergent collective behavior natural systems automatic programming decentralized spatially extended multiprocessor systems',\n",
              " 'We prove general bootstrap theorem possibly infinitedimensional Zestimators builds recent infinitedimensional Ztheorem due Van der Vaart Our result extends finitedimensional results type bootstrap due Arcones Gine Lele Newton Raftery We sketch three examples models infinitedimensional parameter spaces fi applicatons general theorem',\n",
              " 'The prediction survival time recurrence time important learning problem medical domains The Recurrence Surface Approximation RSA method natural effective method predicting recurrence times using censored input data This paper introduces Survival Curve RSA SCRSA extension RSA approach produces accurate predicted rates recurrence maintaining accuracy individual predicted recurrence times The method applied problem breast cancer recurrence using two different datasets',\n",
              " 'We analyze query committee algorithm method filtering informative queries random stream inputs We show twomember committee algorithm achieves information gain positive lower bound prediction error decreases exponentially number queries We show particular exponential decrease holds query learning perceptrons Keywords selective sampling query learning Bayesian Learning experimental design fl Yoav Freund Room B ATT Bell Laboratories Mountain Ave Murray Hill NJ Telephone',\n",
              " 'A new method performing nonlinear form Principal Component Analysis proposed By use integral operator kernel functions one efficiently compute principal components highdimensional feature spaces related input space nonlinear map instance space possible pixel products fi images We give derivation method present first experimental results polynomial feature extraction pattern recognition',\n",
              " 'Modeling techniques developed recently AI uncertain reasoning communities permit significantly flexible specifications probabilistic knowledge Specifically graphical decisionmodeling formalismsbelief networks influence diagrams variantsprovide compact representation probabilistic relationships support inference algorithms automatically exploit dependence structure models These advances brought resurgence interest computational decision systems based normative theories belief preference However graphical decisionmodeling languages still quite limited purposes knowledge representation describe relationships among particular event instances capture general knowledge probabilistic relationships across classes events The inability capture general knowledge serious impediment AI tasks relevant factors decision problem enumerated advance A graphical decision model encodes particular set probabilistic dependencies predefined set decision alternatives specific mathematical form utility function Given properly specified model exist relatively efficient algorithms calculating posterior probabilities optimal decision policies A range similar cases may handled parametric variations original model However structure dependencies set available alternatives form utility function changes situation situation fixed network representation longer adequate An ideal computational decision system would possess general broad knowledge domain would ability reason particular circumstances given decision problem within domain One obvious approachwhich call call knowledgebased model construction KBMCis generate decision model dynamically runtime based problem description information received thus far Model construction consists selection instantiation assembly causal associational relationships broad knowledge base general relationships among domain concepts For example suppose wish develop system recommend appropriate actions maintaining computer network The natural graphical decision model would include chance',\n",
              " 'Determining conditions given learning algorithm appropriate open problem machine learning Methods selecting learning algorithm given domain met limited success This paper proposes new approach predicting given examples class locating example space choosing best learners region example space make predictions The regions example space defined prediction patterns learners used The learners chosen prediction selected according past performance region This dynamic approach learning algorithm selection compared methods selecting multiple learning algorithms The approach extended weight rather select algorithms according past performance given region Both approaches evaluated set Determining conditions given learning algorithm appropriate open problem machine learning Methods selecting learning algorithm given domain eg Aha Breiman portion domain Brodley Brodley met limited success This paper proposes new approach dynamically selects learning algorithm example locating example space choosing best learners prediction part example space The regions example space formed observed prediction patterns learners used The learners chosen prediction selected according past performance region defined crossvalidation history This paper introduces DS method dynamic selection learning algorithms We call dynamic learning algorithms used classify novel example depends example Preliminary experimentation motivated DW extension DS dynamically weights learners predictions according regional accuracy Further experimentation compares DS DW collection metalearning strategies crossvalidation Breiman various forms stacking Wolpert In phase experiementation metalearners six constituent learners heterogeneous search representation methods eg rule learner CN Clark decision tree learner C Quinlan oblique decision tree learner OC Murthy instancebased learner PEBLS Cost knearest neighbor learner ten domains compared several metalearning strategies',\n",
              " 'Tw important issues machine learning explored role memory plays acquiring new concepts extent learner take active part acquiring concepts This chapter describes program called Marvin uses concepts learned previously learn new concepts The program forms hypotheses concept learned tests hypotheses asking trainer questions Learning begins trainer shows Marvin example concept learned The program determines objects example belong concepts stored memory A description new concept formed using information obtained memory generalize description training example The generalized description tested program constructs new examples shows trainer asking belong target concept',\n",
              " 'Adaptation ecological systems environments commonly viewed explicit fitness function defined priori experimenter measured posteriori estimations based population size andor reproductive rates These methods capture role environmental complexity shaping selective pressures control adaptive process Ecological simulations enabled computational tools Latent Energy Environments LEE model allow us characterize closely effects environmental complexity evolution adaptive behaviors LEE described paper Its motivation arises need vary complexity controlled predictable ways without assuming relationship changes adaptive behaviors engender This goal achieved careful characterization environments different forms energy welldefined A genetic algorithm using endogenous fitness local selection used model evolutionary process Individuals population modeled neural networks simple sensorymotor systems variations behaviors related interactions varying environments We outline results three experiments analyze different sources environmental complexity effects collective behaviors evolving populations',\n",
              " 'In paper investigate efficiency subsumption basic provability relation ILP As D C NPcomplete even restrict linked Horn clauses fix C contain small constant number literals investigate several restrictions D We first adapt notion determinate clauses used ILP show subsumption decidable polynomial time D determinate respect C Secondly adapt notion klocal Horn clauses show subsumption efficiently computable reasonably small k We show results combined give efficient reasoning procedure determinate klocal Horn clauses ILPproblem recently suggested polynomial predictable Cohen simple counting argument We finally outline reduction algorithm essential part every lgg ILPlearning algorithm im proved ideas',\n",
              " 'BBN Technical Report Abstract Genetic programming powerful method automatically generating computer programs via process natural selection Koza However limitation known closure ie variables constants arguments functions values returned functions must data type To correct deficiency introduce variation genetic programming called strongly typed genetic programming STGP In STGP variables constants arguments returned values data type provision data type value specified beforehand This allows initialization process genetic operators generate syntactically correct parse trees Key concepts STGP generic functions true strongly typed functions rather templates classes functions generic data types analogous To illustrate STGP present four examples involving vectormatrix manipulation list manipulation multidimensional leastsquares regression problem multidimensional Kalman filter list manipulation function NTH list manipulation function MAPCAR',\n",
              " 'Category algorithms architectures recurrent networks No part paper submitted elsewhere Preference poster Abstract Existing proofs demonstrating computational limitations Recurrent Cascade Correlation RCC Network Fahlman explicitly limit results units sigmoidal hardthreshold transfer functions Giles et al Kremer The proof given shows given finite discrete deterministic transfer function used units RCC network finitestate automata FSA network model matter many units used The proof applies equally well continuous transfer functions finite number fixedpoints sigmoid function',\n",
              " 'subsumption decidable incomplete approximation logic implication important inductive logic programming theorem proving We show context based elimination possible matches certain superset determinate clauses tested subsumption polynomial time We discuss relation subsumption clique problem showing particular using additional prior knowledge substitution space small fraction search space identified possibly containing globally consistent solutions leads effective pruning rule We present empirical results demonstrating combination approaches provides extreme reduction computational effort',\n",
              " 'We introduce new algorithm designed learn sparse perceptrons input representations include highorder features Our algorithm based hypothesisboosting method able PAClearn relatively natural class target concepts Moreover algorithm appears work well practice set three problem domains algorithm produces classifiers utilize small numbers features yet exhibit good generalization performance Perhaps importantly algorithm generates concept descriptions easy humans understand',\n",
              " 'Current inductive machine learning algorithms typically use greedy search limited lookahead This prevents detect significant conditional dependencies attributes describe training objects Instead myopic impurity functions lookahead propose use RELIEFF extension RELIEF developed Kira Rendell heuristic guidance inductive learning algorithms We reimplemented Assistant system top induction decision trees using RELIEFF estimator attributes selection step The algorithm tested several artificial several real world problems results compared well known machine learning algorithms Excellent results artificial data sets two real world problems show advantage presented approach inductive learning',\n",
              " 'This paper presents new approach hierarchical reinforcement learning based MAXQ decomposition value function The MAXQ decomposition procedural semanticsas subroutine hierarchyand declarative semanticsas representation value function hierarchical policy MAXQ unifies extends previous work hierarchical reinforcement learning Singh Kaelbling Dayan Hinton Conditions MAXQ decomposition represent optimal value function derived The paper defines hierarchical Q learning algorithm proves convergence shows experimentally learn much faster ordinary flat Q learning Finally paper discusses interesting issues arise hierarchical reinforcement learning including hierarchical credit assignment problem nonhierarchical execution MAXQ hierarchy',\n",
              " 'Causality relates changes structure object effects changes changes properties behavior object This paper analyzes concept causality Genetic Programming GP suggests used adapting control parameters speeding GP search We first analyze effects crossover show weak causality GP representation operators Hierarchical GP approaches based discovery evolution functions amplify phenomenon However selection gradually retains strongly causal changes Causality correlated search space exploitation discussed context explorationexploitation tradeoff The results described argue bottomup GP evolutionary thesis Finally new developments based idea GP architecture evolution Koza discussed causality perspective',\n",
              " 'Methods voting classification algorithms Bagging AdaBoost shown successful improving accuracy certain classifiers artificial realworld datasets We review algorithms describe large empirical study comparing several variants conjunction decision tree inducer three variants NaiveBayes inducer The purpose study improve understanding algorithms use perturbation reweighting combination techniques affect classification error We provide bias variance decomposition error show different methods variants influence two terms This allowed us determine Bagging reduced variance unstable methods boosting methods AdaBoost Arcx reduced bias variance unstable methods increased variance NaiveBayes stable We observed Arcx behaves differently AdaBoost reweighting used instead resampling indicating fundamental difference Voting variants introduced paper include pruning versus pruning use probabilistic estimates weight perturbations Wagging backfitting data We found Bagging improves probabilistic estimates conjunction nopruning used well data backfit We measure tree sizes show interesting positive correlation increase average tree size AdaBoost trials success reducing error We compare meansquared error voting methods nonvoting methods show voting methods lead large significant reductions meansquared errors Practical problems arise implementing boosting algorithms explored including numerical instabilities underflows We use scatterplots graphically show AdaBoost reweights instances emphasizing hard areas also outliers noise',\n",
              " 'The longterm goal field creation understanding intelligence Productive research AI practical theoretical benefits notion intelligence precise enough allow cumulative development robust systems general results The concept rational agency long considered leading candidate fulfill role This paper outlines gradual evolution formal conception rationality brings closer informal conception intelligence simultaneously reduces gap theory practice Some directions future research indicated',\n",
              " 'A solution problem representing compositional structure using distributed representations described The method uses circular convolution associate items represented vectors Arbitrary variable bindings short sequences various lengths frames reduced representations compressed fixed width vector These representations items right used constructing compositional structures The noisy reconstructions given convolution memories cleaned using separate associative memory good reconstructive properties',\n",
              " 'based Angluins L fl algorithm The algorithm maintains model consistent past examples When new counterexample arrives tries extend model minimal fashion We conducted set experiments random automata represent different strategies generated algorithm tried learn based prefixclosed samples behavior The algorithm managed learn compact models agree samples The size sample small effect size model The experimental results suggest random prefixclosed samples algorithm behaves well However following Angluins result difficulty learning almost uniform complete samples Angluin obvious algorithm solve complexity issue inferring DFA general prefixclosed sample We currently looking classes prefixclosed samples USL behaves well Carmel Markovitch D Carmel S Markovitch The M algorithm Incorporating opponent models adversary search Technical Report CIS report Technion March Carmel Markovitch D Carmel S Markovitch Unsupervised learning finite automata A practical approach Technical Report CIS report Technion March Shoham Tennenholtz Y Shoham M Tennenholtz CoLearning evolution social activity Technical Report STANCSTR Stanford Univrsity Department Computer Science',\n",
              " ...]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abstracts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgxu2eshOT1q"
      },
      "source": [
        "# ***Keyword Extraction***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXgJlJClOT1q"
      },
      "source": [
        "## RAKE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd5QomKtOT1q"
      },
      "outputs": [],
      "source": [
        "# Readability type definitions.\n",
        "Word = str\n",
        "Sentence = str\n",
        "Phrase = Tuple[str, ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz_BL9kQOT1r"
      },
      "outputs": [],
      "source": [
        "class Metric(Enum):\n",
        "    \"\"\"Different metrics that can be used for ranking.\"\"\"\n",
        "\n",
        "    DEGREE_TO_FREQUENCY_RATIO = 0  # Uses d(w)/f(w) as the metric\n",
        "    WORD_DEGREE = 1  # Uses d(w) alone as the metric\n",
        "    WORD_FREQUENCY = 2  # Uses f(w) alone as the metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGtM4ZT7OT1r"
      },
      "outputs": [],
      "source": [
        "class Rake:\n",
        "    \"\"\"Rapid Automatic Keyword Extraction Algorithm.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        stopwords: Optional[Set[str]] = None,\n",
        "        punctuations: Optional[Set[str]] = None,\n",
        "        language: str = 'english',\n",
        "        ranking_metric: Metric = Metric.DEGREE_TO_FREQUENCY_RATIO,\n",
        "        max_length: int = 100000,\n",
        "        min_length: int = 1,\n",
        "        include_repeated_phrases: bool = True,\n",
        "        sentence_tokenizer: Optional[Callable[[str], List[str]]] = None,\n",
        "        word_tokenizer: Optional[Callable[[str], List[str]]] = None\n",
        "    ):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        :param stopwords: Words to be ignored for keyword extraction.\n",
        "        :param punctuations: Punctuations to be ignored for keyword extraction.\n",
        "        :param language: Language to be used for stopwords.\n",
        "        :param max_length: Maximum limit on the number of words in a phrase\n",
        "                           (Inclusive. Defaults to 100000)\n",
        "        :param min_length: Minimum limit on the number of words in a phrase\n",
        "                           (Inclusive. Defaults to 1)\n",
        "        :param include_repeated_phrases: If phrases repeat in phrase list consider\n",
        "                            them as is without dropping any phrases for future\n",
        "                            calculations. (Defaults to True) Ex: \"Magic systems is\n",
        "                            a company. Magic systems was founded by Raul\".\n",
        "\n",
        "                            If repeated phrases are allowed phrase list would be\n",
        "                            [\n",
        "                                (magic, systems), (company,), (magic, systems),\n",
        "                                (founded,), (raul,)\n",
        "                            ]\n",
        "\n",
        "                            If they aren't allowed phrase list would be\n",
        "                            [\n",
        "                                (magic, systems), (company,),\n",
        "                                (founded,), (raul,)\n",
        "                            ]\n",
        "        :param sentence_tokenizer: Tokenizer used to tokenize the text string into sentences.\n",
        "        :param word_tokenizer: Tokenizer used to tokenize the sentence string into words.\n",
        "        \"\"\"\n",
        "\n",
        "        # By default use degree to frequency ratio as the metric.\n",
        "        if isinstance(ranking_metric, Metric):\n",
        "            self.metric = ranking_metric\n",
        "        else:\n",
        "            self.metric = Metric.DEGREE_TO_FREQUENCY_RATIO\n",
        "\n",
        "        # If stopwords not provided we use language stopwords by default.\n",
        "        self.stopwords: Set[str]\n",
        "        if stopwords:\n",
        "            self.stopwords = stopwords\n",
        "        else:\n",
        "            self.stopwords = set(nltk.corpus.stopwords.words(language))\n",
        "\n",
        "        # If punctuations are not provided we ignore all punctuation symbols.\n",
        "        self.punctuations: Set[str]\n",
        "        if punctuations:\n",
        "            self.punctuations = punctuations\n",
        "        else:\n",
        "            self.punctuations = set(string.punctuation)\n",
        "\n",
        "        # All things which act as sentence breaks during keyword extraction.\n",
        "        self.to_ignore: Set[str] = set(chain(self.stopwords, self.punctuations))\n",
        "\n",
        "        # Assign min or max length to the attributes\n",
        "        self.min_length: int = min_length\n",
        "        self.max_length: int = max_length\n",
        "\n",
        "        # Whether we should include repeated phreases in the computation or not.\n",
        "        self.include_repeated_phrases: bool = include_repeated_phrases\n",
        "\n",
        "        # Tokenizers.\n",
        "        self.sentence_tokenizer: Callable[[str], List[str]]\n",
        "        if sentence_tokenizer:\n",
        "            self.sentence_tokenizer = sentence_tokenizer\n",
        "        else:\n",
        "            self.sentence_tokenizer = nltk.tokenize.sent_tokenize\n",
        "\n",
        "        self.word_tokenizer: Callable[[str], List[str]]\n",
        "        if word_tokenizer:\n",
        "            self.word_tokenizer = word_tokenizer\n",
        "        else:\n",
        "            self.word_tokenizer = nltk.tokenize.wordpunct_tokenize\n",
        "\n",
        "        # Stuff to be extracted from the provided text.\n",
        "        self.frequency_dist: Dict[Word, int]\n",
        "        self.degree: Dict[Word, int]\n",
        "        self.rank_list: List[Tuple[float, Sentence]]\n",
        "        self.ranked_phrases: List[Sentence]\n",
        "\n",
        "    def extract_keywords_from_text(self, text: str):\n",
        "        \"\"\"Method to extract keywords from the text provided.\n",
        "\n",
        "        :param text: Text to extract keywords from, provided as a string.\n",
        "        \"\"\"\n",
        "        sentences: List[Sentence] = self._tokenize_text_to_sentences(text)\n",
        "        self.extract_keywords_from_sentences(sentences)\n",
        "\n",
        "\n",
        "    def extract_keywords_from_sentences(self, sentences: List[Sentence]):\n",
        "        \"\"\"Method to extract keywords from the list of sentences provided.\n",
        "\n",
        "        :param sentences: Text to extraxt keywords from, provided as a list\n",
        "                          of strings, where each string is a sentence.\n",
        "        \"\"\"\n",
        "        phrase_list: List[Phrase] = self._generate_phrases(sentences)\n",
        "        self._build_frequency_dist(phrase_list)\n",
        "        self._build_word_co_occurance_graph(phrase_list)\n",
        "        self._build_ranklist(phrase_list)\n",
        "\n",
        "\n",
        "    def get_ranked_phrases(self) -> List[Sentence]:\n",
        "        \"\"\"Method to fetch ranked keyword strings.\n",
        "\n",
        "        :return: List of strings where each string represents an extracted\n",
        "                 keyword string.\n",
        "        \"\"\"\n",
        "        return self.ranked_phrases\n",
        "\n",
        "\n",
        "    def get_ranked_phrases_with_scores(self) -> List[Tuple[float, Sentence]]:\n",
        "        \"\"\"Method to fetch ranked keyword strings along with their scores.\n",
        "\n",
        "        :return: List of tuples where each tuple is formed of an extracted\n",
        "                 keyword string and its score. Ex: (5.68, 'Four Scoures')\n",
        "        \"\"\"\n",
        "        return self.rank_list\n",
        "\n",
        "\n",
        "    def get_word_frequency_distribution(self) -> Dict[Word, int]:\n",
        "        \"\"\"Method to fetch the word frequency distribution in the given text.\n",
        "\n",
        "        :return: Dictionary (defaultdict) of the format `word -> frequency`.\n",
        "        \"\"\"\n",
        "        return self.frequency_dist\n",
        "\n",
        "\n",
        "    def get_word_degrees(self) -> Dict[Word, int]:\n",
        "        \"\"\"Method to fetch the degree of words in the given text. Degree can be\n",
        "        defined as sum of co-occurances of the word with other words in the\n",
        "        given text.\n",
        "\n",
        "        :return: Dictionary (defaultdict) of the format `word -> degree`.\n",
        "        \"\"\"\n",
        "        return self.degree\n",
        "\n",
        "\n",
        "    def _tokenize_text_to_sentences(self, text: str) -> List[Sentence]:\n",
        "        \"\"\"Tokenizes the given text string into sentences using the configured\n",
        "        sentence tokenizer. Configuration uses `nltk.tokenize.sent_tokenize`\n",
        "        by default.\n",
        "\n",
        "        :param text: String text to tokenize into sentences.\n",
        "        :return: List of sentences as per the tokenizer used.\n",
        "        \"\"\"\n",
        "        return self.sentence_tokenizer(text)\n",
        "\n",
        "    def _tokenize_sentence_to_words(self, sentence: Sentence) -> List[Word]:\n",
        "        \"\"\"Tokenizes the given sentence string into words using the configured\n",
        "        word tokenizer. Configuration uses `nltk.tokenize.wordpunct_tokenize`\n",
        "        by default.\n",
        "\n",
        "        :param sentence: String sentence to tokenize into words.\n",
        "        :return: List of words as per the tokenizer used.\n",
        "        \"\"\"\n",
        "        return self.word_tokenizer(sentence)\n",
        "\n",
        "    def _build_frequency_dist(self, phrase_list: List[Phrase]) -> None:\n",
        "        \"\"\"Builds frequency distribution of the words in the given body of text.\n",
        "\n",
        "        :param phrase_list: List of List of strings where each sublist is a\n",
        "                            collection of words which form a contender phrase.\n",
        "        \"\"\"\n",
        "        self.frequency_dist = Counter(chain.from_iterable(phrase_list))\n",
        "\n",
        "    def _build_word_co_occurance_graph(self, phrase_list: List[Phrase]) -> None:\n",
        "        \"\"\"Builds the co-occurance graph of words in the given body of text to\n",
        "        compute degree of each word.\n",
        "\n",
        "        :param phrase_list: List of List of strings where each sublist is a\n",
        "                            collection of words which form a contender phrase.\n",
        "        \"\"\"\n",
        "        co_occurance_graph: DefaultDict[Word, DefaultDict[Word, int]] = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        for phrase in phrase_list:\n",
        "            # For each phrase in the phrase list, count co-occurances of the\n",
        "            # word with other words in the phrase.\n",
        "            #\n",
        "            # Note: Keep the co-occurances graph as is, to help facilitate its\n",
        "            # use in other creative ways if required later.\n",
        "            for (word, coword) in product(phrase, phrase):\n",
        "                co_occurance_graph[word][coword] += 1\n",
        "\n",
        "        # Print the co-occurance_graph\n",
        "        \"\"\"\n",
        "        for word, co_words in co_occurance_graph.items():\n",
        "            print(f\"{word}:\")\n",
        "            for co_word, count in co_words.items():\n",
        "                print(f\"  {co_word}: {count}\")\n",
        "            print(\"=\" * 30)\n",
        "        \"\"\"\n",
        "        self.degree = defaultdict(lambda: 0)\n",
        "        for key in co_occurance_graph:\n",
        "            self.degree[key] = sum(co_occurance_graph[key].values())\n",
        "\n",
        "\n",
        "    def _build_ranklist(self, phrase_list: List[Phrase]):\n",
        "        \"\"\"Method to rank each contender phrase using the formula\n",
        "\n",
        "              phrase_score = sum of scores of words in the phrase.\n",
        "              word_score = d(w) or f(w) or d(w)/f(w) where d is degree\n",
        "                           and f is frequency.\n",
        "\n",
        "        :param phrase_list: List of List of strings where each sublist is a\n",
        "                            collection of words which form a contender phrase.\n",
        "        \"\"\"\n",
        "\n",
        "        self.rank_list = []\n",
        "        for phrase in phrase_list:\n",
        "            rank = 0.0\n",
        "            for word in phrase:\n",
        "                if self.metric == Metric.DEGREE_TO_FREQUENCY_RATIO:\n",
        "                    rank += 1.0 * self.degree[word] / self.frequency_dist[word]\n",
        "                elif self.metric == Metric.WORD_DEGREE:\n",
        "                    rank += 1.0 * self.degree[word]\n",
        "                else:\n",
        "                    rank += 1.0 * self.frequency_dist[word]\n",
        "            self.rank_list.append((rank, ' '.join(phrase)))\n",
        "        self.rank_list.sort(reverse=True)\n",
        "        self.ranked_phrases = [ph[1] for ph in self.rank_list]\n",
        "\n",
        "\n",
        "    # ==========================================================================\n",
        "    def _generate_phrases(self, sentences: List[Sentence]) -> List[Phrase]:\n",
        "        \"\"\"Method to generate contender phrases given the sentences of the text\n",
        "        document.\n",
        "\n",
        "        :param sentences: List of strings where each string represents a\n",
        "                          sentence which forms the text.\n",
        "        :return: Set of string tuples where each tuple is a collection\n",
        "                 of words forming a contender phrase.\n",
        "        \"\"\"\n",
        "        phrase_list: List[Phrase] = []\n",
        "        # Create contender phrases from sentences.\n",
        "        for sentence in sentences:\n",
        "            word_list: List[Word] = [word.lower() for word in self._tokenize_sentence_to_words(sentence)]\n",
        "            phrase_list.extend(self._get_phrase_list_from_words(word_list))\n",
        "\n",
        "        # Based on user's choice to include or not include repeated phrases\n",
        "        # we compute the phrase list and return it. If not including repeated\n",
        "        # phrases, we only include the first occurance of the phrase and drop\n",
        "        # the rest.\n",
        "        if not self.include_repeated_phrases:\n",
        "            unique_phrase_tracker: Set[Phrase] = set()\n",
        "            non_repeated_phrase_list: List[Phrase] = []\n",
        "            for phrase in phrase_list:\n",
        "                if phrase not in unique_phrase_tracker:\n",
        "                    unique_phrase_tracker.add(phrase)\n",
        "                    non_repeated_phrase_list.append(phrase)\n",
        "            return non_repeated_phrase_list\n",
        "\n",
        "        return phrase_list\n",
        "\n",
        "    def _get_phrase_list_from_words(self, word_list: List[Word]) -> List[Phrase]:\n",
        "        \"\"\"Method to create contender phrases from the list of words that form\n",
        "        a sentence by dropping stopwords and punctuations and grouping the left\n",
        "        words into phrases. Only phrases in the given length range (both limits\n",
        "        inclusive) would be considered to build co-occurrence matrix. Ex:\n",
        "\n",
        "        Sentence: Red apples, are good in flavour.\n",
        "        List of words: ['red', 'apples', \",\", 'are', 'good', 'in', 'flavour']\n",
        "        List after dropping punctuations and stopwords.\n",
        "        List of words: ['red', 'apples', *, *, good, *, 'flavour']\n",
        "        List of phrases: [('red', 'apples'), ('good',), ('flavour',)]\n",
        "\n",
        "        List of phrases with a correct length:\n",
        "        For the range [1, 2]: [('red', 'apples'), ('good',), ('flavour',)]\n",
        "        For the range [1, 1]: [('good',), ('flavour',)]\n",
        "        For the range [2, 2]: [('red', 'apples')]\n",
        "\n",
        "        :param word_list: List of words which form a sentence when joined in\n",
        "                          the same order.\n",
        "        :return: List of contender phrases honouring phrase length requirements\n",
        "                 that are formed after dropping stopwords and punctuations.\n",
        "        \"\"\"\n",
        "        groups = groupby(word_list, lambda x: x not in self.to_ignore)\n",
        "        phrases: List[Phrase] = [tuple(group[1]) for group in groups if group[0]]\n",
        "        return list(filter(lambda x: self.min_length <= len(x) <= self.max_length, phrases))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyiHplPbOT1s"
      },
      "source": [
        "## TF-IDF Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78OkrHagOT1s"
      },
      "outputs": [],
      "source": [
        "def extract_keywords_tfidf(abstracts, T):\n",
        "    # Preprocess the abstracts: remove punctuation and stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "\n",
        "    def preprocess(text):\n",
        "        text = text.lower()  # Lowercase\n",
        "        text = ''.join([ch for ch in text if ch not in punctuation])  # Remove punctuation\n",
        "        tokens = text.split()\n",
        "        tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    # Preprocess each abstract\n",
        "    preprocessed_abstracts = [preprocess(abstract) for abstract in abstracts]\n",
        "\n",
        "    # Initialize TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(preprocessed_abstracts)\n",
        "\n",
        "    # Get feature names (i.e., words)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "\n",
        "    # Extract top_n keywords for each abstract\n",
        "    keywords_per_abstract = []\n",
        "    for idx, row in tfidf_df.iterrows():\n",
        "        # Get the top_n words with highest TF-IDF scores\n",
        "        top_keywords = row.nlargest(T).index.tolist()\n",
        "        keywords_per_abstract.append(top_keywords)\n",
        "\n",
        "    return keywords_per_abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5JvzUSROT1t"
      },
      "source": [
        "## Keyword & Keyphrase Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5b7I-M2OT1t"
      },
      "outputs": [],
      "source": [
        "def sample_keywords(ranked_keywords, percentage):\n",
        "    sample_size = int(len(ranked_keywords) * (percentage / 100.0))\n",
        "    return ranked_keywords[:sample_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xge70xZHOT1t"
      },
      "outputs": [],
      "source": [
        "def save_keywords_to_files(lists_of_keywords, file_names):\n",
        "    \"\"\"\n",
        "    Save the keywords from each list to a separate text file.\n",
        "\n",
        "    :param lists_of_keywords: A list of lists, where each sublist contains keywords for an abstract\n",
        "    :param file_names: A list of file names corresponding to each list\n",
        "    \"\"\"\n",
        "    for keywords_list, file_name in zip(lists_of_keywords, file_names):\n",
        "        with open(file_name, 'w') as file:\n",
        "            for keywords in keywords_list:\n",
        "                # Join the keywords for the abstract into a single string\n",
        "                line = ' '.join(keywords)\n",
        "                # Write the line to the file\n",
        "                file.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlVlPr3EOT1t"
      },
      "outputs": [],
      "source": [
        "T = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrI2KBl3OT1u"
      },
      "outputs": [],
      "source": [
        "tfidf_keywords = extract_keywords_tfidf(abstracts, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIQrW4VeOT1u",
        "outputId": "dabec52d-6db8-4b0b-abd0-0b191d13f80c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2277"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tfidf_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH9xSV60OT1u",
        "outputId": "ab5d7bb1-9bfb-43d5-96e1-c77bd82160fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['convex', 'heuristic', 'megaprior', 'sequence', 'discovering'],\n",
              " ['cure', 'colposuspension', 'rate', 'risk', 'medical'],\n",
              " ['channel', 'calls', 'cell', 'call', 'service'],\n",
              " ['pomdps', 'mdps', 'observable', 'partially', 'finding'],\n",
              " ['variational', 'graphical', 'approximations', 'models', 'bounds'],\n",
              " ['realtime', 'goldszmidt', 'algorithms', 'variant', 'decision'],\n",
              " ['learning', 'framework', 'speedup', 'solving', 'macrooperator'],\n",
              " ['hir', 'hischbergs', 'mmb', 'myers', 'sm'],\n",
              " ['offline', 'mistakes', 'elements', 'learner', 'sequence'],\n",
              " ['ss', 'anova', 'klein', 'grkpack', 'gu'],\n",
              " ['solutions', 'problems', 'potential', 'learning', 'discovering'],\n",
              " ['laplacemetropolis', 'estimator', 'effects', 'marginal', 'random'],\n",
              " ['trend', 'utility', 'performance', 'paradigms', 'learned'],\n",
              " ['hmm', 'protein', 'sequences', 'efhand', 'globin'],\n",
              " ['weight', 'initial', 'demonstrate', 'extreme', 'experiments'],\n",
              " ['lobe', 'medial', 'alvarez', 'consolidation', 'neocortex'],\n",
              " ['eyes', 'stripes', 'ocular', 'dominance', 'neighbouring'],\n",
              " ['validating', 'classifier', 'test', 'variance', 'drawing'],\n",
              " ['noise', 'learning', 'learner', 'target', 'function'],\n",
              " ['lookup', 'car', 'table', 'function', 'approximation'],\n",
              " ['strategy', 'evolution', 'develop', 'strategies', 'mobility'],\n",
              " ['sq', 'pac', 'noise', 'nearly', 'boosting'],\n",
              " ['applications', 'neural', 'effort', 'scrutiny', 'much'],\n",
              " ['priors', 'jeffreyss', 'philosophical', 'professor', 'rules'],\n",
              " ['narx', 'models', 'recurrent', 'popular', 'nonlinear'],\n",
              " ['concepts', 'incremental', 'annealingbased', 'confldent', 'flrst'],\n",
              " ['creative', 'design', 'cbr', 'facilitate', 'kinds'],\n",
              " ['parameter', 'estimation', 'mstep', 'contextdependent', 'geometric'],\n",
              " ['design', 'demex', 'designers', 'memorybased', 'exploration'],\n",
              " ['connections', 'uppropagation', 'inverting', 'generative', 'bottomup'],\n",
              " ['surfaces', 'anywhere', 'features', 'retrieve', 'detected'],\n",
              " ['knn', 'lazy', 'differential', 'games', 'game'],\n",
              " ['perceptual', 'hierarchical', 'inference', 'demon', 'strate'],\n",
              " ['search', 'sane', 'neuroevolution', 'hierarchical', 'individual'],\n",
              " ['skills', 'action', 'reinforcement', 'tasks', 'policies'],\n",
              " ['incorrect', 'satisfy', 'learner', 'predictions', 'gvalued'],\n",
              " ['biostatistics', 'mcmc', 'convergence', 'professor', 'diagnostics'],\n",
              " ['invariant', 'randomdot', 'stereograms', 'antihebbian', 'dichotomy'],\n",
              " ['database', 'instancebased', 'cost', 'local', 'data'],\n",
              " ['control', 'strategies', 'mobilerobot', 'unexplored', 'goes'],\n",
              " ['note', 'nge', 'implementation', 'curious', 'publicize'],\n",
              " ['tempering', 'tempered', 'distributions', 'simulated', 'distribution'],\n",
              " ['student', 'students', 'ats', 'mlmodeler', 'expert'],\n",
              " ['introspection', 'metacognitive', 'regulation', 'cognition', 'experience'],\n",
              " ['graphs', 'property', 'lwf', 'udgs', 'markov'],\n",
              " ['diagnoses', 'stanford', 'challenges', 'fault', 'missing'],\n",
              " ['game', 'strategies', 'competitive', 'learning', 'new'],\n",
              " ['bounding', 'hypothesis', 'bounds', 'generalization', 'error'],\n",
              " ['policies', 'returns', 'expected', 'landscape', 'mechanics'],\n",
              " ['nets', 'longstanding', 'settles', 'hardthreshold', 'ow'],\n",
              " ['signals', 'proposed', 'learning', 'crosstalking', 'random'],\n",
              " ['mdts', 'composite', 'elemental', 'architecture', 'tasks'],\n",
              " ['numerical', 'design', 'simulators', 'optimization', 'programs'],\n",
              " ['csi', 'independence', 'cpts', 'independencies', 'qualitatively'],\n",
              " ['trace', 'replacing', 'conventional', 'td', 'replacetrace'],\n",
              " ['reading', 'creative', 'theory', 'complete', 'overlooks'],\n",
              " ['counterfactual', 'vcu', 'conditionals', 'update', 'logic'],\n",
              " ['algorithmically',\n",
              "  'kolmogorov',\n",
              "  'generalization',\n",
              "  'complexity',\n",
              "  'universal'],\n",
              " ['expressive', 'phrase', 'sms', 'tenor', 'recordings'],\n",
              " ['votes', 'margins', 'margin', 'voting', 'boosting'],\n",
              " ['data', 'missing', 'density', 'mixture', 'estimation'],\n",
              " ['script', 'taxonomy', 'scripts', 'maps', 'tracks'],\n",
              " ['fovea', 'adaptive', 'sequential', 'target', 'controller'],\n",
              " ['grant', 'nsf', 'mixture', 'mit', 'architecture'],\n",
              " ['unobserved', 'variant', 'maximizes', 'step', 'variables'],\n",
              " ['oscillator', 'oscillators', 'desynchronize', 'wilsoncowan', 'separator'],\n",
              " ['bugs', 'regression', 'inference', 'inputdependent', 'interpolant'],\n",
              " ['classifying', 'classify', 'data', 'hand', 'classifier'],\n",
              " ['fl', 'massively', 'usually', 'sas', 'sasets'],\n",
              " ['kyburgs', 'right', 'kyburg', 'loui', 'appeal'],\n",
              " ['scheduling', 'scheduler', 'problems', 'schedule', 'evaluation'],\n",
              " ['cart', 'pole', 'minirobot', 'task', 'vertical'],\n",
              " ['restart', 'units', 'platt', 'platts', 'resourceallocation'],\n",
              " ['window', 'paradigm', 'expandable', 'finegrain', 'split'],\n",
              " ['nge', 'bnge', 'fw', 'mi', 'neighbor'],\n",
              " ['cross', 'validation', 'models', 'points', 'differentiating'],\n",
              " ['minfeatures', 'vertexcover', 'determinations', 'feature', 'almuallim'],\n",
              " ['connections', 'layer', 'vector', 'would', 'generative'],\n",
              " ['software', 'library', 'components', 'semantic', 'stored'],\n",
              " ['learning', 'cognitive', 'laws', 'inductive', 'analytical'],\n",
              " ['simulation', 'geometry', 'coupling', 'equilibrium', 'markov'],\n",
              " ['cbr', 'induction', 'cbroriented', 'owing', 'domains'],\n",
              " ['robot', 'adversarial', 'adversary', 'avoid', 'predict'],\n",
              " ['cargnoni', 'firenze', 'muller', 'west', 'professor'],\n",
              " ['gafos', 'steady', 'insights', 'gas', 'analysis'],\n",
              " ['parameter', 'noise', 'evidences', 'injection', 'penalize'],\n",
              " ['lmdt', 'decision', 'tree', 'multivariate', 'lmdts'],\n",
              " ['rl', 'control', 'reinforcement', 'controller', 'action'],\n",
              " ['lateral', 'input', 'connections', 'weights', 'hat'],\n",
              " ['foundations', 'causal', 'mathematical', 'blurring', 'deadend'],\n",
              " ['golem', 'foil', 'similar', 'method', 'programs'],\n",
              " ['bounds', 'ments', 'experi', 'precludes', 'tightness'],\n",
              " ['formalism', 'arebecome', 'imentally', 'nodeelimination', 'exper'],\n",
              " ['vcdimc', 'ffi', 'ln', 'bound', 'lower'],\n",
              " ['tau', 'speech', 'signals', 'net', 'constants'],\n",
              " ['bpsom', 'bp', 'mfns', 'som', 'effects'],\n",
              " ['mlp', 'lvq', 'quantisation', 'compared', 'powers'],\n",
              " ['approximation', 'sampler', 'gibbs', 'parameterization', 'implementational'],\n",
              " ['database', 'instancebased', 'cost', 'local', 'data'],\n",
              " ['coordination', 'expedited', 'multagent', 'reinforcement', 'cars'],\n",
              " ['elimination', 'preprocessing', 'irrelevant', 'whether', 'costsensitive'],\n",
              " ['hgp', 'diversity', 'causality', 'exploitation', 'exploration'],\n",
              " ['recurrent', 'multilevel', 'sequences', 'hierarchy', 'principle'],\n",
              " ['lateral', 'connections', 'ocular', 'eye', 'dominance'],\n",
              " ['singular', 'limit', 'relaxation', 'dynamics', 'oscillations'],\n",
              " ['segmentation', 'laterally', 'model', 'spiking', 'lateral'],\n",
              " ['integrals', 'analytically', 'mcmc', 'cellent', 'priorhyperprior'],\n",
              " ['cftp', 'sampling', 'state', 'penetrable', 'spheres'],\n",
              " ['receptive', 'lateral', 'ocular', 'dominance', 'orientation'],\n",
              " ['attitude', 'critic', 'cost', 'cycle', 'function'],\n",
              " ['clauses', 'predicates', 'paclearnable', 'nonrecursive', 'noise'],\n",
              " ['algorithm', 'enjoyed', 'luttrell', 'pooling', 'dempster'],\n",
              " ['radial', 'symmetry', 'regularization', 'consider', 'rotation'],\n",
              " ['kalman', 'methods', 'filter', 'lms', 'leastsquares'],\n",
              " ['windowing',\n",
              "  'separateandconquer',\n",
              "  'algorithm',\n",
              "  'algorithms',\n",
              "  'divideandconquer'],\n",
              " ['theory', 'examples', 'attain', 'system', 'approach'],\n",
              " ['mcmc', 'swendsenwang', 'decoupling', 'auxiliary', 'joint'],\n",
              " ['deduce', 'fosterlyapunov', 'properties', 'drift', 'ergodicity'],\n",
              " ['adfs', 'gp', 'evenparity', 'annealing', 'simulated'],\n",
              " ['values', 'blockers', 'attributes', 'blocking', 'remove'],\n",
              " ['blocks', 'discovery', 'representation', 'functions', 'adaptating'],\n",
              " ['nonconvex', 'norm', 'fundamental', 'samples', 'pattern'],\n",
              " ['musical', 'metrical', 'perception', 'expectancy', 'rhythmic'],\n",
              " ['libga', 'orderbased', 'generational', 'steadystate', 'packages'],\n",
              " ['capacity', 'binding', 'memory', 'storage', 'perceptual'],\n",
              " ['pollyanna', 'theories', 'candidate', 'empirical', 'costs'],\n",
              " ['nash', 'equilibrium', 'games', 'multiagent', 'game'],\n",
              " ['corporate', 'government', 'peer', 'memories', 'expertise'],\n",
              " ['selfknowledge', 'knowledge', 'deciding', 'system', 'strategies'],\n",
              " ['theoryguided', 'theory', 'systems', 'may', 'revision'],\n",
              " ['replicability', 'cold', 'fusion', 'computing', 'experiment'],\n",
              " ['associations', 'maze', 'robot', 'movements', 'conditioning'],\n",
              " ['audio', 'synthesis', 'modeling', 'inference', 'acoustical'],\n",
              " ['srt', 'ilp', 'nondeterminate', 'numerical', 'domains'],\n",
              " ['bayesian', 'objective', 'gull', 'penalising', 'interpolation'],\n",
              " ['multithreading', 'simultaneous', 'throughput', 'threads', 'superscalar'],\n",
              " ['theory', 'ptr', 'domain', 'theories', 'revision'],\n",
              " ['mixture', 'methodology', 'prior', 'improper', 'jumping'],\n",
              " ['science', 'andy', 'criticisms', 'insightful', 'northeastern'],\n",
              " ['active', 'learning', 'receives', 'selective', 'examples'],\n",
              " ['branch', 'instructions', 'operations', 'prediction', 'predication'],\n",
              " ['precedents', 'employment', 'furtherance', 'case', 'match'],\n",
              " ['hlearning',\n",
              "  'exploration',\n",
              "  'autoexploratory',\n",
              "  'counterbased',\n",
              "  'recencybased'],\n",
              " ['ga', 'parametric', 'fuzzy', 'dynamic', 'gas'],\n",
              " ['award', 'research', 'national', 'bao', 'fmh'],\n",
              " ['sums', 'bounds', 'parents', 'weighted', 'deviations'],\n",
              " ['feature', 'conceptual', 'selection', 'clustering', 'improving'],\n",
              " ['paradigms', 'systems', 'recognition', 'armamentarium', 'synergistic'],\n",
              " ['sardnet', 'sequences', 'sequence', 'phonemic', 'representations'],\n",
              " ['integration', 'knowledge', 'performance', 'aim', 'integrated'],\n",
              " ['bias', 'metabias', 'machine', 'summarized', 'motivate'],\n",
              " ['decision', 'trees', 'compact', 'assigned', 'aqdt'],\n",
              " ['regularizers', 'smoothing', 'pbfs', 'projective', 'functions'],\n",
              " ['musical', 'reductionist', 'representations', 'variations', 'melodies'],\n",
              " ['ensemble', 'minimization', 'energy', 'free', 'tool'],\n",
              " ['stationary', 'chain', 'distribution', 'scheme', 'auxiliary'],\n",
              " ['ca', 'borner', 'analogical', 'support', 'representations'],\n",
              " ['multipath', 'execution', 'branch', 'mispredictions', 'singlepath'],\n",
              " ['perturbations', 'density', 'constant', 'robust', 'expected'],\n",
              " ['sensor', 'signal', 'space', 'robot', 'scheme'],\n",
              " ['extracted', 'decisions', 'feedforward', 'trained', 'output'],\n",
              " ['evolutionary', 'acquisition', 'structure', 'recurrent', 'network'],\n",
              " ['creatures', 'encoding', 'mechanism', 'requires', 'loosely'],\n",
              " ['confidence', 'spline', 'smoothing', 'intervals', 'decomposition'],\n",
              " ['ey', 'dms', 'grants', 'accomodate', 'cowan'],\n",
              " ['assemblies', 'sequencing', 'handediting', 'quality', 'calls'],\n",
              " ['instruction', 'parallelism', 'mimd', 'stream', 'architectures'],\n",
              " ['misc', 'instruction', 'stream', 'parallelism', 'intramisc'],\n",
              " ['transitions', 'bridge', 'variant', 'agent', 'determistic'],\n",
              " ['eeg', 'mental', 'states', 'sequencesof', 'cnaps'],\n",
              " ['perceptron', 'coordinates', 'dependences', 'filtering', 'tight'],\n",
              " ['architectures', 'patterns', 'time', 'taxonomy', 'shortterm'],\n",
              " ['lexical', 'lexicon', 'maps', 'aphasic', 'categoryspecific'],\n",
              " ['maps', 'decomposition', 'environments', 'backpropagation', 'ample'],\n",
              " ['search', 'subset', 'estimates', 'feature', 'features'],\n",
              " ['simd', 'parallel', 'gp', 'maspar', 'implementations'],\n",
              " ['reinforcementlearning',\n",
              "  'qlearning',\n",
              "  'theorem',\n",
              "  'reinforcement',\n",
              "  'risksensitive'],\n",
              " ['minerals', 'hyperspectral', 'mineral', 'pixel', 'materials'],\n",
              " ['bound', 'method', 'control', 'upper', 'computing'],\n",
              " ['inputs', 'regularisation', 'junk', 'irrelevant', 'regression'],\n",
              " ['prototypebased', 'approaches', 'coprocessing', 'storing', 'describe'],\n",
              " ['instruction', 'parallelism', 'mimd', 'stream', 'architectures'],\n",
              " ['processor', 'communication', 'times', 'parallel', 'performance'],\n",
              " ['quinlans', 'publication', 'et', 'statistics', 'breiman'],\n",
              " ['pomdps', 'formulated', 'pomdp', 'solved', 'actions'],\n",
              " ['reasoning', 'introspective', 'failure', 'conclusions', 'system'],\n",
              " ['student', 'students', 'ats', 'mlmodeler', 'expert'],\n",
              " ['parameter', 'target', 'concept', 'magnus', 'returned'],\n",
              " ['negative', 'outputs', 'examples', 'generated', 'chillin'],\n",
              " ['database', 'instancebased', 'cost', 'local', 'data'],\n",
              " ['hyperboxes', 'agglomerative', 'clustering', 'pattern', 'hierarchial'],\n",
              " ['hyperplanes', 'trees', 'descendants', 'find', 'technique'],\n",
              " ['icet', 'five', 'costsensitive', 'classification', 'costs'],\n",
              " ['planes', 'description', 'programming', 'linear', 'neural'],\n",
              " ['creative', 'cbr', 'creativity', 'discusses', 'understanding'],\n",
              " ['dna', 'inhomogeneity', 'compositional', 'segments', 'chain'],\n",
              " ['weight', 'conn', 'matrix', 'hardwired', 'selfreferential'],\n",
              " ['multiassociative', 'pattern', 'enumerative', 'manytomany', 'mm'],\n",
              " ['eye', 'shifts', 'signals', 'position', 'movements'],\n",
              " ['rules', 'conflict', 'outcome', 'management', 'confman'],\n",
              " ['fitness', 'ga', 'optima', 'multimodal', 'iteration'],\n",
              " ['dagsp', 'vi', 'acyclic', 'backups', 'deterministic'],\n",
              " ['design', 'optimization', 'formulation', 'reformulation', 'objective'],\n",
              " ['sets', 'combinations', 'erssar', 'landsattm', 'oneband'],\n",
              " ['noise', 'affected', 'still', 'length', 'noisy'],\n",
              " ['advice', 'web', 'pages', 'finder', 'homepage'],\n",
              " ['concept', 'attribute', 'set', 'attributes', 'concepts'],\n",
              " ['components', 'distribution', 'mixture', 'accommodated', 'proportions'],\n",
              " ['sane', 'symbiotic', 'neuroevolution', 'times', 'faster'],\n",
              " ['plan', 'criterion', 'variables', 'closedform', 'unmeasured'],\n",
              " ['flow', 'control', 'prediction', 'window', 'graph'],\n",
              " ['mean', 'field', 'recognitionthe', 'statistical', 'theory'],\n",
              " ['element', 'pe', 'distribution', 'performance', 'transformations'],\n",
              " ['composite', 'skills', 'tasks', 'cql', 'reinforcement'],\n",
              " ['hyperplanes', 'inertia', 'dynamics', 'hyperplane', 'picture'],\n",
              " ['modifications', 'compressor', 'penn', 'preconditioning', 'presetting'],\n",
              " ['rankboost', 'combining', 'preferences', 'experiment', 'search'],\n",
              " ['cbl', 'decision', 'semiflexible', 'trees', 'prediction'],\n",
              " ['variables', 'wakesleep', 'visible', 'hebbian', 'correlations'],\n",
              " ['hmms', 'acid', 'amino', 'false', 'densities'],\n",
              " ['cost', 'matrix', 'cash', 'confusion', 'deploying'],\n",
              " ['interventions', 'causation', 'effects', 'external', 'manipulative'],\n",
              " ['design', 'focus', 'creative', 'designs', 'search'],\n",
              " ['well', 'model', 'intuitive', 'structure', 'nonlinear'],\n",
              " ['coverage', 'bound', 'concepts', 'maximization', 'upper'],\n",
              " ['gafos', 'transient', 'markov', 'gas', 'explore'],\n",
              " ['behaviour', 'emergent', 'design', 'coevolutionary', 'space'],\n",
              " ['noise', 'attribute', 'rate', 'covering', 'hold'],\n",
              " ['exons', 'hmm', 'dna', 'regions', 'intergenic'],\n",
              " ['tc', 'tasks', 'learning', 'cluster', 'related'],\n",
              " ['belief', 'update', 'revision', 'change', 'plain'],\n",
              " ['overfitting', 'issues', 'regression', 'summarised', 'bayesian'],\n",
              " ['cns', 'sparse', 'code', 'pinpoint', 'memory'],\n",
              " ['diploid', 'haploid', 'genotypes', 'population', 'simulations'],\n",
              " ['beliefs', 'belief', 'observations', 'epistemic', 'status'],\n",
              " ['belief', 'qualitative', 'change', 'observation', 'assumption'],\n",
              " ['state', 'search', 'trajectory', 'searches', 'performs'],\n",
              " ['queries', 'pcfgs', 'sentence', 'pcfg', 'contextfree'],\n",
              " ['ordering', 'beliefs', 'causal', 'rankings', 'rules'],\n",
              " ['clay', 'assemblages', 'motor', 'reinforcement', 'schemas'],\n",
              " ['local', 'units', 'hidden', 'computations', 'time'],\n",
              " ['creativity', 'reading', 'understanding', 'stories', 'creative'],\n",
              " ['pending', 'serendipitous', 'creative', 'recognition', 'design'],\n",
              " ['measures', 'different', 'determine', 'tree', 'gini'],\n",
              " ['switches', 'adversarial', 'plus', 'models', 'number'],\n",
              " ['measures', 'similarity', 'systematic', 'case', 'base'],\n",
              " ['gp', 'list', 'data', 'structures', 'memory'],\n",
              " ['computation', 'polynomialtime', 'analog', 'equivalent', 'constraints'],\n",
              " ['interpretability', 'highlight', 'diagnostic', 'mcmc', 'utility'],\n",
              " ['ica', 'eeg', 'erp', 'source', 'channels'],\n",
              " ['technical', 'cleermans', 'cmucs', 'fki', 'fu'],\n",
              " ['trees', 'lookahead', 'greedy', 'decision', 'tree'],\n",
              " ['cc', 'classifications', 'supervised', 'valued', 'discrete'],\n",
              " ['tasks', 'job', 'merging', 'theoreticallysound', 'mail'],\n",
              " ['tree', 'metric', 'distance', 'fk', 'phard'],\n",
              " ['cbp', 'planning', 'retrieval', 'dersnlpebl', 'judgements'],\n",
              " ['speculation', 'confidence', 'estimation', 'control', 'mechanisms'],\n",
              " ['relational', 'embodying', 'representations', 'commonalities', 'algorithms'],\n",
              " ['neurons', 'boltzmann', 'machines', 'significant', 'solutions'],\n",
              " ['policy', 'instances', 'search', 'control', 'combinatorial'],\n",
              " ['exploration', 'undiscounted', 'rewards', 'return', 'mdps'],\n",
              " ['predicated', 'full', 'execution', 'predication', 'partial'],\n",
              " ['selfdirected', 'grant', 'learning', 'mistakes', 'nsf'],\n",
              " ['lowerbound', 'algorithm', 'genetic', 'convergence', 'behavior'],\n",
              " ['mixture', 'experts', 'model', 'predicts', 'viewed'],\n",
              " ['represen', 'tation', 'td', 'example', 'cost'],\n",
              " ['graphstructured', 'representations', 'relations', 'caper', 'casebased'],\n",
              " ['regression', 'modification', 'induced', 'tree', 'trees'],\n",
              " ['dynamics', 'synaptic', 'neuronal', 'collective', 'orientation'],\n",
              " ['theory', 'audrey', 'revision', 'distance', 'ii'],\n",
              " ['dataset', 'datasets', 'decomposition', 'analyze', 'comprehend'],\n",
              " ['studies', 'case', 'evaluations', 'generalizing', 'databases'],\n",
              " ['descriptions', 'correlated', 'reduction', 'help', 'amount'],\n",
              " ['plannett', 'anns', 'accuracy', 'images', 'endtoend'],\n",
              " ['macro', 'actions', 'planning', 'models', 'reinforcement'],\n",
              " ['test', 'type', 'mcnemars', 'xcv', 'tests'],\n",
              " ['active', 'description', 'obtain', 'classifier', 'cost'],\n",
              " ['elimination', 'algorithms', 'maximum', 'aposteriori', 'eliminationtype'],\n",
              " ['david', 'marsden', 'robert', 'peter', 'sociology'],\n",
              " ['specifica', 'treeclustering', 'timespace', 'meets', 'accomplishing'],\n",
              " ['conditioning', 'loopcutset', 'method', 'global', 'jensen'],\n",
              " ['spikes', 'subthreshold', 'neurons', 'fire', 'associative'],\n",
              " ['tag', 'generational', 'subpopulation', 'replaces', 'illustrating'],\n",
              " ['transformed', 'cost', 'group', 'penalizes', 'term'],\n",
              " ['factorization', 'causal', 'independence', 'conditional', 'inference'],\n",
              " ['human', 'task', 'hybrid', 'cognitive', 'action'],\n",
              " ['pac', 'query', 'statistical', 'queries', 'model'],\n",
              " ['reduced', 'pruning', 'domains', 'thereafter', 'notably'],\n",
              " ['metrical', 'music', 'patterns', 'beat', 'meter'],\n",
              " ['explanations', 'observation', 'abduction', 'accounts', 'diagnosis'],\n",
              " ['jaeckels', 'karlssons', 'design', 'cation', 'modifi'],\n",
              " ['memory', 'locations', 'hard', 'estimate', 'inversely'],\n",
              " ['formalism', 'belief', 'admitting', 'rankedmodel', 'resolves'],\n",
              " ['em', 'matrix', 'gaussian', 'likelihood', 'mathematical'],\n",
              " ['clause', 'realvalued', 'knowledge', 'modelling', 'minimum'],\n",
              " ['organization', 'topographic', 'measures', 'hemispheric', 'assessments'],\n",
              " ['structure', 'sequences', 'temporallyextended', 'instant', 'music'],\n",
              " ['higherorder', 'units', 'neuralnetworks', 'incremental', 'recurrent'],\n",
              " ['markov', 'chains', 'sampler', 'gibbs', 'tests'],\n",
              " ['discriminant', 'statistical', 'data', 'generated', 'nonsupervised'],\n",
              " ['component', 'nonlinear', 'ages', 'expansions', 'multiunit'],\n",
              " ['circadian', 'nadir', 'peak', 'fit', 'hormones'],\n",
              " ['partitioning', 'graph', 'largescale', 'lower', 'billions'],\n",
              " ['disease', 'environmental', 'bayes', 'maps', 'spatial'],\n",
              " ['extracted', 'dimensionality', 'features', 'reduction', 'munro'],\n",
              " ['constructive', 'representation', 'induction', 'representations', 'input'],\n",
              " ['schemes', 'selection', 'replacement', 'competition', 'review'],\n",
              " ['backpropagation', 'selfsupervised', 'competitive', 'maps', 'vector'],\n",
              " ['rhythmic', 'meter', 'oscillators', 'patterns', 'metrical'],\n",
              " ['dyn', 'radial', 'approximation', 'orders', 'spaces'],\n",
              " ['schemes', 'approximation', 'ir', 'basis', 'scattered'],\n",
              " ['splines', 'spaces', 'ladders', 'polyharmonic', 'gauss'],\n",
              " ['ebl', 'rl', 'ebrl', 'batch', 'explanationbased'],\n",
              " ['centers', 'contract', 'nj', 'research', 'clouds'],\n",
              " ['mds', 'vq', 'som', 'quantization', 'clustering'],\n",
              " ['rl', 'exploration', 'policy', 'agent', 'composes'],\n",
              " ['variables', 'unneeded', 'input', 'information', 'weights'],\n",
              " ['diploidy', 'phenotype', 'copies', 'genotype', 'expressed'],\n",
              " ['speculation', 'intertask', 'tasklevel', 'ow', 'compiler'],\n",
              " ['agent', 'ask', 'learner', 'guidance', 'speed'],\n",
              " ['minimal', 'appropriate', 'method', 'multilevel', 'classification'],\n",
              " ['data', 'educational', 'exploratory', 'prospects', 'toolbox'],\n",
              " ['hme', 'tree', 'additions', 'interlocking', 'ups'],\n",
              " ['errors', 'observations', 'examine', 'recognising', 'data'],\n",
              " ['formulations', 'differing', 'generality', 'size', 'evolved'],\n",
              " ['mdl', 'crossvalidation', 'features', 'large', 'subset'],\n",
              " ['rules', 'list', 'decision', 'rule', 'maximally'],\n",
              " ['fuzzy', 'graphs', 'example', 'data', 'build'],\n",
              " ['teaching', 'students', 'rl', 'needs', 'superior'],\n",
              " ['stm', 'temporal', 'compositionality', 'integrators', 'leaky'],\n",
              " ['alertness', 'eeg', 'monitoring', 'noninvasive', 'power'],\n",
              " ['inference', 'density', 'bayesian', 'exact', 'transformation'],\n",
              " ['perceptron', 'tumors', 'malignant', 'diagnose', 'benign'],\n",
              " ['inputs', 'latent', 'variable', 'data', 'unspecified'],\n",
              " ['risk', 'minimization', 'measurement', 'questions', 'generalized'],\n",
              " ['encoding', 'edge', 'cellular', 'operators', 'may'],\n",
              " ['classifications', 'geometric', 'classes', 'similarity', 'different'],\n",
              " ['trash', 'sensory', 'become', 'abundant', 'football'],\n",
              " ['variables', 'causal', 'effect', 'identifiable', 'singleton'],\n",
              " ['visor', 'schema', 'robust', 'mechanisms', 'processing'],\n",
              " ['spectrum', 'along', 'induction', 'allowable', 'traversal'],\n",
              " ['traits', 'costs', 'hump', 'assimilation', 'population'],\n",
              " ['acquired', 'traits', 'genetically', 'phenotypic', 'become'],\n",
              " ['trees', 'option', 'input', 'vector', 'classificationregression'],\n",
              " ['bp', 'online', 'series', 'point', 'diverging'],\n",
              " ['dfa', 'deteriorating', 'instability', 'recurrent', 'states'],\n",
              " ['stability', 'lyapunov', 'converse', 'theorem', 'wellknown'],\n",
              " ['dfas', 'recurrent', 'networks', 'trained', 'finitestate'],\n",
              " ['handengineered', 'previous', 'schedules', 'scheduling', 'task'],\n",
              " ['machines', 'sycon', 'turing', 'processors', 'linear'],\n",
              " ['state', 'stationary', 'goal', 'lrtabased', 'reset'],\n",
              " ['department', 'research', 'trento', 'lemma', 'function'],\n",
              " ['recursive', 'explanation', 'explanationbased', 'iterative', 'concepts'],\n",
              " ['sampler', 'ergodic', 'boundaries', 'gibbs', 'jagged'],\n",
              " ['functions', 'intermediate', 'decomposition', 'concepts', 'attributevector'],\n",
              " ['instances', 'despite', 'samples', 'uncertainty', 'classifier'],\n",
              " ['variables', 'instrumental', 'inequality', 'constraints', 'formula'],\n",
              " ['intervals', 'confidence', 'spline', 'smoothing', 'formula'],\n",
              " ['boosting', 'give', 'confidences', 'adaboost', 'freund'],\n",
              " ['level', 'learning', 'algorithms', 'adaptation', 'evolution'],\n",
              " ['cpds', 'procedure', 'local', 'networks', 'learning'],\n",
              " ['committees', 'classifiers', 'prospective', 'bounds', 'infer'],\n",
              " ['pi', 'coil', 'controller', 'trained', 'minimize'],\n",
              " ['cn', 'ordered', 'laplacian', 'unordered', 'rules'],\n",
              " ['introduction', 'computation', 'neural', 'perspective', 'statistics'],\n",
              " ['superscalar', 'outoforder', 'penalties', 'polypath', 'processor'],\n",
              " ['derived', 'learning', 'algorithm', 'bayesian', 'tree'],\n",
              " ['subset', 'features', 'definitions', 'relevance', 'irrelevance'],\n",
              " ['values', 'solutions', 'method', 'form', 'decision'],\n",
              " ['branch', 'dual', 'execution', 'path', 'predictor'],\n",
              " ['smt', 'threaded', 'multipath', 'threads', 'execution'],\n",
              " ['abstract', 'learning', 'models', 'rhetoric', 'dominate'],\n",
              " ['sequence', 'homologs', 'motif', 'comparisons', 'query'],\n",
              " ['kdd', 'pattern', 'limitations', 'discovery', 'robust'],\n",
              " ['ex', 'study', 'alignment', 'see', 'biocomputing'],\n",
              " ['oblique', 'randomization', 'decision', 'trees', 'attributes'],\n",
              " ['subgoals', 'flann', 'ebrl', 'dietterich', 'explanationbased'],\n",
              " ['brace', 'discretization', 'objectives', 'paradigm', 'valued'],\n",
              " ['classifier', 'bayesian', 'naive', 'attributes', 'examples'],\n",
              " ['alignment', 'generation', 'sequence', 'aspartic', 'distantly'],\n",
              " ['recurrent', 'state', 'al', 'et', 'finite'],\n",
              " ['bias', 'generalization', 'conditions', 'summed', 'probability'],\n",
              " ['reward', 'hlearning', 'undiscounted', 'average', 'methods'],\n",
              " ['lyapunov', 'motivated', 'stability', 'robust', 'converse'],\n",
              " ['grounding', 'agents', 'wallfollowing', 'neglected', 'behavior'],\n",
              " ['theory', 'domain', 'types', 'dejong', 'mitchell'],\n",
              " ['network', 'stochastic', 'variables', 'massively', 'bayesian'],\n",
              " ['messages', 'routing', 'heuristic', 'design', 'networks'],\n",
              " ['statistics', 'washington', 'department', 'university', 'byers'],\n",
              " ['mistakes', 'expected', 'sequence', 'best', 'number'],\n",
              " ['algebra', 'approach', 'cbr', 'enables', 'similarity'],\n",
              " ['learner', 'trainers', 'critics', 'trainer', 'vary'],\n",
              " ['algorithm', 'learnability', 'learning', 'pac', 'upper'],\n",
              " ['decidendi', 'predicates', 'ratio', 'precedential', 'abstract'],\n",
              " ['topographic', 'homeomorphism', 'map', 'neighbourhood', 'quantifying'],\n",
              " ['noise', 'attribute', 'grant', 'flipped', 'tolerate'],\n",
              " ['behavioral', 'assemblages', 'individually', 'teams', 'agents'],\n",
              " ['units', 'product', 'functions', 'networks', 'candidate'],\n",
              " ['task', 'nrl', 'cognitive', 'navigation', 'architectures'],\n",
              " ['postulates', 'belief', 'agm', 'revision', 'epistemic'],\n",
              " ['twolayer', 'finetuning', 'connectionist', 'strategy', 'balancecontrol'],\n",
              " ['indirect', 'direct', 'method', 'methods', 'control'],\n",
              " ['belief', 'plausibility', 'framework', 'properties', 'knowledge'],\n",
              " ['chain', 'markov', 'stationary', 'infinitely', 'distribution'],\n",
              " ['interpolant', 'interpolation', 'regularizer', 'smoothness', 'models'],\n",
              " ['statlog', 'daimlerbenz', 'industrial', 'mlalgorithms', 'project'],\n",
              " ['elevator', 'rl', 'team', 'agents', 'continuous'],\n",
              " ['exploration', 'observable', 'partially', 'fringe', 'maze'],\n",
              " ['advantages', 'absolute', 'policy', 'actions', 'utility'],\n",
              " ['dtselect', 'features', 'pools', 'protein', 'inductive'],\n",
              " ['package', 'extension', 'university', 'dga', 'lisbon'],\n",
              " ['views', 'objects', 'network', 'representations', 'summation'],\n",
              " ['grant', 'supervised', 'awarded', 'research', 'internal'],\n",
              " ['numeric', 'tree', 'handle', 'slewing', 'variables'],\n",
              " ['nk', 'onr', 'address', 'cruz', 'grant'],\n",
              " ['utility', 'control', 'training', 'strategy', 'exampleintensive'],\n",
              " ['statespaces', 'high', 'partigame', 'statespace', 'trajectories'],\n",
              " ['predictive', 'distribution', 'logscore', 'map', 'clearly'],\n",
              " ['cbr', 'propagation', 'reasoning', 'probability', 'casebased'],\n",
              " ['bounds', 'packing', 'scalesensitive', 'upper', 'valued'],\n",
              " ['authority', 'minos', 'modules', 'confidence', 'expert'],\n",
              " ['pomdps', 'problems', 'policies', 'larger', 'finding'],\n",
              " ['auxiliary', 'stationary', 'chain', 'construction', 'rivals'],\n",
              " ['observable', 'partially', 'world', 'approximation', 'spova'],\n",
              " ['update', 'km', 'reasonable', 'explanations', 'observation'],\n",
              " ['brainlike', 'feedbackguided', 'reweighting', 'links', 'brainstructured'],\n",
              " ['tree', 'induction', 'approaches', 'quality', 'dmti'],\n",
              " ['variational', 'closed', 'posterior', 'belief', 'regression'],\n",
              " ['posterior', 'factorized', 'mean', 'field', 'multimodal'],\n",
              " ['pole', 'classic', 'difficult', 'esp', 'yardstick'],\n",
              " ['spatiotemporal', 'spatial', 'temporal', 'patterns', 'structures'],\n",
              " ['qlearning', 'update', 'bounded', 'lookuptables', 'postponed'],\n",
              " ['generative', 'learning', 'processes', 'elements', 'networks'],\n",
              " ['roads', 'alvinn', 'neural', 'drive', 'road'],\n",
              " ['experts', 'adjusting', 'expert', 'incremental', 'predictions'],\n",
              " ['monitoring', 'agent', 'criterion', 'policy', 'case'],\n",
              " ['rectangle', 'product', 'drawn', 'whether', 'points'],\n",
              " ['hierarchy', 'method', 'decomposition', 'hint', 'concept'],\n",
              " ['mprobability', 'estimate', 'probabilities', 'regression', 'estimation'],\n",
              " ['grant', 'research', 'likelihoodbased', 'missing', 'foundation'],\n",
              " ['dfa', 'faults', 'secondorder', 'tolerance', 'neurons'],\n",
              " ['washington', 'department', 'statistics', 'university', 'wa'],\n",
              " ['arm', 'payoff', 'bandit', 'slot', 'best'],\n",
              " ['sensitivities',\n",
              "  'probabilities',\n",
              "  'conditional',\n",
              "  'representation',\n",
              "  'traditional'],\n",
              " ['custom', 'design', 'networkspecific', 'prompted', 'supercomputer'],\n",
              " ['committee', 'reuters', 'label', 'categorization', 'text'],\n",
              " ['covering', 'divideandconquer', 'formalized', 'overly', 'specializing'],\n",
              " ['recurrence', 'feature', 'method', 'generalizer', 'prognosis'],\n",
              " ['wallace', 'mml', 'message', 'boulton', 'snob'],\n",
              " ['visual', 'exible', 'visit', 'attention', 'required'],\n",
              " ['asymmetric', 'interactions', 'lyapunov', 'excitatory', 'inhibitory'],\n",
              " ['sampling', 'ratio', 'importance', 'odds', 'bridge'],\n",
              " ['matching', 'massively', 'access', 'knowledge', 'relevant'],\n",
              " ['training', 'procedures', 'sample', 'paclearning', 'bounds'],\n",
              " ['adaptation', 'matching', 'cbr', 'cases', 'approach'],\n",
              " ['blameassignment', 'types', 'design', 'device', 'modelbased'],\n",
              " ['knowledge', 'design', 'acquisition', 'fabel', 'german'],\n",
              " ['classifiers', 'snob', 'art', 'autoclass', 'classification'],\n",
              " ['problemsolving', 'metacase', 'tmk', 'casebased', 'trace'],\n",
              " ['pseudocounts', 'frequencies', 'acid', 'amino', 'estimates'],\n",
              " ['innateness', 'bias', 'generalist', 'specialised', 'models'],\n",
              " ['alvinn', 'saliency', 'important', 'autonomous', 'attention'],\n",
              " ['scheduling', 'production', 'factory', 'demands', 'value'],\n",
              " ['pconcepts', 'sometimes', 'learning', 'may', 'behaviorthus'],\n",
              " ['deductively', 'learned', 'problem', 'backtracking', 'solvers'],\n",
              " ['thank', 'rich', 'ecs', 'sutton', 'research'],\n",
              " ['wta', 'relations', 'spatial', 'selection', 'network'],\n",
              " ['rl', 'averagepayoff', 'algorithms', 'maximize', 'solving'],\n",
              " ['learner', 'automaton', 'outputs', 'target', 'observes'],\n",
              " ['vertices', 'robot', 'pebble', 'mapping', 'vertex'],\n",
              " ['log', 'complexity', 'sample', 'mdl', 'ffi'],\n",
              " ['arl', 'hlearning', 'agv', 'tablebased', 'averagereward'],\n",
              " ['highdimensional', 'maps', 'selforganizing', 'capture', 'merge'],\n",
              " ['sdts', 'composite', 'elemental', 'tasks', 'learning'],\n",
              " ['arm', 'obstacles', 'locations', 'avoid', 'robot'],\n",
              " ['aggregation', 'rl', 'state', 'soft', 'compact'],\n",
              " ['temporaldifference', 'methods', 'assign', 'credit', 'difference'],\n",
              " ['dynapi', 'dynaq', 'dyna', 'architectures', 'world'],\n",
              " ['approximators', 'boyan', 'function', 'moore', 'whereas'],\n",
              " ['online', 'representation', 'learning', 'supervised', 'methods'],\n",
              " ['prediction', 'online', 'apportioning', 'gambling', 'multipleoutcome'],\n",
              " ['mi', 'dependency', 'expansion', 'outputs', 'signals'],\n",
              " ['bpsom',\n",
              "  'overfitting',\n",
              "  'backpropagation',\n",
              "  'generalisation',\n",
              "  'deterioration'],\n",
              " ['revision', 'acceptance', 'conditional', 'conditionals', 'iterated'],\n",
              " ['theoretical', 'failuresnamely', 'overestimation', 'reinforcement', 'prime'],\n",
              " ['maximisation', 'higherorder', 'information', 'blind', 'transfer'],\n",
              " ['graphical', 'schemas', 'networks', 'operations', 'popular'],\n",
              " ['knowledge', 'utility', 'curve', 'learned', 'training'],\n",
              " ['knn', 'perceptrons', 'kernel', 'radialbasis', 'estimators'],\n",
              " ['adaptation', 'knowledge', 'cbr', 'developer', 'endowing'],\n",
              " ['introspective', 'modeling', 'desires', 'expectations', 'memory'],\n",
              " ['learning', 'acquisition', 'micro', 'macro', 'perspectives'],\n",
              " ['failures', 'task', 'knowledge', 'reasoner', 'declarative'],\n",
              " ['statistics', 'networks', 'mean', 'field', 'blanket'],\n",
              " ['signal', 'steering', 'adaptive', 'system', 'selflearning'],\n",
              " ['onr', 'office', 'afosr', 'research', 'nj'],\n",
              " ['ffi', 'understood', 'setting', 'multiquadric', 'gauss'],\n",
              " ['agnostic', 'learning', 'target', 'pac', 'function'],\n",
              " ['dersnlpebl', 'goals', 'derivations', 'replayed', 'replays'],\n",
              " ['net', 'weight', 'temporal', 'weights', 'fullfledged'],\n",
              " ['dcm', 'taxa', 'reconstruction', 'tree', 'accurate'],\n",
              " ['semantic', 'invents', 'semanticgrammar', 'learned', 'parsers'],\n",
              " ['branch', 'predicated', 'execution', 'instructions', 'predication'],\n",
              " ['auditory', 'icx', 'map', 'visual', 'signal'],\n",
              " ['animals', 'indicative', 'hippocampus', 'old', 'barnes'],\n",
              " ['foveate', 'gesture', 'gestures', 'camera', 'salient'],\n",
              " ['optima', 'sharing', 'implicit', 'find', 'enough'],\n",
              " ['legacy', 'heterogeneous', 'knowledge', 'design', 'problemsolving'],\n",
              " ['series', 'overfitting', 'model', 'mixture', 'noisy'],\n",
              " ['ica', 'views', 'object', 'representation', 'attractor'],\n",
              " ['parallel', 'gas', 'synchronization', 'asynchronous', 'numerical'],\n",
              " ['decision', 'tree', 'vector', 'trees', 'support'],\n",
              " ['regularization', 'smoothness', 'functionals', 'basis', 'functions'],\n",
              " ['functions', 'approximation', 'research', 'grbf', 'generalized'],\n",
              " ['situations', 'case', 'understanding', 'understood', 'domain'],\n",
              " ['genefinding', 'ghmm', 'model', 'dna', 'codon'],\n",
              " ['domination', 'optimality', 'bounded', 'strategies', 'vengeful'],\n",
              " ['play', 'adversaries', 'games', 'history', 'automata'],\n",
              " ['morgan', 'vertebrate', 'dna', 'coding', 'exons'],\n",
              " ['pythia', 'characteristics', 'pde', 'models', 'advice'],\n",
              " ['reduction', 'set', 'criteria', 'hypotheses', 'missclassification'],\n",
              " ['receptive', 'unit', 'factors', 'field', 'alters'],\n",
              " ['semimarkov', 'decision', 'problems', 'algorithms', 'bellmans'],\n",
              " ['hme', 'classification', 'regression', 'ninput', 'maximisation'],\n",
              " ['probabilistic', 'spaces', 'time', 'approxi', 'computa'],\n",
              " ['generic', 'complexity', 'necessitate', 'nongeneric', 'conveniently'],\n",
              " ['bias', 'effects', 'statistical', 'study', 'backpropagation'],\n",
              " ['sgng', 'rbf', 'scatterpartitioning', 'errordriven', 'image'],\n",
              " ['rules', 'nofm', 'networks', 'extracted', 'symbolic'],\n",
              " ['pp', 'parallel', 'vol', 'neural', 'networks'],\n",
              " ['task', 'knowledge', 'strategies', 'must', 'declaratflive'],\n",
              " ['neural', 'networks', 'extracting', 'rules', 'artificial'],\n",
              " ['feature', 'selection', 'features', 'subset', 'dles'],\n",
              " ['features', 'irrelevant', 'oblivion', 'domains', 'closing'],\n",
              " ['agents', 'real', 'architecture', 'behavior', 'robots'],\n",
              " ['states', 'inference', 'network', 'probabilistic', 'similar'],\n",
              " ['higher', 'bench', 'ambiguity', 'helmholtz', 'lowerlevel'],\n",
              " ['errors', 'malicious', 'learning', 'equivalences', 'tolerating'],\n",
              " ['posterior', 'model', 'approximative', 'sample', 'class'],\n",
              " ['mixture', 'finite', 'models', 'sound', 'results'],\n",
              " ['reasoning',\n",
              "  'introspective',\n",
              "  'failures',\n",
              "  'knowledge',\n",
              "  'implementationspecific'],\n",
              " ['multicriteria', 'touched', 'confirm', 'ordered', 'asymptotically'],\n",
              " ['adgs', 'markovequivalence', 'model', 'averaging', 'essential'],\n",
              " ['bayesian', 'probability', 'maximal', 'model', 'given'],\n",
              " ['probabilities', 'expose', 'opinion', 'use', 'evidential'],\n",
              " ['utile', 'utree', 'memory', 'suffix', 'state'],\n",
              " ['monotonic', 'exhaustive', 'measure', 'search', 'subset'],\n",
              " ['dialogue', 'email', 'elvis', 'communicative', 'agent'],\n",
              " ['reduced', 'pruning', 'domains', 'thereafter', 'notably'],\n",
              " ['eeg', 'frequencybased', 'mental', 'distinguished', 'signals'],\n",
              " ['reinforcement', 'field', 'learning', 'work', 'computerscience'],\n",
              " ['xcsm', 'xcs', 'nonmarkovian', 'environments', 'internal'],\n",
              " ['vector', 'nbit', 'entries', 'probability', 'neighborhood'],\n",
              " ['minfeatures', 'bias', 'weightedgreedy', 'features', 'irrelevant'],\n",
              " ['tree', 'parametrically', 'described', 'goodness', 'decision'],\n",
              " ['noisy', 'continuous', 'sequence', 'decoders', 'lfsr'],\n",
              " ['development', 'visual', 'deprivation', 'deficits', 'prof'],\n",
              " ['longterm', 'transition', 'context', 'matrices', 'credit'],\n",
              " ['neural', 'networks', 'finished', 'fzi', 'industry'],\n",
              " ['inspection', 'neuropipe', 'ptx', 'defects', 'corrosion'],\n",
              " ['pca', 'images', 'demonstrably', 'embased', 'loglikelihoods'],\n",
              " ['gating', 'experts', 'gated', 'expert', 'series'],\n",
              " ['machine', 'hansch', 'drug', 'learning', 'modelling'],\n",
              " ['front', 'end', 'databases', 'hiped', 'names'],\n",
              " ['goals', 'temporal', 'learning', 'difference', 'achieve'],\n",
              " ['cryptography', 'intractability', 'hold', 'learning', 'boolean'],\n",
              " ['consensus', 'traceevidence', 'coverage', 'method', 'produced'],\n",
              " ['morphemes', 'words', 'morphology', 'recognize', 'morphologically'],\n",
              " ['ebl', 'rules', 'prolog', 'algorithm', 'transforming'],\n",
              " ['trace', 'rule', 'objects', 'invariant', 'neurons'],\n",
              " ['missing', 'variables', 'input', 'hand', 'eg'],\n",
              " ['transformations', 'expressions', 'fixpoints', 'objective', 'products'],\n",
              " ['design', 'organisation', 'development', 'case', 'memory'],\n",
              " ['kalman', 'visual', 'model', 'recognition', 'spatiotemporal'],\n",
              " ['hiding', 'effect', 'baldwin', 'evolution', 'tradeoff'],\n",
              " ['parameter', 'time', 'computation', 'less', 'honing'],\n",
              " ['efficiency', 'regression', 'corrupt', 'greedier', 'greediness'],\n",
              " ['distributions', 'mml', 'component', 'overlapping', 'modelling'],\n",
              " ['mimd', 'execution', 'transputer', 'decomposed', 'model'],\n",
              " ['prototypes', 'neighbor', 'nearest', 'climbing', 'hill'],\n",
              " ['rbf', 'units', 'variant', 'selforganizing', 'model'],\n",
              " ['columbus', 'robot', 'environments', 'operates', 'environment'],\n",
              " ['asp', 'culling', 'gas', 'additive', 'implicit'],\n",
              " ['crossvalidation', 'fibl', 'parameters', 'voting', 'instancebased'],\n",
              " ['reinforcement', 'learning', 'environemnts', 'foraging', 'multirobot'],\n",
              " ['tree', 'greedy', 'trees', 'induced', 'induce'],\n",
              " ['coprime', 'factorizations', 'stabilizability', 'state', 'sycon'],\n",
              " ['attractor', 'attractors', 'localist', 'basins', 'spurious'],\n",
              " ['generalisation', 'theorems', 'enterprise', 'nofreelunch', 'offset'],\n",
              " ['de', 'network', 'structure', 'incremental', 'units'],\n",
              " ['priors', 'mixture', 'trees', 'spanning', 'dirichlet'],\n",
              " ['dna', 'anns', 'reading', 'regions', 'frames'],\n",
              " ['steering', 'signal', 'sensor', 'input', 'mapping'],\n",
              " ['transfer', 'argues', 'viewed', 'knowledge', 'inductive'],\n",
              " ['target', 'source', 'weights', 'network', 'networks'],\n",
              " ['alvinn', 'cascade', 'vehicle', 'quickprop', 'backprop'],\n",
              " ['model', 'phase', 'class', 'selected', 'mixture'],\n",
              " ['maximalmargin', 'vapniks', 'algorithm', 'rosenblatts', 'warmuths'],\n",
              " ['tlp', 'parallelism', 'processors', 'ilp', 'smt'],\n",
              " ['parameter', 'estimation', 'mstep', 'contextdependent', 'geometric'],\n",
              " ['committee', 'bagging', 'boosting', 'machines', 'regression'],\n",
              " ['expert', 'neula', 'shell', 'imprecisely', 'imprecise'],\n",
              " ['queen', 'red', 'measures', 'effect', 'fitness'],\n",
              " ['dms', 'professor', 'parametric', 'grant', 'statistics'],\n",
              " ['crossover', 'multiparent', 'parents', 'generalizes', 'operators'],\n",
              " ['washington', 'francisco', 'gn', 'statistics', 'university'],\n",
              " ['networks', 'neural', 'article', 'chemical', 'regression'],\n",
              " ['codebook', 'parzen', 'gaussians', 'classification', 'window'],\n",
              " ['lifetime', 'programs', 'allocated', 'barrett', 'lifetimes'],\n",
              " ['coding', 'genes', 'evolved', 'problem', 'search'],\n",
              " ['coverage', 'bound', 'concepts', 'maximization', 'upper'],\n",
              " ['mdps', 'spi', 'iteration', 'structured', 'policies'],\n",
              " ['asocs', 'mappings', 'inputoutput', 'adaptive', 'vectors'],\n",
              " ['mwl', 'likelihood', 'marginal', 'working', 'asymptotic'],\n",
              " ['images', 'natural', 'scenes', 'regularities', 'codes'],\n",
              " ['generators', 'epistasis', 'effects', 'eas', 'studying'],\n",
              " ['crossover', 'uniform', 'points', 'redeeming', 'virtues'],\n",
              " ['nesting', 'worlds', 'formulas', 'conditional', 'agree'],\n",
              " ['units', 'higherorder', 'modify', 'orders', 'incremental'],\n",
              " ['codes', 'principle', 'unit', 'predictability', 'factorial'],\n",
              " ['distribution', 'sufficient', 'learning', 'noise', 'pac'],\n",
              " ['inherent', 'rate', 'learning', 'exploration', 'generation'],\n",
              " ['pomdps', 'updates', 'witness', 'dynamicprogramming', 'pomdp'],\n",
              " ['parallelism', 'stack', 'instruction', 'spec', 'dependency'],\n",
              " ['parameter', 'estimation', 'mstep', 'contextdependent', 'geometric'],\n",
              " ['enforcement', 'subtractive', 'multiplicative', 'synaptic', 'segregation'],\n",
              " ['grant', 'nsf', 'project', 'supported', 'funds'],\n",
              " ['criteria', 'three', 'actively', 'informativeness', 'salient'],\n",
              " ['input', 'map', 'grid', 'cluster', 'clusters'],\n",
              " ['adg', 'lci', 'transitive', 'adgs', 'models'],\n",
              " ['engineering', 'geneticalgorithmbased', 'muta', 'method', 'design'],\n",
              " ['ga', 'supersonic', 'optimization', 'domains', 'engineering'],\n",
              " ['rumelhart', 'microstructure', 'explorations', 'mcclelland', 'cognition'],\n",
              " ['msa', 'tree', 'model', 'gene', 'occurs'],\n",
              " ['suppression', 'synapses', 'feedback', 'feedforward', 'selforganized'],\n",
              " ['sampling', 'slice', 'vertical', 'uniform', 'chain'],\n",
              " ['mdps', 'solving', 'ture', 'problems', 'struc'],\n",
              " ['advice', 'reward', 'subsequent', 'gains', 'learner'],\n",
              " ['dirichlet', 'mixtures', 'acid', 'amino', 'database'],\n",
              " ['derivational', 'analogy', 'mismatches', 'solving', 'problem'],\n",
              " ['regular', 'languages', 'nonregular', 'fsa', 'trained'],\n",
              " ['trees', 'coins', 'decision', 'january', 'multiclass'],\n",
              " ['buildable', 'evolution', 'structures', 'physical', 'objects'],\n",
              " ['knowledge', 'bases', 'integration', 'differ', 'experts'],\n",
              " ['guided', 'controllers', 'behaviours', 'robot', 'visually'],\n",
              " ['jump', 'jumps', 'acceptance', 'reversible', 'mcmc'],\n",
              " ['database', 'instancebased', 'cost', 'local', 'data'],\n",
              " ['apple', 'tasting', 'false', 'acceptances', 'rejections'],\n",
              " ['partitions', 'tells', 'error', 'partition', 'tree'],\n",
              " ['preens', 'transputer', 'neural', 'networks', 'running'],\n",
              " ['instability', 'genetic', 'classifiers', 'classifier', 'alecsys'],\n",
              " ['weights', 'amount', 'information', 'derivatives', 'squared'],\n",
              " ['preference', 'ordering', 'algorithm', 'experts', 'instances'],\n",
              " ['evolutionary', 'classical', 'instances', 'strategy', 'methods'],\n",
              " ['hairy', 'noun', 'architecture', 'fly', 'phrase'],\n",
              " ['euclidian', 'neighborhood', 'changed', 'selforganizing', 'distance'],\n",
              " ['agents', 'expert', 'agent', 'imitating', 'imitation'],\n",
              " ['convolutional', 'eigenfaces', 'nearby', 'network', 'selforganizing'],\n",
              " ['policy', 'iteration', 'modified', 'algorithm', 'asynchronous'],\n",
              " ['iwmde', 'posterior', 'density', 'marginal', 'weighting'],\n",
              " ['pac', 'bound', 'presence', 'noisetolerant', 'lower'],\n",
              " ['virulence', 'shortsighted', 'betweenhost', 'clearance', 'modifier'],\n",
              " ['envelopes', 'monotonic', 'envelope', 'semiquantitative', 'methods'],\n",
              " ['metrics', 'memorybased', 'methods', 'attachment', 'prepositional'],\n",
              " ['electrochemical', 'dr', 'transmission', 'dms', 'turner'],\n",
              " ['mbl', 'nlp', 'modules', 'tasks', 'mandatory'],\n",
              " ['readonce', 'formulas', 'membership', 'generic', 'threshold'],\n",
              " ['calculations', 'decoupled', 'tree', 'markov', 'decision'],\n",
              " ['simulation', 'evidence', 'trials', 'er', 'sof'],\n",
              " ['energy', 'solution', 'temperature', 'changes', 'accepted'],\n",
              " ['disjuncts', 'small', 'prone', 'error', 'noise'],\n",
              " ['queries', 'equivalence', 'formulas', 'number', 'membership'],\n",
              " ['exception', 'rippledown', 'rule', 'rules', 'constant'],\n",
              " ['levels', 'rules', 'concepts', 'cover', 'consistent'],\n",
              " ['words', 'plaut', 'orthography', 'mapping', 'effect'],\n",
              " ['caching', 'cases', 'case', 'predict', 'utility'],\n",
              " ['ggla', 'gla', 'lloyd', 'generalized', 'snr'],\n",
              " ['cbp', 'memory', 'planning', 'retrieval', 'indexing'],\n",
              " ['grid', 'associated', 'equipartition', 'method', 'interprocessor'],\n",
              " ['exploration', 'bonuses', 'systematizes', 'turning', 'control'],\n",
              " ['countability', 'finiteness', 'singlehidden', 'tanhx', 'rough'],\n",
              " ['modeling', 'conceptual', 'generic', 'constructive', 'change'],\n",
              " ['adaptive', 'neurocontrol', 'design', 'exemplified', 'manipulator'],\n",
              " ['discriminators',\n",
              "  'unlabelled',\n",
              "  'discriminants',\n",
              "  'ascent',\n",
              "  'informationtheoretic'],\n",
              " ['asocs', 'mode', 'aa', 'adaptive', 'parallel'],\n",
              " ['dollar', 'markov', 'transition', 'state', 'represented'],\n",
              " ['genetic', 'strategy', 'largegrained', 'evaluation', 'executions'],\n",
              " ['anns', 'topologies', 'dynamic', 'nodes', 'lit'],\n",
              " ['coding', 'genetic', 'configurates', 'flowshop', 'implecitely'],\n",
              " ['pasocs', 'concurrent', 'implementations', 'selforganizing', 'classical'],\n",
              " ['scheduling', 'job', 'shop', 'arising', 'genetic'],\n",
              " ['pruning', 'autoprune', 'lprune', 'early', 'obd'],\n",
              " ['similarity', 'assessment', 'adaptations', 'adaptable', 'cases'],\n",
              " ['knowledge', 'casebased', 'learning', 'different', 'mechanisms'],\n",
              " ['cbr', 'casebased', 'knowledge', 'case', 'assessment'],\n",
              " ['linear', 'small', 'points', 'programs', 'number'],\n",
              " ['nettalk', 'pronunciation', 'words', 'system', 'texttospeech'],\n",
              " ['lpec', 'penalty', 'exact', 'formulation', 'constraints'],\n",
              " ['planning', 'replay', 'merging', 'cases', 'plan'],\n",
              " ['planning', 'plans', 'plan', 'mixedinitiative', 'rationale'],\n",
              " ['networks', 'initialized', 'origin', 'minima', 'generalize'],\n",
              " ['ic', 'pc', 'algorithms', 'equation', 'inducing'],\n",
              " ['manyparticle', 'intermediate', 'store', 'hierarchical', 'simulations'],\n",
              " ['orthogonal', 'oil', 'nodes', 'hidden', 'incremental'],\n",
              " ['metalearning', 'selection', 'users', 'accuracy', 'criterion'],\n",
              " ['attractors', 'continuous', 'object', 'network', 'points'],\n",
              " ['sawing', 'graph', 'ea', 'coloring', 'penalty'],\n",
              " ['independent', 'kurtosis', 'estimate', 'component', 'components'],\n",
              " ['grids', 'place', 'places', 'evidence', 'recognition'],\n",
              " ['constructive', 'ci', 'distinction', 'induction', 'unclear'],\n",
              " ['extensionally', 'defined', 'intensionally', 'database', 'designer'],\n",
              " ['formalisms', 'partition', 'conditioning', 'framework', 'logic'],\n",
              " ['sparseness', 'sparsely', 'compression', 'bit', 'training'],\n",
              " ['nondecomposable', 'graphical', 'gaussian', 'wishart', 'calculate'],\n",
              " ['td', 'respect', 'values', 'bertsekas', 'baird'],\n",
              " ['control', 'lazy', 'learning', 'remembering', 'complex'],\n",
              " ['gp', 'trees', 'functional', 'symbolic', 'regression'],\n",
              " ['compounds', 'chemical', 'binding', 'screening', 'monomers'],\n",
              " ['cross', 'validation', 'hypothesis', 'rate', 'bound'],\n",
              " ['error', 'distribution', 'minimizer', 'true', 'empirical'],\n",
              " ['implication', 'subsumption', 'clauses', 'timplication', 'clause'],\n",
              " ['theory', 'types', 'machine', 'unsupervised', 'learning'],\n",
              " ['variance', 'error', 'bias', 'codes', 'neighbor'],\n",
              " ['search', 'collective', 'engine', 'gp', 'memory'],\n",
              " ['similarity', 'relevance', 'context', 'judging', 'contrary'],\n",
              " ['reactive', 'navigation', 'system', 'control', 'online'],\n",
              " ['onsite', 'filtering', 'classifier', 'cost', 'realworld'],\n",
              " ['response', 'papers', 'explore', 'value', 'finding'],\n",
              " ['holtes', 'holte', 'multilevel', 'decision', 'trees'],\n",
              " ['dataoriented', 'graphemetophoneme', 'spelling', 'phonetic', 'conversion'],\n",
              " ['density', 'entropy', 'emma', 'parametric', 'rule'],\n",
              " ['probabilities', 'cost', 'search', 'experiments', 'success'],\n",
              " ['map', 'orientation', 'phase', 'ansatz', 'tesselation'],\n",
              " ['load', 'balancing', 'adaptive', 'communication', 'efficiency'],\n",
              " ['bitsback', 'coding', 'codewords', 'source', 'codeword'],\n",
              " ['opponent', 'player', 'maximin', 'play', 'weaker'],\n",
              " ['estep', 'cvq', 'hintons', 'zemel', 'quantizer'],\n",
              " ['separation', 'matrix', 'mixing', 'transformation', 'identification'],\n",
              " ['separation', 'source', 'signals', 'noise', 'performance'],\n",
              " ['additive', 'correlated', 'separation', 'sources', 'multilayer'],\n",
              " ['experts', 'algorithms', 'applications', 'family', 'making'],\n",
              " ['ilpr', 'unseen', 'naive', 'sometimes', 'dependencies'],\n",
              " ['lp', 'simulation', 'method', 'detected', 'process'],\n",
              " ['individuals', 'social', 'arguments', 'behavior', 'genetic'],\n",
              " ['proben', 'datasets', 'benchmarking', 'rules', 'collection'],\n",
              " ['neurochess', 'chess', 'learns', 'differencing', 'board'],\n",
              " ['memory', 'indexing', 'prototype', 'contains', 'cases'],\n",
              " ['geometric', 'patterns', 'pattern', 'hausdorff', 'landmark'],\n",
              " ['measure', 'classifier', 'problem', 'function', 'value'],\n",
              " ['attractors', 'articulated', 'networks', 'recurrent', 'attractor'],\n",
              " ['simplification', 'tree', 'trees', 'comprehensible', 'survey'],\n",
              " ['plot', 'cusum', 'sampler', 'path', 'markov'],\n",
              " ['gibbs', 'sampler', 'easy', 'image', 'bounds'],\n",
              " ['ot', 'coupled', 'hmms', 'state', 'cn'],\n",
              " ['fertility', 'frequentist', 'formulations', 'analyses', 'agricultural'],\n",
              " ['chains', 'finite', 'stopping', 'markov', 'criterion'],\n",
              " ['chains', 'acting', 'population', 'mixing', 'high'],\n",
              " ['diagnostic', 'qmr', 'qmrdt', 'hindered', 'methods'],\n",
              " ['centroids', 'rbf', 'networks', 'determinant', 'coevolving'],\n",
              " ['subsets', 'tree', 'feature', 'candidate', 'features'],\n",
              " ['crisis', 'response', 'automaticallygenerated', 'humancomputer', 'incas'],\n",
              " ['reactive', 'subgoals', 'plans', 'rules', 'competitionbased'],\n",
              " ['lowlevel', 'robot', 'enhance', 'highlevel', 'approaches'],\n",
              " ['implementational',\n",
              "  'interpretability',\n",
              "  'notation',\n",
              "  'recommendations',\n",
              "  'particular'],\n",
              " ['object', 'manipulator', 'track', 'position', 'moving'],\n",
              " ['fbd', 'causal', 'covariance', 'predictive', 'information'],\n",
              " ['decision', 'rules', 'learning', 'flight', 'tactical'],\n",
              " ['concepts', 'biasing', 'bias', 'learning', 'inductive'],\n",
              " ['networks', 'issues', 'neural', 'selecting', 'units'],\n",
              " ['causation', 'influences', 'causal', 'inductive', 'modeltheoretic'],\n",
              " ['interface', 'run', 'bound', 'alltoall', 'broadcast'],\n",
              " ['contextsensitive',\n",
              "  'knowledge',\n",
              "  'complexity',\n",
              "  'descriptive',\n",
              "  'expressiveness'],\n",
              " ['bootstrap', 'methods', 'sandwich', 'hessian', 'partly'],\n",
              " ['dirichlet', 'mixtures', 'neurological', 'normals', 'arising'],\n",
              " ['manipulator', 'object', 'position', 'controllers', 'moving'],\n",
              " ['aa', 'adaptive', 'overviews', 'topologically', 'discriminate'],\n",
              " ['sources', 'ml', 'noise', 'separation', 'source'],\n",
              " ['procedure', 'health', 'diagnosticrecovery', 'causes', 'robust'],\n",
              " ['case', 'conflicts', 'combination', 'retrieved', 'minimum'],\n",
              " ['csp', 'satisfaction', 'dcsp', 'cbr', 'constraint'],\n",
              " ['pac', 'bias', 'determinations', 'learning', 'syntactic'],\n",
              " ['mapss', 'parameters', 'free', 'model', 'prior'],\n",
              " ['generalisation', 'seens', 'virtual', 'normalising', 'holtes'],\n",
              " ['libraries', 'conversational', 'guidelines', 'designing', 'cbr'],\n",
              " ['diagnosis', 'database', 'missing', 'information', 'since'],\n",
              " ['minimum', 'binary', 'weights', 'example', 'learnt'],\n",
              " ['credulous', 'default', 'expected', 'optacc', 'accuracy'],\n",
              " ['pressure', 'parsimony', 'length', 'effects', 'compression'],\n",
              " ['xcs', 'populations', 'condensation', 'wilsons', 'evolve'],\n",
              " ['cn', 'rise', 'conquering', 'dwindling', 'stilluncovered'],\n",
              " ['weights', 'nextascent', 'quantifies', 'parsimony', 'differing'],\n",
              " ['subjects', 'human', 'expressions', 'facial', 'interpolated'],\n",
              " ['structured', 'tool', 'quali', 'smog', 'submodels'],\n",
              " ['ranking', 'degree', 'static', 'search', 'genetic'],\n",
              " ['mutation', 'crossover', 'roles', 'captured', 'theoretically'],\n",
              " ['tan', 'attributes', 'continuous', 'discrete', 'classifier'],\n",
              " ['processes', 'representation', 'systems', 'bayesian', 'language'],\n",
              " ['limitations', 'constructive', 'neurons', 'devising', 'fullyrecurrent'],\n",
              " ['numeric', 'weighting', 'attributes', 'cases', 'methods'],\n",
              " ['constructions', 'saturation', 'linear', 'stabilize', 'uncontrolled'],\n",
              " ['ensembles', 'seismic', 'anns', 'classification', 'integration'],\n",
              " ['de', 'paris', 'paul', 'recherche', 'france'],\n",
              " ['preferences', 'user', 'schedule', 'cabins', 'revision'],\n",
              " ['gp', 'hierarchy', 'behavior', 'coordination', 'fuzzy'],\n",
              " ['model', 'combination', 'vectors', 'gradient', 'part'],\n",
              " ['collective', 'society', 'expedite', 'insects', 'action'],\n",
              " ['annealed', 'tighter', 'curve', 'theory', 'bound'],\n",
              " ['array', 'targets', 'nearfield', 'sensors', 'requirement'],\n",
              " ['agent', 'cibased', 'cila', 'si', 'ci'],\n",
              " ['selforganising', 'teaching', 'neurons', 'clusterbasis', 'neuronbasis'],\n",
              " ['datadriven', 'incy', 'modelguided', 'inductive', 'declarative'],\n",
              " ['environment', 'plans', 'target', 'tactical', 'noisy'],\n",
              " ['navigation', 'reactive', 'realtime', 'autonomous', 'robust'],\n",
              " ['theory', 'curves', 'bounds', 'asymptotics', 'behavior'],\n",
              " ['languages', 'eg', 'parenthesis', 'nnpda', 'prerequisite'],\n",
              " ['boltzmann', 'feedforward', 'sigmoid', 'expert', 'machines'],\n",
              " ['gp', 'size', 'programs', 'generality', 'evolved'],\n",
              " ['cause', 'causal', 'canonical', 'definition', 'effect'],\n",
              " ['fuzzy', 'logic', 'flc', 'flcs', 'focussing'],\n",
              " ['regression', 'likelihood', 'estimation', 'nonparametric', 'estimators'],\n",
              " ['evolved', 'empirically', 'automatically', 'programs', 'modelcomparison'],\n",
              " ['hindsight', 'dpns', 'osn', 'time', 'dpn'],\n",
              " ['optimism', 'pessimism', 'preferred', 'naive', 'cautious'],\n",
              " ['iohmms', 'dependencies', 'apriori', 'hidden', 'hmms'],\n",
              " ['flat', 'minimum', 'error', 'argument', 'algorithm'],\n",
              " ['reactive', 'explanations', 'rules', 'phase', 'gaps'],\n",
              " ['backtracks', 'valueordering', 'sane', 'problemspecific', 'ordering'],\n",
              " ['guidelines', 'authoring', 'cbr', 'according', 'conversational'],\n",
              " ['speedaccuracy', 'skills', 'human', 'decelerations', 'lasting'],\n",
              " ['qlearning', 'max', 'classifier', 'vscs', 'cs'],\n",
              " ['coding', 'sparse', 'investigated', 'compact', 'biological'],\n",
              " ['piecewiseanalytic', 'shattered', 'slighly', 'nonempty', 'classes'],\n",
              " ['system', 'casebased', 'characteristics', 'methodology', 'systems'],\n",
              " ['situations', 'planning', 'reasoner', 'abstract', 'adapting'],\n",
              " ['mle', 'parameter', 'rate', 'asymptotically', 'converges'],\n",
              " ['advice', 'stories', 'conditions', 'recommendation', 'storys'],\n",
              " ['reparameterisation', 'secondary', 'mcmc', 'modelling', 'mixture'],\n",
              " ['interfaces', 'servers', 'web', 'server', 'email'],\n",
              " ['survival', 'model', 'uncertainty', 'clinical', 'clinically'],\n",
              " ['averaging', 'bootstrap', 'samples', 'bootstrapbased', 'selection'],\n",
              " ['arcing', 'adaboost', 'game', 'error', 'predictors'],\n",
              " ['ccbr', 'questions', 'reasoning', 'inferencing', 'users'],\n",
              " ['readonce', 'formulas', 'queries', 'formula', 'membership'],\n",
              " ['raam', 'patterns', 'structures', 'distributed', 'aining'],\n",
              " ['generated', 'text', 'markov', 'distribution', 'automata'],\n",
              " ['claudien', 'clausal', 'regularities', 'specification', 'discovery'],\n",
              " ['attributes', 'relieff', 'dependencies', 'impurity', 'relief'],\n",
              " ['series', 'chaotic', 'prediction', 'operator', 'search'],\n",
              " ['beam', 'literals', 'ilp', 'bias', 'heuristic'],\n",
              " ['relieff', 'deal', 'kira', 'rendell', 'myopic'],\n",
              " ['chess', 'tdleaf', 'rating', 'backgammon', 'td'],\n",
              " ['metropolishastings', 'estimator', 'sequential', 'reversible', 'algorithm'],\n",
              " ['pose', 'ica', 'faces', 'temporal', 'pca'],\n",
              " ['regression', 'mixture', 'dirichlet', 'smoothing', 'multidimensional'],\n",
              " ['crossover', 'multipoint', 'operators', 'recombination', 'theoretical'],\n",
              " ['mdn', 'discriminant', 'analysis', 'aspects', 'ants'],\n",
              " ['sasat', 'gsat', 'satisfiability', 'selman', 'sat'],\n",
              " ['discretization',\n",
              "  'entropybased',\n",
              "  'errorbased',\n",
              "  'comparison',\n",
              "  'minimization'],\n",
              " ['sign', 'signlinear', 'let', 'outputs', 'first'],\n",
              " ['ev', 'jyj', 'ieee', 'ffi', 'control'],\n",
              " ['reconciliation', 'variable', 'reconciled', 'data', 'gross'],\n",
              " ['hierarchy', 'categories', 'documents', 'hierarchies', 'classifying'],\n",
              " ['tree', 'pruning', 'decision', 'predictions', 'procedure'],\n",
              " ['concept', 'lt', 'geometric', 'class', 'boolean'],\n",
              " ['criteria', 'pessimistic', 'side', 'well', 'vapnikchervonenkis'],\n",
              " ['methods', 'protein', 'probabilistic', 'prediction', 'perform'],\n",
              " ['error', 'leaveoneout', 'bounds', 'estimate', 'sanitycheck'],\n",
              " ['generalisation', 'observes', 'world', 'states', 'actors'],\n",
              " ['software', 'makeup', 'minimises', 'mirrors', 'system'],\n",
              " ['species', 'preys', 'predator', 'predators', 'coevolution'],\n",
              " ['derivatives', 'units', 'second', 'calculation', 'weights'],\n",
              " ['structures', 'program', 'syntactical', 'discuss', 'treat'],\n",
              " ['styles', 'generalization', 'applications', 'accurate', 'lend'],\n",
              " ['regarding', 'recurrent', 'identifiability', 'cited', 'minimality'],\n",
              " ['lia', 'asocs', 'topologies', 'lit', 'locationindependent'],\n",
              " ['bellman', 'equation', 'markov', 'chains', 'states'],\n",
              " ['design', 'sbf', 'indexing', 'index', 'cases'],\n",
              " ['movement', 'movements', 'observed', 'oxbow', 'structure'],\n",
              " ['constructive', 'space', 'aqdci', 'representation', 'datadriven'],\n",
              " ['data', 'possibility', 'base', 'classifiers', 'types'],\n",
              " ['reconstruction', 'methods', 'physical', 'activity', 'rats'],\n",
              " ['shift', 'profile', 'selfmotion', 'hd', 'activity'],\n",
              " ['decomposition', 'loss', 'biasvariance', 'misclassification', 'commonly'],\n",
              " ['patent', 'sorter', 'sorting', 'fitness', 'hardware'],\n",
              " ['ax', 'parametrically', 'solution', 'nonzero', 'proposed'],\n",
              " ['temporal', 'faces', 'viewpoint', 'views', 'invariant'],\n",
              " ['neuralnetwork', 'datamining', 'networks', 'times', 'models'],\n",
              " ['stopping', 'early', 'asymptotic', 'nonasymptotic', 'overtraining'],\n",
              " ['clustering', 'mathematical', 'database', 'robust', 'kmedian'],\n",
              " ['search', 'space', 'stochastic', 'atris', 'concept'],\n",
              " ['neighborhood', 'eas', 'shape', 'local', 'selection'],\n",
              " ['qualitative', 'relationships', 'ambiguous', 'numeric', 'bounds'],\n",
              " ['rectified', 'gaussian', 'cooperative', 'pattern', 'nonnegative'],\n",
              " ['algorithm', 'fast', 'independent', 'semiadaptive', 'userdetned'],\n",
              " ['entropy', 'events', 'minimal', 'barlows', 'reiterated'],\n",
              " ['constructive', 'space', 'aqdci', 'representation', 'datadriven'],\n",
              " ['relieff', 'attributes', 'quality', 'estimating', 'regressional'],\n",
              " ['rlgg', 'logic', 'ir', 'area', 'programming'],\n",
              " ['bayesian', 'frequentist', 'preferable', 'outlined', 'argued'],\n",
              " ['belief', 'algorithm', 'database', 'underlying', 'dagfaithful'],\n",
              " ['attributes', 'attribute', 'database', 'belief', 'algorithm'],\n",
              " ['svm', 'approximation', 'polynomial', 'series', 'founded'],\n",
              " ['interconnect', 'mcm', 'dense', 'implementation', 'requirement'],\n",
              " ['positive', 'clauses', 'negative', 'specialize', 'examples'],\n",
              " ['positive', 'negative', 'examples', 'computation', 'sldtree'],\n",
              " ['qualitative', 'cognitive', 'modeling', 'decisionaiding', 'firm'],\n",
              " ['continuous', 'reasoning', 'casebased', 'domains', 'navigation'],\n",
              " ['competition', 'programs', 'challenge', 'research', 'ashwin'],\n",
              " ['ci', 'ordering', 'nodes', 'tests', 'bayesianbelief'],\n",
              " ['criterion', 'covariance', 'inflation', 'prediction', 'regression'],\n",
              " ['mng', 'magnetic', 'clusters', 'migrate', 'data'],\n",
              " ['awarded', 'naval', 'office', 'research', 'foundation'],\n",
              " ['profiling', 'errors', 'parameters', 'measurement', 'methods'],\n",
              " ['plasticity', 'contextual', 'model', 'bottomup', 'clustering'],\n",
              " ['adaboost', 'hypotheses', 'ensemble', 'deploy', 'boosted'],\n",
              " ['infusion', 'plasticity', 'al', 'et', 'bear'],\n",
              " ['boxes', 'polyhedron', 'queries', 'log', 'union'],\n",
              " ['topology', 'associated', 'stochastic', 'optimization', 'enhancements'],\n",
              " ['belief', 'beliefs', 'networks', 'loops', 'revision'],\n",
              " ['south', 'wales', 'coded', 'schedule', 'hand'],\n",
              " ['problemspecific', 'space', 'subspaces', 'utilizing', 'redundant'],\n",
              " ['forte', 'firstorder', 'revision', 'revisions', 'refinement'],\n",
              " ['fgen', 'sequences', 'absence', 'selected', 'representation'],\n",
              " ['genetic', 'algorithm', 'underscore', 'parallel', 'good'],\n",
              " ['conflict', 'outcome', 'base', 'tool', 'deveolped'],\n",
              " ['cb', 'casebased', 'learning', 'concept', 'similarity'],\n",
              " ['annoying', 'beginnings', 'bewildering', 'invigorating', 'newcomers'],\n",
              " ['mbr', 'pebls', 'data', 'bayesian', 'classifier'],\n",
              " ['knearestneighbor', 'deflne', 'metric', 'distance', 'object'],\n",
              " ['hybrid', 'staged', 'genetic', 'search', 'local'],\n",
              " ['immune', 'sharing', 'model', 'ga', 'fitness'],\n",
              " ['subspaces', 'accurate', 'representations', 'depths', 'subareas'],\n",
              " ['ij', 'boltzmann', 'saul', 'jordan', 'state'],\n",
              " ['coevolutionary', 'noncoevolutionary', 'approach', 'emer', 'gent'],\n",
              " ['idbd', 'learningrate', 'algorithm', 'lms', 'bias'],\n",
              " ['pruning', 'autoprune', 'lprune', 'obd', 'strength'],\n",
              " ['nets', 'customized', 'user', 'connectionist', 'allow'],\n",
              " ['caseadaptation', 'experiencebased', 'old', 'reasoning', 'cascading'],\n",
              " ['utility', 'systems', 'controlrule', 'problem', 'resistant'],\n",
              " ['remindings', 'structural', 'stage', 'macfac', 'psychological'],\n",
              " ['bounds', 'factor', 'constant', 'online', 'respect'],\n",
              " ['assessment', 'cases', 'similarity', 'description', 'old'],\n",
              " ['memory', 'retrieval', 'discusses', 'modeling', 'issues'],\n",
              " ['variational',\n",
              "  'approximations',\n",
              "  'substructures',\n",
              "  'approximating',\n",
              "  'probability'],\n",
              " ['asocs', 'mode', 'adaptive', 'parallel', 'processing'],\n",
              " ['climbing', 'hill', 'genetic', 'dynamic', 'search'],\n",
              " ['vehicle', 'controller', 'controllers', 'autonomous', 'software'],\n",
              " ['solving', 'speedup', 'problem', 'theoretical', 'congenial'],\n",
              " ['density', 'nonparametric', 'operations', 'estimation', 'hydrodynamics'],\n",
              " ['entailment', 'firstorder', 'horn', 'arity', 'programs'],\n",
              " ['npcomplete', 'canonical', 'problems', 'gas', 'sat'],\n",
              " ['actions', 'agents', 'coordinated', 'equilibrium', 'observable'],\n",
              " ['experiences', 'familiar', 'generic', 'abstractions', 'mechanisms'],\n",
              " ['mutation', 'objective', 'rate', 'string', 'bit'],\n",
              " ['behaviors', 'real', 'simulation', 'world', 'might'],\n",
              " ['uncertainty', 'students', 'itss', 'startling', 'intervention'],\n",
              " ['satisfiability', 'nnsat', 'gsat', 'sat', 'solving'],\n",
              " ['life', 'alnns', 'artificial', 'neural', 'networks'],\n",
              " ['views', 'viewnet', 'object', 'view', 'category'],\n",
              " ['fir', 'impulse', 'algorithms', 'note', 'multilayer'],\n",
              " ['approximation', 'error', 'asymptotical', 'function', 'number'],\n",
              " ['graph', 'prior', 'determination', 'inverse', 'propose'],\n",
              " ['suspended', 'opportunity', 'working', 'recognition', 'opportunistic'],\n",
              " ['training', 'size', 'solution', 'error', 'optimal'],\n",
              " ['training', 'excess', 'freedom', 'degrees', 'convergence'],\n",
              " ['rulearner', 'map', 'explicit', 'rule', 'galois'],\n",
              " ['cases', 'case', 'fish', 'shrink', 'deflne'],\n",
              " ['pga', 'individuals', 'correlation', 'salesman', 'jump'],\n",
              " ['conferences', 'theme', 'casebased', 'recent', 'representations'],\n",
              " ['lexicology', 'lexical', 'acquisition', 'language', 'competenceoriented'],\n",
              " ['estimators', 'approximable', 'sure', 'optimise', 'mild'],\n",
              " ['data', 'complete', 'informationtheoretic', 'missing', 'criterion'],\n",
              " ['hockey', 'league', 'nhl', 'ossp', 'tabu'],\n",
              " ['pfsa', 'alphabet', 'mml', 'symbol', 'pfsas'],\n",
              " ['ar', 'moves', 'series', 'cuedfinfengtr', 'cheaper'],\n",
              " ['planning', 'casebased', 'finegrained', 'inferential', 'learn'],\n",
              " ['scbr', 'instancebased', 'learner', 'constituent', 'target'],\n",
              " ['determinations',\n",
              "  'partial',\n",
              "  'attributes',\n",
              "  'preprocessingbased',\n",
              "  'admissible'],\n",
              " ['explanations', 'measure', 'explanation', 'favoured', 'symbol'],\n",
              " ['particles',\n",
              "  'discovered',\n",
              "  'decentralized',\n",
              "  'synchronization',\n",
              "  'evolutionary'],\n",
              " ['infinitedimensional', 'bootstrap', 'theorem', 'due', 'applicatons'],\n",
              " ['recurrence', 'rsa', 'survival', 'predicted', 'times'],\n",
              " ['query', 'committee', 'queries', 'twomember', 'ave'],\n",
              " ['principal', 'nonlinear', 'feature', 'pixel', 'integral'],\n",
              " ['decision', 'relationships', 'graphical', 'knowledge', 'model'],\n",
              " ['learners', 'example', 'ds', 'learner', 'region'],\n",
              " ['trainer', 'concepts', 'marvin', 'concept', 'program'],\n",
              " ['behaviors', 'environments', 'environmental', 'ecological', 'complexity'],\n",
              " ['clauses', 'determinate', 'subsumption', 'horn', 'klocal'],\n",
              " ['stgp', 'manipulation', 'list', 'functions', 'typed'],\n",
              " ['transfer', 'rcc', 'units', 'proof', 'recurrent'],\n",
              " ['subsumption', 'logic', 'substitution', 'decidable', 'superset'],\n",
              " ['algorithm', 'highorder', 'hypothesisboosting', 'paclearn', 'features'],\n",
              " ['relieff', 'lookahead', 'inductive', 'attributes', 'world'],\n",
              " ['maxq', 'hierarchical', 'semanticsas', 'decomposition', 'value'],\n",
              " ['causality', 'gp', 'changes', 'object', 'discussed'],\n",
              " ['adaboost', 'voting', 'methods', 'variance', 'variants'],\n",
              " ['conception', 'intelligence', 'gradual', 'informal', 'brings'],\n",
              " ['convolution',\n",
              "  'compositional',\n",
              "  'items',\n",
              "  'representations',\n",
              "  'reconstructions'],\n",
              " ['carmel', 'markovitch', 'prefixclosed', 'samples', 'report'],\n",
              " ...]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD7AW4j9OT1v"
      },
      "outputs": [],
      "source": [
        "topicrank = spacy.load(\"en_core_web_lg-3.7.1-py3-none-any/en_core_web_lg/en_core_web_lg-3.7.1\")\n",
        "positionrank = spacy.load(\"en_core_web_lg-3.7.1-py3-none-any/en_core_web_lg/en_core_web_lg-3.7.1\")\n",
        "textrank = spacy.load(\"en_core_web_lg-3.7.1-py3-none-any/en_core_web_lg/en_core_web_lg-3.7.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA6bT_tdOT1v",
        "outputId": "9364eecd-2eb1-443c-a58b-170048ead8df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pytextrank.topicrank.TopicRankFactory at 0x78ee77db1e10>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textrank.add_pipe(\"textrank\")\n",
        "positionrank.add_pipe(\"positionrank\")\n",
        "topicrank.add_pipe(\"topicrank\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC_VchqDOT1v"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "===== This cell will execute all baselines =====\n",
        "\"\"\"\n",
        "\n",
        "#oR = Rake(ranking_metric=Metric.WORD_FREQUENCY)\n",
        "yake_custom_keyword_extractor = yake.KeywordExtractor(lan='en', n=3, dedupLim=0.9, dedupFunc='seqm', windowsSize=1, top=T, features=None)\n",
        "\n",
        "#oRake_keywords = []\n",
        "yake_keywords = []\n",
        "textrank_keywords = []\n",
        "positionrank_keywords = []\n",
        "topicrank_keywords = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(abstracts)):\n",
        "\n",
        "\n",
        "    # ===== Original Rake =====\n",
        "    \"\"\"\n",
        "    oR.extract_keywords_from_text(abstracts[i])\n",
        "    ranked_keywords = oR.get_ranked_phrases_with_scores()\n",
        "\n",
        "    unique_ranked_keywords = list(set(ranked_keywords))\n",
        "    unique_ranked_keywords = sorted(unique_ranked_keywords, key=lambda x: x[0], reverse=True)\n",
        "    oRake_sampled_keywords = sample_keywords(unique_ranked_keywords, 100.0)[:T]\n",
        "    oRake_keywords.append([keyphrase for _, keyphrase in oRake_sampled_keywords])\n",
        "    \"\"\"\n",
        "\n",
        "    # ===== YAKE =====\n",
        "\n",
        "    yake_res = yake_custom_keyword_extractor.extract_keywords(abstracts[i])\n",
        "    unique_ranked_keywords = list(set(yake_res))\n",
        "    yake_sampled_keywords = sorted(unique_ranked_keywords, key=lambda x: x[1], reverse=True)\n",
        "    yake_keywords.append([keyphrase for keyphrase, _ in yake_sampled_keywords])\n",
        "\n",
        "    # ===== TextRank =====\n",
        "\n",
        "    textrank_res = textrank(abstracts[i])\n",
        "    if len(textrank_res._.phrases) >= T:\n",
        "        textrank_keywords.append([textrank_res._.phrases[j].text for j in range(T)])\n",
        "    else:\n",
        "        textrank_keywords.append([keyphrase.text for keyphrase in textrank_res._.phrases])\n",
        "\n",
        "    # ===== PositionRank =====\n",
        "\n",
        "    positionrank_res = positionrank(abstracts[i])\n",
        "    if len(positionrank_res._.phrases) >= T:\n",
        "        positionrank_keywords.append([positionrank_res._.phrases[j].text for j in range(T)])\n",
        "    else:\n",
        "        positionrank_keywords.append([keyphrase.text for keyphrase in positionrank_res._.phrases])\n",
        "\n",
        "    # ===== TopicRank =====\n",
        "\n",
        "    topicrank_res = topicrank(abstracts[i])\n",
        "    if len(topicrank_res._.phrases) >= T:\n",
        "        topicrank_keywords.append([topicrank_res._.phrases[j].text for j in range(T)])\n",
        "    else:\n",
        "        topicrank_keywords.append([keyphrase.text for keyphrase in topicrank_res._.phrases])\n",
        "\n",
        "    print(f'Abstract: {i}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnNcXVFmOT1v",
        "outputId": "c69d1897-8d0f-415e-8e24-95906c2f5393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2277\n",
            "2277\n",
            "2277\n",
            "2277\n"
          ]
        }
      ],
      "source": [
        "#print(len(oRake_keywords))\n",
        "print(len(yake_keywords))\n",
        "print(len(textrank_keywords))\n",
        "print(len(positionrank_keywords))\n",
        "print(len(topicrank_keywords))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO20ffN-OT1w"
      },
      "source": [
        "### Print Keywords (for evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avzsCGihOT1w"
      },
      "outputs": [],
      "source": [
        "oRake_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALN85hFVOT1w",
        "outputId": "753d7890-5f17-4bee-9ed6-01b8c9707bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['include hidden Markov',\n",
              "  'problem convex combinations',\n",
              "  'Markov model HMM',\n",
              "  'MEME Gibbs sampler',\n",
              "  'alignment MEME Gibbs'],\n",
              " ['govern colposuspension cure',\n",
              "  'learning algorithmsR FOIL',\n",
              "  'algorithmsR FOIL InductH',\n",
              "  'FOIL InductH identify',\n",
              "  'colposuspension cure rate'],\n",
              " ['communication resource bandwidth',\n",
              "  'important problem allocate',\n",
              "  'channel reuse constraint',\n",
              "  'systems important problem',\n",
              "  'allocate communication resource'],\n",
              " ['bring techniques operations',\n",
              "  'paper bring techniques',\n",
              "  'theory Markov decision',\n",
              "  'Markov decision processes',\n",
              "  'introducing theory Markov'],\n",
              " ['enhance representational power',\n",
              "  'representational power probability',\n",
              "  'leads greater efficiency',\n",
              "  'expands applicability graphical',\n",
              "  'framework approximating graphical'],\n",
              " ['Goldszmidt Goldszmidt PKreduced',\n",
              "  'Probabilisitic Inference DAmbrosio',\n",
              "  'Horvitz anytime Dean',\n",
              "  'Incremental Probabilisitic Inference',\n",
              "  'Realtime Decision algorithms'],\n",
              " ['improve computational efficiency',\n",
              "  'seeks improve computational',\n",
              "  'macrooperators prove theorems',\n",
              "  'rules macrooperators prove',\n",
              "  'control rules macrooperators'],\n",
              " ['space algorithm Hir',\n",
              "  'Hischbergs linear space',\n",
              "  'extend Hischbergs linear',\n",
              "  'result Myers Miller',\n",
              "  'Myers Miller MMb'],\n",
              " ['guess test trials',\n",
              "  'natural questions arise',\n",
              "  'number mistakes offline',\n",
              "  'constant number mistakes',\n",
              "  'make constant number'],\n",
              " ['GRKPACK collection Fortran',\n",
              "  'families Based RKPACK',\n",
              "  'Smoothing Spline ANalysis',\n",
              "  'Based RKPACK fits',\n",
              "  'introduced Smoothing Spline'],\n",
              " ['hard learning problems',\n",
              "  'length mathematical LISP',\n",
              "  'discovering learning rules',\n",
              "  'ability generalisation testing',\n",
              "  'similar Genetic Programming'],\n",
              " ['needed Bayesian hypothesis',\n",
              "  'quantity needed Bayesian',\n",
              "  'data World Fertility',\n",
              "  'Fertility Survey shown',\n",
              "  'World Fertility Survey'],\n",
              " ['problem Experiments evaluate',\n",
              "  'utility problem Experiments',\n",
              "  'general utility problem',\n",
              "  'learned knowledge Plotting',\n",
              "  'amount learned knowledge'],\n",
              " ['PROSITE dictionary sites',\n",
              "  'HMM PROFILESEARCH technique',\n",
              "  'Models HMMs applied',\n",
              "  'Hidden Markov Models',\n",
              "  'Markov Models HMMs'],\n",
              " ['feedforward networks learning',\n",
              "  'paper explores effect',\n",
              "  'selection feedforward networks',\n",
              "  'Carlo techniques magnitude',\n",
              "  'Monte Carlo techniques'],\n",
              " ['realistic conditions Finally',\n",
              "  'conditions Finally implement',\n",
              "  'Finally implement extended',\n",
              "  'Alvarez Squires original',\n",
              "  'medial temporal lobe'],\n",
              " ['stripes Experimental evidence',\n",
              "  'dominance stripes Experimental',\n",
              "  'normalization rule Inputs',\n",
              "  'Experiments suggested test',\n",
              "  'Experimental evidence frog'],\n",
              " ['error rates set',\n",
              "  'validating single classifier',\n",
              "  'process drawing classifier',\n",
              "  'drawing classifier random',\n",
              "  'test error rate'],\n",
              " ['noisy data Specifically',\n",
              "  'Finally show statistical',\n",
              "  'types noise Finally',\n",
              "  'approximately correct PAC',\n",
              "  'defined Valiant Val'],\n",
              " ['simulated automobile race',\n",
              "  'network function approximator',\n",
              "  'lookup neural network',\n",
              "  'performance neural network',\n",
              "  'neural network function'],\n",
              " ['based artificial evolution',\n",
              "  'strategies Othello randommoving',\n",
              "  'discover strategies Othello',\n",
              "  'advantage changed environment',\n",
              "  'Othello randommoving opponent'],\n",
              " ['Query model PAC',\n",
              "  'noisetolerant PAC algorithms',\n",
              "  'Statistical Query model',\n",
              "  'Drucker Schapire Simard',\n",
              "  'PAC model classification'],\n",
              " ['amenable neural network',\n",
              "  'solutions Neural network',\n",
              "  'nature Comparison supervised',\n",
              "  'occurring nature Comparison',\n",
              "  'Comparison supervised unsupervised'],\n",
              " ['Mellon University Pittsburgh',\n",
              "  'Department Statistics Carnegie',\n",
              "  'Statistics Carnegie Mellon',\n",
              "  'Larry Wasserman Associate',\n",
              "  'Carnegie Mellon University'],\n",
              " ['identification time series',\n",
              "  'prediction NARX Nonlinear',\n",
              "  'NARX Nonlinear AutoRegressive',\n",
              "  'series prediction NARX',\n",
              "  'time series prediction'],\n",
              " ['family considered face',\n",
              "  'space family considered',\n",
              "  'main idea address',\n",
              "  'version space family',\n",
              "  'disjunctive version space'],\n",
              " ['reasoning CBR great',\n",
              "  'standard CBR framework',\n",
              "  'CBR framework extended',\n",
              "  'CBR great deal',\n",
              "  'show standard CBR'],\n",
              " ['paper present framework',\n",
              "  'present framework building',\n",
              "  'framework building probabilistic',\n",
              "  'probabilities Gibbs distributions',\n",
              "  'contextdependent probabilities Gibbs'],\n",
              " ['rely extensively past',\n",
              "  'extensively past experience',\n",
              "  'techniques artificial intelligence',\n",
              "  'employs memorybased techniques',\n",
              "  'memorybased techniques artificial'],\n",
              " ['inference Helmholtz argued',\n",
              "  'topdown connections generate',\n",
              "  'negative feedback loop',\n",
              "  'input processed inverting',\n",
              "  'Sensory input processed'],\n",
              " ['techniques index case',\n",
              "  'vision processing techniques',\n",
              "  'index case base',\n",
              "  'processing techniques index',\n",
              "  'represent optimum choice'],\n",
              " ['lazy version Qlearning',\n",
              "  'version Qlearning performed',\n",
              "  'Qlearning performed moderately',\n",
              "  'Qlearning knearest neighbor',\n",
              "  'approacheslazy Qlearning knearest'],\n",
              " ['viewed nonlinear generalization',\n",
              "  'distributed hierarchical representations',\n",
              "  'connections perform Bayesian',\n",
              "  'Bayesian perceptual inference',\n",
              "  'perform Bayesian perceptual'],\n",
              " ['presented overcomes SANEs',\n",
              "  'paper demonstrates SANE',\n",
              "  'neural network Recent',\n",
              "  'network Recent work',\n",
              "  'Recent work SANE'],\n",
              " ['myriad details operate',\n",
              "  'performance unknown environments',\n",
              "  'representation Empirical results',\n",
              "  'argument representation Empirical',\n",
              "  'Empirical results simple'],\n",
              " ['generalization mistakebound model',\n",
              "  'mistakebound model learning',\n",
              "  'generalpurpose optimal algorithm',\n",
              "  'describe generalpurpose optimal',\n",
              "  'incorrect predictions number'],\n",
              " ['Public Health University',\n",
              "  'Harvard School Public',\n",
              "  'Public Health Boston',\n",
              "  'Assistant Professor Biostatistics',\n",
              "  'School Public Health'],\n",
              " ['recognition tasks connectionist',\n",
              "  'set input patterns',\n",
              "  'input patterns vital',\n",
              "  'tend focus directions',\n",
              "  'information randomdot stereograms'],\n",
              " ['phase form interpolative',\n",
              "  'training phase form',\n",
              "  'instancebased learning Earlier',\n",
              "  'learning Earlier attempts',\n",
              "  'Earlier attempts combat'],\n",
              " ['simulation runs robot',\n",
              "  'partially observable Markov',\n",
              "  'observable Markov decision',\n",
              "  'Markov decision process',\n",
              "  'Discrete Bayesian models'],\n",
              " ['NCARAI technical note',\n",
              "  'describes work Salzbergs',\n",
              "  'AIC describes work',\n",
              "  'work Salzbergs NGE',\n",
              "  'NRL NCARAI technical'],\n",
              " ['tempered transition method',\n",
              "  'simulated tempering tempered',\n",
              "  'Department Statistics University',\n",
              "  'Statistics University Toronto',\n",
              "  'University Toronto Abstract'],\n",
              " ['training system ATS',\n",
              "  'system ATS dynamically',\n",
              "  'component ATS MLModeler',\n",
              "  'design ATS MLModeler',\n",
              "  'modeling component ATS'],\n",
              " ['Planning utilises previous',\n",
              "  'planning metacognitive behaviour',\n",
              "  'Introspection Planning utilises',\n",
              "  'Metacognition addresses issues',\n",
              "  'behaviour system IULIAN'],\n",
              " ['Markov property LWF',\n",
              "  'networks Lauritzen Wermuth',\n",
              "  'Markov property AMP',\n",
              "  'Wermuth Frydenberg LWF',\n",
              "  'Lauritzen Wermuth Frydenberg'],\n",
              " ['Robotics Laboratory Computer',\n",
              "  'Glenn Meredith Chandra',\n",
              "  'Lee Glenn Meredith',\n",
              "  'International Workshop Principles',\n",
              "  'Meredith Chandra Mouleeswaran'],\n",
              " ['worstcase randomized strategy',\n",
              "  'questions arising work',\n",
              "  'Theorem competitive algorithm',\n",
              "  'result Theorem competitive',\n",
              "  'central result Theorem'],\n",
              " ['error data observed',\n",
              "  'based local search',\n",
              "  'generalization error data',\n",
              "  'learning framework Kearns',\n",
              "  'generalization error hypothesis'],\n",
              " ['studying Markov decision',\n",
              "  'Markov decision processes',\n",
              "  'fixed Hamming distance',\n",
              "  'framework studying Markov',\n",
              "  'Methods statistical mechanics'],\n",
              " ['paper shows neural',\n",
              "  'shows neural networks',\n",
              "  'sigmoidal nets Implications',\n",
              "  'Implications number samples',\n",
              "  'valid generalization discussed'],\n",
              " ['rates parameters blind',\n",
              "  'computer simulation experiments',\n",
              "  'time windows Validity',\n",
              "  'Validity performance dynamic',\n",
              "  'windows Validity performance'],\n",
              " ['present modular network',\n",
              "  'number simpler elemental',\n",
              "  'Markovian decision tasks',\n",
              "  'multiple Markovian decision',\n",
              "  'solve multiple Markovian'],\n",
              " ['numerical integration root',\n",
              "  'applications Ellman Murata',\n",
              "  'integration root extraction',\n",
              "  'root extraction routines',\n",
              "  'Ellman Murata Automatic'],\n",
              " ['contextspecific independence CSI',\n",
              "  'CPTs capturing CSI',\n",
              "  'acquisition supports effective',\n",
              "  'supports effective inference',\n",
              "  'effective inference algorithms'],\n",
              " ['run Computational results',\n",
              "  'undiscounted absorbing Markov',\n",
              "  'long run Computational',\n",
              "  'absorbing Markov chains',\n",
              "  'Monte Carlo methods'],\n",
              " ['science fiction stories',\n",
              "  'theory implemented ISAAC',\n",
              "  'implemented ISAAC Integrated',\n",
              "  'ISAAC Integrated Story',\n",
              "  'Integrated Story Analysis'],\n",
              " ['International Conference Principles',\n",
              "  'Reasoning Cambridge Massachusetts',\n",
              "  'Representation Reasoning Cambridge',\n",
              "  'Gardenfors Triviality Theorem',\n",
              "  'Science University Toronto'],\n",
              " ['Occams razor Previous',\n",
              "  'probability Likewise previous',\n",
              "  'Bayesian kind suffer',\n",
              "  'Simulations focus task',\n",
              "  'Kolmogorov complexity Solomonoffs'],\n",
              " ['set cases Finally',\n",
              "  'synthesis capabilities SMS',\n",
              "  'SMS spectral modeling',\n",
              "  'cases Finally SaxEx',\n",
              "  'Finally SaxEx applies'],\n",
              " ['surprising recurring phenomena',\n",
              "  'based biasvariance decomposition',\n",
              "  'analysis Vapniks support',\n",
              "  'Vapniks support vector',\n",
              "  'Finally compare explanation'],\n",
              " ['sets arbitrary patterns',\n",
              "  'arbitrary patterns missing',\n",
              "  'learning problems Results',\n",
              "  'Results classification benchmarkthe',\n",
              "  'problems Results classification'],\n",
              " ['scripts tracks role',\n",
              "  'script tracks roles',\n",
              "  'system recognize incomplete',\n",
              "  'tracks roles extracted',\n",
              "  'tracks role bindings'],\n",
              " ['detection replaced efficient',\n",
              "  'timevarying inputs artificial',\n",
              "  'inspired observation biological',\n",
              "  'eyemovements pattern recognition',\n",
              "  'model timevarying inputs'],\n",
              " ['Tony Robinson Mitsuo',\n",
              "  'Geoffrey Hinton Tony',\n",
              "  'Hinton Tony Robinson',\n",
              "  'National Science Foundation',\n",
              "  'Presidential Young Investigator'],\n",
              " ['perspective easy justify',\n",
              "  'performs maximum likelihood',\n",
              "  'negative free energy',\n",
              "  'free energy show',\n",
              "  'resembles negative free'],\n",
              " ['scale based Hebbian',\n",
              "  'based Hebbian rule',\n",
              "  'Gestalt principles feature',\n",
              "  'encoding Gestalt principles',\n",
              "  'critical encoding Gestalt'],\n",
              " ['BUGS program carries',\n",
              "  'inputdependent noise level',\n",
              "  'model BUGS BUGS',\n",
              "  'program carries Bayesian',\n",
              "  'BUGS BUGS program'],\n",
              " ['psychology experiments long',\n",
              "  'experiments long difficult',\n",
              "  'difficult task quantity',\n",
              "  'coming psychology experiments',\n",
              "  'long difficult task'],\n",
              " ['form gradient descent',\n",
              "  'talk shows fit',\n",
              "  'simple form gradient',\n",
              "  'estimation training methods',\n",
              "  'suitable implementation hardware'],\n",
              " ['problem Kyburgs Evidential',\n",
              "  'proposed Loui Kyburg',\n",
              "  'Loui Kyburg solve',\n",
              "  'Evidential Probability system',\n",
              "  'Kyburgs Evidential Probability'],\n",
              " ['problems NASA space',\n",
              "  'apply reinforcement learning',\n",
              "  'suggest reinforcement learning',\n",
              "  'reinforcement learning provide',\n",
              "  'NASA space shuttle'],\n",
              " ['maximum distance starting',\n",
              "  'classic inverted pendulum',\n",
              "  'outfitted task Origins',\n",
              "  'task Origins details',\n",
              "  'Origins details learning'],\n",
              " ['network RAN Platt',\n",
              "  'algorithm tested Qlearning',\n",
              "  'Solutions found faster',\n",
              "  'pendulum problem Solutions',\n",
              "  'problem Solutions found'],\n",
              " ['Split Window execution',\n",
              "  'implementation Expandable Split',\n",
              "  'called Expandable Split',\n",
              "  'Split Window ESW',\n",
              "  'Expandable Split Window'],\n",
              " ['Exemplar NGE theory',\n",
              "  'based Nested Generalized',\n",
              "  'NGE theory Salzberg',\n",
              "  'Generalized Exemplar NGE',\n",
              "  'Nested Generalized Exemplar'],\n",
              " ['technique finding good',\n",
              "  'search methods Hoeffding',\n",
              "  'Races technique finding',\n",
              "  'methods Hoeffding Races',\n",
              "  'Hoeffding Races technique'],\n",
              " ['determi Define MINFEATURES',\n",
              "  'runtime Almuallim Dietterich',\n",
              "  'Almuallim Dietterich leave',\n",
              "  'Almuallim Dietterich performs',\n",
              "  'due Almuallim Dietterich'],\n",
              " ['produce Supervised learning',\n",
              "  'phase neurons driven',\n",
              "  'correct activity vector',\n",
              "  'connections adapted increase',\n",
              "  'adapted increase probability'],\n",
              " ['stored software components',\n",
              "  'Specifically structure software',\n",
              "  'software reuse Specifically',\n",
              "  'reuse Specifically structure',\n",
              "  'artificial neural network'],\n",
              " ['architectures Soar Laird',\n",
              "  'mechanism Explanation Based',\n",
              "  'Based Neural Network',\n",
              "  'neural network Backpropagation',\n",
              "  'Explanation Based Neural'],\n",
              " ['method Coupling Past',\n",
              "  'Past CFTP delivers',\n",
              "  'Propp Wilson made',\n",
              "  'work Propp Wilson',\n",
              "  'Coupling Past CFTP'],\n",
              " ['close interaction CBR',\n",
              "  'CBR part attempts',\n",
              "  'emerged combining CBR',\n",
              "  'interaction CBR part',\n",
              "  'CBR process future'],\n",
              " ['paper demonstrates tandem',\n",
              "  'DFA model adversarial',\n",
              "  'fulfilling goal requirements',\n",
              "  'learn DFA model',\n",
              "  'project learn DFA'],\n",
              " ['Decision Sciences Duke',\n",
              "  'Institute Statistics Decision',\n",
              "  'Statistics Decision Sciences',\n",
              "  'Dipartimento Statistico Universita',\n",
              "  'Sciences Duke University'],\n",
              " ['Markov chain analysis',\n",
              "  'merits approach provided',\n",
              "  'Traditional schema analysis',\n",
              "  'Markov chain theory',\n",
              "  'transient Markov chain'],\n",
              " ['noise multilayer perceptron',\n",
              "  'relevance determination Noise',\n",
              "  'application training noise',\n",
              "  'training noise multilayer',\n",
              "  'simulated data sets'],\n",
              " ['examine LMDTs ability',\n",
              "  'decision tree algorithm',\n",
              "  'Report January Abstract',\n",
              "  'Technical Report January',\n",
              "  'COINS Technical Report'],\n",
              " ['systems Contrary supervised',\n",
              "  'called reinforcement Depending',\n",
              "  'reinforcement Depending type',\n",
              "  'dynamic systems Contrary',\n",
              "  'Contrary supervised learning'],\n",
              " ['information Predictions algorithm',\n",
              "  'Predictions algorithm agree',\n",
              "  'Mexican hat shape',\n",
              "  'develop Mexican hat',\n",
              "  'random develop Mexican'],\n",
              " ['economists social scientists',\n",
              "  'outlines future challenges',\n",
              "  'Statisticians response beginning',\n",
              "  'knowledgerich applications Statisticians',\n",
              "  'applications Statisticians response'],\n",
              " ['aspects existing ILP',\n",
              "  'Champ elegant solution',\n",
              "  'Systematic experimental comparisons',\n",
              "  'Golem Foil range',\n",
              "  'comparisons Golem Foil'],\n",
              " ['probabilities sigmoid noisyOR',\n",
              "  'computing upper lower',\n",
              "  'precludes exact computations',\n",
              "  'marginal probabilities sigmoid',\n",
              "  'numerical experi ments'],\n",
              " ['Science Technical Report',\n",
              "  'Technical Report Abstract',\n",
              "  'Computational Cognitive Science',\n",
              "  'Cognitive Science Technical',\n",
              "  'MIT Computational Cognitive'],\n",
              " ['VapnikChervonenkis dimension ffi',\n",
              "  'required distributionfree learning',\n",
              "  'including kCNF kDNF',\n",
              "  'classes including kCNF',\n",
              "  'accuracy confidence parameters'],\n",
              " ['discusses Tau Net',\n",
              "  'utterance Tau Net',\n",
              "  'Tau Net neural',\n",
              "  'Tau Nets trained',\n",
              "  'Tau Net applied'],\n",
              " ['reports shown BPSOM',\n",
              "  'material BPSOM extension',\n",
              "  'BPSOM combination multilayered',\n",
              "  'automatic rule extraction',\n",
              "  'Kohonens selforganising maps'],\n",
              " ['MLP Learning Vector',\n",
              "  'analytically Monte Carlo',\n",
              "  'Monte Carlo studies',\n",
              "  'Learning Vector Quantisation',\n",
              "  'Vector Quantisation LVQ'],\n",
              " ['convergence Gibbs sampler',\n",
              "  'Gibbs sampler normal',\n",
              "  'rate convergence Gibbs',\n",
              "  'implementational issues Gibbs',\n",
              "  'target distribution Based'],\n",
              " ['phase form interpolative',\n",
              "  'training phase form',\n",
              "  'instancebased learning Earlier',\n",
              "  'learning Earlier attempts',\n",
              "  'Earlier attempts combat'],\n",
              " ['reinforcement learning architecture',\n",
              "  'control system simulated',\n",
              "  'implemented reinforcement learning',\n",
              "  'extended control system',\n",
              "  'based coordination mechanism'],\n",
              " ['knowledge relevant solving',\n",
              "  'genetic algorithm shows',\n",
              "  'background knowledge relevant',\n",
              "  'hybrid genetic algorithm',\n",
              "  'costs induced hypotheses'],\n",
              " ['higher diversity programs',\n",
              "  'population higher diversity',\n",
              "  'genetic search Unlike',\n",
              "  'Unlike machine learning',\n",
              "  'search Unlike machine'],\n",
              " ['processing computationally expensive',\n",
              "  'computationally expensive perform',\n",
              "  'recurrent net Experiments',\n",
              "  'net Experiments show',\n",
              "  'Experiments show system'],\n",
              " ['binocular input presented',\n",
              "  'selforganizing process results',\n",
              "  'preference Similar selforganization',\n",
              "  'Similar selforganization cortical',\n",
              "  'eye preference Similar'],\n",
              " ['oscillations singular limit',\n",
              "  'networks fast dynamics',\n",
              "  'place intervals slow',\n",
              "  'singular limit method',\n",
              "  'LEGION locally excitatory'],\n",
              " ['visual cortex Laterally',\n",
              "  'cortex Laterally connected',\n",
              "  'inputdriven Hebbian adaptation',\n",
              "  'selforganize inputdriven Hebbian',\n",
              "  'Hebbian adaptation Spiking'],\n",
              " ['Carlo MCMC methods',\n",
              "  'analytically Markov Chain',\n",
              "  'Monte Carlo MCMC',\n",
              "  'Markov Chain Monte',\n",
              "  'Chain Monte Carlo'],\n",
              " ['Propp Wilson proposed',\n",
              "  'Recently Propp Wilson',\n",
              "  'Coupling Past CFTP',\n",
              "  'state space Markov',\n",
              "  'space Markov chains'],\n",
              " ['suggest single Hebbian',\n",
              "  'develop Hebbian selforganization',\n",
              "  'Hebbian selforganization receptive',\n",
              "  'single Hebbian selforganizing',\n",
              "  'ocular dominance orientation'],\n",
              " ['conventional approach RMS',\n",
              "  'network Results simulations',\n",
              "  'critic implemented CMAC',\n",
              "  'Reinforcement Learning method',\n",
              "  'CMAC network Results'],\n",
              " ['describe generic ILP',\n",
              "  'propositional concepts Boolean',\n",
              "  'concepts Boolean domain',\n",
              "  'generic ILP problem',\n",
              "  'generalizes previous result'],\n",
              " ['algorithm due Luttrell',\n",
              "  'fitting mixture density',\n",
              "  'solving MAP estimation',\n",
              "  'MAP estimation problems',\n",
              "  'popularity solving MAP'],\n",
              " ['incorporate prior knowledge',\n",
              "  'function radial symmetry',\n",
              "  'approximated function radial',\n",
              "  'version Radial Basis',\n",
              "  'Radial Basis Functions'],\n",
              " ['optimal Kalman filter',\n",
              "  'Kalman filter require',\n",
              "  'Kalman filter significantly',\n",
              "  'model system varies',\n",
              "  'system varies time'],\n",
              " ['lead decrease performance',\n",
              "  'achieves additional gains',\n",
              "  'proposed procedure efficient',\n",
              "  'procedure efficient memory',\n",
              "  'decision tree learning'],\n",
              " ['combines explanation attempts',\n",
              "  'article describes comprehensive',\n",
              "  'propositional Hornclause theory',\n",
              "  'plant disease diagnosis',\n",
              "  'employing propositional Hornclause'],\n",
              " ['applications Bayesian image',\n",
              "  'algorithm Swendsen Wang',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['extremely robust geometric',\n",
              "  'auxiliary variable demonstrate',\n",
              "  'robust geometric ergodicity',\n",
              "  'paper analyse theoretical',\n",
              "  'drift condition methodology'],\n",
              " ['analyses performance simulated',\n",
              "  'combination simulated annealing',\n",
              "  'simulated annealing run',\n",
              "  'simulated annealing ADFs',\n",
              "  'performance simulated annealing'],\n",
              " ['general PAC model',\n",
              "  'learn general PAC',\n",
              "  'trees DNF formulae',\n",
              "  'decision trees DNF',\n",
              "  'DNF formulae trivial'],\n",
              " ['Measures complexity solution',\n",
              "  'easily Measures complexity',\n",
              "  'Preliminary empirical results',\n",
              "  'found easily Measures',\n",
              "  'functions Genetic Programming'],\n",
              " ['sets shown NPcomplete',\n",
              "  'solved polynomial time',\n",
              "  'effective LPbased finite',\n",
              "  'University Wisconsin Hospitals',\n",
              "  'Wisconsin Hospitals Introduction'],\n",
              " ['rhythmic patterns Networks',\n",
              "  'network behavior embodies',\n",
              "  'resulting network behavior',\n",
              "  'approach theories metrical',\n",
              "  'perception metrical structure'],\n",
              " ['works easily kinds',\n",
              "  'packing routing scheduling',\n",
              "  'dynamic generation gap',\n",
              "  'model inspired GENESIS',\n",
              "  'Finally offers unique'],\n",
              " ['inspired Damasios idea',\n",
              "  'theoretical lower bound',\n",
              "  'magnitude higher number',\n",
              "  'Damasios idea Convergence',\n",
              "  'idea Convergence Zones'],\n",
              " ['Measurements theory space',\n",
              "  'TSS component POLLYANNA',\n",
              "  'testing theory space',\n",
              "  'space search TSS',\n",
              "  'theory space search'],\n",
              " ['converges Nash equilibrium',\n",
              "  'unique Nash equilibrium',\n",
              "  'multiple Nash equilibria',\n",
              "  'prove converges Nash',\n",
              "  'Littman zerosum stochastic'],\n",
              " ['Spain Government Catalonia',\n",
              "  'Government Kingdom Spain',\n",
              "  'Kingdom Spain Government',\n",
              "  'National Science Foundation',\n",
              "  'Nos IRI EEC'],\n",
              " ['Specific kinds selfknowledge',\n",
              "  'RAPTER story understanding',\n",
              "  'alternatives Specific kinds',\n",
              "  'hypothesis candidates Making',\n",
              "  'called RAPTER story'],\n",
              " ['desired properties Designed',\n",
              "  'coarse domain theory',\n",
              "  'theoryguided learning systems',\n",
              "  'constructive induction Experiments',\n",
              "  'theoryguided constructive induction'],\n",
              " ['proponents cold fusion',\n",
              "  'cold fusion reporting',\n",
              "  'experiment Ernest Rutherford',\n",
              "  'backpropagation training multilayer',\n",
              "  'Huizenga Cold Fusion'],\n",
              " ['Qlearning algorithm Finally',\n",
              "  'Probabilistic Conditioning Rule',\n",
              "  'conditioning rule PCR',\n",
              "  'rule PCR Probabilistic',\n",
              "  'PCR Probabilistic Conditioning'],\n",
              " ['based datadriven probabilistic',\n",
              "  'series boundary conditions',\n",
              "  'time series boundary',\n",
              "  'boundary conditions played',\n",
              "  'recorded nonlinear mapping'],\n",
              " ['Programming ILP concerned',\n",
              "  'present Structural Regression',\n",
              "  'Structural Regression Trees',\n",
              "  'Logic Programming ILP',\n",
              "  'Inductive Logic Programming'],\n",
              " ['Bayesian evidence obtained',\n",
              "  'Gull Bayesian evidence',\n",
              "  'due Gull Skilling',\n",
              "  'Gull Skilling Gull',\n",
              "  'Skilling Gull Bayesian'],\n",
              " ['previous work demonstrated',\n",
              "  'goals minimizes architectural',\n",
              "  'speedup enhanced advantage',\n",
              "  'fold improvement unmodified',\n",
              "  'ability favor fetch'],\n",
              " ['revision problem problem',\n",
              "  'theory PTR proved',\n",
              "  'revision problem propositional',\n",
              "  'theory revision problem',\n",
              "  'PTR proved converge'],\n",
              " ['jump Markov chain',\n",
              "  'reversible jump Markov',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'Monte Carlo methods'],\n",
              " ['Singh Vijay Gullapalli',\n",
              "  'University College Computer',\n",
              "  'Grant IRI National',\n",
              "  'Satinder Singh Vijay',\n",
              "  'Technical Report NUCCS'],\n",
              " ['fixed number training',\n",
              "  'approximately implemented neural',\n",
              "  'selective sampling learner',\n",
              "  'selective sampling show',\n",
              "  'absence noise Valiant'],\n",
              " ['altogether Predication remove',\n",
              "  'branch operations Microprocessor',\n",
              "  'operations Microprocessor designs',\n",
              "  'impact branch operations',\n",
              "  'Branch prediction schemes'],\n",
              " ['Gardner McCarty Sridharan',\n",
              "  'furtherance employment Determining',\n",
              "  'furtherance employment Bills',\n",
              "  'term activity furtherance',\n",
              "  'activity furtherance employment'],\n",
              " ['Reinforcement Learning method',\n",
              "  'Adaptive RealTime Dynamic',\n",
              "  'RealTime Dynamic Programming',\n",
              "  'Dynamic Programming simulated',\n",
              "  'reward Reinforcement Learning'],\n",
              " ['Dynamic Parametric',\n",
              "  'Results initial experiments',\n",
              "  'general applicability Dynamic',\n",
              "  'applicability Dynamic Parametric',\n",
              "  'describe Dynamic Parametric'],\n",
              " ['Brain Cognitive Sciences',\n",
              "  'BAO NIMH FMH',\n",
              "  'Department Brain Cognitive',\n",
              "  'Massachusetts Institute Technology',\n",
              "  'Center Biological Computational'],\n",
              " ['probabilities Prchildjparents depend',\n",
              "  'Prchildjparents depend monotonically',\n",
              "  'weighted sums parents',\n",
              "  'bounds marginal probabilities',\n",
              "  'upper lower bounds'],\n",
              " ['number attributes considered',\n",
              "  'accuracy reducing number',\n",
              "  'reducing number attributes',\n",
              "  'investigate potential similar',\n",
              "  'predictive accuracy reducing'],\n",
              " ['sufficiently general vision',\n",
              "  'description complex dimensional',\n",
              "  'complex dimensional objects',\n",
              "  'flexible sufficiently general',\n",
              "  'Robust flexible sufficiently'],\n",
              " ['SARDNET extends Kohonen',\n",
              "  'English words Potential',\n",
              "  'Feature Map architecture',\n",
              "  'extends Kohonen Feature',\n",
              "  'Kohonen Feature Map'],\n",
              " ['paper discuss methodology',\n",
              "  'paper address problem',\n",
              "  'address problem acquiring',\n",
              "  'Technical Report Abstract',\n",
              "  'LIACC Technical Report'],\n",
              " ['motivate importance automated',\n",
              "  'introduction define term',\n",
              "  'spaces Recent research',\n",
              "  'Recent research field',\n",
              "  'metabias spaces Recent'],\n",
              " ['preliminary experiments AQDT',\n",
              "  'AQDT shown decision',\n",
              "  'decision trees compact',\n",
              "  'compact decision trees',\n",
              "  'conventional decision trees'],\n",
              " ['costly Monte Carlo',\n",
              "  'Report Abstract Smoothing',\n",
              "  'Technical Report Abstract',\n",
              "  'CSE Technical Report',\n",
              "  'OGI CSE Technical'],\n",
              " ['judge structural importance',\n",
              "  'mechanism producing memory',\n",
              "  'production reduced memory',\n",
              "  'produce reduced memory',\n",
              "  'reduced memory representations'],\n",
              " ['van Camp learning',\n",
              "  'networks Hinton van',\n",
              "  'neural networks Hinton',\n",
              "  'free energy minimization',\n",
              "  'Hinton van Camp'],\n",
              " ['distribution Elements auxiliary',\n",
              "  'stationary distribution Elements',\n",
              "  'stationary distribution Sahu',\n",
              "  'Bayesian computation performance',\n",
              "  'distribution Sahu Zhigljavsky'],\n",
              " ['complex case representations',\n",
              "  'standard approaches CBR',\n",
              "  'terms adaptability Thirdly',\n",
              "  'engineering Borner Janetzko',\n",
              "  'Borner Janetzko Borner'],\n",
              " ['branchprediction techniques necessarily',\n",
              "  'sophisticated branchprediction techniques',\n",
              "  'small mispredict rates',\n",
              "  'techniques necessarily suffer',\n",
              "  'costs amortized approaches'],\n",
              " ['Mellon University',\n",
              "  'analysis Bayesian networks',\n",
              "  'robustness analysis Bayesian',\n",
              "  'neighborhoods Robust Bayesian',\n",
              "  'Carnegie Mellon University'],\n",
              " ['paper describes selflearning',\n",
              "  'find correct mapping',\n",
              "  'Based local sensor',\n",
              "  'mobile robot Based',\n",
              "  'robot Based local'],\n",
              " ['applied Wisconsin breast',\n",
              "  'techniques applied Wisconsin',\n",
              "  'performance measures Detailed',\n",
              "  'measures Detailed experiments',\n",
              "  'Wisconsin breast cancer'],\n",
              " ['paper argues genetic',\n",
              "  'computation includes genetic',\n",
              "  'GNARL simultaneously acquires',\n",
              "  'called GNARL simultaneously',\n",
              "  'program called GNARL'],\n",
              " ['loosely based marker',\n",
              "  'including number nodes',\n",
              "  'proposed loosely based',\n",
              "  'structure biological DNA',\n",
              "  'movement sensory input'],\n",
              " ['RKPACK originally designed',\n",
              "  'carry small Monte',\n",
              "  'code RKPACK originally',\n",
              "  'Monte Carlo study',\n",
              "  'small Monte Carlo'],\n",
              " ['Systems San Francisco',\n",
              "  'Information Processing Systems',\n",
              "  'Advances Neural Information',\n",
              "  'Conference Neural Information',\n",
              "  'Neural Information Processing'],\n",
              " ['aid determination DNA',\n",
              "  'determination DNA sequences',\n",
              "  'made fluorescentlylabeled DNA',\n",
              "  'Current ABI sequencing',\n",
              "  'reduced Current ABI'],\n",
              " ['architectures performing ILP',\n",
              "  'limitations prevented MIMD',\n",
              "  'current superscalar VLIW',\n",
              "  'performing ILP operation',\n",
              "  'superscalar VLIW machines'],\n",
              " ['MISC capable extracting',\n",
              "  'Instruction Stream Computer',\n",
              "  'machines SuperScalar VLIW',\n",
              "  'Stream Computer MISC',\n",
              "  'Computer MISC capable'],\n",
              " ['sized problems Finally',\n",
              "  'models reduction Markov',\n",
              "  'Finally suggest neurodynamic',\n",
              "  'Markov decision processes',\n",
              "  'reduction Markov decision'],\n",
              " ['CNAPS server processor',\n",
              "  'implemented CNAPS server',\n",
              "  'training time Sun',\n",
              "  'SIMD architecture Adaptive',\n",
              "  'architecture Adaptive Solutions'],\n",
              " ['classifiers generalize classical',\n",
              "  'account correlations dependences',\n",
              "  'input coordinates arise',\n",
              "  'models experimental data',\n",
              "  'Recurrent perceptron classifiers'],\n",
              " ['Kreider Lapedes Farber',\n",
              "  'Lapedes Farber Weigend',\n",
              "  'Curtiss Brandemuehl Kreider',\n",
              "  'Brandemuehl Kreider Lapedes',\n",
              "  'Farber Weigend Huberman'],\n",
              " ['artificial neural network',\n",
              "  'connected ordered pathways',\n",
              "  'built test computationally',\n",
              "  'observed human patients',\n",
              "  'DISLEX artificial neural'],\n",
              " ['scheme Feature Maps',\n",
              "  'approximator Backpropagation RHW',\n",
              "  'RMS Extensions method',\n",
              "  'Maps Koh nonlinear',\n",
              "  'Feature Maps Koh'],\n",
              " ['concepts induced supervised',\n",
              "  'function random variable',\n",
              "  'evaluation function random',\n",
              "  'estimates Searching space',\n",
              "  'probabilistic estimates Searching'],\n",
              " ['matures breadth application',\n",
              "  'extent SIMD machines',\n",
              "  'recently presented Koza',\n",
              "  'Sexpressions single instruction',\n",
              "  'field Genetic Programming'],\n",
              " ['multistate updates Qlearning',\n",
              "  'Qlearning multistate updates',\n",
              "  'Markov games risksensitive',\n",
              "  'Qlearning Markov games',\n",
              "  'updates Qlearning Markov'],\n",
              " ['introduce contextual ICA',\n",
              "  'Independent Component Analysis',\n",
              "  'Analysis ICA assumes',\n",
              "  'Component Analysis ICA',\n",
              "  'blind source separation'],\n",
              " ['computing initial upper',\n",
              "  'method Sondiks updates',\n",
              "  'observable Markov decision',\n",
              "  'Markov decision processes',\n",
              "  'Partially observable Markov'],\n",
              " ['ARD model puts',\n",
              "  'Bayesian methods regularisation',\n",
              "  'Determination ARD model',\n",
              "  'Automatic Relevance Determination',\n",
              "  'Relevance Determination ARD'],\n",
              " ['concepts supervised learning',\n",
              "  'hybrid model classification',\n",
              "  'specific instances CBR',\n",
              "  'instances CBR memory',\n",
              "  'CBR memory system'],\n",
              " ['architectures performing ILP',\n",
              "  'limitations prevented MIMD',\n",
              "  'superscalar VLIW machines',\n",
              "  'performing ILP operation',\n",
              "  'current superscalar VLIW'],\n",
              " ['range MIMD parallel',\n",
              "  'networks backpropagation Kohonen',\n",
              "  'Agreement model measurements',\n",
              "  'backpropagation Kohonen selforganizing',\n",
              "  'Kohonen selforganizing feature'],\n",
              " ['Comparative experiments reimplementations',\n",
              "  'appeared Volume pages',\n",
              "  'replace pruning Comparative',\n",
              "  'pruning Comparative experiments',\n",
              "  'als CART Breiman'],\n",
              " ['limited lack effective',\n",
              "  'robot navigation planning',\n",
              "  'algorithms Recently started',\n",
              "  'effective algorithms Recently',\n",
              "  'Recently started change'],\n",
              " ['situation difficult determine',\n",
              "  'goal research provide',\n",
              "  'representation processing framework',\n",
              "  'overreli ance programmer',\n",
              "  'called MetaExplanation Pattern'],\n",
              " ['training system ATS',\n",
              "  'system ATS dynamically',\n",
              "  'component ATS MLModeler',\n",
              "  'design ATS MLModeler',\n",
              "  'modeling component ATS'],\n",
              " ['setting nontrivial task',\n",
              "  'algorithms parameter setting',\n",
              "  'returned algorithm Parameter',\n",
              "  'parameter setting nontrivial',\n",
              "  'learning system Magnus'],\n",
              " ['mode declaration supplied',\n",
              "  'illustrate advantages approach',\n",
              "  'systems Chillin IFoil',\n",
              "  'background knowledge Tests',\n",
              "  'ILP systems Chillin'],\n",
              " ['phase form interpolative',\n",
              "  'training phase form',\n",
              "  'instancebased learning Earlier',\n",
              "  'learning Earlier attempts',\n",
              "  'Earlier attempts combat'],\n",
              " ['cluster represented collection',\n",
              "  'realworld clustering problems',\n",
              "  'hyperboxes Initially number',\n",
              "  'fuzzy hyperboxes Initially',\n",
              "  'Initially number hyperboxes'],\n",
              " ['oblique hyperplanes Standard',\n",
              "  'descriptions problem domain',\n",
              "  'Standard decision tree',\n",
              "  'predictive accuracy Small',\n",
              "  'produces surprisingly small'],\n",
              " ['establishes ICET performs',\n",
              "  'errors ICET compared',\n",
              "  'conditions shows ICET',\n",
              "  'paper introduces ICET',\n",
              "  'costsensitive classification ICET'],\n",
              " ['paper highlights role',\n",
              "  'highlights role mathematical',\n",
              "  'training neural networks',\n",
              "  'techniques training neural',\n",
              "  'major medical facility'],\n",
              " ['CBR systems prompted',\n",
              "  'CBR research paradigm',\n",
              "  'casebased reasoning CBR',\n",
              "  'Dissatisfaction existing standard',\n",
              "  'role cases CBR'],\n",
              " ['units Taking account',\n",
              "  'biological units Taking',\n",
              "  'completely sequenced Saccharomyces',\n",
              "  'sequenced Saccharomyces cerevisiae',\n",
              "  'DNA sequences compositional'],\n",
              " ['improve weight change',\n",
              "  'previous weight change',\n",
              "  'weight change algorithms',\n",
              "  'analyzing modifying weight',\n",
              "  'modifying weight matrix'],\n",
              " ['algorithms Classical pattern',\n",
              "  'demonstrate feasibility concept',\n",
              "  'enumerative algorithms Classical',\n",
              "  'Pollack fit task',\n",
              "  'Traditional symbolic approaches'],\n",
              " ['circuit Olshausen Anderson',\n",
              "  'eye position signals',\n",
              "  'Van Essen modeled',\n",
              "  'Olshausen Anderson Van',\n",
              "  'Anderson Van Essen'],\n",
              " ['show simple patterns',\n",
              "  'cases CONFMAN database',\n",
              "  'Learning algorithm generating',\n",
              "  'Machine Learning algorithm',\n",
              "  'advanced Machine Learning'],\n",
              " ['problem space solutions',\n",
              "  'regions problem space',\n",
              "  'commercial purposes Abstract',\n",
              "  'COMMA Technical Report',\n",
              "  'UWCC COMMA Technical'],\n",
              " ['solve MDPs belonging',\n",
              "  'class Dijkstras shortestpath',\n",
              "  'inefficient compared DAGSP',\n",
              "  'Dijkstra DAGSP deterministic',\n",
              "  'DirectedAcyclicGraphShortestPaths DAGSP DAGSP'],\n",
              " ['research demonstrates viability',\n",
              "  'Automatic design optimization',\n",
              "  'Research Engineering Design',\n",
              "  'Fully accepted Research',\n",
              "  'accepted Research Engineering'],\n",
              " ['combined sixband LandsatTM',\n",
              "  'LandsatTM oneband ERSSAR',\n",
              "  'PRI imagery scene',\n",
              "  'oneband ERSSAR PRI',\n",
              "  'ERSSAR PRI imagery'],\n",
              " ['Finally experimental results',\n",
              "  'corrupted English text',\n",
              "  'variable memory length',\n",
              "  'theory Ron Singer',\n",
              "  'Ron Singer Tishby'],\n",
              " ['software agents Webbased',\n",
              "  'mapped neural network',\n",
              "  'Web search site',\n",
              "  'advice mapped neural',\n",
              "  'Subsequent reinforcements Web'],\n",
              " ['describe Existing concept',\n",
              "  'Existing concept learners',\n",
              "  'Additionally systems possess',\n",
              "  'begins Additionally systems',\n",
              "  'learning begins Additionally'],\n",
              " ['simple classification task',\n",
              "  'true Bayesian predictive',\n",
              "  'Bayesian inference data',\n",
              "  'exhibits true Bayesian',\n",
              "  'Monte Carlo simulation'],\n",
              " ['faster Adaptive Heuristic',\n",
              "  'SANE Symbiotic Adaptive',\n",
              "  'Heuristic Critic times',\n",
              "  'faster Qlearning GENITOR',\n",
              "  'Adaptive Heuristic Critic'],\n",
              " ['paper concerns probabilistic',\n",
              "  'predicted passive observations',\n",
              "  'concurrent sequential actions',\n",
              "  'concerns probabilistic evaluation',\n",
              "  'passive observations measured'],\n",
              " ['Control Flow Tables',\n",
              "  'Flow Tables Control',\n",
              "  'Tables Control Flow',\n",
              "  'control flow graph',\n",
              "  'control flow prediction'],\n",
              " ['true probability distribution',\n",
              "  'approximation true probability',\n",
              "  'tractable approximation true',\n",
              "  'field theory sigmoid',\n",
              "  'classification handwritten digits'],\n",
              " ['Science Engineering Research',\n",
              "  'Research Council Canada',\n",
              "  'Engineering Research Council',\n",
              "  'Institute Robotics Intelligent',\n",
              "  'National Science Engineering'],\n",
              " ['Hierarchical Mixtures Experts',\n",
              "  'Controller CMAC Albus',\n",
              "  'Cerebellar Model Articulation',\n",
              "  'Articulation Controller CMAC',\n",
              "  'Model Articulation Controller'],\n",
              " ['processing performed feedforward',\n",
              "  'model adaptation process',\n",
              "  'Relaxation system determined',\n",
              "  'patterns Relaxation system',\n",
              "  'represent patterns Relaxation'],\n",
              " ['Modifications Recursive AutoAssociative',\n",
              "  'AutoAssociative Memory presented',\n",
              "  'trees extracted Penn',\n",
              "  'Recursive AutoAssociative Memory',\n",
              "  'extracted Penn Treebank'],\n",
              " ['carried assess performance',\n",
              "  'nearest neighbor regression',\n",
              "  'specifically making movie',\n",
              "  'making movie recommendations',\n",
              "  'give formal framework'],\n",
              " ['improve performance CBL',\n",
              "  'CBL hybrid approach',\n",
              "  'case retrieval Results',\n",
              "  'decision trees CBL',\n",
              "  'trees CBL hybrid'],\n",
              " ['Helmholtz machine parameters',\n",
              "  'sible alternative Hebbian',\n",
              "  'Ojas version Hebbian',\n",
              "  'Statistics University Toronto',\n",
              "  'Department Statistics University'],\n",
              " ['training sets Specific',\n",
              "  'sets Specific experiments',\n",
              "  'hidden Markov model',\n",
              "  'states hidden Markov',\n",
              "  'amino acid distributions'],\n",
              " ['paper proposes simple',\n",
              "  'theory longer apply',\n",
              "  'ROC convex hull',\n",
              "  'Fawcetts ROC convex',\n",
              "  'Provost Fawcetts ROC'],\n",
              " ['interpretation Rubins model',\n",
              "  'account causation show',\n",
              "  'review Markovian account',\n",
              "  'Markovian account causation',\n",
              "  'manipulative account causation'],\n",
              " ['requirements plays important',\n",
              "  'sufficient adapt predefined',\n",
              "  'adapt predefined set',\n",
              "  'plays important role',\n",
              "  'adaptation based notion'],\n",
              " ['benchmark time series',\n",
              "  'data sets Efficient',\n",
              "  'Efficient estimation algorithms',\n",
              "  'sets Efficient estimation',\n",
              "  'Large sample properties'],\n",
              " ['weak preference biases',\n",
              "  'FRINGE algorithms shows',\n",
              "  'Boolean concept learning',\n",
              "  'bound Experimental measurement',\n",
              "  'upper bound Experimental'],\n",
              " ['space Analysis reordered',\n",
              "  'Analysis reordered lumped',\n",
              "  'FOGA workshop presented',\n",
              "  'previous FOGA workshop',\n",
              "  'initially Nix Vose'],\n",
              " ['Schnier extended demonstrate',\n",
              "  'Life ALife research',\n",
              "  'behaviour Artificial Life',\n",
              "  'Gero Schnier extended',\n",
              "  'Artificial Life ALife'],\n",
              " ['DNF representations conjunctions',\n",
              "  'ktermDNF DNF representations',\n",
              "  'PAC models training',\n",
              "  'classification noise Classes',\n",
              "  'rates attribute Finally'],\n",
              " ['Markov Model HMM',\n",
              "  'called VEIL Viterbi',\n",
              "  'VEIL Viterbi ExonIntron',\n",
              "  'Viterbi ExonIntron Locator',\n",
              "  'Hidden Markov Model'],\n",
              " ['increase robustness approaches',\n",
              "  'interest lifelong machine',\n",
              "  'increased interest lifelong',\n",
              "  'desirable reason relatedness',\n",
              "  'Recently increased interest'],\n",
              " ['capture changes belief',\n",
              "  'revision intended capture',\n",
              "  'revision belief update',\n",
              "  'Belief revision belief',\n",
              "  'intended capture changes'],\n",
              " ['propose Bayesian framework',\n",
              "  'approaches true Bayesian',\n",
              "  'regression problems Kalman',\n",
              "  'problems Kalman filter',\n",
              "  'implementation summarised Simulations'],\n",
              " ['report deals efficient',\n",
              "  'deals efficient mapping',\n",
              "  'neural networks CNS',\n",
              "  'bottlenecks current CNS',\n",
              "  'current CNS design'],\n",
              " ['ecological neural networks',\n",
              "  'networks living fixed',\n",
              "  'organisms exhibits diploidy',\n",
              "  'neural networks living',\n",
              "  'parallel biological findings'],\n",
              " ['status observations arise',\n",
              "  'confront possibility revising',\n",
              "  'external world Issues',\n",
              "  'world Issues status',\n",
              "  'Issues status observations'],\n",
              " ['studied detail Roughly',\n",
              "  'detail Roughly speaking',\n",
              "  'show Markov assumption',\n",
              "  'treats surprising observation',\n",
              "  'qualitative Markov assumption'],\n",
              " ['local searches agent',\n",
              "  'hard problem finding',\n",
              "  'agent performs finitedepth',\n",
              "  'searches agent performs',\n",
              "  'problem finding good'],\n",
              " ['Bayesian networks PCFGs',\n",
              "  'constructing Bayesian network',\n",
              "  'language Efficient parsing',\n",
              "  'algorithm constructing Bayesian',\n",
              "  'works constructing Bayesian'],\n",
              " ['Inferences supported unique',\n",
              "  'answering queries Imprecise',\n",
              "  'Practical algorithms developed',\n",
              "  'interpreted imposing Markovian',\n",
              "  'Jeffreys Rule Bayesian'],\n",
              " ['Clay evolutionary architecture',\n",
              "  'utilizing Clay benefit',\n",
              "  'Experiments robot soccer',\n",
              "  'time Experiments robot',\n",
              "  'signal time Experiments'],\n",
              " ['paper propose parallel',\n",
              "  'approach inspired Hollands',\n",
              "  'Hollands idea bucket',\n",
              "  'inspired Hollands idea',\n",
              "  'Simple experiments demonstrating'],\n",
              " ['largely studied problem',\n",
              "  'implemented portion ISAAC',\n",
              "  'portion ISAAC Integrated',\n",
              "  'Integrated Story Analysis',\n",
              "  'ISAAC Integrated Story'],\n",
              " ['everyday objects surrounding',\n",
              "  'functions purposes common',\n",
              "  'lead innovation insight',\n",
              "  'paper characterizes ability',\n",
              "  'assessment casebased reasoning'],\n",
              " ['methods estimating probabilities',\n",
              "  'structure constructed decision',\n",
              "  'informativity gini index',\n",
              "  'induction informativity gini',\n",
              "  'results experiments show'],\n",
              " ['single adversary controls',\n",
              "  'show relationships benign',\n",
              "  'Schapire present polynomialtime',\n",
              "  'Kearns Schapire present',\n",
              "  'pconcepts Kearns Schapire'],\n",
              " ['approach facilitates identification',\n",
              "  'report presents toolbox',\n",
              "  'facilitates identification opportunities',\n",
              "  'systems typically retrieve',\n",
              "  'based systems typically'],\n",
              " ['Section Section presents',\n",
              "  'system Turing Complete',\n",
              "  'Hopcroft Ullman suggest',\n",
              "  'abstract data structures',\n",
              "  'Aho Hopcroft Ullman'],\n",
              " ['fixed structure invariant',\n",
              "  'unchanging number neurons',\n",
              "  'standard polynomial hierarchy',\n",
              "  'powerful Turing Machines',\n",
              "  'Report SYCON ABSTRACT'],\n",
              " ['Metropolis Hastings algorithm',\n",
              "  'Hastings algorithm Illustrative',\n",
              "  'MCMC samplers Gibbs',\n",
              "  'Gibbs Sampler Metropolis',\n",
              "  'Sampler Metropolis Hastings'],\n",
              " ['ICA algorithm Bell',\n",
              "  'Component Analysis ICA',\n",
              "  'Bell Sejnowski suitable',\n",
              "  'algorithm Bell Sejnowski',\n",
              "  'Independent Component Analysis'],\n",
              " ['Psychological Review Schmidhuber',\n",
              "  'networks Technical Report',\n",
              "  'Technical Report CMUCS',\n",
              "  'Technical Report FKI',\n",
              "  'Computer Science Department'],\n",
              " ['locally optimal irrevocable',\n",
              "  'makes locally optimal',\n",
              "  'induction exhibits pathology',\n",
              "  'decision tree induction',\n",
              "  'accurate trees produced'],\n",
              " ['results analyzed Based',\n",
              "  'machine learning model',\n",
              "  'continuous valued input',\n",
              "  'valued input features',\n",
              "  'creating ASOCSAFE IDAFE'],\n",
              " ['processes MDPs composite',\n",
              "  'multiple Markov decision',\n",
              "  'Markov decision processes',\n",
              "  'task isolation paper',\n",
              "  'MDPs composite MDP'],\n",
              " ['algorithm finding additive',\n",
              "  'finding additive tree',\n",
              "  'tree metric min',\n",
              "  'closest tree metric',\n",
              "  'Phard find tree'],\n",
              " ['general CBP demonstrated',\n",
              "  'CBP demonstrated improve',\n",
              "  'success CBP depends',\n",
              "  'extends current CBP',\n",
              "  'goal subproblems Multigoal'],\n",
              " ['applying confidence estimators',\n",
              "  'confidence estimators providing',\n",
              "  'confidence estimation methods',\n",
              "  'activities Confidence estimation',\n",
              "  'confidence estimation mechanisms'],\n",
              " ['community offer practical',\n",
              "  'interest members machine',\n",
              "  'offer practical methods',\n",
              "  'special interest members',\n",
              "  'directions future research'],\n",
              " ['role Finally apply',\n",
              "  'algorithm Boltzmann Machines',\n",
              "  'process Boltzmann Machines',\n",
              "  'Boltzmann Machines based',\n",
              "  'Boltzmann Machines computationally'],\n",
              " ['Results applying methodology',\n",
              "  'finding quickly Results',\n",
              "  'methodology NASA scheduling',\n",
              "  'quickly Results applying',\n",
              "  'search control policy'],\n",
              " ['state spaces computing',\n",
              "  'large state spaces',\n",
              "  'size state space',\n",
              "  'spaces computing averages',\n",
              "  'based imperfect statistics'],\n",
              " ['presents preliminary study',\n",
              "  'preliminary study qualitatively',\n",
              "  'paper presents preliminary',\n",
              "  'predicated execution support',\n",
              "  'partial predicated execution'],\n",
              " ['Science supported NSF',\n",
              "  'MIT Laboratory Computer',\n",
              "  'Foundation Junior Faculty',\n",
              "  'Siemens Corporation Net',\n",
              "  'Laboratory Computer Science'],\n",
              " ['prove class monotonic',\n",
              "  'lie ahead genetic',\n",
              "  'presents lowerbound result',\n",
              "  'lowerbound result computational',\n",
              "  'result power Abstract'],\n",
              " ['viewed nonlinear autoregression',\n",
              "  'viewed nonlinear regression',\n",
              "  'predicting French electric',\n",
              "  'French electric daily',\n",
              "  'experts predicting French'],\n",
              " ['tation cost function',\n",
              "  'tation obtained dep',\n",
              "  'tation optimal resp',\n",
              "  'Qlearning obtain satisfactory',\n",
              "  'function absorbing Mark'],\n",
              " ['semantic networks lists',\n",
              "  'networks lists concrete',\n",
              "  'lists concrete propositions',\n",
              "  'specific pieces experience',\n",
              "  'pieces experience reasoners'],\n",
              " ['tested artificial reallife',\n",
              "  'construction pruning interpretation',\n",
              "  'artificial reallife domains',\n",
              "  'affects construction pruning',\n",
              "  'Bayesian approach estimation'],\n",
              " ['patterns determined Poisson',\n",
              "  'determined Poisson equation',\n",
              "  'Altogether general theory',\n",
              "  'Theory Quantitative Results',\n",
              "  'Quantitative Results Abstract'],\n",
              " ['Methodology Evaluating Theory',\n",
              "  'Results Abstract Theory',\n",
              "  'Revision Systems Results',\n",
              "  'Theory Revision Systems',\n",
              "  'Systems Results Abstract'],\n",
              " ['data mining approach',\n",
              "  'classifier high classification',\n",
              "  'effect comprehensibility classification',\n",
              "  'high classification accuracy',\n",
              "  'comprehensibility classification accuracy'],\n",
              " ['databases Authors case',\n",
              "  'Advantages generalizing case',\n",
              "  'measures Advantages generalizing',\n",
              "  'Authors case studies',\n",
              "  'dependent measures Advantages'],\n",
              " ['reduction varies greatly',\n",
              "  'reduction linked degree',\n",
              "  'amount error reduction',\n",
              "  'make errors correlated',\n",
              "  'errors correlated manner'],\n",
              " ['system called JAR',\n",
              "  'surface planet Venus',\n",
              "  'called JAR tool',\n",
              "  'JAR tool endtoend',\n",
              "  'planet Venus Plannett'],\n",
              " ['Markov decision processes',\n",
              "  'Sutton extends prediction',\n",
              "  'framework Markov decision',\n",
              "  'mathematical framework Markov',\n",
              "  'Conventional modelbased reinforcement'],\n",
              " ['test acceptable Type',\n",
              "  'high probability Type',\n",
              "  'elevated probability Type',\n",
              "  'difference exists type',\n",
              "  'shown low Type'],\n",
              " ['algorithms passive assign',\n",
              "  'assign classlabel instance',\n",
              "  'passive assign classlabel',\n",
              "  'variant probablyapproximatelycorrect PAC',\n",
              "  'probablyapproximatelycorrect PAC model'],\n",
              " ['expected utility updating',\n",
              "  'finding probable explanation',\n",
              "  'utility updating belief',\n",
              "  'problems struc ture',\n",
              "  'framework Bounds complexity'],\n",
              " ['Mass Blackwells Adrian',\n",
              "  'Raftery Professor Statistics',\n",
              "  'Hout Steven Lewis',\n",
              "  'University Washington Seattle',\n",
              "  'Cambridge Mass Blackwells'],\n",
              " ['paper propose family',\n",
              "  'treeclustering conditioning trade',\n",
              "  'combining treeclustering conditioning',\n",
              "  'conditioning trade space',\n",
              "  'timespace specifica tion'],\n",
              " ['loopcutset conditioning Jensens',\n",
              "  'simple generalization Pearls',\n",
              "  'method Lauritzen Spiegelhalter',\n",
              "  'Spiegelhalter refined Jensen',\n",
              "  'Lauritzen Spiegelhalter refined'],\n",
              " ['dynamics collective properties',\n",
              "  'collective properties feedback',\n",
              "  'neurons investigated Special',\n",
              "  'traditional firingrate picture',\n",
              "  'investigated Special emphasis'],\n",
              " ['maintaining diversity creating',\n",
              "  'algorithm Unlike methods',\n",
              "  'Unlike methods replaces',\n",
              "  'illustrating feasibility approach',\n",
              "  'evolutionary algorithm Unlike'],\n",
              " ['constant output inputs',\n",
              "  'unchanged Alternatively cost',\n",
              "  'targets unchanged Alternatively',\n",
              "  'inputs transformed group',\n",
              "  'output inputs transformed'],\n",
              " ['independence Empirical studies',\n",
              "  'studies based CPCS',\n",
              "  'Empirical studies based',\n",
              "  'independencies exact Bayesian',\n",
              "  'Bayesian network inference'],\n",
              " ['human learning task',\n",
              "  'Navigation task requires',\n",
              "  'computational architectures NRL',\n",
              "  'NRL Navigation task',\n",
              "  'architectures NRL Navigation'],\n",
              " ['Research Computing Technology',\n",
              "  'Technology Division Applied',\n",
              "  'Computing Technology Division',\n",
              "  'Center Research Computing',\n",
              "  'Division Applied Sciences'],\n",
              " ['Error Pruning proposed',\n",
              "  'Error Pruning relational',\n",
              "  'occur Reduced Error',\n",
              "  'Incremental Reduced Error',\n",
              "  'Reduced Error Pruning'],\n",
              " ['Models general class',\n",
              "  'phase angle coinciding',\n",
              "  'standard Western musical',\n",
              "  'Western musical notation',\n",
              "  'implied standard Western'],\n",
              " ['Conf Artificial Intelligence',\n",
              "  'Artificial Intelligence AAAI',\n",
              "  'Eleventh National Conf',\n",
              "  'National Conf Artificial',\n",
              "  'Proc Eleventh National'],\n",
              " ['Karlssons modifi cation',\n",
              "  'designs Sparse Distributed',\n",
              "  'SICSRSE ISSN Abstract',\n",
              "  'ISRN SICSRSE ISSN',\n",
              "  'Sparse Distributed Memory'],\n",
              " ['unbiased coefficient variation',\n",
              "  'coefficient variation roughly',\n",
              "  'extra location introduced',\n",
              "  'SICSRSE ISSN Abstract',\n",
              "  'ISRN SICSRSE ISSN'],\n",
              " ['semantics ifthen rules',\n",
              "  'update reasoning actions',\n",
              "  'Markov shielding imposes',\n",
              "  'incorporates principle Markov',\n",
              "  'principle Markov shielding'],\n",
              " ['learning finite Gaussian',\n",
              "  'algorithms learning Gaussian',\n",
              "  'learning Gaussian mixture',\n",
              "  'finite Gaussian mixtures',\n",
              "  'Gaussian mixture models'],\n",
              " ['standard ILP concepts',\n",
              "  'discharge machining Special',\n",
              "  'machining Special emphasis',\n",
              "  'learning standard ILP',\n",
              "  'local improvement minimum'],\n",
              " ['model bihemispheric cerebral',\n",
              "  'selforganization initially random',\n",
              "  'bihemispheric cerebral cortex',\n",
              "  'initially random network',\n",
              "  'computational model bihemispheric'],\n",
              " ['constants Simulation experiments',\n",
              "  'sequences difficult computational',\n",
              "  'temporallyextended sequences difficult',\n",
              "  'difficult computational problem',\n",
              "  'Learning structure temporallyextended'],\n",
              " ['fast Experiments demonstrated',\n",
              "  'Experiments demonstrated speedups',\n",
              "  'prediction Temporal tasks',\n",
              "  'bear prediction Temporal',\n",
              "  'simple fast Experiments'],\n",
              " ['stability Markov chain',\n",
              "  'Markov chains convergence',\n",
              "  'Markov chain asymptotic',\n",
              "  'mixture hidden Markov',\n",
              "  'hidden Markov chains'],\n",
              " ['investigated determine ability',\n",
              "  'determine ability detect',\n",
              "  'ability detect classify',\n",
              "  'categories diffuse liver',\n",
              "  'shown justified profitable'],\n",
              " ['ICA Separation results',\n",
              "  'Principal Component Analysis',\n",
              "  'Independent Component Analysis',\n",
              "  'Component Analysis PCA',\n",
              "  'Analysis ICA Separation'],\n",
              " ['hormones physiological processes',\n",
              "  'physiological processes vary',\n",
              "  'model Data experiment',\n",
              "  'components model Data',\n",
              "  'Data experiment study'],\n",
              " ['present highlevel decompositionbased',\n",
              "  'widelyused graph partitioning',\n",
              "  'graph partitioning techniques',\n",
              "  'partitioning techniques based',\n",
              "  'graph partitioning problems'],\n",
              " ['Carlo MCMC methods',\n",
              "  'state Ohio period',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['governing learning Bienenstock',\n",
              "  'learning Bienenstock Cooper',\n",
              "  'Munro BCM neurons',\n",
              "  'Bienenstock Cooper Munro',\n",
              "  'Cooper Munro BCM'],\n",
              " ['Learning Theory Natural',\n",
              "  'Computational Learning Theory',\n",
              "  'Theory Natural Learning',\n",
              "  'MIT Press Abstract',\n",
              "  'Copyrighted MIT Press'],\n",
              " ['competition replacement schemes',\n",
              "  'Genetic Algorithms Evolution',\n",
              "  'Algorithms Evolution Strategies',\n",
              "  'Evolution Strategies Genetic',\n",
              "  'Strategies Genetic Programming'],\n",
              " ['CLONES parallel machine',\n",
              "  'parallel machine RAP',\n",
              "  'applied Traveling Salesman',\n",
              "  'Traveling Salesman Problem',\n",
              "  'Salesman Problem TSP'],\n",
              " ['call simple rhythmic',\n",
              "  'production simple rhythmic',\n",
              "  'meter Rests rhythmic',\n",
              "  'rhythmic pattern Figure',\n",
              "  'simple rhythmic pattern'],\n",
              " ['basis functions Buhmann',\n",
              "  'functions Buhmann Dyn',\n",
              "  'Dyn Levin Dyn',\n",
              "  'Levin Dyn Ron',\n",
              "  'Buhmann Dyn Levin'],\n",
              " ['Attention restricted functions',\n",
              "  'function Attention restricted',\n",
              "  'basis function Attention',\n",
              "  'Fourier transform smooth',\n",
              "  'translates basis function'],\n",
              " ['derived mild assumptions',\n",
              "  'mild assumptions generator',\n",
              "  'provided principal shiftinvariant',\n",
              "  'splines multiquadrics Gauss',\n",
              "  'multiquadrics Gauss kernel'],\n",
              " ['regionbyregion basis Based',\n",
              "  'basis Based observation',\n",
              "  'Reinforcement Learning EBRL',\n",
              "  'EBRL batch online',\n",
              "  'batch online versions'],\n",
              " ['Department Brain Cognitive',\n",
              "  'Learning Department Brain',\n",
              "  'Biological Computational Learning',\n",
              "  'Computational Learning Department',\n",
              "  'National Institutes Health'],\n",
              " ['MDS discussed reviewing',\n",
              "  'scaling MDS discussed',\n",
              "  'MDS time challenged',\n",
              "  'multidimensional scaling MDS',\n",
              "  'technique online Kmeans'],\n",
              " ['perform worse acceptable',\n",
              "  'modeled terms reaching',\n",
              "  'performing online reinforcement',\n",
              "  'knowledge reduce number',\n",
              "  'domain motion planning'],\n",
              " ['trained finite sized',\n",
              "  'finite sized training',\n",
              "  'source unneeded weights',\n",
              "  'obtained unneeded weights',\n",
              "  'nonlinear time series'],\n",
              " ['neural networks real',\n",
              "  'populations neural networks',\n",
              "  'functional difference products',\n",
              "  'networks real distinction',\n",
              "  'parallel biological findings'],\n",
              " ['Multiscalar architecture advocates',\n",
              "  'larger ILP windows',\n",
              "  'organization tasklevel speculation',\n",
              "  'distributed processor organization',\n",
              "  'processor organization tasklevel'],\n",
              " ['introduces Introspection Approach',\n",
              "  'Introspection Approach method',\n",
              "  'paper introduces Introspection',\n",
              "  'Technical Report January',\n",
              "  'Report January Abstract'],\n",
              " ['outperforms constructive induction',\n",
              "  'boolean expressions presented',\n",
              "  'constructive induction algorithms',\n",
              "  'multilevel boolean expressions',\n",
              "  'construction selection finds'],\n",
              " ['Bayesian classification approach',\n",
              "  'discuss Bayesian approach',\n",
              "  'Bayesian approach finding',\n",
              "  'exploratory data analysis',\n",
              "  'paper discuss Bayesian'],\n",
              " ['mixture experts HME',\n",
              "  'bit parity patterns',\n",
              "  'Firstly applying likelihood',\n",
              "  'classifier Firstly applying',\n",
              "  'structured classifier Firstly'],\n",
              " ['helping future problemsolving',\n",
              "  'framework discussing imperfect',\n",
              "  'address issues raised',\n",
              "  'present framework discussing',\n",
              "  'Systems interacting realworld'],\n",
              " ['generality discovered Adding',\n",
              "  'discovered Adding inverse',\n",
              "  'Programming applied task',\n",
              "  'differing problem formulations',\n",
              "  'Genetic Programming applied'],\n",
              " ['common Machine Learning',\n",
              "  'Machine Learning approaches',\n",
              "  'Length MDL measure',\n",
              "  'Description Length MDL',\n",
              "  'Minimum Description Length'],\n",
              " ['UCI repository MONKs',\n",
              "  'rules Rivest Inductive',\n",
              "  'problem finding maximally',\n",
              "  'Rivest Inductive algorithms',\n",
              "  'finding maximally accurate'],\n",
              " ['gained considerable interest',\n",
              "  'considerable interest past',\n",
              "  'set demonstrated resulting',\n",
              "  'Methods build function',\n",
              "  'resulting fuzzy graphs'],\n",
              " ['system make high',\n",
              "  'strategies responsive learners',\n",
              "  'decisions basis low',\n",
              "  'strategy decisions basis',\n",
              "  'order accomplish reinforcement'],\n",
              " ['work propose neural',\n",
              "  'shortterm memory capacity',\n",
              "  'express dynamic bindings',\n",
              "  'STM realized leaky',\n",
              "  'memory capacity STM'],\n",
              " ['requiring sustained attention',\n",
              "  'varies minute time',\n",
              "  'operators attentioncritical settings',\n",
              "  'EEG performance auditory',\n",
              "  'EEG measures recorded'],\n",
              " ['problems Bayesian network',\n",
              "  'distributions Robust Bayesian',\n",
              "  'parameters Bayesian network',\n",
              "  'paper presents exact',\n",
              "  'Carnegie Mellon University'],\n",
              " ['perceptron Depending define',\n",
              "  'training perceptron Depending',\n",
              "  'discriminate benign malignant',\n",
              "  'distinguishing benign malignant',\n",
              "  'benign malignant tumors'],\n",
              " ['present preliminary results',\n",
              "  'form neural network',\n",
              "  'network target outputs',\n",
              "  'neural network target',\n",
              "  'space lower dimensionality'],\n",
              " ['Forschungsgemeinschaft NSFCISE Postdoctoral',\n",
              "  'Department Brain Cognitive',\n",
              "  'Massachusetts Institute Technology',\n",
              "  'Center Biological Computational',\n",
              "  'Deutsche Forschungsgemeinschaft NSFCISE'],\n",
              " ['encoding Experimental investigation',\n",
              "  'technique Gruau evolving',\n",
              "  'cellular encoding Experimental',\n",
              "  'Gruau evolving graph',\n",
              "  'Experimental investigation relative'],\n",
              " ['Rules represented objects',\n",
              "  'attribute sets Experimental',\n",
              "  'sets Experimental results',\n",
              "  'medical domain included',\n",
              "  'Experimental results case'],\n",
              " ['interested adept utilisation',\n",
              "  'utilisation waste materials',\n",
              "  'adept utilisation waste',\n",
              "  'football playing mobot',\n",
              "  'Truth Trash model'],\n",
              " ['time polynomial number',\n",
              "  'paper concerns probabilistic',\n",
              "  'accomplished systematically time',\n",
              "  'concerns probabilistic evaluation',\n",
              "  'systematically time polynomial'],\n",
              " ['VISOR large connectionist',\n",
              "  'networks Processing VISOR',\n",
              "  'Processing VISOR based',\n",
              "  'ambiguous objects Experiments',\n",
              "  'Simulations show VISOR'],\n",
              " ['characterizing Bayesian classification',\n",
              "  'full Bayesian networks',\n",
              "  'Bayesian classification methods',\n",
              "  'model Naive Bayes',\n",
              "  'Naive Bayes algorithm'],\n",
              " ['paid ability learn',\n",
              "  'lifetime adaptive processes',\n",
              "  'paper explores idea',\n",
              "  'robot Results experiment',\n",
              "  'mobile robot Results'],\n",
              " ['paper presents conditions',\n",
              "  'presents conditions genetic',\n",
              "  'implies small distance',\n",
              "  'Effect speed evolutionary',\n",
              "  'Baldwin Effect speed'],\n",
              " ['build compared Neural',\n",
              "  'trees based input',\n",
              "  'based input vector',\n",
              "  'Neural Networks understandable',\n",
              "  'compared Neural Networks'],\n",
              " ['algorithm training artificial',\n",
              "  'artificial neural networks',\n",
              "  'training artificial neural',\n",
              "  'accumulation point online',\n",
              "  'serial parallel online'],\n",
              " ['methods proposed literature',\n",
              "  'DFAs show deteriorating',\n",
              "  'automata DFAs show',\n",
              "  'finitestate automata DFAs',\n",
              "  'sigmoidal discriminant function'],\n",
              " ['Recent Results Lyapunovtheoretic',\n",
              "  'Results Lyapunovtheoretic Techniques',\n",
              "  'Converse Lyapunov Function',\n",
              "  'Report SYCON Recent',\n",
              "  'Lyapunovtheoretic Techniques Nonlinear'],\n",
              " ['CSTR UMIACSTR University',\n",
              "  'UMIACSTR University Maryland',\n",
              "  'Maryland College Park',\n",
              "  'Report CSTR UMIACSTR',\n",
              "  'University Maryland College'],\n",
              " ['steps required construct',\n",
              "  'neural network TDNN',\n",
              "  'network TDNN architecture',\n",
              "  'irregularlength schedules Experimental',\n",
              "  'TDNN architecture apply'],\n",
              " ['simulate Turing machines',\n",
              "  'Turing machines neural',\n",
              "  'deals simulation Turing',\n",
              "  'update Report SYCON',\n",
              "  'Report SYCON ABSTRACT'],\n",
              " ['stationary moving goal',\n",
              "  'bidirectional LRTS algorithm',\n",
              "  'LRTA algorithm realtime',\n",
              "  'LRTS algorithm determines',\n",
              "  'algorithm developed Korf'],\n",
              " ['Massachusetts Institute Technology',\n",
              "  'Trento Italy Gabriele',\n",
              "  'Department Mathematics University',\n",
              "  'University Trento Italy',\n",
              "  'Mathematics University Trento'],\n",
              " ['Sciences Technical Report',\n",
              "  'Technical Report September',\n",
              "  'University Wisconsin Computer',\n",
              "  'Wisconsin Computer Sciences',\n",
              "  'Computer Sciences Technical'],\n",
              " ['applied uniform distribution',\n",
              "  'properties Gibbs sampler',\n",
              "  'Gibbs sampler depend',\n",
              "  'Gibbs sampler applied',\n",
              "  'convergence properties Gibbs'],\n",
              " ['paper introduce modifications',\n",
              "  'concepts class attributes',\n",
              "  'attributevector representation intermediate',\n",
              "  'intermediate concepts class',\n",
              "  'representation intermediate concepts'],\n",
              " ['greatly reduce number',\n",
              "  'rule induction program',\n",
              "  'iteratively request class',\n",
              "  'highly efficient probabilistic',\n",
              "  'ten times larger'],\n",
              " ['model involving instrumental',\n",
              "  'paper derives general',\n",
              "  'account data conversely',\n",
              "  'models involving unmeasured',\n",
              "  'causal models involving'],\n",
              " ['Applied Probability University',\n",
              "  'Statistics Applied Probability',\n",
              "  'Address Department Statistics',\n",
              "  'Probability University California',\n",
              "  'Department Statistics Applied'],\n",
              " ['Freund Schapires AdaBoost',\n",
              "  'proposed Kearns Mansour',\n",
              "  'suggested Freund Schapire',\n",
              "  'improvements Freund Schapires',\n",
              "  'Freund Schapire Finally'],\n",
              " ['Genetic Algorithms illustrate',\n",
              "  'Evolutionary Algorithms direct',\n",
              "  'Strategies demonstrate learning',\n",
              "  'learning Evolution Strategies',\n",
              "  'Evolution Strategies demonstrate'],\n",
              " ['explicitly represents learns',\n",
              "  'emulate interactions present',\n",
              "  'approach explicitly represents',\n",
              "  'conditional probability distributions',\n",
              "  'methods learning Bayesian'],\n",
              " ['linear programming infer',\n",
              "  'validating directly achieve',\n",
              "  'credit card data',\n",
              "  'chosen pool trained',\n",
              "  'members chosen pool'],\n",
              " ['networks result improved',\n",
              "  'neural networks result',\n",
              "  'task neural networks',\n",
              "  'neural network trained',\n",
              "  'controller neural network'],\n",
              " ['improvements algorithm Firstly',\n",
              "  'algorithm Firstly present',\n",
              "  'Laplacian error estimate',\n",
              "  'inductive tool Comparisons',\n",
              "  'tool Comparisons Quinlans'],\n",
              " ['Palmer subsequently referred',\n",
              "  'Neural Computation Hertz',\n",
              "  'Krogh Palmer subsequently',\n",
              "  'Computation Hertz Krogh',\n",
              "  'Hertz Krogh Palmer'],\n",
              " ['sequences Results executiondriven',\n",
              "  'Results executiondriven pipelinelevel',\n",
              "  'code sequences Results',\n",
              "  'present Selective Eager',\n",
              "  'Selective Eager Execution'],\n",
              " ['approximates Bayesian decision',\n",
              "  'Bayesian decision theoretic',\n",
              "  'data Implications incremental',\n",
              "  'networks data Implications',\n",
              "  'task Comparative experiments'],\n",
              " ['address problem finding',\n",
              "  'induce small highaccuracy',\n",
              "  'machine learning literature',\n",
              "  'crossvalidation applicable induction',\n",
              "  'artificial real datasets'],\n",
              " ['form DNF decision',\n",
              "  'superior regression performance',\n",
              "  'normal form DNF',\n",
              "  'DNF decision rules',\n",
              "  'Experimental results realworld'],\n",
              " ['imply dual path',\n",
              "  'exclusively dual path',\n",
              "  'limited form dual',\n",
              "  'form dual path',\n",
              "  'dual path execution'],\n",
              " ['hardware Simultaneous Multithreading',\n",
              "  'Multithreading SMT processor',\n",
              "  'Threaded MultiPath Execution',\n",
              "  'Simultaneous Multithreading SMT',\n",
              "  'Mapping Synchronization Bus'],\n",
              " ['initially concept induction',\n",
              "  'paper review research',\n",
              "  'focus initially concept',\n",
              "  'suggest concrete computational',\n",
              "  'review research machine'],\n",
              " ['Markov models HMMs',\n",
              "  'hidden Markov modeling',\n",
              "  'analysis hidden Markov',\n",
              "  'Hidden Markov models',\n",
              "  'Markov modeling Pair'],\n",
              " ['limitations Pattern Theoretic',\n",
              "  'directions Knowledge Discovery',\n",
              "  'Databases KDD include',\n",
              "  'Discovery Databases KDD',\n",
              "  'Knowledge Discovery Databases'],\n",
              " ['Hypertext Book GNAVSNS',\n",
              "  'Book GNAVSNS Biocomputing',\n",
              "  'History Version Sep',\n",
              "  'Revision History Version',\n",
              "  'Chapter Hypertext Book'],\n",
              " ['node decision tree',\n",
              "  'induction oblique decision',\n",
              "  'construction oblique decision',\n",
              "  'hyperplane node decision',\n",
              "  'oblique decision trees'],\n",
              " ['fashion Hierarchical EBRL',\n",
              "  'introduced Dietterich Flann',\n",
              "  'Reinforcement Learning EBRL',\n",
              "  'Learning EBL Dietterich',\n",
              "  'EBL Dietterich Flann'],\n",
              " ['Discretization continuously valued',\n",
              "  'called BRACE Boundary',\n",
              "  'continuously valued data',\n",
              "  'Classification Evaluation attempts',\n",
              "  'BRACE Boundary Ranking'],\n",
              " ['Duda Hart probabilistic',\n",
              "  'Bayesian classifier Duda',\n",
              "  'Kononenko Bayesian classifier',\n",
              "  'naive Kononenko Bayesian',\n",
              "  'naive Bayesian classifier'],\n",
              " ['distantly related viral',\n",
              "  'Markov model approach',\n",
              "  'hidden Markov model',\n",
              "  'SAM HMMER methods',\n",
              "  'sequences SAM HMMER'],\n",
              " ['proposed representations task',\n",
              "  'finite state descriptions',\n",
              "  'discrete measurements Kolen',\n",
              "  'measurements Kolen Pollack',\n",
              "  'Watrous Kuhn Cleeremans'],\n",
              " ['faced inputs previously',\n",
              "  'shows domain knowledge',\n",
              "  'previously presented system',\n",
              "  'researchers recent years',\n",
              "  'inputs previously presented'],\n",
              " ['Vehicles transportation robots',\n",
              "  'undiscounted average reward',\n",
              "  'scheduling Automatic Guided',\n",
              "  'Guided Vehicles transportation',\n",
              "  'Automatic Guided Vehicles'],\n",
              " ['Lyapunov functions applies',\n",
              "  'differentiable Lyapunov functions',\n",
              "  'Lyapunov Function Theorem',\n",
              "  'presents Converse Lyapunov',\n",
              "  'Converse Lyapunov Function'],\n",
              " ['neglected problem field',\n",
              "  'build cognitive maps',\n",
              "  'problem field Artificial',\n",
              "  'Artificial Intelligence grounding',\n",
              "  'field Artificial Intelligence'],\n",
              " ['Mooney shown promise',\n",
              "  'EBL severely hampered',\n",
              "  'errors result Correcting',\n",
              "  'types performance errors',\n",
              "  'ExplanationBased Learning Mitchell'],\n",
              " ['set Bayesian network',\n",
              "  'instantiation Bayesian network',\n",
              "  'massively parallel Bolztmann',\n",
              "  'Bayesian network variables',\n",
              "  'MAP instantiation Bayesian'],\n",
              " ['directions future research',\n",
              "  'intelligent autonomous adaptive',\n",
              "  'adaptive communication networks',\n",
              "  'autonomous adaptive communication',\n",
              "  'Quo Vadis based'],\n",
              " ['Derek Stanford Graduate',\n",
              "  'University Washington Box',\n",
              "  'University Washington Derek',\n",
              "  'Department Statistics University',\n",
              "  'Statistics University Washington'],\n",
              " ['difference expected number',\n",
              "  'number mistakes made',\n",
              "  'root number mistakes',\n",
              "  'square root number',\n",
              "  'expected number mistakes'],\n",
              " ['structural similarity assessment',\n",
              "  'reasoning Cbr synthesis',\n",
              "  'casebased reasoning Cbr',\n",
              "  'transformation combinations Cbr',\n",
              "  'building design Borner'],\n",
              " ['present approach automated',\n",
              "  'sparse weakly informative',\n",
              "  'results show significant',\n",
              "  'time step allowing',\n",
              "  'learn perform task'],\n",
              " ['ideas presented Schapire',\n",
              "  'presented Schapire paper',\n",
              "  'method parallelizing PAC',\n",
              "  'general upper bounds',\n",
              "  'Valiants polynomial PAC'],\n",
              " ['steps relate abstract',\n",
              "  'set characteristics ratio',\n",
              "  'abstract predicates abstract',\n",
              "  'model ratio decidendi',\n",
              "  'relate abstract predicates'],\n",
              " ['give definition perfectly',\n",
              "  'definition perfectly neighbourhood',\n",
              "  'abstract computational principles',\n",
              "  'paper abstract computational',\n",
              "  'computational principles underlying'],\n",
              " ['Science supported NSF',\n",
              "  'Siemens Corporation Net',\n",
              "  'Laboratory Computer Science',\n",
              "  'MIT Laboratory Computer',\n",
              "  'Foundation Junior Faculty'],\n",
              " ['common set skills',\n",
              "  'set skills motor',\n",
              "  'describes research investigating',\n",
              "  'paper describes research',\n",
              "  'converge identical policies'],\n",
              " ['random Boolean logic',\n",
              "  'synthesis Boolean logic',\n",
              "  'units Cascade Correlation',\n",
              "  'functions product units',\n",
              "  'Boolean logic functions'],\n",
              " ['paper analyze NRL',\n",
              "  'computational architectures NRL',\n",
              "  'architectures NRL Navigation',\n",
              "  'analyze NRL Navigation',\n",
              "  'NRL Navigation task'],\n",
              " ['modification AGM framework',\n",
              "  'AGM framework proposed',\n",
              "  'probabilistic conditioning Contrary',\n",
              "  'conditioning Contrary AGM',\n",
              "  'Contrary AGM framework'],\n",
              " ['symbolic productionrule formalism',\n",
              "  'Results presented demonstrate',\n",
              "  'connectionist mechanisms Previous',\n",
              "  'Previous studies strategy',\n",
              "  'mechanisms Previous studies'],\n",
              " ['horizon Markov decision',\n",
              "  'Comprehensive answers questions',\n",
              "  'infinite horizon Markov',\n",
              "  'reinforcement learning method',\n",
              "  'direct reinforcement learning'],\n",
              " ['capture analogue prior',\n",
              "  'extends framework Halpern',\n",
              "  'Finally add time',\n",
              "  'operator Finally add',\n",
              "  'framework Halpern Fagin'],\n",
              " ['Gibbs sampling Markov',\n",
              "  'Key Words Adaptive',\n",
              "  'Monte Carlo MCMC',\n",
              "  'chain Monte Carlo',\n",
              "  'Markov chain Monte'],\n",
              " ['model Typically regularizer',\n",
              "  'describe Bayesian models',\n",
              "  'improvement generalization error',\n",
              "  'noise model Typically',\n",
              "  'Typically regularizer single'],\n",
              " ['supported financially European',\n",
              "  'field Machine Learning',\n",
              "  'real industrial commercial',\n",
              "  'coordinator Machine Learning',\n",
              "  'financially European Community'],\n",
              " ['paper describes application',\n",
              "  'poses combination challenges',\n",
              "  'domain poses combination',\n",
              "  'difficult real world',\n",
              "  'problem practical utility'],\n",
              " ['dramatic performance improvements',\n",
              "  'Fringe Exploration technique',\n",
              "  'Experimental results partially',\n",
              "  'presents Fringe Exploration',\n",
              "  'paper presents Fringe'],\n",
              " ['programming including Bairds',\n",
              "  'Performing policy iteration',\n",
              "  'including Bairds compute',\n",
              "  'actions Baird calls',\n",
              "  'Bairds compute form'],\n",
              " ['learning algorithms predict',\n",
              "  'Empirical experiments protein',\n",
              "  'algorithms Empirical experiments',\n",
              "  'learning algorithms Empirical',\n",
              "  'inductive learning algorithms'],\n",
              " ['Serial Genetic Algorithms',\n",
              "  'Distributed Genetic Algorithms',\n",
              "  'Sequential Serial Genetic',\n",
              "  'Faculty Sciences Technology',\n",
              "  'Genetic Algorithms SGA'],\n",
              " ['demonstrate ability twolayer',\n",
              "  'thresholded summation units',\n",
              "  'Hebbian relaxation network',\n",
              "  'similar human subjects',\n",
              "  'unsupervised Hebbian relaxation'],\n",
              " ['MIT Center Cognitive',\n",
              "  'Mozer Andrew Barto',\n",
              "  'Andrew Barto Robert',\n",
              "  'Michael Mozer Andrew',\n",
              "  'Barto Robert Jacobs'],\n",
              " ['Proceedings Eleventh International',\n",
              "  'Conference Machine Learning',\n",
              "  'International Conference Machine',\n",
              "  'Machine Learning Abstract',\n",
              "  'Eleventh International Conference'],\n",
              " ['Department Computer Science',\n",
              "  'Aiken Computation Laboratory',\n",
              "  'Calif Santa Cruz',\n",
              "  'California Santa Cruz',\n",
              "  'Santa Cruz Email'],\n",
              " ['selection strategy retaining',\n",
              "  'control knowledge Empirical',\n",
              "  'knowledge Empirical results',\n",
              "  'Empirical results presented',\n",
              "  'simple selection strategy'],\n",
              " ['dimensional spaces Future',\n",
              "  'Future versions designed',\n",
              "  'regions high dimensional',\n",
              "  'goal regions high',\n",
              "  'trajectories goal regions'],\n",
              " ['performed family Naive',\n",
              "  'posteriori MAP posterior',\n",
              "  'maximum posteriori MAP',\n",
              "  'Naive Bayes models',\n",
              "  'family Naive Bayes'],\n",
              " ['network adapted CBR',\n",
              "  'CBR perform theoretically',\n",
              "  'CBR system search',\n",
              "  'sound Bayesian reasoning',\n",
              "  'theoretically sound Bayesian'],\n",
              " ['Benedek Itai obtain',\n",
              "  'due Haussler Benedek',\n",
              "  'Kearns Schapires fatshattering',\n",
              "  'terms Kearns Schapires',\n",
              "  'Haussler Benedek Itai'],\n",
              " ['Minos modules Authority',\n",
              "  'employs collection Minoses',\n",
              "  'details Pre sented',\n",
              "  'wetware details Pre',\n",
              "  'Pre sented architecture'],\n",
              " ['maximize reward face',\n",
              "  'larger complicated domains',\n",
              "  'Markov decision processes',\n",
              "  'observable Markov decision',\n",
              "  'Partially observable Markov'],\n",
              " ['suitable number times',\n",
              "  'simple analysis faster',\n",
              "  'analysis faster efficient',\n",
              "  'algorithm MCMC techniques',\n",
              "  'proposed algorithm MCMC'],\n",
              " ['partially observable Partially',\n",
              "  'Observable Markov Decision',\n",
              "  'Partially Observable Markov',\n",
              "  'Smooth Partially Observable',\n",
              "  'Markov Decision Process'],\n",
              " ['Abductive Model Update',\n",
              "  'EventBased Abductive Model',\n",
              "  'Update Proc Tenth',\n",
              "  'Proc Tenth Canadian',\n",
              "  'Tenth Canadian Conf'],\n",
              " ['Recognition Cone models',\n",
              "  'predesigned Recognition Cone',\n",
              "  'parallelhierarchical Recognition Cone',\n",
              "  'Neuronal Connectionist models',\n",
              "  'Brainlike Neuronal Connectionist'],\n",
              " ['efficiently enables variety',\n",
              "  'tree induction ITI',\n",
              "  'ITI nonincremental tree',\n",
              "  'test quality DMTI',\n",
              "  'induction ITI nonincremental'],\n",
              " ['model Gaussian prior',\n",
              "  'derive closed form',\n",
              "  'obtain closed form',\n",
              "  'Finally show dual',\n",
              "  'Gaussian prior distribution'],\n",
              " ['provide computationally efficient',\n",
              "  'probability distributions graphical',\n",
              "  'field methods provide',\n",
              "  'field methods make',\n",
              "  'graphical models Simple'],\n",
              " ['ESP solve difficult',\n",
              "  'system Enforced SubPopulations',\n",
              "  'neuroevolution system Enforced',\n",
              "  'SubPopulations ESP solve',\n",
              "  'Enforced SubPopulations ESP'],\n",
              " ['learning spatial temporal',\n",
              "  'spatiotemporal patterns connectionist',\n",
              "  'spatiotemporal patterns discussed',\n",
              "  'spatial temporal spatiotemporal',\n",
              "  'temporal spatiotemporal patterns'],\n",
              " ['complexity previous online',\n",
              "  'size stateaction space',\n",
              "  'TDmethods accelerate Qlearning',\n",
              "  'observation Qvalue updates',\n",
              "  'based observation Qvalue'],\n",
              " ['Massively parallel networks',\n",
              "  'examined Empirical results',\n",
              "  'Empirical results study',\n",
              "  'learning structures processes',\n",
              "  'simple computing elements'],\n",
              " ['promising results ALVINN',\n",
              "  'ALVINN networks connectionist',\n",
              "  'pretrained ALVINN networks',\n",
              "  'results ALVINN Pomerleau',\n",
              "  'ALVINN Pomerleau shown'],\n",
              " ['asymptotic results method',\n",
              "  'introduce constructive incremental',\n",
              "  'task oriented incremental',\n",
              "  'trained independently compete',\n",
              "  'trained minimizing penalized'],\n",
              " ['feedback imperfect monitoring',\n",
              "  'Bayesian form prior',\n",
              "  'Finally show approach',\n",
              "  'exist imperfect monitoring',\n",
              "  'imperfect monitoring case'],\n",
              " ['accuracy probability ffi',\n",
              "  'product distributions multipleinstance',\n",
              "  'respect product distributions',\n",
              "  'unknown product distribution',\n",
              "  'assume unknown product'],\n",
              " ['inspired Boolean function',\n",
              "  'implemented program HINT',\n",
              "  'HINT HIerarchy Induction',\n",
              "  'HIerarchy Induction Tool',\n",
              "  'Induction Tool experimentally'],\n",
              " ['induction regression trees',\n",
              "  'construction regression trees',\n",
              "  'learning Bayesian approach',\n",
              "  'inductive learning Bayesian',\n",
              "  'Bayesian approach turned'],\n",
              " ['Massachusetts Institute Technology',\n",
              "  'Projects Agency Department',\n",
              "  'Presidential Young Investigator',\n",
              "  'IRI National Science',\n",
              "  'National Science Foundation'],\n",
              " ['proven dynamics deterministic',\n",
              "  'internal representation DFA',\n",
              "  'DFAs dense internal',\n",
              "  'finitestate automata DFA',\n",
              "  'Recently proven dynamics'],\n",
              " ['University Washington October',\n",
              "  'Department Statistics University',\n",
              "  'Statistics University Washington',\n",
              "  'University Washington Box',\n",
              "  'Washington Box Seattle'],\n",
              " ['trials maximize reward',\n",
              "  'attention simple model',\n",
              "  'expert Finally apply',\n",
              "  'Finally apply result',\n",
              "  'Past solutions bandit'],\n",
              " ['size network Finally',\n",
              "  'Bayesian belief network',\n",
              "  'Finally alternative traditional',\n",
              "  'messages neigh bors',\n",
              "  'representing Bayesian belief'],\n",
              " ['massively parallel supercomputer',\n",
              "  'requirement train large',\n",
              "  'Studies show peak',\n",
              "  'processor chip Studies',\n",
              "  'chip Studies show'],\n",
              " ['Reuters STAT Data',\n",
              "  'Data Manipulation Analysis',\n",
              "  'STAT Data Manipulation',\n",
              "  'Analysis Programs Perlman',\n",
              "  'Manipulation Analysis Programs'],\n",
              " ['repeatedly specializing overly',\n",
              "  'ing recursive definitions',\n",
              "  'Experimental results presented',\n",
              "  'overly general hypothesis',\n",
              "  'specializing overly general'],\n",
              " ['generalizer Computational results',\n",
              "  'Approximation inductive learning',\n",
              "  'introduces Recurrence Surface',\n",
              "  'Surface Approximation inductive',\n",
              "  'Recurrence Surface Approximation'],\n",
              " ['Wallace Wallace Dowe',\n",
              "  'Boulton Wallace Wallace',\n",
              "  'Snob Wallace Boulton',\n",
              "  'Boulton Wallace Freeman',\n",
              "  'Wallace Boulton Wallace'],\n",
              " ['presents VISIT connectionist',\n",
              "  'thesis presents VISIT',\n",
              "  'Effective parallel strategies',\n",
              "  'search Simulations show',\n",
              "  'pixels Effective parallel'],\n",
              " ['relations Lyapunov function',\n",
              "  'Lyapunov function yields',\n",
              "  'Lyapunov function optimization',\n",
              "  'Lyapunov function excitatoryinhibitory',\n",
              "  'fixed point attractors'],\n",
              " ['Bayesian inference Bayes',\n",
              "  'Chen Shao directly',\n",
              "  'sampling bridge sampling',\n",
              "  'importance sampling bridge',\n",
              "  'ratio importance sampling'],\n",
              " ['system runs Connection',\n",
              "  'PARKA massively parallel',\n",
              "  'top PARKA massively',\n",
              "  'built top PARKA',\n",
              "  'runs Connection Machine'],\n",
              " ['analyze worst case',\n",
              "  'fixed sample size',\n",
              "  'learning procedures distributionfree',\n",
              "  'series sequential learning',\n",
              "  'sequential learning procedures'],\n",
              " ['casebased reasoning Cbr',\n",
              "  'solving performance Cbr',\n",
              "  'performance Cbr explainability',\n",
              "  'building design Additionally',\n",
              "  'design Additionally sketch'],\n",
              " ['accessing models Finally',\n",
              "  'describe KRITIK system',\n",
              "  'types blameassignment tasks',\n",
              "  'KRITIK system implements',\n",
              "  'Finally describe KRITIK'],\n",
              " ['Science GMD Sankt',\n",
              "  'Computer Science GMD',\n",
              "  'Center Computer Science',\n",
              "  'GMD Sankt Augustin',\n",
              "  'Freiburg University Karlsruhe'],\n",
              " ['classifiers Autoclass Snob',\n",
              "  'Kohonens networks ART',\n",
              "  'comparison ART Autoclass',\n",
              "  'Autoclass Snob search',\n",
              "  'ART Autoclass Snob'],\n",
              " ['increasingly important issue',\n",
              "  'decisions partial justification',\n",
              "  'knowledge TMK model',\n",
              "  'taskmethod knowledge TMK',\n",
              "  'Interactive Kritik computerbased'],\n",
              " ['Statistical decision theory',\n",
              "  'observed data Experimental',\n",
              "  'data Experimental results',\n",
              "  'Experimental results show',\n",
              "  'amino acid frequencies'],\n",
              " ['isotropy Generalist models',\n",
              "  'socalled generalist models',\n",
              "  'properties generalist models',\n",
              "  'related isotropy Generalist',\n",
              "  'candidates cognitive modelling'],\n",
              " ['scenes confuse ALVINN',\n",
              "  'Reliable visionbased control',\n",
              "  'Pomerleau yielded good',\n",
              "  'system ALVINN Pomerleau',\n",
              "  'ALVINN Pomerleau yielded'],\n",
              " ['paper describe Markov',\n",
              "  'describe Markov Decision',\n",
              "  'Process MDP formulation',\n",
              "  'Decision Process MDP',\n",
              "  'Markov Decision Process'],\n",
              " ['boolean function learned',\n",
              "  'situations weather prediction',\n",
              "  'weather prediction measured',\n",
              "  'arise situations weather',\n",
              "  'adopt Valiant model'],\n",
              " ['backtracking mechanism problem',\n",
              "  'occurs deductive problem',\n",
              "  'deductive problem solvers',\n",
              "  'deductively learned knowledge',\n",
              "  'deductively learned rule'],\n",
              " ['Yee Vijay Gullapalli',\n",
              "  'Sutton Chris Watkins',\n",
              "  'Rich Yee Vijay',\n",
              "  'Rich Sutton Chris',\n",
              "  'Bolling AFB AFOSR'],\n",
              " ['Technical Report OSUCISRC',\n",
              "  'LEGION Locally Excitatory',\n",
              "  'Excitatory Globally Inhibitory',\n",
              "  'Locally Excitatory Globally',\n",
              "  'Globally Inhibitory Oscillator'],\n",
              " ['significant variation Schwartzs',\n",
              "  'Schwartzs Rlearning algorithm',\n",
              "  'Preliminary empirical results',\n",
              "  'Rlearning algorithm Preliminary',\n",
              "  'variation Schwartzs Rlearning'],\n",
              " ['deterministic finite automata',\n",
              "  'reset access teacher',\n",
              "  'learning unknown environments',\n",
              "  'labeled edge traverse',\n",
              "  'chooses labeled edge'],\n",
              " ['studied variety contexts',\n",
              "  'works focused finding',\n",
              "  'cases algorithms deterministic',\n",
              "  'bound number vertices',\n",
              "  'upper bound number'],\n",
              " ['description length MDL',\n",
              "  'target distribution Finally',\n",
              "  'distribution Finally address',\n",
              "  'Finally address questions',\n",
              "  'MDL principle Previous'],\n",
              " ['Vehicle AGV show',\n",
              "  'Reinforcement Learning ARL',\n",
              "  'Averagereward Reinforcement Learning',\n",
              "  'Automatic Guided Vehicle',\n",
              "  'Guided Vehicle AGV'],\n",
              " ['merge clustering selforganizing',\n",
              "  'discontinuities Merge clustering',\n",
              "  'Merge clustering extracts',\n",
              "  'boundaries discontinuities Merge',\n",
              "  'Methods merge clustering'],\n",
              " ['composite sequential decision',\n",
              "  'straightforward application reinforcement',\n",
              "  'class sequential decision',\n",
              "  'elemental sequential decision',\n",
              "  'sequential decision tasks'],\n",
              " ['sensory input Neural',\n",
              "  'Existing approaches learning',\n",
              "  'OSCAR robot arm',\n",
              "  'simulation OSCAR robot',\n",
              "  'tested simulation OSCAR'],\n",
              " ['simple extension state',\n",
              "  'aggregation Preliminary empirical',\n",
              "  'Preliminary empirical results',\n",
              "  'state aggregation Preliminary',\n",
              "  'soft state aggregation'],\n",
              " ['Samuels checker player',\n",
              "  'methods assign credit',\n",
              "  'Heuristic Critic remained',\n",
              "  'authors Adaptive Heuristic',\n",
              "  'Adaptive Heuristic Critic'],\n",
              " ['Dyna class architectures',\n",
              "  'programming methods Dyna',\n",
              "  'work Dyna class',\n",
              "  'previous work Dyna',\n",
              "  'based Watkinss Qlearning'],\n",
              " ['rollouts classical Monte',\n",
              "  'classical Monte Carlo',\n",
              "  'Monte Carlo methods',\n",
              "  'oine Boyan Moore',\n",
              "  'Boyan Moore reported'],\n",
              " ['researchers Rosenblatt Gallant',\n",
              "  'Smith Kanerva Prager',\n",
              "  'Rosenblatt Gallant Smith',\n",
              "  'Kanerva Prager Fallside',\n",
              "  'Gallant Smith Kanerva'],\n",
              " ['dynamically apportioning resources',\n",
              "  'Warmuth adapted model',\n",
              "  'weightupdate rule Littlestone',\n",
              "  'Littlestone Warmuth adapted',\n",
              "  'rule Littlestone Warmuth'],\n",
              " ['learning algorithm verified',\n",
              "  'learning algorithm equivariant',\n",
              "  'verified computer simulations',\n",
              "  'proposed online learning',\n",
              "  'online learning algorithm'],\n",
              " ['fields symbolic connectionist',\n",
              "  'pruning methods fail',\n",
              "  'network mfn Kohonens',\n",
              "  'Kohonens selforganising maps',\n",
              "  'mfn Kohonens selforganising'],\n",
              " ['belief set Adopting',\n",
              "  'Ramsey test minimal',\n",
              "  'extends AGM theory',\n",
              "  'Adopting Ramsey test',\n",
              "  'set Adopting Ramsey'],\n",
              " ['techniques address problem',\n",
              "  'learning fail Employing',\n",
              "  'Employing popular function',\n",
              "  'Reinforcement learning techniques',\n",
              "  'fail Employing popular'],\n",
              " ['UCSD San Diego',\n",
              "  'February Institute Neural',\n",
              "  'Computation UCSD San',\n",
              "  'Neural Computation UCSD',\n",
              "  'Institute Neural Computation'],\n",
              " ['Markov chain undirected',\n",
              "  'graphs representing Markov',\n",
              "  'representing Markov chain',\n",
              "  'representing Markov field',\n",
              "  'Gaussian discrete Bayesian'],\n",
              " ['Empirical results presented',\n",
              "  'solver Experimentation illustrates',\n",
              "  'Experimentation illustrates existence',\n",
              "  'simple selection strategy',\n",
              "  'amount learned knowledge'],\n",
              " ['neighbor knn Parzen',\n",
              "  'Parzen windows generalized',\n",
              "  'Condensed Nearest Neighbor',\n",
              "  'Grow Learn Condensed',\n",
              "  'Learn Condensed Nearest'],\n",
              " ['open questions study',\n",
              "  'CBR systems needed',\n",
              "  'endowing CBR systems',\n",
              "  'current CBR systems',\n",
              "  'impediment endowing CBR'],\n",
              " ['principles modeling introspective',\n",
              "  'introspective reasoning discusses',\n",
              "  'introspective reasoning step',\n",
              "  'framework modeling introspective',\n",
              "  'modeling introspective reasoning'],\n",
              " ['learning techniques perceived',\n",
              "  'learning techniques studied',\n",
              "  'simple algorithms Complex',\n",
              "  'multistrategy learning techniques',\n",
              "  'Machine learning techniques'],\n",
              " ['based MetaXPs explanation',\n",
              "  'chapter presents taxonomy',\n",
              "  'task Introspection requires',\n",
              "  'current task Introspection',\n",
              "  'Introspection requires declarative'],\n",
              " ['field equations relate',\n",
              "  'field approximation large',\n",
              "  'statistical pattern recognition',\n",
              "  'statistics unit Markov',\n",
              "  'unit Markov blanket'],\n",
              " ['learns basis external',\n",
              "  'basis external reinforcement',\n",
              "  'mobile robot Based',\n",
              "  'Based sensor information',\n",
              "  'robot Based sensor'],\n",
              " ['Scientific Research AFOSR',\n",
              "  'Office Naval Research',\n",
              "  'Office Scientific Research',\n",
              "  'Naval Research ONR',\n",
              "  'Force Office Scientific'],\n",
              " ['integer translates radially',\n",
              "  'spanned integer translates',\n",
              "  'spaces spanned integer',\n",
              "  'Gauss kernel Generalized',\n",
              "  'kernel Generalized Multiquadric'],\n",
              " ['give belief Nature',\n",
              "  'belief Nature represented',\n",
              "  'Nature represented target',\n",
              "  'Correct PAC learning',\n",
              "  'Approximately Correct PAC'],\n",
              " ['paper describe design',\n",
              "  'framework dersnlpebl Derivational',\n",
              "  'dersnlpebl Derivational snlpebl',\n",
              "  'drawn complex domain',\n",
              "  'Derivational snlpebl based'],\n",
              " ['Previous algorithms supervised',\n",
              "  'temporary variable binding',\n",
              "  'STM storage efficiency',\n",
              "  'potential STM storage',\n",
              "  'offers potential STM'],\n",
              " ['analyzed DCM smaller',\n",
              "  'DCM smaller computationally',\n",
              "  'ideas techniques DCM',\n",
              "  'subproblems analyzed DCM',\n",
              "  'DCM obtains decomposition'],\n",
              " ['Automating construction semantic',\n",
              "  'semantic categories Empirical',\n",
              "  'Empirical results show',\n",
              "  'based connectionist techniques',\n",
              "  'categories Empirical results'],\n",
              " ['Dynamic predication dynamically',\n",
              "  'called Dynamic Predication',\n",
              "  'show dynamic predication',\n",
              "  'set Dynamic predication',\n",
              "  'dynamic predication accrue'],\n",
              " ['space external nucleus',\n",
              "  'external nucleus inferior',\n",
              "  'twodimensional Kohonen map',\n",
              "  'learn signal based',\n",
              "  'Similar results observed'],\n",
              " ['theory proposed Samsonovich',\n",
              "  'McNaughton suggests Barnes',\n",
              "  'greater indicative similar',\n",
              "  'indicative similar representation',\n",
              "  'similar representation experiences'],\n",
              " ['Laboratory Perceptual Computing',\n",
              "  'Media Laboratory Perceptual',\n",
              "  'Perceptual Computing Section',\n",
              "  'Computing Section Technical',\n",
              "  'MIT Media Laboratory'],\n",
              " ['succeed range management',\n",
              "  'range management control',\n",
              "  'narrow bases implicit',\n",
              "  'comprehensively population large',\n",
              "  'extensions Genetic Algorithm'],\n",
              " ['Modern knowledge systems',\n",
              "  'methodspecific datatoknowledge compilation',\n",
              "  'called Interactive Kritik',\n",
              "  'Kritik integrated ORACLE',\n",
              "  'Interactive Kritik integrated'],\n",
              " ['paper investigates advantages',\n",
              "  'investigates advantages disadvantages',\n",
              "  'connectionist community JJNH',\n",
              "  'community JJNH applied',\n",
              "  'JJNH applied time'],\n",
              " ['dynamics developed Griniasty',\n",
              "  'patterns Bell Sejnowski',\n",
              "  'Tsodyks Amit multiple',\n",
              "  'developed Griniasty Tsodyks',\n",
              "  'Griniasty Tsodyks Amit'],\n",
              " ['paper examines effects',\n",
              "  'describe coarsegrain geographically',\n",
              "  'examines effects relaxed',\n",
              "  'coarsegrain geographically structured',\n",
              "  'experiments provide preliminary'],\n",
              " ['Key ideas statistical',\n",
              "  'theory support vector',\n",
              "  'single support vector',\n",
              "  'vector machines generalized',\n",
              "  'support vector machines'],\n",
              " ['Basis Functions RBF',\n",
              "  'classes basis functions',\n",
              "  'RBF Hyper Basis',\n",
              "  'Hyper Basis Functions',\n",
              "  'Radial Basis Functions'],\n",
              " ['Massachusetts Institute Technology',\n",
              "  'Biological Information Processing',\n",
              "  'Aircraft Corporation Alfred',\n",
              "  'Hughes Aircraft Corporation',\n",
              "  'Radial Basis Functions'],\n",
              " ['Casebased reasoning process',\n",
              "  'complements work casebased',\n",
              "  'implemented casebased story',\n",
              "  'work casebased reasoning',\n",
              "  'casebased reasoning providing'],\n",
              " ['sequence Stormo Haussler',\n",
              "  'Engelbrecht Knudsen splice',\n",
              "  'Stormo Haussler Probabilities',\n",
              "  'Brunak Engelbrecht Knudsen',\n",
              "  'Generalized Hidden Markov'],\n",
              " ['rates infinite payoff',\n",
              "  'repeated stage games',\n",
              "  'convergence rates infinite',\n",
              "  'develop notion grace',\n",
              "  'notion grace period'],\n",
              " ['efficient algorithms learning',\n",
              "  'algorithms learning play',\n",
              "  'learning play game',\n",
              "  'action determined simple',\n",
              "  'current action determined'],\n",
              " ['optimal segmentation DNA',\n",
              "  'DNA sequences MORGAN',\n",
              "  'genes vertebrate DNA',\n",
              "  'vertebrate DNA sequences',\n",
              "  'database vertebrate DNA'],\n",
              " ['intelligence process PYTHIA',\n",
              "  'process PYTHIA expert',\n",
              "  'PDE based application',\n",
              "  'PDEs PYTHIA exemplar',\n",
              "  'equations PDEs PYTHIA'],\n",
              " ['algorithm induce compact',\n",
              "  'smaller probability missclassification',\n",
              "  'criteria Comparison syntactical',\n",
              "  'Comparison syntactical hypotheses',\n",
              "  'fulfill criteria Comparison'],\n",
              " ['density structure target',\n",
              "  'noise sample density',\n",
              "  'algorithm dynamically alters',\n",
              "  'structure target function',\n",
              "  'sample density structure'],\n",
              " ['Decision Problems based',\n",
              "  'Decision Problems continuous',\n",
              "  'Decision Problems Bellmans',\n",
              "  'SemiMarkov Decision Problems',\n",
              "  'Markov Decision Problems'],\n",
              " ['Experts HME successful',\n",
              "  'ExclusiveOr Ninput Parity',\n",
              "  'Expectation Maximisation algorithm',\n",
              "  'Mixture Experts HME',\n",
              "  'Hierarchical Mixture Experts'],\n",
              " ['tional complexity evaluating',\n",
              "  'determining computa tional',\n",
              "  'computa tional complexity',\n",
              "  'factor determining computa',\n",
              "  'important factor determining'],\n",
              " ['conveniently applied specific',\n",
              "  'necessitate making assumptions',\n",
              "  'theory conveniently applied',\n",
              "  'degree generic difficulty',\n",
              "  'Existing complexity measures'],\n",
              " ['presents results empirical',\n",
              "  'paper shows existence',\n",
              "  'effectively constitutes weakness',\n",
              "  'conditionality order proposes',\n",
              "  'ability discount noise'],\n",
              " ['Gaussian RBF GRBF',\n",
              "  'Instrumentation July San',\n",
              "  'July San Diego',\n",
              "  'Engineering Instrumentation July',\n",
              "  'International Symposium Optical'],\n",
              " ['experiments demonstrate extracted',\n",
              "  'addition accurate extracted',\n",
              "  'Previously NofM algorithm',\n",
              "  'weightsharing Previously NofM',\n",
              "  'soft weightsharing Previously'],\n",
              " ['neural networks Advances',\n",
              "  'networks Advances Neural',\n",
              "  'Parallel Computing vol',\n",
              "  'neural network models',\n",
              "  'Artificial Neural Networks'],\n",
              " ['introspectively reason performs',\n",
              "  'task Introspection requires',\n",
              "  'current task Introspection',\n",
              "  'domain drug smuggling',\n",
              "  'Introspection requires declaratflive'],\n",
              " ['Backpropagationstyle neural networks',\n",
              "  'neural networks Empirical',\n",
              "  'knowledge Backpropagationstyle neural',\n",
              "  'rules artificial neural',\n",
              "  'artificial neural networks'],\n",
              " ['Initially framework defining',\n",
              "  'method feature subset',\n",
              "  'based Information Theory',\n",
              "  'Theory Initially framework',\n",
              "  'Information Theory Initially'],\n",
              " ['paper address problem',\n",
              "  'address problem casebased',\n",
              "  'directions future research',\n",
              "  'Oblivion carries greedy',\n",
              "  'algorithm Oblivion carries'],\n",
              " ['classifier system extended',\n",
              "  'systems genetic algorithms',\n",
              "  'classifier systems genetic',\n",
              "  'kinds Animatlike behaviors',\n",
              "  'LECSYS parallel implementation'],\n",
              " ['computational complexity probabilistic',\n",
              "  'show BNO networka',\n",
              "  'inference general Bayesian',\n",
              "  'general Bayesian belief',\n",
              "  'multiple similar states'],\n",
              " ['Bayesian belief networks',\n",
              "  'belief networks Helmholtz',\n",
              "  'networks Helmholtz machines',\n",
              "  'bench mark problems',\n",
              "  'Helmholtz machines provide'],\n",
              " ['generated adversary unbounded',\n",
              "  'adversary unbounded computational',\n",
              "  'learning introduced Valiant',\n",
              "  'correct PAC model',\n",
              "  'approximately correct PAC'],\n",
              " ['share parametric form',\n",
              "  'family finite mixture',\n",
              "  'good estimates true',\n",
              "  'class selection experiments',\n",
              "  'size grows large'],\n",
              " ['finite mixture models',\n",
              "  'University Helsinki Department',\n",
              "  'Helsinki Department Computer',\n",
              "  'Computer Science Abstract',\n",
              "  'Department Computer Science'],\n",
              " ['reasoner introspectively detect',\n",
              "  'address issues transferability',\n",
              "  'introspectively detect repair',\n",
              "  'evaluating introspective component',\n",
              "  'show ROBBIEs hierarchical'],\n",
              " ['decisions derived Computer',\n",
              "  'Structural properties problems',\n",
              "  'derived Computer experiments',\n",
              "  'Computer experiments confirm',\n",
              "  'importance Structural properties'],\n",
              " ['building Bayesian networks',\n",
              "  'suited building Bayesian',\n",
              "  'inefficiencies Recent results',\n",
              "  'Recent results shown',\n",
              "  'computational inefficiencies Recent'],\n",
              " ['complex multiconnected Bayesian',\n",
              "  'good approximative Bayesian',\n",
              "  'simulated annealing algorithm',\n",
              "  'called Bayesian prototype',\n",
              "  'Bayesian prototype trees'],\n",
              " ['knowledge underlying distributions',\n",
              "  'main ideas Evidential',\n",
              "  'Probability Specifically show',\n",
              "  'ideas Evidential Probability',\n",
              "  'Evidential Probability Specifically'],\n",
              " ['Variable Resolution Dynamic',\n",
              "  'Kaelbling Variable Resolution',\n",
              "  'Galgorithm Chapman Kaelbling',\n",
              "  'Resolution Dynamic Programming',\n",
              "  'Chapman Kaelbling Variable'],\n",
              " ['Feature selection problem',\n",
              "  'selection problem choosing',\n",
              "  'exhaustive Experiments conducted',\n",
              "  'complete exhaustive Experiments',\n",
              "  'Experiments conducted verification'],\n",
              " ['System supports access',\n",
              "  'dynamic programming Qlearning',\n",
              "  'EmaiL Voice Interactive',\n",
              "  'Interactive System supports',\n",
              "  'Voice Interactive System'],\n",
              " ['Pruning Inductive Logic',\n",
              "  'Inductive Logic Programming',\n",
              "  'Incremental Reduced Error',\n",
              "  'Error Pruning Inductive',\n",
              "  'Reduced Error Pruning'],\n",
              " ['network implemented CNAPS',\n",
              "  'implemented CNAPS server',\n",
              "  'architecture Adaptive Solutions',\n",
              "  'SIMD architecture Adaptive',\n",
              "  'speed Sun Sparc'],\n",
              " ['problem faced agent',\n",
              "  'accessible researchers familiar',\n",
              "  'researchers familiar machine',\n",
              "  'written accessible researchers',\n",
              "  'Markov decision theory'],\n",
              " ['employed XCS adequate',\n",
              "  'XCS adequate guarantee',\n",
              "  'XCS classifier system',\n",
              "  'complex nonMarkovian environments',\n",
              "  'aliasing states Experimental'],\n",
              " ['discussed Basic concept',\n",
              "  'Effectiveness proposed method',\n",
              "  'formal analogue Hebbian',\n",
              "  'Basic concept approach',\n",
              "  'task Resemblance genetic'],\n",
              " ['MINFEATURES bias prefers',\n",
              "  'implements MINFEATURES bias',\n",
              "  'implementation MINFEATURES bias',\n",
              "  'approximating MINFEATURES bias',\n",
              "  'approximate implementation MINFEATURES'],\n",
              " ['sequences temporal dependencies',\n",
              "  'Markov version tree',\n",
              "  'approach decision tree',\n",
              "  'hidden Markov version',\n",
              "  'MAP estimation techniques'],\n",
              " ['assumptions statistical properties',\n",
              "  'register LFSR noisy',\n",
              "  'LFSR noisy observation',\n",
              "  'awkward posterior distribution',\n",
              "  'shift register LFSR'],\n",
              " ['Mitchell Movshon Hirsch',\n",
              "  'National Science Foundation',\n",
              "  'Hirsch Boothe Singer',\n",
              "  'Movshon Hirsch Boothe',\n",
              "  'Wisconsin Graduate School'],\n",
              " ['descent BaumWelch algorithm',\n",
              "  'Markov chain theory',\n",
              "  'represent longterm context',\n",
              "  'transition probability matrices',\n",
              "  'probability matrices Markovian'],\n",
              " ['Planning Research Center',\n",
              "  'Interactive Planning Research',\n",
              "  'Research Center Computer',\n",
              "  'Center Computer Science',\n",
              "  'Computer Science FZI'],\n",
              " ['pipe pig Research',\n",
              "  'pig Research center',\n",
              "  'PTX Karlsruhe developed',\n",
              "  'GmbH PTX Karlsruhe',\n",
              "  'Pipetronix GmbH PTX'],\n",
              " ['algorithm Mstep computationally',\n",
              "  'Mstep computationally straightforward',\n",
              "  'EMbased algorithm Mstep',\n",
              "  'PCA Incorporating tangentplane',\n",
              "  'analysis PCA Incorporating'],\n",
              " ['Science Technical Report',\n",
              "  'Computer Science Technical',\n",
              "  'University Colorado Computer',\n",
              "  'International Journal Neural',\n",
              "  'Colorado Computer Science'],\n",
              " ['learning system Golem',\n",
              "  'systems Magnus Assistant',\n",
              "  'Assistant Retis data',\n",
              "  'machine learning systems',\n",
              "  'Magnus Assistant Retis'],\n",
              " ['interactive KRITIK multimodal',\n",
              "  'consisted interactive KRITIK',\n",
              "  'front end HIPED',\n",
              "  'received front end',\n",
              "  'front end evaluated'],\n",
              " ['difference methods solve',\n",
              "  'problem Finally experimental',\n",
              "  'applied problem Finally',\n",
              "  'Finally experimental results',\n",
              "  'Temporal difference methods'],\n",
              " ['ONRNK NSFDCR NSFCCR',\n",
              "  'NSFDCR NSFCCR DAALK',\n",
              "  'NSFCCR DAALK DARPA',\n",
              "  'Approximately Correct PAC',\n",
              "  'DARPA AFOSR SERC'],\n",
              " ['Additionally improvements achieved',\n",
              "  'aligned ABI trace',\n",
              "  'incorporates aligned ABI',\n",
              "  'ABI trace information',\n",
              "  'DNA fragment assemblies'],\n",
              " ['capacity recognize morphologically',\n",
              "  'word Experiments artificial',\n",
              "  'Experiments artificial language',\n",
              "  'morphologically complex words',\n",
              "  'recognize morphologically complex'],\n",
              " ['improvement competing EBL',\n",
              "  'combines traditional EBL',\n",
              "  'EBL techniques recent',\n",
              "  'traditional EBL techniques',\n",
              "  'competing EBL approaches'],\n",
              " ['Anatomical neurophysiological evidence',\n",
              "  'view Anatomical neurophysiological',\n",
              "  'enables neurons learn',\n",
              "  'rule enables neurons',\n",
              "  'trace rule enables'],\n",
              " ['minimize output error',\n",
              "  'input variables missing',\n",
              "  'data input variables',\n",
              "  'Unlike case probabilistic',\n",
              "  'frequencies Unlike case'],\n",
              " ['number structured neural',\n",
              "  'sorting Simulations show',\n",
              "  'Simulations show fixpointpreserving',\n",
              "  'dynamics reconciling Lagrangian',\n",
              "  'reconciling Lagrangian formalism'],\n",
              " ['involves subtasks recalling',\n",
              "  'reasoning process model',\n",
              "  'systems CASECAD CADSYN',\n",
              "  'CASECAD CADSYN WIN',\n",
              "  'CADSYN WIN DEMEX'],\n",
              " ['Kalman filtering optimal',\n",
              "  'Previous work elucidated',\n",
              "  'Kalman filters operating',\n",
              "  'implement Kalman filters',\n",
              "  'cortex Previous work'],\n",
              " ['hiding genetic differences',\n",
              "  'Baldwin effect Hiding',\n",
              "  'Baldwin effect Baldwin',\n",
              "  'effect Baldwin Hinton',\n",
              "  'Baldwin Hinton Nowlan'],\n",
              " ['describe kind racing',\n",
              "  'honing estimates promising',\n",
              "  'based learner show',\n",
              "  'estimates promising regions',\n",
              "  'memory based learner'],\n",
              " ['Based analysis experiments',\n",
              "  'Japanese handwriting recognition',\n",
              "  'develop offline Chinese',\n",
              "  'offline Chinese Japanese',\n",
              "  'Chinese Japanese handwriting'],\n",
              " ['message length MML',\n",
              "  'experiments show MML',\n",
              "  'relative Bayesian criteria',\n",
              "  'show MML criterion',\n",
              "  'length MML criterion'],\n",
              " ['connection structure MIMD',\n",
              "  'range MIMD parallel',\n",
              "  'decomposition techniques Agreement',\n",
              "  'backpropagation Kohonen selforganizing',\n",
              "  'Kohonen selforganizing feature'],\n",
              " ['Finally explain performance',\n",
              "  'simultaneously Finally explain',\n",
              "  'mutation hill climbing',\n",
              "  'random mutation hill',\n",
              "  'Monte Carlo sampling'],\n",
              " ['positioning RBF units',\n",
              "  'toperform positioning RBF',\n",
              "  'basis function RBF',\n",
              "  'function RBF approach',\n",
              "  'Kohonen feature map'],\n",
              " ['COLUMBUS operates realtime',\n",
              "  'COLUMBUS operates initially',\n",
              "  'Realworld experiences generalized',\n",
              "  'maximize exploration COLUMBUS',\n",
              "  'exploration COLUMBUS operates'],\n",
              " ['Parallel Search succeeds',\n",
              "  'aware Genetic Type',\n",
              "  'Genetic Type Algorithm',\n",
              "  'Field Theoretic algorithm',\n",
              "  'Explicitly Parallel Search'],\n",
              " ['experiments datasets FIBL',\n",
              "  'proposes Fuzzy Instance',\n",
              "  'Based Learning FIBL',\n",
              "  'Instance Based Learning',\n",
              "  'Fuzzy Instance Based'],\n",
              " ['paper describes formulation',\n",
              "  'complex concurrent multirobot',\n",
              "  'dynamic environemnts complex',\n",
              "  'noisy dynamic environemnts',\n",
              "  'environemnts complex concurrent'],\n",
              " ['suboptimal believed produce',\n",
              "  'current work attempt',\n",
              "  'attempt verify belief',\n",
              "  'work attempt verify',\n",
              "  'approach suboptimal believed'],\n",
              " ['results input state',\n",
              "  'Previous results input',\n",
              "  'ABSTRACT Previous results',\n",
              "  'Report SYCON ABSTRACT',\n",
              "  'SYCON ABSTRACT Previous'],\n",
              " ['statistical formulation localist',\n",
              "  'explore behavior localist',\n",
              "  'procedures CPU intensive',\n",
              "  'training procedures CPU',\n",
              "  'localist attractor nets'],\n",
              " ['enterprise Good generalisation',\n",
              "  'nofreelunch NFL theorems',\n",
              "  'set key importance',\n",
              "  'zerosum enterprise Good',\n",
              "  'Wolperts nofreelunch NFL'],\n",
              " ['Ecole Polytechnique Federale',\n",
              "  'International Computer Science',\n",
              "  'Microinformatique Ecole Polytechnique',\n",
              "  'Fonds National Suisse',\n",
              "  'Omohondro Leon Personnaz'],\n",
              " ['priors including Dirichlet',\n",
              "  'MAP mixture trees',\n",
              "  'Dirichlet MDL priors',\n",
              "  'Minimum Spanning Tree',\n",
              "  'including Dirichlet MDL'],\n",
              " ['problems analyzing DNA',\n",
              "  'human DNA compare',\n",
              "  'DNA compare performance',\n",
              "  'Mural identify coding',\n",
              "  'Uberbacher Mural identify'],\n",
              " ['Based sensor information',\n",
              "  'robot Based sensor',\n",
              "  'mobile robot Based',\n",
              "  'Temporal Difference learning',\n",
              "  'Rules Temporal Difference'],\n",
              " ['viewed logically separate',\n",
              "  'leads number conceptual',\n",
              "  'view leads number',\n",
              "  'number conceptual difficulties',\n",
              "  'seperatist view leads'],\n",
              " ['address question neural',\n",
              "  'incorporation information extracted',\n",
              "  'general problem call',\n",
              "  'speed ten times',\n",
              "  'studies address question'],\n",
              " ['Net Backpropagation trained',\n",
              "  'Neural Net Backpropagation',\n",
              "  'Correlation Cascade compare',\n",
              "  'Quickprop Cascade Correlation',\n",
              "  'Cascade Correlation Cascade'],\n",
              " ['work describe Bayesian',\n",
              "  'Bayes optimal decision',\n",
              "  'tool supporting Bayes',\n",
              "  'supporting Bayes optimal',\n",
              "  'finite mixture models'],\n",
              " ['classification combines Rosenblatts',\n",
              "  'algorithm Helmbold Warmuths',\n",
              "  'Vapniks maximalmargin classifier',\n",
              "  'margins Compared Vapniks',\n",
              "  'Helmbold Warmuths leaveoneout'],\n",
              " ['levels ILP TLP',\n",
              "  'Systems August Permission',\n",
              "  'Computer Systems August',\n",
              "  'Transactions Computer Systems',\n",
              "  'ACM Transactions Computer'],\n",
              " ['paper present framework',\n",
              "  'present framework building',\n",
              "  'framework building probabilistic',\n",
              "  'probabilities Gibbs distributions',\n",
              "  'contextdependent probabilities Gibbs'],\n",
              " ['terms prediction error',\n",
              "  'machines Performance analyzed',\n",
              "  'Boston housing database',\n",
              "  'nonlinear functions Boston',\n",
              "  'functions Boston housing'],\n",
              " ['properly handle imprecise',\n",
              "  'handle imprecise incomplete',\n",
              "  'Current expert systems',\n",
              "  'approximate probabilistic reasoning',\n",
              "  'system shell NEULA'],\n",
              " ['Queen effect significantly',\n",
              "  'Queen effect interacting',\n",
              "  'Queen effect developed',\n",
              "  'rise Red Queen',\n",
              "  'Red Queen effect'],\n",
              " ['Statistics Nutrition Toxicology',\n",
              "  'Toxicology Department Statistics',\n",
              "  'Department Statistics Texas',\n",
              "  'National Cancer Institute',\n",
              "  'Nutrition Toxicology Department'],\n",
              " ['conduct experiments tough',\n",
              "  'recombination mechanisms arbitrary',\n",
              "  'paper investigate phenomenon',\n",
              "  'participate creating children',\n",
              "  'operators work distributions'],\n",
              " ['Policy Postdoctoral Fellow',\n",
              "  'Paula Diehr Kevin',\n",
              "  'Diehr Kevin Cain',\n",
              "  'Service Award TCA',\n",
              "  'University Washington Seattle'],\n",
              " ['University Pennsylvania Abstract',\n",
              "  'Ungar Williams College',\n",
              "  'College University Pennsylvania',\n",
              "  'Williams College University',\n",
              "  'Artificial neural networks'],\n",
              " ['class Parzen window',\n",
              "  'properties Parzen window',\n",
              "  'memory Parzen window',\n",
              "  'applications Parzen window',\n",
              "  'Parzen window estimation'],\n",
              " ['improve time space',\n",
              "  'dynamically allocated objects',\n",
              "  'computer programs Barrett',\n",
              "  'choose relevant subset',\n",
              "  'programs Barrett Zorn'],\n",
              " ['describes approach user',\n",
              "  'paper describes approach',\n",
              "  'approach user specifies',\n",
              "  'turbine design scheduling',\n",
              "  'search time evolutionary'],\n",
              " ['weak preference biases',\n",
              "  'FRINGE algorithms shows',\n",
              "  'Boolean concept learning',\n",
              "  'bound Experimental measurement',\n",
              "  'upper bound Experimental'],\n",
              " ['policy iteration SPI',\n",
              "  'iteration SPI constructs',\n",
              "  'SPI constructs optimal',\n",
              "  'temporal Bayesian network',\n",
              "  'reflected temporal Bayesian'],\n",
              " ['information Function specification',\n",
              "  'local information Function',\n",
              "  'Systems ASOCS similar',\n",
              "  'SelfOrganizing Concurrent Systems',\n",
              "  'Concurrent Systems ASOCS'],\n",
              " ['Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'Monte Carlo quadrature',\n",
              "  'KEY WORDS Convergence',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['based linear Hebbian',\n",
              "  'linear Hebbian learning',\n",
              "  'Understanding regularities enable',\n",
              "  'random images Understanding',\n",
              "  'Hebbian learning principal'],\n",
              " ['develop empirical methodology',\n",
              "  'paper develop empirical',\n",
              "  'epistasis simple GAs',\n",
              "  'performance EAs Finally',\n",
              "  'EAs Finally illustrate'],\n",
              " ['work focused uniform',\n",
              "  'sampling disruption uniform',\n",
              "  'framework understanding virtues',\n",
              "  'Traditionally genetic algorithms',\n",
              "  'Theoretical results suggest'],\n",
              " ['formulas bounded nesting',\n",
              "  'logics introduced Lewis',\n",
              "  'Stalnaker utilized artificial',\n",
              "  'Lewis Stalnaker utilized',\n",
              "  'introduced Lewis Stalnaker'],\n",
              " ['timestep information previous',\n",
              "  'distant past Experiments',\n",
              "  'Reber grammar demonstrated',\n",
              "  'Experiments Reber grammar',\n",
              "  'past Experiments Reber'],\n",
              " ['output redundancy Illustrative',\n",
              "  'redundancy Illustrative experiments',\n",
              "  'implement Occams razor',\n",
              "  'automatically implement Occams',\n",
              "  'Unlike previous methods'],\n",
              " ['misclassified Kearns recently',\n",
              "  'learning PAC model',\n",
              "  'sufficient condition PAC',\n",
              "  'statistical queries sufficient',\n",
              "  'PAC model Valiant'],\n",
              " ['stage study evolution',\n",
              "  'task individual encode',\n",
              "  'initial Qvalues learning',\n",
              "  'parameters initial Qvalues',\n",
              "  'Sutton task individual'],\n",
              " ['performing exact dynamicprogramming',\n",
              "  'wide range pomdp',\n",
              "  'Markov decision processes',\n",
              "  'partially observable Markov',\n",
              "  'observable Markov decision'],\n",
              " ['suite differs earlier',\n",
              "  'benchmark suite differs',\n",
              "  'recent version SPEC',\n",
              "  'version SPEC benchmark',\n",
              "  'SPEC benchmark suite'],\n",
              " ['paper present framework',\n",
              "  'present framework building',\n",
              "  'framework building probabilistic',\n",
              "  'probabilities Gibbs distributions',\n",
              "  'contextdependent probabilities Gibbs'],\n",
              " ['Models unsupervised correlationbased',\n",
              "  'distinguished multiplicative subtractive',\n",
              "  'correlationbased Hebbian synaptic',\n",
              "  'Hebbian synaptic plasticity',\n",
              "  'unsupervised correlationbased Hebbian'],\n",
              " ['Human Information Processing',\n",
              "  'Center Biological Computational',\n",
              "  'Biological Computational Learning',\n",
              "  'ATR Human Information',\n",
              "  'Presidential Young Investigator'],\n",
              " ['efficient actively select',\n",
              "  'made efficient actively',\n",
              "  'framework objective functions',\n",
              "  'Bayesian learning framework',\n",
              "  'prove main weakness'],\n",
              " ['Incremental feature map',\n",
              "  'map Incremental feature',\n",
              "  'Ordinary feature maps',\n",
              "  'unknown distribution Ordinary',\n",
              "  'distribution Ordinary feature'],\n",
              " ['characterization ADGs Markov',\n",
              "  'conditional independence LCI',\n",
              "  'ADGs Markov equivalent',\n",
              "  'equivalent transitive ADG',\n",
              "  'Markov equivalent transitive'],\n",
              " ['improving geneticalgorithmbased optimization',\n",
              "  'idea utilize sequence',\n",
              "  'design Empirical results',\n",
              "  'muta tion rate',\n",
              "  'engineering design Empirical'],\n",
              " ['realistic engineering design',\n",
              "  'Empirical results domains',\n",
              "  'domains Empirical results',\n",
              "  'Genetic algorithms GAs',\n",
              "  'design domains Empirical'],\n",
              " ['Internal Representations Error',\n",
              "  'Williams Learning Internal',\n",
              "  'Representations Error Propagation',\n",
              "  'Learning Internal Representations',\n",
              "  'Vol MIT Press'],\n",
              " ['biological questions MSAs',\n",
              "  'sequence alignment MSA',\n",
              "  'MSA light broad',\n",
              "  'major applications MSA',\n",
              "  'functional applications MSA'],\n",
              " ['mechanism combining associative',\n",
              "  'proposed mechanism combining',\n",
              "  'feedforward synapses Experimental',\n",
              "  'synapses Experimental data',\n",
              "  'Experimental data demonstrates'],\n",
              " ['chain Monte Carlo',\n",
              "  'Markov chain Monte',\n",
              "  'Department Statistics University',\n",
              "  'Statistics University Toronto',\n",
              "  'University Toronto Abstract'],\n",
              " ['studying automated planning',\n",
              "  'provide foundations number',\n",
              "  'researchers studying automated',\n",
              "  'automated planning reinforcement',\n",
              "  'planning reinforcement learning'],\n",
              " ['language Based techniques',\n",
              "  'Finally present experimental',\n",
              "  'programming language Based',\n",
              "  'allowing connectionist Qlearner',\n",
              "  'connectionist Qlearner accept'],\n",
              " ['Markov model statistical',\n",
              "  'complete derivations Dirichlet',\n",
              "  'mathematical foundations Dirichlet',\n",
              "  'profile hidden Markov',\n",
              "  'expected amino acid'],\n",
              " ['depends ability overcome',\n",
              "  'amount contributes depends',\n",
              "  'contributes depends ability',\n",
              "  'empirical study shows',\n",
              "  'scratch amount contributes'],\n",
              " ['state automaton FSA',\n",
              "  'automaton FSA trained',\n",
              "  'sets Followon work',\n",
              "  'capable learning Tomita',\n",
              "  'Followon work focused'],\n",
              " ['controlled manner Empirical',\n",
              "  'manner Empirical results',\n",
              "  'Technical Report January',\n",
              "  'Report January Abstract',\n",
              "  'COINS Technical Report'],\n",
              " ['Evolution Buildable Objects',\n",
              "  'Computer Evolution Buildable',\n",
              "  'Fourth European Conference',\n",
              "  'European Conference Artificial',\n",
              "  'Conference Artificial Life'],\n",
              " ['bases acquired independently',\n",
              "  'demonstrate advantages method',\n",
              "  'implemented system INTEG',\n",
              "  'system INTEG present',\n",
              "  'INTEG present concrete'],\n",
              " ['evolutionary process Initial',\n",
              "  'eye Inspired observation',\n",
              "  'process Initial experiments',\n",
              "  'compound eye Inspired',\n",
              "  'Initial experiments performed'],\n",
              " ['Euclidean structure guide',\n",
              "  'Essentially method involves',\n",
              "  'MCMC application involving',\n",
              "  'MCMC commonly natural',\n",
              "  'reversible jump MCMC'],\n",
              " ['phase form interpolative',\n",
              "  'training phase form',\n",
              "  'instancebased learning Earlier',\n",
              "  'learning Earlier attempts',\n",
              "  'Earlier attempts combat'],\n",
              " ['total number mistakes',\n",
              "  'minimize total number',\n",
              "  'number mistakes made',\n",
              "  'relate apple tasting',\n",
              "  'purpose apple tasting'],\n",
              " ['order break domain',\n",
              "  'learnable partitions Traditionally',\n",
              "  'Traditionally error distribution',\n",
              "  'error measure RMS',\n",
              "  'based learners crossvalidation'],\n",
              " ['high performance MIMD',\n",
              "  'execution platforms PREENS',\n",
              "  'Research Execution Environment',\n",
              "  'Parallel Research Execution',\n",
              "  'PREENS Parallel Research'],\n",
              " ['Energy quantity introduced',\n",
              "  'ALECSYS parallel version',\n",
              "  'original features Mutespec',\n",
              "  'steady state Dynamical',\n",
              "  'standard learning classifier'],\n",
              " ['adding Gaussian noise',\n",
              "  'controlled adding Gaussian',\n",
              "  'expected squared error',\n",
              "  'Monte Carlo simulations',\n",
              "  'timeconsuming Monte Carlo'],\n",
              " ['algorithm based Hedge',\n",
              "  'online learning algorithm',\n",
              "  'WWW search engine',\n",
              "  'strategy WWW search',\n",
              "  'expansion strategy WWW'],\n",
              " ['operation principles inspired',\n",
              "  'March Abstract Evolutionary',\n",
              "  'Technical Report CSRP',\n",
              "  'Report CSRP March',\n",
              "  'CSRP March Abstract'],\n",
              " ['neural net architecture',\n",
              "  'studied Mozer Ring',\n",
              "  'present neural net',\n",
              "  'Ring Rohwer Schmidhuber',\n",
              "  'Mozer Ring Rohwer'],\n",
              " ['vector closest Euclidian',\n",
              "  'Euclidian distance input',\n",
              "  'changed proportional Euclidian',\n",
              "  'closest Euclidian distance',\n",
              "  'proportional Euclidian distance'],\n",
              " ['application decision making',\n",
              "  'reductions training time',\n",
              "  'integrates imitation Qlearning',\n",
              "  'imitation Qlearning Roughly',\n",
              "  'Qlearning Roughly Qlearner'],\n",
              " ['hybrid neural network',\n",
              "  'present hybrid neural',\n",
              "  'map neural network',\n",
              "  'selforganizing map neural',\n",
              "  'convolutional neural network'],\n",
              " ['iteration Specifically set',\n",
              "  'solving Markov decision',\n",
              "  'policy iteration Specifically',\n",
              "  'algorithm Puterman Shin',\n",
              "  'modified policy iteration'],\n",
              " ['develop Monte Carlo',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'Savage Award session',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['PAC model Specifically',\n",
              "  'Combined result Simon',\n",
              "  'presence classification noise',\n",
              "  'learning presence classification',\n",
              "  'PAC learning presence'],\n",
              " ['hosts adaptive trait',\n",
              "  'paper describes simulations',\n",
              "  'betweenhost tradeoffs result',\n",
              "  'describes simulations study',\n",
              "  'adaptive trait Selection'],\n",
              " ['work qualitative physics',\n",
              "  'qualitative physics involves',\n",
              "  'pressure Semiquantitative methods',\n",
              "  'Semiquantitative methods improve',\n",
              "  'increases pressure Semiquantitative'],\n",
              " ['MemoryBased Learning problem',\n",
              "  'problem Prepositional Phrase',\n",
              "  'Prepositional Phrase attachment',\n",
              "  'Learning problem Prepositional',\n",
              "  'metrics Lexical Space'],\n",
              " ['University Medical Center',\n",
              "  'Duke University Medical',\n",
              "  'Mitchell Prize Bayesian',\n",
              "  'Medical Center Durham',\n",
              "  'DMS DMS DMS'],\n",
              " ['processing NLP tasks',\n",
              "  'NLP tasks growing',\n",
              "  'mandatory Recent work',\n",
              "  'large class NLP',\n",
              "  'language processing NLP'],\n",
              " ['readonce formulas basis',\n",
              "  'identifying class readonce',\n",
              "  'formulas basis boolean',\n",
              "  'class readonce formulas',\n",
              "  'Angluin Hellerstein Karpinski'],\n",
              " ['data Bach chorales',\n",
              "  'Viterbilike assumption made',\n",
              "  'artificial data Bach',\n",
              "  'oral presentation NIPS',\n",
              "  'Bach chorales Accepted'],\n",
              " ['characteristics dynamic probabilistic',\n",
              "  'posterior probabilities probabilistic',\n",
              "  'sampling SOF repopulates',\n",
              "  'fittest sampling SOF',\n",
              "  'SOF repopulates set'],\n",
              " ['Search technique single',\n",
              "  'Initially temperature high',\n",
              "  'Temperature Initially temperature',\n",
              "  'Annealing Search technique',\n",
              "  'Simulated Annealing Search'],\n",
              " ['small disjuncts error',\n",
              "  'disjuncts error prone',\n",
              "  'prone large disjuncts',\n",
              "  'Holte Acker Porter',\n",
              "  'error prone large'],\n",
              " ['membership equivalence queries',\n",
              "  'DNF formulas Horn',\n",
              "  'equivalence queries needed',\n",
              "  'Olog nterm DNF',\n",
              "  'number equivalence queries'],\n",
              " ['rule sets Rippledown',\n",
              "  'exception rules exception',\n",
              "  'constant depth rippledown',\n",
              "  'depth rippledown rule',\n",
              "  'rippledown rule sets'],\n",
              " ['set cover problems',\n",
              "  'algorithm learns PAC',\n",
              "  'representation size Olog',\n",
              "  'learns PAC model',\n",
              "  'Boolean attributes infinite'],\n",
              " ['words dense semantic',\n",
              "  'distressing finding Reaction',\n",
              "  'phonology Seidenberg McClelland',\n",
              "  'orthography phonology Seidenberg',\n",
              "  'Seidenberg McClelland Plaut'],\n",
              " ['paper describe utility',\n",
              "  'Simply storing cases',\n",
              "  'space Simply storing',\n",
              "  'storage space Simply',\n",
              "  'Casebased reasoning CBR'],\n",
              " ['Algorithm GLA presented',\n",
              "  'conventional Generalized Lloyd',\n",
              "  'Genetic Generalized Lloyd',\n",
              "  'Lloyd Algorithm GLA',\n",
              "  'Generalized Lloyd Algorithm'],\n",
              " ['drawback CBP systems',\n",
              "  'CBP system CaPER',\n",
              "  'article appearing IEEE',\n",
              "  'appearing IEEE Expert',\n",
              "  'IEEE Expert February'],\n",
              " ['Load balancing equipartition',\n",
              "  'Genetic Algorithm utilizes',\n",
              "  'parallel Genetic Algorithm',\n",
              "  'variables Quadratic Assignment',\n",
              "  'Quadratic Assignment formulation'],\n",
              " ['exploitation adaptive optimal',\n",
              "  'Bayesian balance exploration',\n",
              "  'turning exploratory behaviour',\n",
              "  'reinforcement learning Sutton',\n",
              "  'Finding Bayesian balance'],\n",
              " ['deals nonlinear leastsquares',\n",
              "  'nonlinear leastsquares problems',\n",
              "  'paper deals nonlinear',\n",
              "  'leastsquares problems involving',\n",
              "  'problems involving fitting'],\n",
              " ['interpretation Ryan Tweney',\n",
              "  'collected John Clement',\n",
              "  'John Clement problem',\n",
              "  'Nersessian Ashok Goel',\n",
              "  'Ashok Goel Abstract'],\n",
              " ['neural networks solve',\n",
              "  'controller robot manipulator',\n",
              "  'Based investigation systematic',\n",
              "  'neurocontrol Based investigation',\n",
              "  'framework neurocontrol Based'],\n",
              " ['algorithm clusters unlabelled',\n",
              "  'derivation learning algorithm',\n",
              "  'present informationtheoretic derivation',\n",
              "  'informationtheoretic derivation learning',\n",
              "  'learning algorithm clusters'],\n",
              " ['ASOCS Adaptive SelfOrganizing',\n",
              "  'ASOCS adaptive network',\n",
              "  'presents ASOCS Adaptive',\n",
              "  'Adaptive SelfOrganizing Concurrent',\n",
              "  'SelfOrganizing Concurrent System'],\n",
              " ['mixed memory Markov',\n",
              "  'Canadian dollar Deutsch',\n",
              "  'Japanese yen Swiss',\n",
              "  'Deutsch mark Japanese',\n",
              "  'British pound Canadian'],\n",
              " ['methods extracting knowledge',\n",
              "  'learn rulebased strategies',\n",
              "  'meaningful estimate quality',\n",
              "  'produce meaningful estimate',\n",
              "  'fairly substantial amount'],\n",
              " ['Artificial Neural Networks',\n",
              "  'network Keywords Neural',\n",
              "  'Implementation Design Dynamic',\n",
              "  'Topologies Reconfigurable Architectures',\n",
              "  'Backpropagation Implementation Design'],\n",
              " ['Canonical coding symmetric',\n",
              "  'genetic algorithms Canonical',\n",
              "  'computer network Computational',\n",
              "  'network Computational results',\n",
              "  'symmetric TSP modified'],\n",
              " ['ASOCS Adaptive SelfOrganizing',\n",
              "  'Priority Adaptive SelfOrganizing',\n",
              "  'Concurrent System PASOCS',\n",
              "  'SelfOrganizing Concurrent System',\n",
              "  'Adaptive SelfOrganizing Concurrent'],\n",
              " ['Population based approaches',\n",
              "  'interest Population based',\n",
              "  'broad interest Population',\n",
              "  'releases Temporal Decomposition',\n",
              "  'Temporal Decomposition leads'],\n",
              " ['OBS autoprune epsiprune',\n",
              "  'superior OBD diagnosis',\n",
              "  'OBD diagnosis tasks',\n",
              "  'OBD OBS autoprune',\n",
              "  'today OBD OBS'],\n",
              " ['assessment strategies show',\n",
              "  'assessment strategies evaluation',\n",
              "  'adaptations Empirical tests',\n",
              "  'similarity assessment strategies',\n",
              "  'Empirical tests alternative'],\n",
              " ['reasoning process depends',\n",
              "  'mechanisms interact combined',\n",
              "  'learning Exploiting opportunities',\n",
              "  'opportunity learning Exploiting',\n",
              "  'Exploiting opportunities requires'],\n",
              " ['CBR point potential',\n",
              "  'CBR systems appealing',\n",
              "  'CBR system designed',\n",
              "  'systems CBR systems',\n",
              "  'CBR systems CBR'],\n",
              " ['dataset Numerical results',\n",
              "  'small linear programs',\n",
              "  'handle large problems',\n",
              "  'Numerical results fully',\n",
              "  'entire dataset Numerical'],\n",
              " ['pronunciation correct Based',\n",
              "  'rate DECTalk rulebase',\n",
              "  'correct Based judgements',\n",
              "  'Rosenberg developed famous',\n",
              "  'Sejnowski Rosenberg developed'],\n",
              " ['parameter general LPEC',\n",
              "  'general LPEC explicitly',\n",
              "  'general LPEC converted',\n",
              "  'LPEC explicitly exact',\n",
              "  'LPEC converted exact'],\n",
              " ['strategies specific domains',\n",
              "  'Retrieval driven domaindependent',\n",
              "  'consists storage retrieval',\n",
              "  'multiple goals retrieval',\n",
              "  'cases Retrieval driven'],\n",
              " ['casebased planning Stored',\n",
              "  'system MICBP integrates',\n",
              "  'MICBP integrates ForMAT',\n",
              "  'present MICBP concrete',\n",
              "  'MICBP concrete application'],\n",
              " ['separately trained neural',\n",
              "  'reachable local minima',\n",
              "  'future inputs Hansen',\n",
              "  'inputs Hansen Salamon',\n",
              "  'Hansen Salamon showed'],\n",
              " ['inducing structural equation',\n",
              "  'causal interpretation parameters',\n",
              "  'models data Assuming',\n",
              "  'Assuming latent variables',\n",
              "  'data Assuming latent'],\n",
              " ['locality basis functions',\n",
              "  'basis functions propose',\n",
              "  'samples Intermediate nodes',\n",
              "  'learning samples Intermediate',\n",
              "  'simulations starting point'],\n",
              " ['backpropagation OBP rule',\n",
              "  'tested twospirals Net',\n",
              "  'Talk benchmark problems',\n",
              "  'twospirals Net Talk',\n",
              "  'Net Talk benchmark'],\n",
              " ['technology faced nontrivial',\n",
              "  'faced nontrivial problem',\n",
              "  'Todays potential users',\n",
              "  'Historically predictive accuracy',\n",
              "  'solution Historically predictive'],\n",
              " ['learns complete patterns',\n",
              "  'neural network associative',\n",
              "  'attractive fixed points',\n",
              "  'stored attractive fixed',\n",
              "  'filling missing information'],\n",
              " ['constraint handling mechanism',\n",
              "  'linear scaleup behaviour',\n",
              "  'handling mechanism Stepwise',\n",
              "  'mechanism Stepwise Adaptation',\n",
              "  'Stepwise Adaptation Weights'],\n",
              " ['hypotheses distributions independent',\n",
              "  'simple Hebbianlike learning',\n",
              "  'Hebbianlike learning rules',\n",
              "  'estimate independent component',\n",
              "  'Independent Component Analysis'],\n",
              " ['grids Experimental studies',\n",
              "  'evidence grids Experimental',\n",
              "  'places Previous researchers',\n",
              "  'numbers places Previous',\n",
              "  'Previous researchers studied'],\n",
              " ['learners problem representation',\n",
              "  'propose theoretical model',\n",
              "  'exclusively context supervised',\n",
              "  'nonconstructive methods unclear',\n",
              "  'part unsupervised regime'],\n",
              " ['system presented assist',\n",
              "  'area inductive logic',\n",
              "  'techniques area inductive',\n",
              "  'employs techniques area',\n",
              "  'inductive logic programming'],\n",
              " ['information multiple sources',\n",
              "  'employs handle uncertainty',\n",
              "  'basis characterizing evaluating',\n",
              "  'combine knowledge bases',\n",
              "  'work information multiple'],\n",
              " ['creating sparsely connected',\n",
              "  'paper investigates technique',\n",
              "  'technique creating sparsely',\n",
              "  'investigates technique creating',\n",
              "  'bit compression problem'],\n",
              " ['Gaussian models including',\n",
              "  'class graphical Gaussian',\n",
              "  'device sample Wishart',\n",
              "  'sample Wishart distributions',\n",
              "  'Wishart distributions conditional'],\n",
              " ['Klopf weight errors',\n",
              "  'methods Baird Harmon',\n",
              "  'Baird Klopf weight',\n",
              "  'Harmon Baird Klopf',\n",
              "  'Baird Harmon Baird'],\n",
              " ['representations training algorithms',\n",
              "  'section explores interesting',\n",
              "  'discussion section explores',\n",
              "  'explores interesting impact',\n",
              "  'phenomena autonomous adaptive'],\n",
              " ['relationships computer programs',\n",
              "  'regression determination function',\n",
              "  'paper feasibility symbolic',\n",
              "  'feasibility symbolic regression',\n",
              "  'Symbolic regression determination'],\n",
              " ['discovery Pharmaceutical research',\n",
              "  'Comments current potential',\n",
              "  'Pharmaceutical research laboratories',\n",
              "  'bound Comments current',\n",
              "  'design discovery Pharmaceutical'],\n",
              " ['cross validation terms',\n",
              "  'qualitative properties cross',\n",
              "  'function number hypothesis',\n",
              "  'error cross validation',\n",
              "  'number hypothesis parameters'],\n",
              " ['empirical minimizer model',\n",
              "  'distribution true errors',\n",
              "  'error empirical minimizer',\n",
              "  'true error empirical',\n",
              "  'expected true error'],\n",
              " ['implication called Timplication',\n",
              "  'exists Tcomplete expansion',\n",
              "  'general generalization Timplication',\n",
              "  'Recently rising interest',\n",
              "  'called Timplication decidable'],\n",
              " ['perfect independent facts',\n",
              "  'noisy perfect independent',\n",
              "  'Bayesian probability theory',\n",
              "  'paper argues Bayesian',\n",
              "  'argues Bayesian probability'],\n",
              " ['presented reveals performance',\n",
              "  'reveals performance improvement',\n",
              "  'performance improvement obtained',\n",
              "  'nearest neighbor Ricci',\n",
              "  'neighbor Ricci Aha'],\n",
              " ['problem complexity natural',\n",
              "  'show problem complexity',\n",
              "  'problem complexity increased',\n",
              "  'collective memory search',\n",
              "  'random search engine'],\n",
              " ['guarantee similar items',\n",
              "  'retrieved information based',\n",
              "  'similarity assessment Contrary',\n",
              "  'Contrary systems define',\n",
              "  'assessment Contrary systems'],\n",
              " ['selfimproving reactive control',\n",
              "  'schemabased reactive control',\n",
              "  'parameters reactive control',\n",
              "  'perform online adaptation',\n",
              "  'reactive control system'],\n",
              " ['problem realworld OCR',\n",
              "  'significant cost reduction',\n",
              "  'realworld OCR task',\n",
              "  'QuerybyCommittee algorithm Seung',\n",
              "  'realworld domains Results'],\n",
              " ['support finding contrary',\n",
              "  'support finding memorybased',\n",
              "  'papers experimental results',\n",
              "  'results support finding',\n",
              "  'experimental results support'],\n",
              " ['Holtes recentlypublished article',\n",
              "  'implications Holtes recentlypublished',\n",
              "  'extent Holte questioned',\n",
              "  'Holte questioned sense',\n",
              "  'trees produced Quinlans'],\n",
              " ['rules implicit training',\n",
              "  'implicit training data',\n",
              "  'performance knowledgebased alternative',\n",
              "  'compare performance knowledgebased',\n",
              "  'alternative dataoriented approaches'],\n",
              " ['finite sample sufficient',\n",
              "  'rule called EMMA',\n",
              "  'EMMA optimizes entropy',\n",
              "  'called EMMA optimizes',\n",
              "  'resonance images MRI'],\n",
              " ['order chosen Earlier',\n",
              "  'outset Working fully',\n",
              "  'Working fully general',\n",
              "  'chosen Earlier work',\n",
              "  'Earlier work concentrated'],\n",
              " ['diagrams highdimensional variant',\n",
              "  'ansatz tesselation data',\n",
              "  'highdimensional variant SelfOrganizing',\n",
              "  'requires ansatz tesselation',\n",
              "  'SelfOrganizing Map SOM'],\n",
              " ['load balancing distributed',\n",
              "  'context Finally show',\n",
              "  'adaptive load balancing',\n",
              "  'Finally show naive',\n",
              "  'exploitation context Finally'],\n",
              " ['tractable approximation Boltzmann',\n",
              "  'maximum likelihood estimation',\n",
              "  'application Bayesian network',\n",
              "  'Bayesian network source',\n",
              "  'binary Bayesian network'],\n",
              " ['maximin strategy Experiments',\n",
              "  'board game Connect',\n",
              "  'strategy Experiments popular',\n",
              "  'strategies Researchers developed',\n",
              "  'Experiments popular board'],\n",
              " ['factors Discovering causal',\n",
              "  'Estep proposed Gibbs',\n",
              "  'paper Based Zemel',\n",
              "  'Zemel Hintons cooperative',\n",
              "  'Based Zemel Hintons'],\n",
              " ['paper deals problem',\n",
              "  'deals problem blind',\n",
              "  'IOIdentification device constant',\n",
              "  'problem blind identification',\n",
              "  'illustrated computer simulations'],\n",
              " ['order information whitening',\n",
              "  'consists recovering set',\n",
              "  'possibly corrupted additive',\n",
              "  'information whitening operation',\n",
              "  'whitening operation reduces'],\n",
              " ['solve problem blind',\n",
              "  'improve performance robustness',\n",
              "  'developed solve problem',\n",
              "  'approach reconstruction natural',\n",
              "  'VLSI electronic circuits'],\n",
              " ['belong multiplicative weights',\n",
              "  'degrades logarithmically number',\n",
              "  'family online learning',\n",
              "  'study online learning',\n",
              "  'online learning algorithms'],\n",
              " ['clever RELIEF based',\n",
              "  'RELIEF based heuristic',\n",
              "  'Part blame ascribed',\n",
              "  'developed naive Bayesian',\n",
              "  'naive Bayesian classifier'],\n",
              " ['work extend capabilities',\n",
              "  'design analysis operation',\n",
              "  'emerged valuable tool',\n",
              "  'interval consideration detected',\n",
              "  'correspondence addressed emailbieglercmuedu'],\n",
              " ['Changes social state',\n",
              "  'genetic algorithm significantly',\n",
              "  'genetic algorithm Computational',\n",
              "  'algorithm Computational experiments',\n",
              "  'Computational experiments largescale'],\n",
              " ['conventions carrying benchmark',\n",
              "  'learning realm pattern',\n",
              "  'realm pattern classification',\n",
              "  'pattern classification function',\n",
              "  'classification function approximation'],\n",
              " ['final outcome games',\n",
              "  'explanationbased learning Performance',\n",
              "  'learning Performance results',\n",
              "  'strengths weaknesses approach',\n",
              "  'Performance results illustrate'],\n",
              " ['determining performances CBR',\n",
              "  'performances CBR CaseBased',\n",
              "  'mode CBRNN coupling',\n",
              "  'neural network serves',\n",
              "  'CBR CaseBased Reasoning'],\n",
              " ['resemble Hausdorff metric',\n",
              "  'class geometric patterns',\n",
              "  'points real line',\n",
              "  'concept class geometric',\n",
              "  'Hausdorff metric Informally'],\n",
              " ['combination training set',\n",
              "  'selecting evaluating learned',\n",
              "  'generalization performance suggested',\n",
              "  'based incremental search',\n",
              "  'deeper understanding existing'],\n",
              " ['investigates conditions articulated',\n",
              "  'distal error signals',\n",
              "  'error signals backpropagated',\n",
              "  'error signal presented',\n",
              "  'future attempts surmount'],\n",
              " ['users due size',\n",
              "  'induction algorithms shown',\n",
              "  'induction algorithms case',\n",
              "  'casebased reasoning systems',\n",
              "  'tree induction algorithms'],\n",
              " ['argue cusum path',\n",
              "  'monitor Markov chain',\n",
              "  'propose monitor Markov',\n",
              "  'convergence diagnostics Markov',\n",
              "  'cusum path plot'],\n",
              " ['model Markov chain',\n",
              "  'Gibbs sampler Ising',\n",
              "  'Ising model Markov',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo'],\n",
              " ['Computing Learning Common',\n",
              "  'Learning Common Sense',\n",
              "  'Media Lab Perceptual',\n",
              "  'Perceptual Computing Learning',\n",
              "  'Lab Perceptual Computing'],\n",
              " ['Adoption Bayesian paradigm',\n",
              "  'literature Adoption Bayesian',\n",
              "  'Monte Carlo methods',\n",
              "  'Markov chain Monte',\n",
              "  'chain Monte Carlo'],\n",
              " ['MCMC output general',\n",
              "  'Birkhoffs pointwise ergodic',\n",
              "  'discretized finite Markov',\n",
              "  'state space Markov',\n",
              "  'derived Kemeny Snell'],\n",
              " ['Markov chain Monte',\n",
              "  'chain Monte Carlo',\n",
              "  'crossover operator acting',\n",
              "  'Carlo MCMC samplers',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['Science Technical Report',\n",
              "  'Technical Report Abstract',\n",
              "  'Computational Cognitive Science',\n",
              "  'Cognitive Science Technical',\n",
              "  'MIT Computational Cognitive'],\n",
              " ['optimise Kmeans clustering',\n",
              "  'positions Empirical results',\n",
              "  'Kmeans clustering process',\n",
              "  'solution problem RBF',\n",
              "  'efficient approximation RBF'],\n",
              " ['subset Experimental results',\n",
              "  'aspects Baldwin effect',\n",
              "  'Baldwin effect exhibited',\n",
              "  'subtle aspects Baldwin',\n",
              "  'Experimental results presented'],\n",
              " ['task responding spills',\n",
              "  'focus INCAs strategy',\n",
              "  'INCAs strategy retrieving',\n",
              "  'INCA intelligent assistant',\n",
              "  'sacrificing solution quality'],\n",
              " ['adequate simulation model',\n",
              "  'environment payoff function',\n",
              "  'system called SAMUEL',\n",
              "  'SAMUEL learning reactive',\n",
              "  'called SAMUEL learning'],\n",
              " ['tool improving flexibility',\n",
              "  'valuable tool improving',\n",
              "  'mobile robot Perception',\n",
              "  'Perception action combined',\n",
              "  'defines terms grammars'],\n",
              " ['diagnostic techniques Markov',\n",
              "  'techniques Markov Chain',\n",
              "  'Monte Carlo algorithms',\n",
              "  'Chain Monte Carlo',\n",
              "  'Markov Chain Monte'],\n",
              " ['camera anthropomorphic OSCARrobot',\n",
              "  'moves arbitrarily table',\n",
              "  'task handheld camera',\n",
              "  'handheld camera anthropomorphic',\n",
              "  'tracking task handheld'],\n",
              " ['discarded conditional independence',\n",
              "  'heuristic build predictive',\n",
              "  'models estimate strengths',\n",
              "  'predictive causal models',\n",
              "  'measures Pearl Vermas'],\n",
              " ['sequential tasks addressed',\n",
              "  'simple flight simulator',\n",
              "  'tasks addressed focusing',\n",
              "  'method relies notion',\n",
              "  'rules ultimately tested'],\n",
              " ['noisefree noisy data',\n",
              "  'bias present MFOCL',\n",
              "  'Horn clause relational',\n",
              "  'present MFOCL Horn',\n",
              "  'MFOCL Horn clause'],\n",
              " ['Choosing architecture neural',\n",
              "  'workable approximate answers',\n",
              "  'discussions References discuss',\n",
              "  'recent discussions References',\n",
              "  'References discuss neural'],\n",
              " ['contrary common folklore',\n",
              "  'propose modeltheoretic definition',\n",
              "  'common folklore genuine',\n",
              "  'causal influences defined',\n",
              "  'Finally provide prooftheoretical'],\n",
              " ['time present algorithm',\n",
              "  'analyze performance alternative',\n",
              "  'deals alltoall broadcast',\n",
              "  'present algorithm meeting',\n",
              "  'alltoall broadcast CNS'],\n",
              " ['attempts integrate categorical',\n",
              "  'approach attempts integrate',\n",
              "  'integrate categorical uncertain',\n",
              "  'variations underlying phenomena',\n",
              "  'Automated decision making'],\n",
              " ['estimating standard error',\n",
              "  'method based Hessian',\n",
              "  'Hessian bootstrap estimators',\n",
              "  'choice starting weights',\n",
              "  'based Hessian bootstrap'],\n",
              " ['induces Dirichlet mixture',\n",
              "  'Dirichlet mixture mixtures',\n",
              "  'convolutions Dirichlet process',\n",
              "  'Dirichlet process mixtures',\n",
              "  'arising Dirichlet process'],\n",
              " ['desired camerajoint mapping',\n",
              "  'camerajoint mapping approximated',\n",
              "  'camera DOF anthropomorphic',\n",
              "  'handheld camera DOF',\n",
              "  'DOF anthropomorphic OSCARrobot'],\n",
              " ['model ASOCS Adaptive',\n",
              "  'Adaptive Algorithm model',\n",
              "  'Algorithm model ASOCS',\n",
              "  'Concurrent Systems approach',\n",
              "  'Organizing Concurrent Systems'],\n",
              " ['model spatial structure',\n",
              "  'covariance matrix additive',\n",
              "  'offered case discrete',\n",
              "  'Gaussian noise covariance',\n",
              "  'approach Gaussian noise'],\n",
              " ['NASAs Deep Space',\n",
              "  'Deep Space Communications',\n",
              "  'Space Communications Complex',\n",
              "  'Communications Complex Goldstone',\n",
              "  'Complex Goldstone California'],\n",
              " ['exhibit conflicts merged',\n",
              "  'problem Case Based',\n",
              "  'minimum conflicts algorithm',\n",
              "  'Case Based Reasoning',\n",
              "  'Based Reasoning subcases'],\n",
              " ['framework Dynamic Constraint',\n",
              "  'observed dynamic constraint',\n",
              "  'constraint satisfaction matches',\n",
              "  'Constraint Satisfaction enables',\n",
              "  'Dynamic Constraint Satisfaction'],\n",
              " ['paper demonstrates PAC',\n",
              "  'paper presents PAC',\n",
              "  'hypothesis space PAC',\n",
              "  'Correct PAC learning',\n",
              "  'Approximately Correct PAC'],\n",
              " ['called MAPSS Mapped',\n",
              "  'MAPSS Mapped AtmospherePlantSoil',\n",
              "  'collaborator Ron Neilson',\n",
              "  'Neilson Standard machine',\n",
              "  'Ron Neilson Standard'],\n",
              " ['account frequency virtual',\n",
              "  'derive normalising baseline',\n",
              "  'normalisation process demonstrated',\n",
              "  'Holtes study generalisation',\n",
              "  'application Holtes study'],\n",
              " ['casebased reasoning CBR',\n",
              "  'conversational case libraries',\n",
              "  'Abstract Conversational casebased',\n",
              "  'Results Abstract Conversational',\n",
              "  'Initial Results Abstract'],\n",
              " ['process identifying disorders',\n",
              "  'history symptoms signs',\n",
              "  'requested sequential manner',\n",
              "  'symptoms signs Starting',\n",
              "  'handled correctly Request'],\n",
              " ['squared errors regarded',\n",
              "  'vectors sum squared',\n",
              "  'sum squared errors',\n",
              "  'hidden layers sigmoid',\n",
              "  'layers sigmoid transfer'],\n",
              " ['Appeared ECAI Workshop',\n",
              "  'Workshop Theoretical Foundations',\n",
              "  'Theoretical Foundations Knowledge',\n",
              "  'ECAI Workshop Theoretical',\n",
              "  'Knowledge Representation Reasoning'],\n",
              " ['information important concept',\n",
              "  'concept theory learning',\n",
              "  'genetic programming system',\n",
              "  'short elegant general',\n",
              "  'important concept theory'],\n",
              " ['Hypothesis XCS tendency',\n",
              "  'Wilsons Generalization Hypothesis',\n",
              "  'evolve optimal populations',\n",
              "  'Generalization Hypothesis XCS',\n",
              "  'XCS Optimality Hypothesis'],\n",
              " ['domain difficulty grows',\n",
              "  'system Empirical comparison',\n",
              "  'approach implemented Rise',\n",
              "  'Rise system Empirical',\n",
              "  'Empirical comparison Rise'],\n",
              " ['programming method investigated',\n",
              "  'method investigated optimizing',\n",
              "  'scaling properties algorithm',\n",
              "  'quantifies principle Occams',\n",
              "  'principle Occams razor'],\n",
              " ['American subjects facial',\n",
              "  'Facial Affect Database',\n",
              "  'Pictures Facial Affect',\n",
              "  'Affect Database Ekman',\n",
              "  'Database Ekman Friesen'],\n",
              " ['tative fitness criteria',\n",
              "  'basic concept SMOG',\n",
              "  'Structured MOdel Generator',\n",
              "  'SMOG Structured MOdel',\n",
              "  'concept SMOG Structured'],\n",
              " ['performed simple genetic',\n",
              "  'algorithm highly correlated',\n",
              "  'initial genera tions',\n",
              "  'develop metric measuring',\n",
              "  'simple genetic algorithm'],\n",
              " ['Genetic algorithms rely',\n",
              "  'exists large body',\n",
              "  'body conventional wisdom',\n",
              "  'large body conventional',\n",
              "  'demonstrating important characteristics'],\n",
              " ['Geiger Goldszmidt introduced',\n",
              "  'Naive Bayes TAN',\n",
              "  'Tree Augmented Naive',\n",
              "  'Augmented Naive Bayes',\n",
              "  'Friedman Geiger Goldszmidt'],\n",
              " ['objectoriented Bayesian network',\n",
              "  'networks objectoriented Bayesian',\n",
              "  'time Dynamic Bayesian',\n",
              "  'extends dynamic Bayesian',\n",
              "  'Dynamic Bayesian networks'],\n",
              " ['devising simple constructive',\n",
              "  'Correlation due topology',\n",
              "  'method Recurrent Cascade',\n",
              "  'Cascade Correlation due',\n",
              "  'Recurrent Cascade Correlation'],\n",
              " ['framework Generated attribute',\n",
              "  'attributes framework Generated',\n",
              "  'tolerate noisy data',\n",
              "  'called Quantification Method',\n",
              "  'technique called Quantification'],\n",
              " ['globally stabilize linear',\n",
              "  'Stabilization Linear Systems',\n",
              "  'Result Stabilization Linear',\n",
              "  'Bounded Controls ABSTRACT',\n",
              "  'General Result Stabilization'],\n",
              " ['trained Bootstrap Sample',\n",
              "  'Neural Networks created',\n",
              "  'Redundant Classification Environment',\n",
              "  'Ensembles Neural Networks',\n",
              "  'Bootstrap Sample Sets'],\n",
              " ['University Washington Seattle',\n",
              "  'Sylvia Richardson Directeur',\n",
              "  'USA Sylvia Richardson',\n",
              "  'INRIA Rocquencourt France',\n",
              "  'Villejuif CEDEX France'],\n",
              " ['results show CABINS',\n",
              "  'system called CABINS',\n",
              "  'manner case base',\n",
              "  'CABINS records situationdependent',\n",
              "  'called CABINS records'],\n",
              " ['evident performance results',\n",
              "  'decomposed efficiently implemented',\n",
              "  'performance results simulated',\n",
              "  'conveniently decomposed efficiently',\n",
              "  'simulated autonomous navigation'],\n",
              " ['Harmonium model defined',\n",
              "  'gradient general Boltzmann',\n",
              "  'general Boltzmann machine',\n",
              "  'closely related Harmonium',\n",
              "  'defined Smolensky RMCh'],\n",
              " ['optimization problems Dorigo',\n",
              "  'insects Adler Gordon',\n",
              "  'systems Garland Alterman',\n",
              "  'Gordon Oster Wilson',\n",
              "  'Adler Gordon Oster'],\n",
              " ['inverse square root',\n",
              "  'concept class finite',\n",
              "  'results previously obtained',\n",
              "  'class finite cardinality',\n",
              "  'replica symmetry breaking'],\n",
              " ['efficiently locate track',\n",
              "  'track underwater sonar',\n",
              "  'locate track underwater',\n",
              "  'bearing range estimation',\n",
              "  'data significant noise'],\n",
              " ['method Selective induction',\n",
              "  'proposed CILA methods',\n",
              "  'CILA methods overcoming',\n",
              "  'learning method Selective',\n",
              "  'good representation space'],\n",
              " ['amount order selforganising',\n",
              "  'measure amount order',\n",
              "  'introduce measure amount',\n",
              "  'disjoint clusters Teaching',\n",
              "  'teaching Nneuron network'],\n",
              " ['Words Inductive learning',\n",
              "  'learning relational domains',\n",
              "  'induction Key Words',\n",
              "  'Inductive learning relational',\n",
              "  'Key Words Inductive'],\n",
              " ['experiments examine effect',\n",
              "  'noisefree environment Empirical',\n",
              "  'Empirical results show',\n",
              "  'ultimately tested Specifically',\n",
              "  'learning tactical plans'],\n",
              " ['obstacles mine fields',\n",
              "  'fields important capability',\n",
              "  'mine fields important',\n",
              "  'work SAMUEL learning',\n",
              "  'SAMUEL learning system'],\n",
              " ['paper introduce investigate',\n",
              "  'curves based ideas',\n",
              "  'functional form learning',\n",
              "  'learning curves based',\n",
              "  'form learning curves'],\n",
              " ['recurrent neural networks',\n",
              "  'Automaton NNPDA model',\n",
              "  'Neural Network Pushdown',\n",
              "  'Network Pushdown Automaton',\n",
              "  'Pushdown Automaton NNPDA'],\n",
              " ['Boltzmann machines due',\n",
              "  'Conditional probability distributions',\n",
              "  'correlations Conditional probability',\n",
              "  'express correlations Conditional',\n",
              "  'negative phase Boltzmann'],\n",
              " ['important interesting emergent',\n",
              "  'controlling controlled factor',\n",
              "  'emergent property structures',\n",
              "  'interesting emergent property',\n",
              "  'exemplified PacMan game'],\n",
              " ['terms decisiontheoretic primitives',\n",
              "  'show relationship Pearls',\n",
              "  'Finally show canonical',\n",
              "  'effect Finally show',\n",
              "  'relationship Pearls representation'],\n",
              " ['complete FLC designed',\n",
              "  'FLCs evaluated focussing',\n",
              "  'path tracking Performance',\n",
              "  'tracking Performance results',\n",
              "  'Performance results incomplete'],\n",
              " ['describe computational procedures',\n",
              "  'odds accelerated failure',\n",
              "  'maximum likelihood estimators',\n",
              "  'Fisher information regression',\n",
              "  'calculation Fisher information'],\n",
              " ['linear strings fixed',\n",
              "  'distinguished evolutionary algorithms',\n",
              "  'problem apply Bayesian',\n",
              "  'Bayesian modelcomparison framework',\n",
              "  'apply Bayesian modelcomparison'],\n",
              " ['space OSN log',\n",
              "  'Dynamic probabilistic networks',\n",
              "  'models data Existing',\n",
              "  'possibility OSspace OSN',\n",
              "  'computing posterior distribution'],\n",
              " ['Schaffer discuss relevance',\n",
              "  'earlier findings Fisher',\n",
              "  'findings Fisher Schlimmer',\n",
              "  'Schlimmer Schaffer discuss',\n",
              "  'Fisher Schlimmer Schaffer'],\n",
              " ['inputoutput hidden Markov',\n",
              "  'time scales Experiments',\n",
              "  'scales Experiments confirm',\n",
              "  'Experiments confirm advantages',\n",
              "  'hidden Markov models'],\n",
              " ['approaches require Gaussian',\n",
              "  'MDLbased Bayesian argument',\n",
              "  'argument based Gibbs',\n",
              "  'Gaussian assumptions depend',\n",
              "  'Automatically effectively prunes'],\n",
              " ['accuracy generality reactive',\n",
              "  'generality reactive plans',\n",
              "  'improving comprehensibility accuracy',\n",
              "  'comprehensibility accuracy generality',\n",
              "  'consists taking subset'],\n",
              " ['method developing good',\n",
              "  'technique called SANE',\n",
              "  'called SANE individual',\n",
              "  'SANE individual neurons',\n",
              "  'SANE approach extend'],\n",
              " ['implementation Clire empirical',\n",
              "  'Express commercially successful',\n",
              "  'Designing complex libraries',\n",
              "  'CBR Express commercially',\n",
              "  'Inferences CBR Express'],\n",
              " ['addressed class trajectory',\n",
              "  'multiple accelerations decelerations',\n",
              "  'involving multiple accelerations',\n",
              "  'observation improved practice',\n",
              "  'acquired observation improved'],\n",
              " ['MAX VSCS converges',\n",
              "  'MAX VSCS boils',\n",
              "  'Watkins Dayan draw',\n",
              "  'proved Watkins Dayan',\n",
              "  'Qlearning classifier systems'],\n",
              " ['capable forming compact',\n",
              "  'limiting factor transcended',\n",
              "  'basis simple Hebbian',\n",
              "  'simple Hebbian learning',\n",
              "  'Hebbian learning negative'],\n",
              " ['sets samples length',\n",
              "  'nonempty open sets',\n",
              "  'open sets samples',\n",
              "  'parameters nonempty open',\n",
              "  'neural networks discussed'],\n",
              " ['typically complex tasks',\n",
              "  'configurations environmental conditions',\n",
              "  'evaluation casebased reasoning',\n",
              "  'difficult casebased reasoning',\n",
              "  'casebased reasoning systems'],\n",
              " ['cope variation form',\n",
              "  'requires reconciling incommensurate',\n",
              "  'organization adaptation process',\n",
              "  'variation form problems',\n",
              "  'paper address task'],\n",
              " ['Estimation asymptotic variance',\n",
              "  'tumoriginicity study Introduction',\n",
              "  'matrix MLE regression',\n",
              "  'shown MLE regression',\n",
              "  'MLE regression parameter'],\n",
              " ['CSTR October Abstract',\n",
              "  'Tel Fax Internet',\n",
              "  'Report CSTR October',\n",
              "  'Technical Report CSTR',\n",
              "  'Zealand Tel Fax'],\n",
              " ['propose paper Bayesian',\n",
              "  'Bayesian noninformative approach',\n",
              "  'paper Bayesian noninformative',\n",
              "  'extending Mengersen Robert',\n",
              "  'Mengersen Robert show'],\n",
              " ['question answering Continuing',\n",
              "  'Web WWW server',\n",
              "  'Common LISP order',\n",
              "  'WorldWide Web WWW',\n",
              "  'implemented Common LISP'],\n",
              " ['partial Bayes factors',\n",
              "  'factors Cox proportional',\n",
              "  'Cox proportional hazards',\n",
              "  'introducing partial Bayes',\n",
              "  'Bayes factors Cox'],\n",
              " ['Bayesian approaches model',\n",
              "  'fewer subjective choices',\n",
              "  'model averaging selection',\n",
              "  'provide alternatives Bayesian',\n",
              "  'alternatives Bayesian approaches'],\n",
              " ['Report December Statistics',\n",
              "  'Statistics Department University',\n",
              "  'University California Berkeley',\n",
              "  'December Statistics Department',\n",
              "  'Department University California'],\n",
              " ['casebased reasoning CCBR',\n",
              "  'Breslow Aha Figure',\n",
              "  'AAAI Spring Symposium',\n",
              "  'Spring Symposium Multimodal',\n",
              "  'Aha Figure CCBR'],\n",
              " ['results improve Valiants',\n",
              "  'improve Valiants previous',\n",
              "  'algorithm exact identification',\n",
              "  'time algorithm exact',\n",
              "  'polynomial time algorithm'],\n",
              " ['sequential RAAM effectively',\n",
              "  'Memory RAAM structures',\n",
              "  'simple Elmanstyle recurrent',\n",
              "  'Recursive AutoAssociative Memory',\n",
              "  'AutoAssociative Memory RAAM'],\n",
              " ['subclass probabilistic finite',\n",
              "  'Markov hidden Markov',\n",
              "  'probabilistic finite automata',\n",
              "  'Finite Suffix Automata',\n",
              "  'Probabilistic Finite Suffix'],\n",
              " ['representative inductive logic',\n",
              "  'inductive logic programming',\n",
              "  'logic programming paradigm',\n",
              "  'theories larger attribute',\n",
              "  'engineering classification rules'],\n",
              " ['Greedy search prevents',\n",
              "  'Rendell developed RELIEF',\n",
              "  'attributes Recently Kira',\n",
              "  'Kira Rendell developed',\n",
              "  'Recently Kira Rendell'],\n",
              " ['chaotic time series',\n",
              "  'Genetic Programmings flexible',\n",
              "  'dynamics Genetic Programming',\n",
              "  'Genetic Programming applied',\n",
              "  'time series prediction'],\n",
              " ['guidance ILP algorithms',\n",
              "  'ILP algorithms typically',\n",
              "  'based RELIEF guidance',\n",
              "  'Current ILP algorithms',\n",
              "  'RELIEF guidance ILP'],\n",
              " ['logic programming ILP',\n",
              "  'RELIEF developed Kira',\n",
              "  'developed Kira Rendell',\n",
              "  'Kira Rendell Kira',\n",
              "  'Rendell Kira Rendell'],\n",
              " ['Free Internet Chess',\n",
              "  'Chess Server FICS',\n",
              "  'Internet Chess Server',\n",
              "  'playing Free Internet',\n",
              "  'Server FICS ficsonenetnet'],\n",
              " ['sequential estimator density',\n",
              "  'unknown approximated sequential',\n",
              "  'measure MetropolisHastings Kernel',\n",
              "  'sequential estimator energy',\n",
              "  'algorithm sequential estimator'],\n",
              " ['spatially local PCA',\n",
              "  'filter basic Hebbian',\n",
              "  'local PCA basis',\n",
              "  'component analysis PCA',\n",
              "  'PCA basis vectors'],\n",
              " ['versions existing Markov',\n",
              "  'functions naturally Computations',\n",
              "  'Computations based multidimensional',\n",
              "  'univariate Dirichlet mixture',\n",
              "  'Dirichlet mixture models'],\n",
              " ['theory role multipoint',\n",
              "  'genetic algorithms typically',\n",
              "  'role multipoint crossover',\n",
              "  'crossover genetic algorithms',\n",
              "  'multipoint crossover genetic'],\n",
              " ['Networks MDN discriminant',\n",
              "  'networks called Mixture',\n",
              "  'Density Networks MDN',\n",
              "  'called Mixture Density',\n",
              "  'Mixture Density Networks'],\n",
              " ['produced DIMACS challenge',\n",
              "  'advantage SASAT GSAT',\n",
              "  'Results suggest SASAT',\n",
              "  'implemented GSAT Selman',\n",
              "  'SASAT GSAT Selman'],\n",
              " ['Principle recently proposed',\n",
              "  'Length Principle recently',\n",
              "  'employs Minimum Description',\n",
              "  'Minimum Description Length',\n",
              "  'Description Length Principle'],\n",
              " ['ith row Markov',\n",
              "  'outputs signlinear system',\n",
              "  'signlinear system state',\n",
              "  'output initial state',\n",
              "  'outputs Perform change'],\n",
              " ['IEEE CDC Tampa',\n",
              "  'IEEE Publications Teel',\n",
              "  'controls Proc IEEE',\n",
              "  'Dec IEEE Publications',\n",
              "  'Proc IEEE CDC'],\n",
              " ['reconciliation dynamic systems',\n",
              "  'data reconciliation performed',\n",
              "  'estimation data reconciliation',\n",
              "  'reconciliation dynamic steady',\n",
              "  'data reconciliation dynamic'],\n",
              " ['significant realworld classification',\n",
              "  'classification tasks involve',\n",
              "  'realworld classification tasks',\n",
              "  'tasks involve large',\n",
              "  'prior knowledge encodes'],\n",
              " ['Tjalkens derive efficient',\n",
              "  'Shtarkov Tjalkens derive',\n",
              "  'developed Buntine Willems',\n",
              "  'Buntine Willems Shtarkov',\n",
              "  'Willems Shtarkov Tjalkens'],\n",
              " ['Finally present generalization',\n",
              "  'net result Haussler',\n",
              "  'Welzl apply give',\n",
              "  'result Haussler Welzl',\n",
              "  'Haussler Welzl apply'],\n",
              " ['pessimistic decision tree',\n",
              "  'theoretically sound based',\n",
              "  'sound based theoretical',\n",
              "  'based theoretical concepts',\n",
              "  'decision tree pruning'],\n",
              " ['Specifically causal statistical',\n",
              "  'global structure Windowbased',\n",
              "  'biology Specifically report',\n",
              "  'molecular biology Specifically',\n",
              "  'Specifically report results'],\n",
              " ['algorithmic stability Previous',\n",
              "  'bounds error leaveoneout',\n",
              "  'minimization procedures Bayesian',\n",
              "  'training error estimate',\n",
              "  'training error minimization'],\n",
              " ['sequence actions carried',\n",
              "  'partial matching algorithm',\n",
              "  'observations guides conducting',\n",
              "  'support weaken case',\n",
              "  'order support weaken'],\n",
              " ['Consisting loose collection',\n",
              "  'Programming techniques domainindependent',\n",
              "  'Widespread adoption Genetic',\n",
              "  'adoption Genetic Programming',\n",
              "  'Genetic Programming techniques'],\n",
              " ['testbed study role',\n",
              "  'interesting testbed study',\n",
              "  'robots Kheperas infrared',\n",
              "  'Kheperas infrared proximity',\n",
              "  'mobile robots Kheperas'],\n",
              " ['error Softmax units',\n",
              "  'layers radial basis',\n",
              "  'crossentropy error Softmax',\n",
              "  'requires Ojwj operations',\n",
              "  'derivatives requires Ojwj'],\n",
              " ['paper describe principles',\n",
              "  'describe principles problem',\n",
              "  'Engine existing system',\n",
              "  'Structure Mapping Engine',\n",
              "  'Mapping Engine existing'],\n",
              " ['architectures Empirical results',\n",
              "  'Empirical results generalizing',\n",
              "  'provide accurate generalization',\n",
              "  'parallel architectures Empirical',\n",
              "  'training set data'],\n",
              " ['exposition recent research',\n",
              "  'systemtheoretic aspects continuoustime',\n",
              "  'result minimality Facts',\n",
              "  'Air Force Grant',\n",
              "  'Force Grant AFOSR'],\n",
              " ['LIT ASOCS Adaptive',\n",
              "  'Location Independent ASOCS',\n",
              "  'Artificial Neural Networks',\n",
              "  'Concurrent Systems ASOCS',\n",
              "  'Organizing Concurrent Systems'],\n",
              " ['Reinforcement learning algorithms',\n",
              "  'functions satisfy Bellman',\n",
              "  'show case Bellman',\n",
              "  'policies Baird Algorithms',\n",
              "  'Baird Algorithms conditions'],\n",
              " ['envision knowledge Irrespective',\n",
              "  'show structurebehaviorfunction SBF',\n",
              "  'structurebehaviorfunction SBF models',\n",
              "  'describe SBF model',\n",
              "  'SBF model design'],\n",
              " ['representational format observed',\n",
              "  'classes movements Empirical',\n",
              "  'movements Empirical results',\n",
              "  'present OXBOW unsupervised',\n",
              "  'OXBOW unsupervised learning'],\n",
              " ['experimentally applied GNP',\n",
              "  'applied GNP prediction',\n",
              "  'constructive induction DCI',\n",
              "  'datadriven constructive induction',\n",
              "  'World Bank database'],\n",
              " ['small subset data',\n",
              "  'overlapping small subsets',\n",
              "  'extracting small subset',\n",
              "  'Vector Algorithm train',\n",
              "  'Support Vector Algorithm'],\n",
              " ['probabilistic Bayesian methods',\n",
              "  'dimensions Finally reconstruction',\n",
              "  'Gaussian tuning function',\n",
              "  'independent width Gaussian',\n",
              "  'width Gaussian tuning'],\n",
              " ['selfmotion information inertially',\n",
              "  'activity profile close',\n",
              "  'static activity profile',\n",
              "  'activity profile network',\n",
              "  'stable activity profile'],\n",
              " ['algorithms datasets UCI',\n",
              "  'recent work Kong',\n",
              "  'datasets UCI repository',\n",
              "  'work Kong Dietterich',\n",
              "  'Kong Dietterich Breiman'],\n",
              " ['Computing Corporations lowcost',\n",
              "  'Floyd Knuth subsequent',\n",
              "  'Corporations lowcost HOTS',\n",
              "  'devised Floyd Knuth',\n",
              "  'Virtual Computing Corporations'],\n",
              " ['theoretically justifiable fast',\n",
              "  'specific number nonzero',\n",
              "  'minimizing number nonzero',\n",
              "  'Numerical tests signalprocessingbased',\n",
              "  'number nonzero elements'],\n",
              " ['learning Foldiak feedforward',\n",
              "  'generalization Hopfield network',\n",
              "  'signals Hebbian learning',\n",
              "  'activity signals Hebbian',\n",
              "  'Hebbian learning Foldiak'],\n",
              " ['state art neuralnetwork',\n",
              "  'article describe neuralnetwork',\n",
              "  'boxes datamining specialists',\n",
              "  'training times Specifically',\n",
              "  'times Specifically discuss'],\n",
              " ['error small perform',\n",
              "  'generalization error small',\n",
              "  'gain generalization error',\n",
              "  'decreases generalization error',\n",
              "  'agreement analytical findings'],\n",
              " ['selection clustering robust',\n",
              "  'Algorithm utilized discover',\n",
              "  'kMedian Algorithm utilized',\n",
              "  'Computational results real',\n",
              "  'resulting kMedian Algorithm'],\n",
              " ['ATRIS learning algorithm',\n",
              "  'Concept learning viewed',\n",
              "  'search space concept',\n",
              "  'space concept descriptions',\n",
              "  'stochastic search method'],\n",
              " ['understood generally tested',\n",
              "  'resulted variety evolutionary',\n",
              "  'increasing availability finelygrained',\n",
              "  'architectures resulted variety',\n",
              "  'population spatially distributed'],\n",
              " ['nodes Bayesian network',\n",
              "  'evaluates approximate Bayesian',\n",
              "  'approximate Bayesian networks',\n",
              "  'probabilistic reasoning Bayesian',\n",
              "  'reasoning Bayesian network'],\n",
              " ['rectified Gaussian constrained',\n",
              "  'power rectified Gaussian',\n",
              "  'variables rectified Gaussian',\n",
              "  'Gaussian constrained nonnegative',\n",
              "  'modification standard Gaussian'],\n",
              " ['neural network learning',\n",
              "  'time nonGaussian independent',\n",
              "  'nonGaussian independent components',\n",
              "  'Neural Computation Abstract',\n",
              "  'Independent Component Analysis'],\n",
              " ['put practical neuronal',\n",
              "  'variant BCM learning',\n",
              "  'BCM learning rule',\n",
              "  'minimal entropy coding',\n",
              "  'Barlows seminal work'],\n",
              " ['experimentally applied GNP',\n",
              "  'applied GNP prediction',\n",
              "  'constructive induction DCI',\n",
              "  'datadriven constructive induction',\n",
              "  'World Bank database'],\n",
              " ['regression trees Regressional',\n",
              "  'strong dependencies attributes',\n",
              "  'poor Relief extension',\n",
              "  'performance poor Relief',\n",
              "  'sets show Regressional'],\n",
              " ['Logic Programming Machine',\n",
              "  'Programming Machine Learning',\n",
              "  'Buntines Inverse Resolution',\n",
              "  'Muggleton Buntines Inverse',\n",
              "  'Inductive Logic Programming'],\n",
              " ['Bayesian methods applicable',\n",
              "  'argued Bayesian methods',\n",
              "  'principles Bayesian inference',\n",
              "  'review principles Bayesian',\n",
              "  'Bayesian inference presented'],\n",
              " ['Section probability distribution',\n",
              "  'perfect map Pearl',\n",
              "  'wellknown ALARM network',\n",
              "  'learning Bayesian belief',\n",
              "  'Bayesian belief networks'],\n",
              " ['versions wellknown ALARM',\n",
              "  'wellknown ALARM network',\n",
              "  'ALARM network database',\n",
              "  'constructing Bayesian belief',\n",
              "  'Bayesian belief networks'],\n",
              " ['Basis Functions Neural',\n",
              "  'Functions Neural Networks',\n",
              "  'Radial Basis Functions',\n",
              "  'Vector Machine SVM',\n",
              "  'Support Vector Machine'],\n",
              " ['apply neural network',\n",
              "  'neural networks versatile',\n",
              "  'multichip modules MCMs',\n",
              "  'fulfilled exploiting MCM',\n",
              "  'adapted apply neural'],\n",
              " ['derivations positive negative',\n",
              "  'exclude set negative',\n",
              "  'remove clauses refutation',\n",
              "  'clauses refutation negative',\n",
              "  'specialize remove clauses'],\n",
              " ['shown generality resulting',\n",
              "  'program positive negative',\n",
              "  'SLDtree refutations negative',\n",
              "  'discriminating positive negative',\n",
              "  'wrt positive negative'],\n",
              " ['decision modeling technique',\n",
              "  'formalisms qualitative decision',\n",
              "  'mapping qualitative decision',\n",
              "  'expressiveness models sort',\n",
              "  'qualitative decision modeling'],\n",
              " ['discuss applied dynamic',\n",
              "  'applied dynamic selection',\n",
              "  'dynamic selection modification',\n",
              "  'sensorimotor interaction environment',\n",
              "  'issues addressed work'],\n",
              " ['Office Naval Research',\n",
              "  'Naval Research Grant',\n",
              "  'Muggleton David Page',\n",
              "  'Page Ashwin Srinivasan',\n",
              "  'David Page Ashwin'],\n",
              " ['recover underlying Bayesian',\n",
              "  'based method Results',\n",
              "  'method Results evaluation',\n",
              "  'LED SOYBEAN presented',\n",
              "  'ALARM LED SOYBEAN'],\n",
              " ['adjusts training error',\n",
              "  'permuted versions dataset',\n",
              "  'training error average',\n",
              "  'criterion model selection',\n",
              "  'covariance inflation criterion'],\n",
              " ['gas MNG algorithm',\n",
              "  'neural gas MNG',\n",
              "  'data set Results',\n",
              "  'set Results demonstrate',\n",
              "  'Results demonstrate promise'],\n",
              " ['Foundation Office Naval',\n",
              "  'Salvucci Office Naval',\n",
              "  'Science Foundation Fellowship',\n",
              "  'Office Naval Research',\n",
              "  'National Science Foundation'],\n",
              " ['Laplaces method integrate',\n",
              "  'methods ErrorinVariableMeasurement EVM',\n",
              "  'needed Linear approximations',\n",
              "  'Linear approximations provide',\n",
              "  'uncertainty needed Linear'],\n",
              " ['rules cortical selforganization',\n",
              "  'learning rules cortical',\n",
              "  'cortical selforganization proposed',\n",
              "  'based idea multiple',\n",
              "  'specific stimulus features'],\n",
              " ['constructs composite hypothesis',\n",
              "  'AdaBoost developed Freund',\n",
              "  'Schapire exhibited outstanding',\n",
              "  'Freund Schapire exhibited',\n",
              "  'developed Freund Schapire'],\n",
              " ['Marshall Marshall Gupta',\n",
              "  'Goda Stevens Kirkwood',\n",
              "  'Dudek Bear Goda',\n",
              "  'Bear Goda Stevens',\n",
              "  'Reiter Stryker Kasamatsu'],\n",
              " ['queries polynomial log',\n",
              "  'exact learnability DNF',\n",
              "  'Euclidean space coordinate',\n",
              "  'learnability DNF formulas',\n",
              "  'Osd log axisparallel'],\n",
              " ['searches Simulation results',\n",
              "  'Approaches combining genetic',\n",
              "  'simple random search',\n",
              "  'optimizer Enhancements discussed',\n",
              "  'Enhancements discussed improve'],\n",
              " ['Department Brain Cognitive',\n",
              "  'Learning Department Brain',\n",
              "  'Biological Computational Learning',\n",
              "  'Computational Learning Department',\n",
              "  'MAP estimate obtained'],\n",
              " ['combination Genetic Algorithm',\n",
              "  'South Wales region',\n",
              "  'base South Wales',\n",
              "  'coded Greedy Optimizers',\n",
              "  'Greedy Optimizers readily'],\n",
              " ['normal set Experiments',\n",
              "  'Experiments boolean multiplexer',\n",
              "  'valid possibly unique',\n",
              "  'Supported grant NASAJSC',\n",
              "  'grant NASAJSC NAG'],\n",
              " ['programming qualitative modelling',\n",
              "  'inverse resolution Forte',\n",
              "  'resolution Forte demonstrated',\n",
              "  'firstorder Hornclause theories',\n",
              "  'Hornclause theories integrating'],\n",
              " ['computed FGEN improves',\n",
              "  'called FGEN creates',\n",
              "  'show superiority FGEN',\n",
              "  'DNA sequences Unix',\n",
              "  'FGEN creates Boolean'],\n",
              " ['carry extensive computational',\n",
              "  'general description genetic',\n",
              "  'Line Balancing Problem',\n",
              "  'problem Assembly Line',\n",
              "  'Assembly Line Balancing'],\n",
              " ['CaseBased Reasoning methods',\n",
              "  'application CaseBased Reasoning',\n",
              "  'methods KOSIMO data',\n",
              "  'Reasoning tool VIECBR',\n",
              "  'Reasoning methods KOSIMO'],\n",
              " ['casebased learner PAC',\n",
              "  'form hCB Reasoning',\n",
              "  'Reasoning casebased representation',\n",
              "  'PAC learning algorithm',\n",
              "  'casebased learning algorithm'],\n",
              " ['past years evolutionary',\n",
              "  'emergent properties paper',\n",
              "  'field Emerging activity',\n",
              "  'newcomers field Emerging',\n",
              "  'Emerging activity beginnings'],\n",
              " ['varying complexity Finally',\n",
              "  'Finally show formally',\n",
              "  'Markov models varying',\n",
              "  'generated Markov models',\n",
              "  'complexity Finally show'],\n",
              " ['statistics machine learning',\n",
              "  'regular Knearestneighbor methods',\n",
              "  'Knearestneighbor decision rule',\n",
              "  'hybrid regular Knearestneighbor',\n",
              "  'Knearestneighbor methods treestructured'],\n",
              " ['offspring produced genetic',\n",
              "  'show staged hybrid',\n",
              "  'traditional hybrid genetic',\n",
              "  'hybrid genetic algorithms',\n",
              "  'staged hybrid genetic'],\n",
              " ['sharing techniques genetic',\n",
              "  'understanding pattern recognition',\n",
              "  'explicit fitness sharing',\n",
              "  'immune systems Finally',\n",
              "  'systems Finally compare'],\n",
              " ['samples drawn input',\n",
              "  'process good generalisation',\n",
              "  'random samples drawn',\n",
              "  'linear approximation computed',\n",
              "  'depths tree retained'],\n",
              " ['Luttrell Williams Saul',\n",
              "  'Williams Saul Jordan',\n",
              "  'Jordan Saul Jordan',\n",
              "  'Saul Jordan Saul',\n",
              "  'linear Boltzmann chain'],\n",
              " ['Results presented showing',\n",
              "  'steps Results presented',\n",
              "  'addition results suggest',\n",
              "  'training steps Results',\n",
              "  'gent problem decompositions'],\n",
              " ['IDBD algorithm developed',\n",
              "  'DeltaBarDelta IDBD algorithm',\n",
              "  'presenting derivation IDBD',\n",
              "  'IDBD algorithm incremental',\n",
              "  'Incremental DeltaBarDelta IDBD'],\n",
              " ['OBS autoprune epsiprune',\n",
              "  'superior OBD diagnosis',\n",
              "  'OBD diagnosis tasks',\n",
              "  'OBD OBS autoprune',\n",
              "  'today OBD OBS'],\n",
              " ['specializing behaviour General',\n",
              "  'simulator developed ICSI',\n",
              "  'developed ICSI written',\n",
              "  'ICSIM connectionist net',\n",
              "  'ICSI written Sather'],\n",
              " ['paper examine class',\n",
              "  'solved retrieving adapting',\n",
              "  'teleological mechanisms GTMs',\n",
              "  'mechanisms GTMs cascading',\n",
              "  'Kritik system evaluates'],\n",
              " ['occurs knowledge learned',\n",
              "  'suggests casebased reasoning',\n",
              "  'casebased reasoning controlrule',\n",
              "  'reasoning controlrule learning',\n",
              "  'controlrule learning systems'],\n",
              " ['phenomena people extremely',\n",
              "  'compare Superficial remindings',\n",
              "  'items compare Superficial',\n",
              "  'MACFAC fully implemented',\n",
              "  'SME compute true'],\n",
              " ['factor Key words',\n",
              "  'online learning linear',\n",
              "  'learning linear functions',\n",
              "  'constant factor Key',\n",
              "  'Key words Machine'],\n",
              " ['approach call constructive',\n",
              "  'call constructive similarity',\n",
              "  'assessment Constructive similarity',\n",
              "  'similarity assessment Constructive',\n",
              "  'constructive similarity assessment'],\n",
              " ['retrieving relevant information',\n",
              "  'problem retrieving relevant',\n",
              "  'applied problem retrieving',\n",
              "  'discusses general requirements',\n",
              "  'processes focused identifying'],\n",
              " ['structured variational approximations',\n",
              "  'Jordan recently proposed',\n",
              "  'neural networks Saul',\n",
              "  'Saul Jordan recently',\n",
              "  'networks Saul Jordan'],\n",
              " ['mode ASOCS acts',\n",
              "  'processing mode ASOCS',\n",
              "  'advantages previous ASOCS',\n",
              "  'paper presents ASOCS',\n",
              "  'data processing mode'],\n",
              " ['techniques Unlike genetic',\n",
              "  'called dynamic hill',\n",
              "  'climbing techniques Unlike',\n",
              "  'Unlike genetic hill',\n",
              "  'dynamic hill climbing'],\n",
              " ['evaluation complex software',\n",
              "  'require sophisticated software',\n",
              "  'testing sophisticated software',\n",
              "  'controller autonomous vehicle',\n",
              "  'sophisticated software controllers'],\n",
              " ['improve efficiency searchbased',\n",
              "  'captures systems improve',\n",
              "  'seeks improve efficiency',\n",
              "  'motivate notion batch',\n",
              "  'applicable serially decomposable'],\n",
              " ['calculations based Smoothed',\n",
              "  'based Smoothed Particle',\n",
              "  'Hydrodynamics Usual estimators',\n",
              "  'Smoothed Particle Hydrodynamics',\n",
              "  'Particle Hydrodynamics Usual'],\n",
              " ['acyclic determinate Horn',\n",
              "  'acyclic Horn programs',\n",
              "  'determinate Horn programs',\n",
              "  'programs constant arity',\n",
              "  'Horn programs constant'],\n",
              " ['Initial empirical results',\n",
              "  'Genetic Algorithms GAs',\n",
              "  'Satisfiability Problem SAT',\n",
              "  'Boolean Satisfiability Problem',\n",
              "  'claim Boolean Satisfiability'],\n",
              " ['adopted Bayesian learning',\n",
              "  'Fully cooperative multiagent',\n",
              "  'models setting Finally',\n",
              "  'setting Finally propose',\n",
              "  'theory adopted Bayesian'],\n",
              " ['making crossdomain analogies',\n",
              "  'crossdomain analogies hard',\n",
              "  'target domains Recent',\n",
              "  'domains Recent work',\n",
              "  'Recent work casebased'],\n",
              " ['Gray coded integer',\n",
              "  'Algorithm discussed respect',\n",
              "  'integer Gray coded',\n",
              "  'encoded integer Gray',\n",
              "  'Genetic Algorithm discussed'],\n",
              " ['task actual robot',\n",
              "  'environments Previous studies',\n",
              "  'realworld environments Previous',\n",
              "  'Previous studies illustrated',\n",
              "  'illustrated Figure current'],\n",
              " ['Building developments describe',\n",
              "  'systems Building developments',\n",
              "  'knowledgebased systems Building',\n",
              "  'Intelligent Tutoring Systems',\n",
              "  'Conventional Intelligent Tutoring'],\n",
              " ['algorithm NNSAT GSAT',\n",
              "  'suggest NNSAT scales',\n",
              "  'SAT refers task',\n",
              "  'NNSAT GSAT greedy',\n",
              "  'Results suggest NNSAT'],\n",
              " ['Artificial Life Neural',\n",
              "  'Networks Artificial Life',\n",
              "  'Neural Networks Explicitly',\n",
              "  'Artificial Life Mobile',\n",
              "  'Life Mobile Robotics'],\n",
              " ['system Fuzzy ARTMAP',\n",
              "  'VIEWNET benchmarked MIT',\n",
              "  'object category nodes',\n",
              "  'View Information Encoded',\n",
              "  'MIT Lincoln Laboratory'],\n",
              " ['response IIR filters',\n",
              "  'impulse response IIR',\n",
              "  'Globally Feedforward Networks',\n",
              "  'Locally Recurrent Globally',\n",
              "  'Recurrent Globally Feedforward'],\n",
              " ['hidden units needed',\n",
              "  'Based asymptotical behavior',\n",
              "  'samples Based asymptotical',\n",
              "  'AMEF introduced parameters',\n",
              "  'number hidden units'],\n",
              " ['Wishart prior distribution',\n",
              "  'decomposable graphical Gaussian',\n",
              "  'reversible jump MCMC',\n",
              "  'Finally statistical computational',\n",
              "  'jump MCMC sampler'],\n",
              " ['behavior opportunity recognition',\n",
              "  'opportunistic behavior opportunity',\n",
              "  'real world opportunity',\n",
              "  'implemented part IMPROVISER',\n",
              "  'part IMPROVISER system'],\n",
              " ['Advanced Computer Studies',\n",
              "  'CSTR Institute Advanced',\n",
              "  'UMIACSTR CSTR Institute',\n",
              "  'Report UMIACSTR CSTR',\n",
              "  'Institute Advanced Computer'],\n",
              " ['importance MLPBP bias',\n",
              "  'MLPBP bias possibly',\n",
              "  'Finally analyze relevant',\n",
              "  'machine learning models',\n",
              "  'excess degrees freedom'],\n",
              " ['Rulearner system shown',\n",
              "  'Galois lattice explicit',\n",
              "  'Rulearner induces classification',\n",
              "  'induction algorithm Rulearner',\n",
              "  'algorithm Rulearner induces'],\n",
              " ['Keywords CaseBased Reasoning',\n",
              "  'Previously collected cases',\n",
              "  'Fish Shrink algorithms',\n",
              "  'algorithm Fish Shrink',\n",
              "  'compare Fish Shrink'],\n",
              " ['Abstractly PGA parallel',\n",
              "  'Firstly selection mating',\n",
              "  'algorithm Firstly selection',\n",
              "  'PGA succesful Abstractly',\n",
              "  'succesful Abstractly PGA'],\n",
              " ['conferences classifying cases',\n",
              "  'dominant theme casebased',\n",
              "  'represented feature vectors',\n",
              "  'focusing alternative performance',\n",
              "  'learning focusing alternative'],\n",
              " ['approach Natural Language',\n",
              "  'Current approaches computational',\n",
              "  'Processing based automatic',\n",
              "  'Language Processing based',\n",
              "  'Natural Language Processing'],\n",
              " ['sequential algorithm optimise',\n",
              "  'prove mild conditions',\n",
              "  'defined approximable sequence',\n",
              "  'explicitly defined approximable',\n",
              "  'function explicitly defined'],\n",
              " ['independence assumptions Based',\n",
              "  'Intuitively general criterion',\n",
              "  'complete data matrix',\n",
              "  'matrices Intuitively general',\n",
              "  'relative model class'],\n",
              " ['principle National Hockey',\n",
              "  'suited Open Shop',\n",
              "  'Open Shop Scheduling',\n",
              "  'National Hockey League',\n",
              "  'Hockey League NHL'],\n",
              " ['optimal Fogels Evolutionary',\n",
              "  'Message Length MML',\n",
              "  'Length MML Wallace',\n",
              "  'Minimum Message Length',\n",
              "  'Fogels Evolutionary Programming'],\n",
              " ['Markov chain Monte',\n",
              "  'Bayesian framework Efficient',\n",
              "  'chain Monte Carlo',\n",
              "  'Technical Report CUEDFINFENGTR',\n",
              "  'Monte Carlo MCMC'],\n",
              " ['primitive inferential operators',\n",
              "  'series modifications memory',\n",
              "  'simple finegrained primitive',\n",
              "  'finegrained primitive inferential',\n",
              "  'inferential operators needed'],\n",
              " ['SCBR learns quickly',\n",
              "  'Applying approaches show',\n",
              "  'Firstly hypothesis spaces',\n",
              "  'base Applying approaches',\n",
              "  'SCBR motivated PAC'],\n",
              " ['interesting form dependency',\n",
              "  'generalize functional dependencies',\n",
              "  'functional dependencies allowing',\n",
              "  'viability presented ideas',\n",
              "  'MDL formula evaluating'],\n",
              " ['measure finite state',\n",
              "  'optimal finite state',\n",
              "  'probabilistic finite state',\n",
              "  'Approximate bounds acceptance',\n",
              "  'finite state machine'],\n",
              " ['evolve cellular automata',\n",
              "  'cellular automata CAs',\n",
              "  'order produce globally',\n",
              "  'produce globally coordinated',\n",
              "  'automata CAs show'],\n",
              " ['Ztheorem due Van',\n",
              "  'Van der Vaart',\n",
              "  'Lele Newton Raftery',\n",
              "  'Arcones Gine Lele',\n",
              "  'Gine Lele Newton'],\n",
              " ['SCRSA extension RSA',\n",
              "  'RSA SCRSA extension',\n",
              "  'Survival Curve RSA',\n",
              "  'Curve RSA SCRSA',\n",
              "  'Surface Approximation RSA'],\n",
              " ['Bell Laboratories Mountain',\n",
              "  'Laboratories Mountain Ave',\n",
              "  'Mountain Ave Murray',\n",
              "  'Yoav Freund Room',\n",
              "  'ATT Bell Laboratories'],\n",
              " ['compute principal components',\n",
              "  'form Principal Component',\n",
              "  'principal components highdimensional',\n",
              "  'Component Analysis proposed',\n",
              "  'Principal Component Analysis'],\n",
              " ['knowledge Specifically graphical',\n",
              "  'graphical decision model',\n",
              "  'capture general knowledge',\n",
              "  'Specifically graphical decisionmodeling',\n",
              "  'form utility function'],\n",
              " ['PEBLS Cost knearest',\n",
              "  'Brodley Brodley met',\n",
              "  'machine learning Methods',\n",
              "  'learning Methods selecting',\n",
              "  'Methods selecting learning'],\n",
              " ['learning explored role',\n",
              "  'questions Learning begins',\n",
              "  'machine learning explored',\n",
              "  'issues machine learning',\n",
              "  'program called Marvin'],\n",
              " ['Energy Environments LEE',\n",
              "  'evolutionary process Individuals',\n",
              "  'Latent Energy Environments',\n",
              "  'computational tools Latent',\n",
              "  'tools Latent Energy'],\n",
              " ['predictable Cohen simple',\n",
              "  'Cohen simple counting',\n",
              "  'notion klocal Horn',\n",
              "  'restrict linked Horn',\n",
              "  'klocal Horn clauses'],\n",
              " ['variables constants arguments',\n",
              "  'Key concepts STGP',\n",
              "  'Report Abstract Genetic',\n",
              "  'Technical Report Abstract',\n",
              "  'BBN Technical Report'],\n",
              " ['RCC Network Fahlman',\n",
              "  'Preference poster Abstract',\n",
              "  'poster Abstract Existing',\n",
              "  'Recurrent Cascade Correlation',\n",
              "  'Cascade Correlation RCC'],\n",
              " ['show context based',\n",
              "  'programming theorem proving',\n",
              "  'decidable incomplete approximation',\n",
              "  'implication important inductive',\n",
              "  'reduction computational effort'],\n",
              " ['learn sparse perceptrons',\n",
              "  'sparse perceptrons input',\n",
              "  'perceptrons input representations',\n",
              "  'designed learn sparse',\n",
              "  'easy humans understand'],\n",
              " ['real world problems',\n",
              "  'RELIEFF extension RELIEF',\n",
              "  'Kira Rendell heuristic',\n",
              "  'RELIEF developed Kira',\n",
              "  'developed Kira Rendell'],\n",
              " ['Conditions MAXQ decomposition',\n",
              "  'Hinton Conditions MAXQ',\n",
              "  'Dayan Hinton Conditions',\n",
              "  'Kaelbling Dayan Hinton',\n",
              "  'Singh Kaelbling Dayan'],\n",
              " ['concept causality Genetic',\n",
              "  'architecture evolution Koza',\n",
              "  'evolutionary thesis Finally',\n",
              "  'representation operators Hierarchical',\n",
              "  'causality Genetic Programming'],\n",
              " ['weight perturbations Wagging',\n",
              "  'perturbations Wagging backfitting',\n",
              "  'Arcx behaves differently',\n",
              "  'observed Arcx behaves',\n",
              "  'Practical problems arise'],\n",
              " ['longterm goal field',\n",
              "  'field creation understanding',\n",
              "  'goal field creation',\n",
              "  'practical theoretical benefits',\n",
              "  'understanding intelligence Productive'],\n",
              " ['solution problem representing',\n",
              "  'represented vectors Arbitrary',\n",
              "  'vectors Arbitrary variable',\n",
              "  'good reconstructive properties',\n",
              "  'Arbitrary variable bindings'],\n",
              " ['Technion March Carmel',\n",
              "  'Report CIS report',\n",
              "  'report Technion March',\n",
              "  'Technical Report CIS',\n",
              "  'CIS report Technion'],\n",
              " ...]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yake_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uVsdbZ6OT1w",
        "outputId": "4d8dea71-8ba2-4961-85d7-5b303711bc3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['based fitting parameters statistical model group related sequences',\n",
              "  'part statistical model',\n",
              "  'patterns groups protein sequences',\n",
              "  'column final model',\n",
              "  'prior proportion size sequence dataset'],\n",
              " ['colposuspension cure rate',\n",
              "  'differences cure rate',\n",
              "  'learning strategies',\n",
              "  'useful role large scale medical problem',\n",
              "  'risk factors'],\n",
              " ['channel available call',\n",
              "  'free channel',\n",
              "  'call requests service',\n",
              "  'channel reuse constraint',\n",
              "  'number blocked calls'],\n",
              " ['finitememory controller extracted solution',\n",
              "  'pomdps line show cases',\n",
              "  'techniques operations research bear problem',\n",
              "  'exact solutions pomdps possibilities',\n",
              "  'previous work complexity'],\n",
              " ['Graphical models',\n",
              "  'graphical models',\n",
              "  'applicability graphical models',\n",
              "  'representational power probability models',\n",
              "  'variational methods'],\n",
              " ['test domain realtime decision algorithms',\n",
              "  'Incremental Probabilisitic Inference DAmbrosio variant algorithm',\n",
              "  'broader applicability algorithms',\n",
              "  'experimental results',\n",
              "  'decisionevaluation variant'],\n",
              " ['framework implementations',\n",
              "  'formal framework',\n",
              "  'computational efficiency problem',\n",
              "  'framework',\n",
              "  'random problems solutions'],\n",
              " ['paper show results',\n",
              "  'cost functions',\n",
              "  'objective functions',\n",
              "  'linear space algorithm Hir',\n",
              "  'result'],\n",
              " ['known offline model sequence elements',\n",
              "  'constant number mistakes sequence',\n",
              "  'number mistakes',\n",
              "  'constant number mistakes',\n",
              "  'offline model'],\n",
              " ['ANalysis VAriance SS ANOVA method data exponential families',\n",
              "  'Bayesian confidence intervals SS ANOVA',\n",
              "  'SS ANOVA',\n",
              "  'binary binomial Poisson Gamma data',\n",
              "  'Wahba Wang Gu Klein Klein'],\n",
              " ['learning rules problems',\n",
              "  'evolutionary approach potential solutions',\n",
              "  'simple supervised learning problems',\n",
              "  'larger size codings potential solutions ability generalisation testing',\n",
              "  'hill climbing strategy incremental coding potential solutions'],\n",
              " ['basic LaplaceMetropolis estimator models',\n",
              "  'Bayesian hypothesis testing model selection marginal likelihood model',\n",
              "  'compound LaplaceMetropolis estimator',\n",
              "  'LaplaceMetropolis estimator',\n",
              "  'integrated likelihood marginal probability data'],\n",
              " ['empirical learning utility problem',\n",
              "  'knowledge course learning performance response',\n",
              "  'mechanisms different learning paradigms model',\n",
              "  'particular empirical model trend analysis learners',\n",
              "  'general utility problem'],\n",
              " ['multiple sequence alignment protein families protein domains',\n",
              "  'multiple alignment training sequences',\n",
              "  'search relationships protein sequence',\n",
              "  'HMMs HMM',\n",
              "  'protein family'],\n",
              " ['Monte Carlo techniques magnitude initial condition vector weight space',\n",
              "  'effect initial weight selection feedforward networks',\n",
              "  'simple functions backpropagation technique',\n",
              "  'significant parameter convergence time variability',\n",
              "  'additional deterministic experiments'],\n",
              " ['consolidation responsible transfer memory medial temporal lobe neocortex',\n",
              "  'medial temporal lobe',\n",
              "  'performance model realistic conditions',\n",
              "  'performance model',\n",
              "  'extended version model'],\n",
              " ['investigation dependence pattern stripes degree correlation eyes',\n",
              "  'eyes',\n",
              "  'subtractive enforcement weight normalization rule Inputs model',\n",
              "  'computational model addresses',\n",
              "  'previous models'],\n",
              " ['average variance test error rates',\n",
              "  'test error rate',\n",
              "  'classifier random example',\n",
              "  'validation data average test error rate',\n",
              "  'test example inputs variance'],\n",
              " ['combinations noise models',\n",
              "  'information target function distribution',\n",
              "  'formal model',\n",
              "  'formal models',\n",
              "  'example learner'],\n",
              " ['decision tree based approach function approximation reinforcement',\n",
              "  'better learning performance neural network function approximation',\n",
              "  'neural network function approximator',\n",
              "  'large problems',\n",
              "  'decision tree'],\n",
              " ['new game playing strategies',\n",
              "  'discover strategies',\n",
              "  'evolutionary neural networks',\n",
              "  'neural networks',\n",
              "  'first standard positional strategy subsequently mobility strategy advanced strategy'],\n",
              " ['model classification noise',\n",
              "  'Statistical Query model PAC model classification noise',\n",
              "  'general framework efficient PAC learning presence classification noise',\n",
              "  'weak SQ learning algorithms',\n",
              "  'general upper bounds'],\n",
              " ['Neural network features',\n",
              "  'applications classes',\n",
              "  'class applications',\n",
              "  'features applications',\n",
              "  'model applications'],\n",
              " ['socalled noninformative priors priors',\n",
              "  'Jeffreyss rules variants',\n",
              "  'Jeffreyss rules',\n",
              "  'formal rule',\n",
              "  'formal rules'],\n",
              " ['eXogenous inputs neural network models popular subclass recurrent networks',\n",
              "  'recurrent network models',\n",
              "  'Recurrent neural networks',\n",
              "  'generalization predictive performance nonlinear systems problems',\n",
              "  'intelligent memory order selection'],\n",
              " ['incremental concept learning approach identiflcation concepts',\n",
              "  'concepts original stochastic complexity formula',\n",
              "  'Many traditional inductive algorithms disjunctive version space family',\n",
              "  'certain degree sensitivity order examples third handles',\n",
              "  'simulated annealingbased beam search'],\n",
              " ['creative design',\n",
              "  'casebased design systems support based study designers',\n",
              "  'CBR systems',\n",
              "  'design alternatives',\n",
              "  'exploration ideas elaboration redefinition problems'],\n",
              " ['stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'generalized iterative scaling procedure',\n",
              "  'probabilistic automata',\n",
              "  'contextdependent probabilities'],\n",
              " ['design problems',\n",
              "  'demex interactive computeraided design system',\n",
              "  'new designs',\n",
              "  'hisher understanding problem',\n",
              "  'better understanding requirements problems'],\n",
              " ['hidden variables Inversion generative model',\n",
              "  'algorithm recognition models',\n",
              "  'generative model',\n",
              "  'generative models',\n",
              "  'generative model examples'],\n",
              " ['certain vision processing techniques index case base surfaces',\n",
              "  'early learning process',\n",
              "  'interaction system environment',\n",
              "  'relevant surface',\n",
              "  'orders magnitude increase learning rate'],\n",
              " ['genetic algorithm bootstrapping method',\n",
              "  'robotics planning game playing areas solutions differential games',\n",
              "  'difficult class delayed reinforcement learning problems',\n",
              "  'general class planning control problems',\n",
              "  'genetic algorithmto particular differential game'],\n",
              " ['hierarchical generative model',\n",
              "  'demon strate network',\n",
              "  'bottomup topdown lateral connections',\n",
              "  'nonlinear generalization factor analysis',\n",
              "  'neural network'],\n",
              " ['neuronbased search networkbased search',\n",
              "  'neuronlevel exploratory search',\n",
              "  'efficient genetic search',\n",
              "  'complete neural network Recent work SANE system',\n",
              "  'neuroevolution individual population'],\n",
              " ['select actions order',\n",
              "  'compactness action policies',\n",
              "  'simple grid navigation tasks',\n",
              "  'context multiple related tasks',\n",
              "  'successful discovery structure reinforcement'],\n",
              " ['general constraint number M incorrect predictions number M incorrect predictions',\n",
              "  'f gvalued functions learner',\n",
              "  'several applications general results',\n",
              "  'situations learner wishes',\n",
              "  'generalpurpose optimal algorithm formulation problem'],\n",
              " ['accelerating MCMC sampler convergence',\n",
              "  'Division Biostatistics School Public Health University',\n",
              "  'theoretical convergence bounds',\n",
              "  'Minnesota Assistant Professor Biostatistics Section Department Preventive Societal Medicine University Nebraska Medical Center',\n",
              "  'first author graduate student Divison Biostatistics University'],\n",
              " ['coherent depth information randomdot',\n",
              "  'high variance principal components',\n",
              "  'set input patterns',\n",
              "  'detection invariant structure',\n",
              "  'many recognition tasks'],\n",
              " ['query search database',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'online local model local average local regression',\n",
              "  'database experiences resolutions interest',\n",
              "  'multiresolution data structure'],\n",
              " ['optimal control policy',\n",
              "  'variety heuristic control strategies',\n",
              "  'model uncertainty mobilerobot navigation question actions',\n",
              "  'optimal solution problem',\n",
              "  'Discrete Bayesian models'],\n",
              " ['implementation note',\n",
              "  'Salzbergs NGE',\n",
              "  'algorithm run case studies',\n",
              "  'NGE',\n",
              "  'available WWW address'],\n",
              " ['distribution easilysampled distribution',\n",
              "  'distribution interest distribution sampling',\n",
              "  'recentlydeveloped method simulated tempering tempered transition method',\n",
              "  'tempering tempered transitions',\n",
              "  'series distributions'],\n",
              " ['students solution',\n",
              "  'uncertainty student model',\n",
              "  'student',\n",
              "  'students',\n",
              "  'tutor student typical session'],\n",
              " ['previous regulation processes',\n",
              "  'previous experience',\n",
              "  'regulation process',\n",
              "  'casebased approach Introspection Planning',\n",
              "  'various metacognitive tasks'],\n",
              " ['Markov property chain graphs',\n",
              "  'direct extension ADG Markov property LWF property chain graph',\n",
              "  'paper alternative Markov property AMP chain graphs',\n",
              "  'Applications undirected graphs UDGs',\n",
              "  'mixed graphs'],\n",
              " ['CheoungNam Lee Glenn Meredith Chandra Mouleeswaran z Current address Robotics Laboratory Computer Science Department Stanford University Stanford CA email',\n",
              "  'Proceedings Fifth International Workshop Principles Diagnosis Dx New',\n",
              "  'Proceedings Fifth International Workshop Principles Diagnosis',\n",
              "  'correctness diagnoses returns set tests',\n",
              "  'noise quality candidate theory'],\n",
              " ['Machine learning game strategies',\n",
              "  'new strategies',\n",
              "  'repeated use strategy learning component',\n",
              "  'total number strategies',\n",
              "  'complexity analysis game learning list number new questions'],\n",
              " ['algorithm learning algorithms',\n",
              "  'generalization error hypothesis',\n",
              "  'different approach bounding generalization error data',\n",
              "  'learning algorithm based methods theory',\n",
              "  'A selfbounding learning algorithm algorithm addition hypothesis outputs outputs reliable upper bound generalization error hypothesis'],\n",
              " ['energy landscape policy space Methods',\n",
              "  'optimal policies empirical estimates',\n",
              "  'policy yields',\n",
              "  'policies',\n",
              "  'return'],\n",
              " ['general sigmoidal nets Implications number samples',\n",
              "  'least large square number weights',\n",
              "  'longstanding open question',\n",
              "  'continuous activation functions',\n",
              "  'whether wellknown Ow log w bound known hardthreshold nets'],\n",
              " ['ability chaotic random switching crossover output signals',\n",
              "  'associated learning algorithms',\n",
              "  'learning algorithms',\n",
              "  'Novel online learning algorithms',\n",
              "  'blind separation signals'],\n",
              " ['composite tasks',\n",
              "  'set composite elemental MDTs',\n",
              "  'single learning agent',\n",
              "  'multiple Markovian decision tasks',\n",
              "  'composite MDT'],\n",
              " ['numerical simulators computational design jet engine',\n",
              "  'order address problem developed system',\n",
              "  'interactive formulation testing reformulation design optimization strategies',\n",
              "  'numerical simulation programs',\n",
              "  'Ellman Murata Automatic design optimization'],\n",
              " ['effective inference algorithms',\n",
              "  'support effective inference algorithms',\n",
              "  'conditional independence properties distribution',\n",
              "  'analogous based dseparation determining independence',\n",
              "  'Bayesian network structure independencies'],\n",
              " ['method corresponding replacetrace TD',\n",
              "  'conventional trace',\n",
              "  'addition show method',\n",
              "  'trace assign credit',\n",
              "  'conventional TD'],\n",
              " ['intensive reading known creative reading',\n",
              "  'functional theory complete reading process',\n",
              "  'creative reading aspect',\n",
              "  'framework developed theory',\n",
              "  'necessary reading'],\n",
              " ['counterfactual conditionals',\n",
              "  'counterfactual implication connectives',\n",
              "  'propositional knowledgebases Intuitively update',\n",
              "  'Second International Conference Principles Knowledge Representation Reasoning Cambridge',\n",
              "  'revision operators'],\n",
              " ['unmatchable previous neural net algorithms',\n",
              "  'Levin complexity timebounded generalization',\n",
              "  'given problem solution candidates',\n",
              "  'optimal universal search algorithm',\n",
              "  'Kolmogorov complexity'],\n",
              " ['inferred expressive transformations new phrase',\n",
              "  'expressive musical performances context tenor saxophone interpretations',\n",
              "  'several expressive parameters',\n",
              "  'background musical knowledge new phrase',\n",
              "  'possible expressive transformations'],\n",
              " ['paper show phenomenon related distribution margins training examples respect',\n",
              "  'margin distribution test error',\n",
              "  'analysis Vapniks support vector classifiers neural networks small weights',\n",
              "  'test error',\n",
              "  'voting classification rule margin example simply difference number correct votes maximum number votes'],\n",
              " ['missing data',\n",
              "  'highdimensional data',\n",
              "  'data sets',\n",
              "  'based maximum likelihood density estimation',\n",
              "  'estimation mixture components'],\n",
              " ['input story instance particular script',\n",
              "  'unique memory location script instantiation',\n",
              "  'scripts',\n",
              "  'taxonomy maps',\n",
              "  'ordinary singlelevel feature mapping'],\n",
              " ['adaptive attentive systems general',\n",
              "  'static neural approaches adaptive target detection',\n",
              "  'adaptive model',\n",
              "  'artificial fovea controlled adaptive neural controller',\n",
              "  'sequential generation fovea trajectories'],\n",
              " ['DARPA HPCC program NSF',\n",
              "  'Center Biological Computational Learning MIT',\n",
              "  'parameters architecture',\n",
              "  'online learning algorithm parameters',\n",
              "  'Jordan NSF Presidential Young Investigator'],\n",
              " ['wide range variant algorithms',\n",
              "  'incremental variant EM algorithm',\n",
              "  'maximum likelihood estimation data variables',\n",
              "  'unobserved variables',\n",
              "  'E step'],\n",
              " ['desynchronize oscillator groups',\n",
              "  'different oscillator groups',\n",
              "  'WilsonCowan oscillators',\n",
              "  'feedback oscillator matrix',\n",
              "  'linear approximation WilsonCowan oscillator'],\n",
              " ['implementation probabilistic regression model BUGS BUGS program',\n",
              "  'Bayesian inference statistical problems',\n",
              "  'BUGS BUGS',\n",
              "  'simultaneous inference',\n",
              "  'simulation technique'],\n",
              " ['hand complex data',\n",
              "  'unseen data',\n",
              "  'classifier based decision trees',\n",
              "  'machine learning techniques',\n",
              "  'classifying process'],\n",
              " ['neural network literature',\n",
              "  'R fl software',\n",
              "  'several SAS procedures',\n",
              "  'suitable implementation hardware',\n",
              "  'fit neural networks'],\n",
              " ['Kyburgs Evidential Probability system Various methods',\n",
              "  'subset style dominance problem',\n",
              "  'Kyburgs framework',\n",
              "  'stronger statistical assertions',\n",
              "  'Kyburgs latest proposal'],\n",
              " ['new scheduling problems',\n",
              "  'reinforcement learning methods',\n",
              "  'domainspecific heuristics job shop scheduling',\n",
              "  'new method',\n",
              "  'approach synthetic problems'],\n",
              " ['difficult control problem parameters cartpole system',\n",
              "  'current state system failure signal pole angle',\n",
              "  'cart free fall plane',\n",
              "  'great cart',\n",
              "  'scheme specifics minirobot hardware results'],\n",
              " ['faster average restart algorithm',\n",
              "  'Platts resourceallocation network RAN Platt b',\n",
              "  'hidden units',\n",
              "  'Qlearning network',\n",
              "  'new units'],\n",
              " ['Expandable Split Window ESW paradigm',\n",
              "  'multiple sequential processors',\n",
              "  'implementation Expandable Split Window execution model preliminary performance results',\n",
              "  'new processing paradigm',\n",
              "  'Expandable Split Window ESW'],\n",
              " ['axisparallel NGE approach',\n",
              "  'NGE',\n",
              "  'Nested Generalized Exemplar NGE theory',\n",
              "  'knearest neighbor kNN algorithm domains',\n",
              "  'complete nesting rectangles Performance'],\n",
              " ['good model',\n",
              "  'good model data',\n",
              "  'bad models',\n",
              "  'helpful searching space models',\n",
              "  'applicable class model selection problems'],\n",
              " ['binary value specifying value target feature vector binary values',\n",
              "  'V V size edge E',\n",
              "  'algorithm learning determinations functional dependencies',\n",
              "  'many learning problems',\n",
              "  'benefits determination learning show'],\n",
              " ['generative connections recognition connections',\n",
              "  'input representations',\n",
              "  'successive hidden layers topdown generative connections',\n",
              "  'input vectors',\n",
              "  'required force hidden units'],\n",
              " ['semantic relationship stored software components',\n",
              "  'structure software library',\n",
              "  'actual user software library',\n",
              "  'functional similarity stored software components order',\n",
              "  'notion semantic relationship components terms'],\n",
              " ['inductive analytical learning architecture',\n",
              "  'learning EBNN',\n",
              "  'rich variety learning capabilities',\n",
              "  'individual training examples detail',\n",
              "  'large set training examples'],\n",
              " ['approximate samples random set models',\n",
              "  'simplest random set models',\n",
              "  'perfect say exact simulations',\n",
              "  'important contribution simulation',\n",
              "  'Many simulation algorithms'],\n",
              " ['CBR induction techniques',\n",
              "  'rules particular context ie problem',\n",
              "  'whole problem space',\n",
              "  'CBR process future',\n",
              "  'CBR'],\n",
              " ['DFA model adversarial robot use automaton',\n",
              "  'robot reasoning model object machine',\n",
              "  'many applications robot agents',\n",
              "  'algorithm utility planner adversarial robotic domain',\n",
              "  'tandem use finite automata'],\n",
              " ['Claudia Cargnoni Dipartimento Statistico Universita di Firenze Firenze Italy Peter Muller Assistant Professor Mike West Professor Institute Statistics Decision Sciences Duke University Durham NC Research Cargnoni',\n",
              "  'ISDS Muller West',\n",
              "  'Firenze Firenze',\n",
              "  'Institute Statistics Decision Sciences',\n",
              "  'Peter Muller'],\n",
              " ['transient Markov chain analysis model',\n",
              "  'Traditional schema analysis',\n",
              "  'steady states',\n",
              "  'first order insights',\n",
              "  'new insights circumstances'],\n",
              " ['application training noise multilayer perceptron input variables',\n",
              "  'presentation method experimental evidences',\n",
              "  'Noise injection modified order',\n",
              "  'penalization inputs',\n",
              "  'single parameter'],\n",
              " ['present new multivariate decision tree algorithm LMDT',\n",
              "  'linear machines decision trees LMDT',\n",
              "  'test decision tree training linear machine',\n",
              "  'small accurate trees',\n",
              "  'good generalizations present results'],\n",
              " ['RL methods',\n",
              "  'RL system',\n",
              "  'type control task reinforcement',\n",
              "  'RL modelfree tuning adaptation method',\n",
              "  'outcome individual control action'],\n",
              " ['neural network modifiable lateral connections',\n",
              "  'experimental observations development lateral connections cortical feature maps',\n",
              "  'input information Predictions algorithm',\n",
              "  'Mexican hat shape',\n",
              "  'selforganization bootstrap'],\n",
              " ['formal natural explication relations graphical methods',\n",
              "  'lack mathematical notation',\n",
              "  'causality metaphysical deadend meaningful concept',\n",
              "  'statistical causal foundations',\n",
              "  'knowledgerich applications Statisticians'],\n",
              " ['method predicate invention similar Champ elegant solution noisy oracle problem',\n",
              "  'Systematic experimental comparisons Golem Foil range problems',\n",
              "  'logic programs examples attempts',\n",
              "  'bottomup method',\n",
              "  'new method'],\n",
              " ['upper lower bounds marginal probabilities',\n",
              "  'useful size network clique size',\n",
              "  'tightness bounds numerical experi ments',\n",
              "  'sigmoid noisyOR networks',\n",
              "  'deterministic techniques'],\n",
              " ['Boltzmann machines sigmoid belief networks combination',\n",
              "  'large probabilistic networks',\n",
              "  'MIT Computational Cognitive Science Technical Report',\n",
              "  'recursive nodeelimination formalism',\n",
              "  'network topologies'],\n",
              " ['distributionfree learning concept class C VCdimC VapnikChervonenkis dimension ffi accuracy confidence parameters',\n",
              "  'many interesting concept classes',\n",
              "  'ffi',\n",
              "  'number random examples',\n",
              "  'previous best lower bound ln ffi VCdimC'],\n",
              " ['measure temporal variation signal Tau Net',\n",
              "  'dynamic signals application speech',\n",
              "  'Tau Net neural network',\n",
              "  'energy contour simple speech utterance Tau Net',\n",
              "  'adaptable time constants network adjusted respect prediction error Adapting time constants'],\n",
              " ['BPSOM training activations hidden units MFNs',\n",
              "  'material BPSOM extension BP',\n",
              "  'BPSOM combination multilayered feedforward network MFN',\n",
              "  'BP Kohonens',\n",
              "  'loss generalisation performance'],\n",
              " ['MLP network',\n",
              "  'M M training set size',\n",
              "  'MLP Learning Vector Quantisation',\n",
              "  'MLP',\n",
              "  'M M'],\n",
              " ['article approximate rate convergence Gibbs sampler normal approximation target distribution',\n",
              "  'approximation illustrate methods',\n",
              "  'approximation',\n",
              "  'many implementational issues',\n",
              "  'Gibbs'],\n",
              " ['query search database',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'online local model local average local regression',\n",
              "  'database experiences resolutions interest',\n",
              "  'multiresolution data structure'],\n",
              " ['test tuning decomposition coordination low level behaviors',\n",
              "  'control system',\n",
              "  'reinforcement learning architecture reactive component two layer control system simulated race car',\n",
              "  'competition multagent interaction',\n",
              "  'separate networks behavior coarse coded input simple rule based coordination mechanism'],\n",
              " ['irrelevant information',\n",
              "  'training data background knowledge',\n",
              "  'irrelevant features',\n",
              "  'relevant solving learning problem',\n",
              "  'hybrid genetic algorithm'],\n",
              " ['Hierarchical genetic programming HGP approaches',\n",
              "  'analysis evolution process dual perspective diversity causality',\n",
              "  'HGP approach',\n",
              "  'extra machinery control tradeoff HGP',\n",
              "  'dynamic point view analysis causality crossover operator'],\n",
              " ['many fewer training sequences conventional training algorithms recurrent nets',\n",
              "  'multilevel hierarchy recurrent networks',\n",
              "  'descriptions event sequences',\n",
              "  'single recurrent net Experiments show system',\n",
              "  'construction neural architectures'],\n",
              " ['lateral connections',\n",
              "  'lateral connection patterns',\n",
              "  'A neural network model selforganization ocular dominance lateral connections',\n",
              "  'Similar selforganization cortical structures',\n",
              "  'receptive field properties'],\n",
              " ['singular limit method',\n",
              "  'method iterative operation slow dynamics',\n",
              "  'analysis relaxation oscillations singular limit',\n",
              "  'large systems relaxation oscillators',\n",
              "  'limit system evolution'],\n",
              " ['model spiking neurons',\n",
              "  'model image segmentation binding synchronization desynchronization neuronal activity',\n",
              "  'model afferent structures lateral connections',\n",
              "  'unified model development',\n",
              "  'tested image segmentation task'],\n",
              " ['integrated MCMC methods',\n",
              "  'neural networks prediction problem',\n",
              "  'Carlo MCMC methods',\n",
              "  'idea classification problems',\n",
              "  'realworld problems'],\n",
              " ['exact sampling algorithm',\n",
              "  'partial order mixture model state space',\n",
              "  'Gibbs sampling',\n",
              "  'Fills version rejection sampling',\n",
              "  'rejection sampling'],\n",
              " ['Hebbian selforganization receptive fields different sizes',\n",
              "  'receptive field organization',\n",
              "  'visual cortex selective ocular dominance orientation input',\n",
              "  'major receptive field properties',\n",
              "  'sparse coding visual input recurrent lateral interactions'],\n",
              " ['approach estimated cost function',\n",
              "  'cycle position dependent error observed attitude',\n",
              "  'conventional approach RMS attitude error',\n",
              "  'practical application artificial neural networks',\n",
              "  'controller cost function'],\n",
              " ['new noise model call fixed attribute noise model',\n",
              "  'new results',\n",
              "  'E positive negative examples target',\n",
              "  'previous result',\n",
              "  'B H negative example'],\n",
              " ['simple derivation algorithm',\n",
              "  'data multiple noisy sources',\n",
              "  'MAP estimation problems',\n",
              "  'Dempster et al',\n",
              "  'fitting mixture density'],\n",
              " ['problem framework regularization theory',\n",
              "  'invariance constraint regularization theory framework',\n",
              "  'approximated function radial symmetry',\n",
              "  'rotation invariant version Radial Basis Functions',\n",
              "  'radial symmetry'],\n",
              " ['simple computational experiment new methods',\n",
              "  'respect classical methods',\n",
              "  'gainadaptation algorithms based part connectionist learning methods',\n",
              "  'least squares classical parameterestimation methods',\n",
              "  'LMS methods'],\n",
              " ['present new windowing algorithm',\n",
              "  'noisy data windowing present preliminary ideas',\n",
              "  'appropriate windowing divideandconquer algorithms',\n",
              "  'Windowing proposed procedure efficient memory use ID decision tree learning algorithm',\n",
              "  'extension algorithm'],\n",
              " ['imperfect theory approach',\n",
              "  'approximate domain theory',\n",
              "  'comprehensive approach automatic theory revision',\n",
              "  'theory fault',\n",
              "  'structure original theory'],\n",
              " ['generalized SwendsenWang algorithm',\n",
              "  'joint distribution',\n",
              "  'new auxiliary variable method',\n",
              "  'SwendsenWang algorithm generalizations paper',\n",
              "  'SW single site Metropolis'],\n",
              " ['theoretical properties',\n",
              "  'FosterLyapunov drift condition methodology',\n",
              "  'algorithm',\n",
              "  'analytic bounds',\n",
              "  'extremely robust geometric ergodicity properties'],\n",
              " ['ADFs evenparity problem GP',\n",
              "  'GP results suite simulated annealing run ADFs problem size',\n",
              "  'simulated annealing ADFs',\n",
              "  'suite composed evenkparity problems k analyses performance simulated annealing ADFs',\n",
              "  'genetic programming GP style program discovery problems'],\n",
              " ['values attributes',\n",
              "  'irrelevant attribute values',\n",
              "  'values critical attributes handicap learner paper',\n",
              "  'superfluous values',\n",
              "  'general PAC model viz decision trees'],\n",
              " ['based hierarchy discovered functions',\n",
              "  'problems fitness function Preliminary empirical results',\n",
              "  'hierarchical organization extended function set',\n",
              "  'new functions',\n",
              "  'discovery useful building blocks'],\n",
              " ['fundamental nonconvex model',\n",
              "  'latter model',\n",
              "  'benign malignant human breasts',\n",
              "  'linear programs',\n",
              "  'University Wisconsin Hospitals Introduction'],\n",
              " ['metrical structure musical expectancy',\n",
              "  'perception metrical structure dynamic process temporal organization external musical events',\n",
              "  'perception metrical structure',\n",
              "  'perception musical meter',\n",
              "  'rhythmic patterns Networks units selforganize'],\n",
              " ['generational steadystate genetic algorithms particular problem',\n",
              "  'easy use operators',\n",
              "  'variety genetic operators reproduction crossover mutation',\n",
              "  'new operators',\n",
              "  'workbench genetic algorithm'],\n",
              " ['large capacity hippocampal memory',\n",
              "  'binding pattern turn',\n",
              "  'descriptive binding patterns',\n",
              "  'neural network model hippocampal episodic memory',\n",
              "  'Human episodic memory'],\n",
              " ['results testing theory space search',\n",
              "  'Theory space search',\n",
              "  'results testing theory space search component POLLYANNA',\n",
              "  'empirical testing feasible candidate approximate theories',\n",
              "  'candidate theories'],\n",
              " ['generalsum stochastic games framework multiagent reinforcement',\n",
              "  'Littman zerosum stochastic games broader framework',\n",
              "  'unique Nash equilibrium game',\n",
              "  'multiagent Qlearning method framework',\n",
              "  'Nash equilibrium'],\n",
              " ['different resources corporate memory form good overall case',\n",
              "  'Corporate memories',\n",
              "  'corporate memories',\n",
              "  'position policy US Government Kingdom Spain Government Catalonia Government official endorsement',\n",
              "  'US Government Kingdom Spain Government'],\n",
              " ['reasoning failures knowledge system',\n",
              "  'knowledge operation knowledge',\n",
              "  'wrong system',\n",
              "  'systems',\n",
              "  'RAPTER story understanding system'],\n",
              " ['initial theory accurate theory',\n",
              "  'various theory revision systems',\n",
              "  'Theory revision',\n",
              "  'theory revision',\n",
              "  'accurate theory'],\n",
              " ['degree replicability neural computing experiment',\n",
              "  'paper address issue replicability experiments',\n",
              "  'complete abstract specification neural computing experiment',\n",
              "  'framework empirical studies replicability respect experimental controls validity implementations backpropagation algorithm',\n",
              "  'claimed precision empirical results'],\n",
              " ['real maze experiment mobile robot',\n",
              "  'use algorithm simulation order test',\n",
              "  'visual categories movements',\n",
              "  'new neural conditioning rule PCR',\n",
              "  'different kind mazes'],\n",
              " ['framework analysis synthesis acoustical instruments',\n",
              "  'realtime synthesis audio sequences new input data',\n",
              "  'general inference framework ClusterWeighted Modeling',\n",
              "  'nonlinear mapping control data audio space',\n",
              "  'datadriven probabilistic inference'],\n",
              " ['numerical value leaf SRT',\n",
              "  'Structural Regression Trees SRT new algorithm',\n",
              "  'statistical method regression trees',\n",
              "  'ILP SRT',\n",
              "  'many realworld domains task machine learning algorithms'],\n",
              " ['Bayesian framework regularisation model comparison',\n",
              "  'error bars network parameters network output objective comparisons',\n",
              "  'interpolation models',\n",
              "  'objective stopping rules network pruning growing procedures objective choice magnitude type weight decay',\n",
              "  'effective number welldetermined parameters model'],\n",
              " ['performance potential simultaneous multithreading',\n",
              "  'simultaneous multithreading',\n",
              "  'Simultaneous multithreading technique',\n",
              "  'conventional superscalar design minimal performance impact single thread',\n",
              "  'multiple instructions cycle'],\n",
              " ['deficient domain theory',\n",
              "  'probabilities associated domain theory elements',\n",
              "  'paper present approach theory revision problem',\n",
              "  'awed elements theory',\n",
              "  'proof theory'],\n",
              " ['analysis univariate normal mixtures',\n",
              "  'improper priors mixture context',\n",
              "  'capable jumping parameter subspaces',\n",
              "  'weak prior information',\n",
              "  'hierarchical prior model'],\n",
              " ['Grant IRI National Science Foundation U S Air Force',\n",
              "  'Northeastern University College Computer Science Technical Report',\n",
              "  'Satinder Singh Vijay Gullapalli',\n",
              "  'substantial contributions effort',\n",
              "  'original interest questions'],\n",
              " ['oracle parts domain',\n",
              "  'part input domain',\n",
              "  'better generalization fixed number training examples',\n",
              "  'passive learning examples',\n",
              "  'Active learning'],\n",
              " ['branch instructions',\n",
              "  'forward branch instructions',\n",
              "  'elimination branch prediction schemes',\n",
              "  'branch operations',\n",
              "  'impact branch operations Microprocessor'],\n",
              " ['antecedents precedents level generality cases generality gap',\n",
              "  'specific case',\n",
              "  'abstract terms specific facts',\n",
              "  'case category',\n",
              "  'similarity cases term reformulation process'],\n",
              " ['Autoexploratory Hlearning',\n",
              "  'extension Hlearning',\n",
              "  'Adaptive RealTime Dynamic Programming simulated robot scheduling task',\n",
              "  'modelbased average reward Reinforcement Learning method',\n",
              "  'Hlearning'],\n",
              " ['Dynamic Parametric GA GA',\n",
              "  'Dynamic Parametric GA',\n",
              "  'general applicability Dynamic Parametric GA wide range',\n",
              "  'GA parameters',\n",
              "  'fuzzy knowledgebase system'],\n",
              " ['Individual National Research Service Award BAO NIMH FMH',\n",
              "  'National Science Foundation contract ASC award',\n",
              "  'Olshausen Field algorithm',\n",
              "  'Center Biological Computational Learning Department Brain Cognitive Sciences Massachusetts Institute Technology',\n",
              "  'formal relationship algorithm'],\n",
              " ['parents node network Bounds marginal probabilities',\n",
              "  'rates convergence accuracy bounds function network size',\n",
              "  'large networks methods',\n",
              "  'rigorous bounds marginal probabilities evidence output layer',\n",
              "  'efficient algorithms approximate inference fixed networks'],\n",
              " ['implementation sequential feature selection algorithm',\n",
              "  'feature selection absence class labels',\n",
              "  'Feature selection',\n",
              "  'existing conceptual clustering system',\n",
              "  'second implementation'],\n",
              " ['different learning paradigms symbol processing systems connectionist networks statistical syntactic pattern recognition systems possible candidates',\n",
              "  'adequate armamentarium representations learning mechanisms',\n",
              "  'multiple paradigms synergistic fashion',\n",
              "  'several promising directions',\n",
              "  'Robust flexible sufficiently general vision systems recognition description complex dimensional objects'],\n",
              " ['neural network sequence classification',\n",
              "  'isolated spoken word recognition cognitive science models sequence processing',\n",
              "  'successful mapping arbitrary sequences binary real numbers',\n",
              "  'phonemic representations English words',\n",
              "  'Kohonen Feature Map architecture activation retention decay order'],\n",
              " ['knowledge integration',\n",
              "  'methodology knowledge integration present concrete results',\n",
              "  'integrated knowledge base',\n",
              "  'knowledge',\n",
              "  'performance individual theories'],\n",
              " ['framework bias selection search bias',\n",
              "  'Recent research field machine learning bias',\n",
              "  'selecting biases',\n",
              "  'define term bias',\n",
              "  'machine learning systems'],\n",
              " ['conventional decision trees compact trees',\n",
              "  'decision tree',\n",
              "  'decision trees',\n",
              "  'compact decision trees',\n",
              "  'conventional decision trees compact mode'],\n",
              " ['regularizers networks projective basis functions',\n",
              "  'radial basis functions',\n",
              "  'projective basis functions',\n",
              "  'fi fl u general transfer functions',\n",
              "  'Abstract Smoothing'],\n",
              " ['structural importance musical events',\n",
              "  'musical variation natural result reductionist mechanism',\n",
              "  'different musical sequences variations',\n",
              "  'problem musical variation identification',\n",
              "  'reduced memory representations melodies'],\n",
              " ['variational free energy minimization tool',\n",
              "  'described terms optimization ensemble parameter vectors',\n",
              "  'linear regression model parameters hyperparameters',\n",
              "  'evidence approximation optimization regularization constants',\n",
              "  'variety statistical inference problems'],\n",
              " ['auxiliary chain stationary distribution Elements auxiliary chain',\n",
              "  'chain stationary distribution Sahu Zhigljavsky',\n",
              "  'stationary distribution',\n",
              "  'knowledge stationary distribution',\n",
              "  'nonlinear dynamics model modeling predatorprey relationships'],\n",
              " ['complex case representations relevance object',\n",
              "  'CBR AR First CA',\n",
              "  'support design tasks',\n",
              "  'memory organization analogical reasoning',\n",
              "  'CA standard'],\n",
              " ['multipath execution',\n",
              "  'various dynamic confidenceprediction schemes gauge likelihood branch mispredictions',\n",
              "  'imperfect branch predictors processor',\n",
              "  'significant improvements singlepath performance',\n",
              "  'nottaken outcomes branch'],\n",
              " ['contaminated constant density ratio constant density bounded total variation classes distributions',\n",
              "  'algorithms robust inference',\n",
              "  'Robust Bayesian inference calculation',\n",
              "  'Bayesian networks global neighborhoods',\n",
              "  'c fl Carnegie Mellon University'],\n",
              " ['correct mapping input sensor space output steering signal space',\n",
              "  'selflearning control system mobile robot',\n",
              "  'discrete division input space',\n",
              "  'local sensor data robot',\n",
              "  'external reinforcement signal'],\n",
              " ['network output decisions',\n",
              "  'trained feedforward networks',\n",
              "  'feedforward networks',\n",
              "  'corresponding trained network',\n",
              "  'mechanism orders rules'],\n",
              " ['genetic algorithms inappropriate network acquisition',\n",
              "  'standard network induction methods',\n",
              "  'genetic algorithms evolutionary programming populationbased search method',\n",
              "  'recurrent networks',\n",
              "  'recurrent neural networks fit'],\n",
              " ['aspects network structure',\n",
              "  'functional understanding effects creatures movement',\n",
              "  'object recognition task',\n",
              "  'highlevel finitestate exploration discrimination strategies',\n",
              "  'artificial creatures'],\n",
              " ['multivariate smoothing spline estimate function',\n",
              "  'Bayesian confidence intervals components decomposition',\n",
              "  'main effect functions',\n",
              "  'polynomial thin plate spline main effects model',\n",
              "  'confidence intervals'],\n",
              " ['Conference Neural Information Processing',\n",
              "  'poster session Conference Neural Information Processing SystemsNatural',\n",
              "  'Advances Neural Information Processing Systems',\n",
              "  'Neural Information Processing Systems San Francisco',\n",
              "  'DMS DMS National Eye InstituteNIH'],\n",
              " ['essential improve quality automated assemblies',\n",
              "  'quality assemblies',\n",
              "  'significant improvement quality subsequent assemblies',\n",
              "  'fragment assembly',\n",
              "  'new representation fluorescent trace data associated individual base'],\n",
              " ['new architecture partitioning instructions',\n",
              "  'extract instruction level parallelism',\n",
              "  'MIMD architectures',\n",
              "  'multiple instruction stream design addressing limitations',\n",
              "  'level parallelism'],\n",
              " ['alternative approach single instruction stream multiissue machines',\n",
              "  'increased machine parallelism minimal code expansion',\n",
              "  'single chip Multiple Instruction Stream Computer MISC',\n",
              "  'lowest level processor design',\n",
              "  'separate program streams'],\n",
              " ['neurodynamic programming method value function approximation types',\n",
              "  'second variant transitions',\n",
              "  'fixed probability time step',\n",
              "  'probabilities transitions',\n",
              "  'note methods'],\n",
              " ['wheelchair composing sequencesof mental states',\n",
              "  'CNAPS server processor SIMD architecture Adaptive Solutions Inc',\n",
              "  'EEG paralyzed person',\n",
              "  'several mental states',\n",
              "  'fold decrease training time'],\n",
              " ['classical perceptron model',\n",
              "  'tight bounds sample complexity',\n",
              "  'fitting models',\n",
              "  'account correlations dependences',\n",
              "  'Recurrent perceptron classifiers'],\n",
              " ['temporal pattern recognition',\n",
              "  'input feature pattern',\n",
              "  'timevarying patterns',\n",
              "  'Neural networks',\n",
              "  'processing patterns'],\n",
              " ['different lexical modalities lexical semantics',\n",
              "  'various damage lexical system',\n",
              "  'model orthographic phonological semantic feature maps associations',\n",
              "  'separate feature maps',\n",
              "  'artificial neural network model mental lexicon'],\n",
              " ['proposed RS RMS Extensions method',\n",
              "  'unsupervised learning scheme Feature Maps Koh',\n",
              "  'new selforganizing decomposition technique',\n",
              "  'effective changing environments',\n",
              "  'Feature Maps Koh'],\n",
              " ['search feature subset abstract search problem probabilistic estimates',\n",
              "  'recent feature subset selection algorithms machine',\n",
              "  'literature fit search problem',\n",
              "  'trading accuracy estimates',\n",
              "  'bestfirst search technique'],\n",
              " ['parallel implementations',\n",
              "  'parallel GP',\n",
              "  'parallel evaluation different Sexpressions single instruction',\n",
              "  'The aim paper present implementation parallel GP SIMD system processor',\n",
              "  'MasPar MP computer present timing results'],\n",
              " ['reinforcementlearning algorithms',\n",
              "  'asynchronous convergence complex reinforcementlearning algorithm',\n",
              "  'unified analysis valuefunctionbased reinforcementlearning algorithms',\n",
              "  'reinforcementlearning problems',\n",
              "  'simpler synchronous algorithm'],\n",
              " ['method mineral data',\n",
              "  'specific case blind source separation problem data',\n",
              "  'mixed signals case minerals goal',\n",
              "  'contextual ICA context hyperspectral data analysis',\n",
              "  'unsupervised method blind source separation'],\n",
              " ['various incremental methods',\n",
              "  'bounds value function control problems',\n",
              "  'new method',\n",
              "  'dynamic optimization problem value function',\n",
              "  'gridbased linear interpolation method'],\n",
              " ['regularisation constants junk inputs',\n",
              "  'irrelevant inputs output conventional neural network',\n",
              "  'junk inputs',\n",
              "  'large preventing inputs',\n",
              "  'many possible input variables'],\n",
              " ['incremental neural networks',\n",
              "  'casebased reasoning approaches',\n",
              "  'Several different approaches',\n",
              "  'hybrid model classification',\n",
              "  'specific instances'],\n",
              " ['new architecture partitioning instructions',\n",
              "  'extract instruction level parallelism',\n",
              "  'MIMD architectures',\n",
              "  'multiple instruction stream design addressing limitations',\n",
              "  'level parallelism'],\n",
              " ['larger processor system',\n",
              "  'performance range MIMD parallel processor systems neural network simulations The total execution time parallel application modeled sum calculation communication',\n",
              "  'GCel transputer system Agreement model measurements',\n",
              "  'feature map',\n",
              "  'two popular neural networks backpropagation Kohonen'],\n",
              " ['tree learning algorithm',\n",
              "  'smoothing tree',\n",
              "  'publication Statistics Computing journal version minor changes',\n",
              "  'Volume pages accurate predictions versions',\n",
              "  'full Bayesian algorithm'],\n",
              " ['formulated solved pomdps',\n",
              "  'pomdps general models sequential decisions actions',\n",
              "  'interest formulated pomdps',\n",
              "  'pomdps limited lack effective algorithms',\n",
              "  'pomdps general models'],\n",
              " ['reasoning failure',\n",
              "  'reasoning failures',\n",
              "  'general representation processing framework introspective reasoning strategy selection',\n",
              "  'appropriate learning strategies order',\n",
              "  'reasoning task'],\n",
              " ['students solution',\n",
              "  'uncertainty student model',\n",
              "  'student',\n",
              "  'students',\n",
              "  'tutor student typical session'],\n",
              " ['background knowledge target problem',\n",
              "  'nontrivial task influence knowledge model',\n",
              "  'empirical evaluation constructed concept description guide search',\n",
              "  'characteristics target problem',\n",
              "  'machine learning algorithms parameter'],\n",
              " ['explicit negative examples',\n",
              "  'negative examples',\n",
              "  'pasttense learning illustrate advantages',\n",
              "  'assumption output completeness',\n",
              "  'legal outputs'],\n",
              " ['query search database',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'online local model local average local regression',\n",
              "  'database experiences resolutions interest',\n",
              "  'multiresolution data structure'],\n",
              " ['new agglomerative clustering algorithm pattern cluster',\n",
              "  'Such agglomerative scheme',\n",
              "  'hyperboxes hierarchial manner',\n",
              "  'realworld clustering problems',\n",
              "  'pattern samples'],\n",
              " ['Small trees',\n",
              "  'randomized technique partitioning examples',\n",
              "  'oblique hyperplanes',\n",
              "  'ID descendants partition set points',\n",
              "  'simple qualitative descriptions problem domain'],\n",
              " ['genetic algorithm',\n",
              "  'new algorithm',\n",
              "  'ICET variety conditions',\n",
              "  'costsensitive classification',\n",
              "  'ICET'],\n",
              " ['linear programming',\n",
              "  'brief description system breast cancer diagnosis use',\n",
              "  'leads use unconstrained minimization techniques training neural network',\n",
              "  'planes input space',\n",
              "  'square error output space'],\n",
              " ['CBR creative problem',\n",
              "  'CBR research paradigm',\n",
              "  'interesting kind casebased reasoning',\n",
              "  'CBR systems',\n",
              "  'Dissatisfaction existing standard casebased reasoning'],\n",
              " ['DNA sequences',\n",
              "  'important property natural DNA sequences',\n",
              "  'present technique DNA segmentation',\n",
              "  'hidden Markov models',\n",
              "  'chain homogeneous segments'],\n",
              " ['efficient introspective selfreferential weight change algorithm show algorithms',\n",
              "  'weight matrix',\n",
              "  'weight change',\n",
              "  'previous weight change',\n",
              "  'weight matrix terms activations'],\n",
              " ['multiple outputs single input pattern recent research recurrent networks promising field',\n",
              "  'MM several possible variants',\n",
              "  'several initial experiments',\n",
              "  'sequential cascaded networks',\n",
              "  'manytomany multiassociative mapping'],\n",
              " ['direction gaze eye position signals',\n",
              "  'eye movements',\n",
              "  'dynamic shifts receptive field RF neurons visual system',\n",
              "  'neural circuit',\n",
              "  'movement retinal image'],\n",
              " ['outcome conflict management attempt',\n",
              "  'predictive outcome international conflict management attempts',\n",
              "  'decision trees prediction rules',\n",
              "  'simple patterns rules',\n",
              "  'Simple decision trees'],\n",
              " ['subsequent iterations regions problem space solutions',\n",
              "  'unimodal function optimization methods',\n",
              "  'least fast fitness sharing methods',\n",
              "  'optima multimodal problems',\n",
              "  'speedup p problem p optima'],\n",
              " ['TD several domains state Using VI',\n",
              "  'classical algorithms problem classes',\n",
              "  'DAGSP algorithm',\n",
              "  'deterministic class Dijkstras shortestpath algorithm',\n",
              "  'large stochastic state spaces'],\n",
              " ['interactive formulation testing reformulation design optimization strategies',\n",
              "  'performance automatic design optimization',\n",
              "  'yacht design jet engine nozzle design',\n",
              "  'computational cost optimization quality resulting design',\n",
              "  'optimization strategies'],\n",
              " ['available ground truth polygons training test sets',\n",
              "  'Different combinations data',\n",
              "  'test sets',\n",
              "  'LandsatTM oneband ERSSAR',\n",
              "  'PRI imagery scene'],\n",
              " ['English text measure performance learning algorithm affected size noisy sample noise rate',\n",
              "  'Markov models variable memory length probabilistic finite suffix automata',\n",
              "  'particular show class Markov chains variable memory length',\n",
              "  'noisecorrupted sample knowledge noise structure',\n",
              "  'observed sequence direct output underlying generation process'],\n",
              " ['advice language advice',\n",
              "  'approximate advice functions',\n",
              "  'generalpurpose system homepage finder',\n",
              "  'link pagescoring functions',\n",
              "  'appealing middle ground nonadaptive agent programming languages systems'],\n",
              " ['attribute set concepts',\n",
              "  'usefulness concepts limited task attributes',\n",
              "  'capability concept learning system',\n",
              "  'Existing concept learners',\n",
              "  'concept learning objects domain'],\n",
              " ['Bayesian inference data modeled mixture distribution',\n",
              "  'correct number components',\n",
              "  'true Bayesian predictive distribution',\n",
              "  'prior distribution mixing proportions',\n",
              "  'reasonable subset components'],\n",
              " ['approach broad range reinforcement learning problems',\n",
              "  'new reinforcement learning method',\n",
              "  'SANE Symbiotic Adaptive NeuroEvolution',\n",
              "  'Such efficient learning combined domain assumptions',\n",
              "  'population neurons genetic algorithms'],\n",
              " ['probabilistic evaluation plans presence unmeasured variables plan',\n",
              "  'probability plan',\n",
              "  'plan',\n",
              "  'passive observations measured variables',\n",
              "  'several concurrent sequential actions'],\n",
              " ['control flow prediction',\n",
              "  'potential control flow prediction abstract machine dynamic ILP processing model',\n",
              "  'information control flow graph program',\n",
              "  'information present control flow graph',\n",
              "  'hardware making informed run time decisions program control flow'],\n",
              " ['utility framework benchmark problem statistical pattern',\n",
              "  'tractable approximation true probability distribution networks',\n",
              "  'mean field theory sigmoid belief networks based ideas statistical mechanics',\n",
              "  'lower bound likelihood evidence',\n",
              "  'Our mean field theory'],\n",
              " ['performance element PE',\n",
              "  'performance element',\n",
              "  'learning system context general class performance elements',\n",
              "  'distribution problems',\n",
              "  'new element PE'],\n",
              " ['decomposition composite task',\n",
              "  'composite tasks',\n",
              "  'elemental tasks',\n",
              "  'several elemental tasks',\n",
              "  'QLearning Watkins planning tasks'],\n",
              " ['paper dynamics decision hyperplanes',\n",
              "  'dynamics hyperplanes',\n",
              "  'use decision hyperplanes',\n",
              "  'Hyperplane inertia',\n",
              "  'increasing hyperplane inertia mass'],\n",
              " ['deeper complex data structures',\n",
              "  'Recursive AutoAssociative Memory',\n",
              "  'syntactic trees',\n",
              "  'data',\n",
              "  'reconstructor networks'],\n",
              " ['RankBoost individual search strategies',\n",
              "  'RankBoost nearest neighbor regression algorithms',\n",
              "  'efficient algorithm',\n",
              "  'efficient implementation algorithm',\n",
              "  'different search strategies'],\n",
              " ['hybrid approach decision trees',\n",
              "  'decision tree',\n",
              "  'decision trees',\n",
              "  'performance CBL systems',\n",
              "  'CBL systems'],\n",
              " ['linear network models correlations',\n",
              "  'primary generative model',\n",
              "  'analysis model',\n",
              "  'recognition model',\n",
              "  'Ojas version Hebbian learning'],\n",
              " ['amino acid distributions',\n",
              "  'HMMs multiple alignments',\n",
              "  'Markov model HMM protein family columns',\n",
              "  'Dirichlet mixture densities',\n",
              "  'multiple alignment family'],\n",
              " ['simple cost model machine learning applications',\n",
              "  'systems confusion matrix cash flow matrix application cost',\n",
              "  'convex hull method present model',\n",
              "  'machine learning system prototype stage',\n",
              "  'onetime cost deploying system rate return investment'],\n",
              " ['quantitative predictions effects interventions',\n",
              "  'complex information external interventions',\n",
              "  'external interventions',\n",
              "  'manipulative account causation',\n",
              "  'external interventions system'],\n",
              " ['casebased design adaptation design case',\n",
              "  'new design requirements',\n",
              "  'similar example case lie focus search',\n",
              "  'new designs',\n",
              "  'If sufficient adapt predefined set design parameters task'],\n",
              " ['nonlinear models',\n",
              "  'novel nonlinear model time series analysis',\n",
              "  'linear models',\n",
              "  'parameterization model',\n",
              "  'data structure'],\n",
              " ['previous upper bound coverage Boolean concept learning algorithm',\n",
              "  'upper bound Experimental measurement coverage ID FRINGE algorithms',\n",
              "  'way coverage maximization',\n",
              "  'definition coverage',\n",
              "  'coverage'],\n",
              " ['alternative orderings states',\n",
              "  'lumped Markov models',\n",
              "  'transient behavior GAs general GAFOs',\n",
              "  'Markov model',\n",
              "  'Markov models'],\n",
              " ['emergent behaviour coevolutionary model design',\n",
              "  'behaviour space active participant behaviour',\n",
              "  'emergent behaviour',\n",
              "  'response problem space behaviour space',\n",
              "  'coevolutionary design process'],\n",
              " ['learnable attribute noise attribute noise rate',\n",
              "  'simultaneous attribute noise classification noise',\n",
              "  'attribute noise learnability results',\n",
              "  'classification noise Classes results',\n",
              "  'exact noise rate'],\n",
              " ['exons exons',\n",
              "  'exons introns intergenic regions',\n",
              "  'new Hidden Markov Model HMM system',\n",
              "  'Separate HMM modules',\n",
              "  'Hidden Markov Model HMM'],\n",
              " ['multiple learning tasks',\n",
              "  'new learning task',\n",
              "  'relatedness individual learning tasks order',\n",
              "  'small number tasks',\n",
              "  'tasks classes'],\n",
              " ['Belief revision belief update',\n",
              "  'belief revision belief update',\n",
              "  'belief change',\n",
              "  'Belief revision',\n",
              "  'new information static world Belief update'],\n",
              " ['Bayesian framework regression problems',\n",
              "  'regression problems',\n",
              "  'important issues',\n",
              "  'infinite dimension limit',\n",
              "  'increasing model complexity'],\n",
              " ['sparse neural networks',\n",
              "  'sparse network',\n",
              "  'memory systems',\n",
              "  'parallel vector code',\n",
              "  'prototype pinpoint bottlenecks'],\n",
              " ['diploid populations ecological neural networks',\n",
              "  'diploid population appropriate mutation rate',\n",
              "  'average peak fitness single population',\n",
              "  'variability fitness population',\n",
              "  'diploid genotypes'],\n",
              " ['set beliefs language beliefs',\n",
              "  'belief change',\n",
              "  'unreasonable agents beliefs',\n",
              "  'beliefs',\n",
              "  'firm belief'],\n",
              " ['novel approach belief change',\n",
              "  'qualitative Markov assumption',\n",
              "  'earlier beliefs',\n",
              "  'previous beliefs',\n",
              "  'surprising observation indication world'],\n",
              " ['search trajectory way current state goal state',\n",
              "  'online search',\n",
              "  'online search cases',\n",
              "  'finitedepth lookahead search global searches agent',\n",
              "  'local searches agent'],\n",
              " ['queries patterns queries',\n",
              "  'particular queries',\n",
              "  'class queries',\n",
              "  'particular class distributions',\n",
              "  'Bayesian network'],\n",
              " ['ifthen rules',\n",
              "  'unique priority ordering rules',\n",
              "  'analyzed testing consistency computing rule',\n",
              "  'Rules',\n",
              "  'rules'],\n",
              " ['motor schemabased control reinforcement learning Robots',\n",
              "  'assemblages samples reinforcement signal time',\n",
              "  'Clay benefit realtime performance motor schemas continuous dynamic environments',\n",
              "  'Clay evolutionary architecture autonomous robots',\n",
              "  'adaptive reinforcement'],\n",
              " ['hidden units units',\n",
              "  'local time space',\n",
              "  'many hidden units',\n",
              "  'parallel online learning algorithm',\n",
              "  'Hollands idea bucket brigade classifier systems'],\n",
              " ['particular creativity essential part',\n",
              "  'contexts creativity',\n",
              "  'system system models',\n",
              "  'Creativity',\n",
              "  'creativity'],\n",
              " ['serendipitous recognition solutions',\n",
              "  'serendipitous recognition',\n",
              "  'design problems',\n",
              "  'new functions purposes common design pieces process',\n",
              "  'creative mechanical design'],\n",
              " ['several different trees',\n",
              "  'different measures',\n",
              "  'different probability estimation methods',\n",
              "  'selection decision tree induction informativity gini index',\n",
              "  'different methods'],\n",
              " ['adversarial model present model success',\n",
              "  'adversarial models',\n",
              "  'oblivious models switches',\n",
              "  'class model probability',\n",
              "  'several models situations'],\n",
              " ['toolbox systematic construction similarity measures',\n",
              "  'similarity measures',\n",
              "  'design methodology similarity measures',\n",
              "  'cases case base',\n",
              "  'identification opportunities parallelisation case base retrieval'],\n",
              " ['simple abstract data structures',\n",
              "  'possible evolve list data structure',\n",
              "  'abstract data structures',\n",
              "  'corresponding structured approach use data',\n",
              "  'simple read write primitives data structures'],\n",
              " ['exponential time computation',\n",
              "  'classical digital computation',\n",
              "  'standard nonuniform circuits',\n",
              "  'analog devices',\n",
              "  'neural networks research'],\n",
              " ['applicability utility computational expense interpretability',\n",
              "  'utility interpretability',\n",
              "  'convergence diagnostic procedure MCMC',\n",
              "  'total variation distances distribution algorithm',\n",
              "  'Gibbs Sampler Metropolis Hastings'],\n",
              " ['electroencephalographic EEG data',\n",
              "  'ICA algorithm',\n",
              "  'EEG data volume conduction',\n",
              "  'separate ICA channels',\n",
              "  'EEG phenomena'],\n",
              " ['Technical Report',\n",
              "  'A McClelland J Encoding sequential structure simple recurrent networks Technical Report CMUCS Carnegie Mellon University Computer Science Department',\n",
              "  'Carnegie Mellon University Computer Science Department',\n",
              "  'capacity processing information',\n",
              "  'Schmidhuber J b'],\n",
              " ['large number decision trees quality decision trees',\n",
              "  'trees accurate trees',\n",
              "  'greedy approach trees',\n",
              "  'trees',\n",
              "  'greedy approach'],\n",
              " ['supervised machine learning model',\n",
              "  'machine learning model',\n",
              "  'discrete classifications',\n",
              "  'continuous valued input',\n",
              "  'discrete classes'],\n",
              " ['optimal solution task isolation paper',\n",
              "  'multiple tasks',\n",
              "  'good solutions tasks',\n",
              "  'optimal solution entire set tasks',\n",
              "  'task isolation paper'],\n",
              " ['additive tree T k T D k',\n",
              "  'n fi n distance matrix D tree',\n",
              "  'metric T',\n",
              "  'Second show',\n",
              "  'N Phard'],\n",
              " ['dependent adequate judgements problem similarity',\n",
              "  'Large problems',\n",
              "  'large problems complex domains',\n",
              "  'current CBP methodology',\n",
              "  'Multigoal problems'],\n",
              " ['number confidence estimation mechanisms',\n",
              "  'confidence estimation mechanisms',\n",
              "  'form speculation control balance benefits speculation',\n",
              "  'Confidence estimation',\n",
              "  'performance different confidence estimation methods'],\n",
              " ['special interest members machine learning community',\n",
              "  'used algorithms',\n",
              "  'relational representations',\n",
              "  'Relational learning',\n",
              "  'supervised learning tasks'],\n",
              " ['new approximate learning algorithm',\n",
              "  'use gradient descent procedure learning process',\n",
              "  'fixed point equation learning rules',\n",
              "  'Boltzmann Machines based mean field theory linear response theorem',\n",
              "  'cubic number neurons'],\n",
              " ['search control policy',\n",
              "  'combinatorial optimization problem',\n",
              "  'combinatorial optimization problems application reinforcement learning methods',\n",
              "  'training problem instances',\n",
              "  'methodology NASA scheduling problem show'],\n",
              " ['exploration time T',\n",
              "  'exploration times',\n",
              "  'stochastic exploration state space',\n",
              "  'lower bound return policies',\n",
              "  'thermodynamic limit T N ff T N finite T number time steps'],\n",
              " ['partial predicated execution support conditional moves',\n",
              "  'predicated execution',\n",
              "  'partial full predication',\n",
              "  'partial full predication Preliminary experimental results',\n",
              "  'partial predication'],\n",
              " ['learning models',\n",
              "  'learning algorithms',\n",
              "  'NSF grant DCR grant Siemens Corporation Net address sgcswustledu',\n",
              "  'variant online learning model learner',\n",
              "  'relationship Mitchells version space algorithm existence'],\n",
              " ['genetic algorithm',\n",
              "  'new genetic algorithm',\n",
              "  'ideal behavior algorithm main task',\n",
              "  'indicative efficient solvability samplebounded algorithm',\n",
              "  'class monotonic functions algorithm'],\n",
              " ['nonlinear regression model mixture Gaussians',\n",
              "  'paper study forecasting model based mixture experts',\n",
              "  'nonlinear autoregression model',\n",
              "  'first model',\n",
              "  'single neural network second model'],\n",
              " ['represen tation',\n",
              "  'represen tations',\n",
              "  'represen tation cost function',\n",
              "  'represen tation optimal resp ect',\n",
              "  'satisfactory neural net workbased compact represen tations cost function'],\n",
              " ['graphstructured representations',\n",
              "  'term graphstructured representations',\n",
              "  'vary case case',\n",
              "  'graphstructured representation',\n",
              "  'Such representations'],\n",
              " ['regression tree',\n",
              "  'regression trees',\n",
              "  'construction pruning interpretation regression tree',\n",
              "  'linear regression',\n",
              "  'smaller classification errors'],\n",
              " ['microscopic neurosynaptic dynamics stochastic dynamics',\n",
              "  'neuronal action potentials synaptic dynamics',\n",
              "  'transformation collective dynamics',\n",
              "  'collective dynamics reminiscent hydrodynamics',\n",
              "  'local coupling dynamics type Hebbrule synaptic efficiency'],\n",
              " ['computing distance original theory',\n",
              "  'revisions theory',\n",
              "  'small changes original theory',\n",
              "  'Abstract Theory revision systems',\n",
              "  'accuracy distance metric'],\n",
              " ['dataset method',\n",
              "  'realworld housing loans allocation dataset',\n",
              "  'novel data mining approach based decomposition',\n",
              "  'human interaction positive effect comprehensibility classification accuracy',\n",
              "  'derive classifier high classification accuracy'],\n",
              " ['case studies',\n",
              "  'results case studies example application',\n",
              "  'Authors case studies',\n",
              "  'multiple algorithms',\n",
              "  'general class learning problems'],\n",
              " ['generalization error amount error reduction',\n",
              "  'multiple descriptions class data',\n",
              "  'degree descriptions class',\n",
              "  'errors',\n",
              "  'twentynine data sets show amount'],\n",
              " ['best algorithmic accuracy images',\n",
              "  'volcanos radar images surface planet Venus Plannett',\n",
              "  'classification module threestage image analysis system',\n",
              "  'Plannett system',\n",
              "  'JAR tool endtoend accuracy sensitivity specificity'],\n",
              " ['macro actions',\n",
              "  'actions control planning',\n",
              "  'Macro actions',\n",
              "  'primitive actions',\n",
              "  'commonsense higherlevel actions'],\n",
              " ['McNemars test test',\n",
              "  'show test',\n",
              "  'tests',\n",
              "  'best test',\n",
              "  'test difference two proportions b paireddifferences test'],\n",
              " ['active classifier cost',\n",
              "  'nearoptimal active classifiers',\n",
              "  'active classifier',\n",
              "  'additional attribute values penalty',\n",
              "  'passive assign classlabel instance'],\n",
              " ['eliminationtype algorithm',\n",
              "  'nonserial dynamic programming algorithms',\n",
              "  'principle common many algorithms',\n",
              "  'algorithms',\n",
              "  'conditioning elimination'],\n",
              " ['Robert Hauser Michael Hout Steven Lewis Scott Long Diane Lye Peter Marsden',\n",
              "  'Clem Brooks Sir David Cox Tom DiPrete John Goldthorpe David Grusky Jennifer',\n",
              "  'Robert Kass David Madigan',\n",
              "  'Peter Marsden Bruce',\n",
              "  'Peter V Marsden'],\n",
              " ['Such algorithms useful reasoning probabilistic deterministic networks',\n",
              "  'possible select spectrum algorithm',\n",
              "  'treeclustering conditioning trade space time',\n",
              "  'problem structure',\n",
              "  'optimization tasks'],\n",
              " ['loopcutset conditioning Jensens method',\n",
              "  'new approach probabilistic inference belief networks global conditioning simple generalization Pearls b method loopcutset conditioning',\n",
              "  'global conditioning',\n",
              "  'relationships methods',\n",
              "  'hybrid method'],\n",
              " ['second level analog patterns',\n",
              "  'potential computational role subthreshold oscillations',\n",
              "  'spike activity fire fire',\n",
              "  'first level binary patterns',\n",
              "  'underlying subthreshold oscillation'],\n",
              " ['new method',\n",
              "  'subpopulation individual',\n",
              "  'concept distance individuals tag bits',\n",
              "  'methods',\n",
              "  'standard generational evolutionary algorithm'],\n",
              " ['changes output input transformed group',\n",
              "  'transformed distorted examples training data',\n",
              "  'changes output inputs',\n",
              "  'equivalent sum original cost function',\n",
              "  'training data'],\n",
              " ['finergrain factorization joint probability',\n",
              "  'conditional probability variable',\n",
              "  'factorization joint probability multiplication',\n",
              "  'VE Bayesian network inference',\n",
              "  'conditional probabilities'],\n",
              " ['human learning task reinforcement',\n",
              "  'skills complex cognitive tasks',\n",
              "  'hybrid cognitive model humans',\n",
              "  'performance action models',\n",
              "  'NRL Navigation task'],\n",
              " ['statistical query model',\n",
              "  'new variant statistical query model',\n",
              "  'relative error statistical queries PAC simulation',\n",
              "  'complexity statistical query',\n",
              "  'new variant statistical query model order'],\n",
              " ['Reduced Error Pruning relational learning algorithms',\n",
              "  'Incremental Reduced Error Pruning',\n",
              "  'use algorithm',\n",
              "  'many noisy domains',\n",
              "  'attempts address problems'],\n",
              " ['metrical patterns pulses',\n",
              "  'store particular metrical patterns',\n",
              "  'language metrical Meter',\n",
              "  'data music speech',\n",
              "  'musical patterns'],\n",
              " ['deductive relationship explanation observation',\n",
              "  'model abduction based revision epistemic state agent Explanations',\n",
              "  'semantic preferences explanations',\n",
              "  'predictive explanations',\n",
              "  'explanations'],\n",
              " ['hard locations Karlssons case masks storage addresses',\n",
              "  'Karlssons modifi cation Jaeckels',\n",
              "  'Report R ISRN SICSRSE',\n",
              "  'Sparse Distributed Memory',\n",
              "  'different levels'],\n",
              " ['sparse distributed memory',\n",
              "  'unknown number T random data vectors',\n",
              "  'hard locations',\n",
              "  'special extra location',\n",
              "  'memory'],\n",
              " ['unifying belief revision belief update reasoning actions',\n",
              "  'rankedmodel semantics ifthen rules',\n",
              "  'plausible beliefs',\n",
              "  'stratified set independence constraints rankings interpretations',\n",
              "  'Rule priorities'],\n",
              " ['EM algorithms',\n",
              "  'EM step parameter space',\n",
              "  'ExpectationMaximization EM',\n",
              "  'EM terms',\n",
              "  'projection matrix P'],\n",
              " ['knowledge acquisition process',\n",
              "  'first order concept description background knowledge',\n",
              "  'background knowledge literals',\n",
              "  'local improvement minimum number examples maximum clause length minimum local improvement minimum description length',\n",
              "  'several important guidelines knowledge acquisition'],\n",
              " ['organization measures',\n",
              "  'degree hemispheric organization asymmetry organization computational model bihemispheric cerebral cortex',\n",
              "  'degree organization symmetry lateralization topographic map formation',\n",
              "  'several topographic maps',\n",
              "  'resulting measures'],\n",
              " ['global structure structure',\n",
              "  'Figure map sequence inputs sequence outputs Learning structure temporallyextended sequences difficult computational problem input pattern',\n",
              "  'Learning structure temporallyextended sequences',\n",
              "  'musical structure',\n",
              "  'musical phrasebut structure'],\n",
              " ['incremental introduction new units',\n",
              "  'new units',\n",
              "  'recurrent connections',\n",
              "  'neuralnetworks higherorder connections',\n",
              "  'recurrent neuralnetworks'],\n",
              " ['hidden Markov chains',\n",
              "  'independence startup distribution stability Markov chain',\n",
              "  'hidden Markov chains convergence MCMC algorithms',\n",
              "  'paper series online controls',\n",
              "  'graphical control spreadsheets'],\n",
              " ['data training networks discriminant classifier',\n",
              "  'neural networks attractive alternative traditional statistical techniques',\n",
              "  'additional independent data identical statistical properties',\n",
              "  'neural network',\n",
              "  'original patient data validation'],\n",
              " ['multiunit Principal Component Analysis PCA neural networks',\n",
              "  'Projection Pursuit PP Independent Component Analysis ICA Separation',\n",
              "  'The networks nonlinear Hebbian learning rules related signal expansions',\n",
              "  'real world',\n",
              "  'Nonlinear extensions'],\n",
              " ['model patterns',\n",
              "  'functional form appropriate asymmetry peak nadir phases',\n",
              "  'phase amplitude time magnitude peak nadir',\n",
              "  'components model Data experiment',\n",
              "  'circadian pattern'],\n",
              " ['effectiveness solution largescale graph partitioning problems',\n",
              "  'widelyused graph partitioning techniques',\n",
              "  'highlevel decompositionbased algorithms largescale blockangular optimization problems',\n",
              "  'subproblemcoordination paradigm lower bounds pricedirective decomposition methods',\n",
              "  'highquality solutions'],\n",
              " ['useful smoothing crude maps disease risk',\n",
              "  'existing hierarchical spatial models',\n",
              "  'spatial patterns disease',\n",
              "  'Maps regional morbidity mortality rates useful tools',\n",
              "  'novel techniques model evaluation selection'],\n",
              " ['new statistical insight synaptic modification equations',\n",
              "  'connection exploratory projection pursuit methods',\n",
              "  'Bienenstock Cooper Munro BCM',\n",
              "  'Bienenstock Cooper Munro',\n",
              "  'phoneme recognition experiment'],\n",
              " ['constructive induction mediate effect input representation accuracy',\n",
              "  'effect input representation generalization performance realworld problem',\n",
              "  'better representation',\n",
              "  'representation',\n",
              "  'constructive induction'],\n",
              " ['selection schemes',\n",
              "  'parent selection schemes',\n",
              "  'common selection schemes',\n",
              "  'short reference standard advanced selection schemes',\n",
              "  'global competition replacement schemes'],\n",
              " ['competitive version selfsupervised backpropagation',\n",
              "  'Selfsupervised backpropagation',\n",
              "  'backpropagation simulator CLONES',\n",
              "  'case selfsupervised backpropagation version',\n",
              "  'backpropagation'],\n",
              " ['pattern patterns',\n",
              "  'simple rhythmic pattern',\n",
              "  'meter Rests rhythmic patterns',\n",
              "  'evolving computational model perception production simple rhythmic patterns',\n",
              "  'couple input patterns Oscillators'],\n",
              " ['uniform approximation orders radial basis functions',\n",
              "  'radial basis functions',\n",
              "  'quasiinterpolation leastsquares approximation radial function spaces',\n",
              "  'Buhmann Dyn Levin Dyn Ron L p approximation orders',\n",
              "  'Examples results'],\n",
              " ['basis function Attention restricted functions',\n",
              "  'approximation schemes',\n",
              "  'basis function nonuniform case',\n",
              "  'types radial basis functions',\n",
              "  'IR many optimal quasioptimal approximation schemes'],\n",
              " ['exponential box splines polyharmonic splines',\n",
              "  'principal shiftinvariant spaces',\n",
              "  'polyharmonic splines multiquadrics Gauss',\n",
              "  'spaces',\n",
              "  'L p'],\n",
              " ['RL standard EBL',\n",
              "  'dynamic programming version EBL',\n",
              "  'propagation statebystate basis EBL',\n",
              "  'state RL',\n",
              "  'Based observation RL form asynchronous dynamic programming paper shows'],\n",
              " ['Office Naval Research contracts NJ NJ',\n",
              "  'ONR contract NJ JL Marroquin',\n",
              "  'efficient use image segmentation pattern classification tasks',\n",
              "  'National Institutes Health contract',\n",
              "  'North Atlantic Treaty Organization ATR Audio Visual Perception Research Laboratories Mitsubishi Electric Corporation Sumitomo Metal Industries Siemens AG'],\n",
              " ['VQ MDS time',\n",
              "  'VQ MDS',\n",
              "  'topology comprehensive empirical study',\n",
              "  'Sammon mapping cluster centroids',\n",
              "  'recent empirical findings'],\n",
              " ['RL agent',\n",
              "  'number failures exploration',\n",
              "  'suboptimal solution',\n",
              "  'agents',\n",
              "  'common many applications'],\n",
              " ['input variables',\n",
              "  'relationship input output variables',\n",
              "  'inclusion input variables',\n",
              "  'little information output variables',\n",
              "  'nonparametric density estimation measures relevance input variables'],\n",
              " ['paper review literature use diploidy dominance operators genetic algorithms',\n",
              "  'genetic algorithms populations',\n",
              "  'genetic information phenotype',\n",
              "  'results simulations',\n",
              "  'new results'],\n",
              " ['tasklevel speculation compiler task selection point view performance',\n",
              "  'speculation data communication data dependence speculation load imbalance task',\n",
              "  'processor organization tasklevel speculation',\n",
              "  'task size intertask control ow intertask data dependence',\n",
              "  'fundamental performance issues'],\n",
              " ['interaction training agent learning agent',\n",
              "  'learning agent',\n",
              "  'speed learner',\n",
              "  'training agent instruction',\n",
              "  'intelligent learner'],\n",
              " ['method feature construction selection',\n",
              "  'appropriate method',\n",
              "  'higher classification accuracy',\n",
              "  'classification task',\n",
              "  'constructive induction algorithms'],\n",
              " ['addition standard toolbox exploratory data analysis educational data',\n",
              "  'exploratory data analysis',\n",
              "  'underlying structure data',\n",
              "  'latent classes data',\n",
              "  'data'],\n",
              " ['likelihood splitting criteria expert HME',\n",
              "  'hierarchical mixture experts HME architecture',\n",
              "  'probable path tree',\n",
              "  'significant speed ups efficient use parameters',\n",
              "  'conventional algorithms'],\n",
              " ['data random errors',\n",
              "  'possible presence errors observations',\n",
              "  'imperfect data',\n",
              "  'interacting realworld data',\n",
              "  'realworld data'],\n",
              " ['differing problem formulations',\n",
              "  'variety differing problem formulations',\n",
              "  'sort problem formulation',\n",
              "  'task evolving general iterative sorting algorithms',\n",
              "  'evolved algorithms'],\n",
              " ['value feature subsets',\n",
              "  'crossvalidation Domains large number training examples large number possible features',\n",
              "  'task feature subset selection',\n",
              "  'relevant features',\n",
              "  'Irrelevant redundant features'],\n",
              " ['problem classification accuracy decision list',\n",
              "  'homogeneous rules',\n",
              "  'decision lists',\n",
              "  'training examples match rule',\n",
              "  'rule'],\n",
              " ['fuzzy graphs example data',\n",
              "  'resulting fuzzy graphs',\n",
              "  'fuzzy graphs',\n",
              "  'quick insights structure example data underlying model',\n",
              "  'efficient easy use algorithm'],\n",
              " ['superior hand coding teaching strategies',\n",
              "  'offline learning methodology',\n",
              "  'sample data simulated students',\n",
              "  'associate superior teaching actions',\n",
              "  'low level student'],\n",
              " ['basic primitive temporal elements',\n",
              "  'neural model',\n",
              "  'system',\n",
              "  'compositionality ability extract',\n",
              "  'hierarchical manner'],\n",
              " ['electroencephalographic EEG power spectrum accompany fluctuations',\n",
              "  'operators global level alertness',\n",
              "  'power spectrum estimation principal component analysis artificial neural networks',\n",
              "  'level alertness',\n",
              "  'EEG performance auditory monitoring task'],\n",
              " ['Robust Bayesian inference calculation',\n",
              "  'exact inference algorithms',\n",
              "  'exact solutions convergent approximations inferences',\n",
              "  'exact inference',\n",
              "  'robust inference problem estimation probabilistic parameters'],\n",
              " ['different methods training perceptron',\n",
              "  'best perceptron different minimization problems',\n",
              "  'benign malignant tumors',\n",
              "  'new tumors',\n",
              "  'prior knowledge machine learning pattern recognition'],\n",
              " ['latent variable model form neural network target outputs',\n",
              "  'preliminary results application models protein data',\n",
              "  'simple probability distribution unknown inputs',\n",
              "  'latent variable space lower dimensionality',\n",
              "  'probability data'],\n",
              " ['posterior maximization subsequent risk minimization analyses empirical risk minimization aspect nonlocal information',\n",
              "  'examples stationarity conditions maximum posterior approximation nonlocal nonconvex priors',\n",
              "  'inhomogeneous nonlinear equations similar example equations',\n",
              "  'training examples',\n",
              "  'Postdoctoral Fellowship Le Deutsche Forschungsgemeinschaft NSFCISE Postdoctoral Fellowship'],\n",
              " ['cellular encoding edge encoding',\n",
              "  'edge encoding',\n",
              "  'alternative cellular encoding technique',\n",
              "  'node operators cellular encoding',\n",
              "  'edge operators'],\n",
              " ['different algorithms different numbers classes',\n",
              "  'geometric class descriptions',\n",
              "  'degree similarity pair classes',\n",
              "  'geometric comparison rule sets',\n",
              "  'Experimental results case study medical domain'],\n",
              " ['fortuitous sensory predispositions sensory trash useful information vehicles',\n",
              "  'computer implementation model',\n",
              "  'interested adept utilisation waste materials',\n",
              "  'Truth Trash model',\n",
              "  'truthful indicators'],\n",
              " ['singleton variable X set variables',\n",
              "  'probabilistic evaluation effects actions',\n",
              "  'causal effect',\n",
              "  'polynomial number variables graph',\n",
              "  'presence unmeasured variables'],\n",
              " ['robust highlevel vision systems',\n",
              "  'natural neural networks Processing VISOR',\n",
              "  'VISOR robust noise variations inputs parameters',\n",
              "  'cooperation competition parallel bottomup topdown activation schema',\n",
              "  'VISOR large connectionist system'],\n",
              " ['spectrum show tradeoffs model accuracy',\n",
              "  'traversal spectrum',\n",
              "  'general induction algorithm',\n",
              "  'probabilistic model Naive Bayes algorithm',\n",
              "  'critical consider variety data mining domains'],\n",
              " ['level learning population',\n",
              "  'population lifetime adaptive processes',\n",
              "  'supply selection pressure genetic assimilation',\n",
              "  'effect explicit implicit costs assimilation',\n",
              "  'small mobile robot Results experiment'],\n",
              " ['phenotypic space adaptive processes',\n",
              "  'Baldwin Effect speed evolutionary process traits',\n",
              "  'phenotypic space',\n",
              "  'genotypic space evolution',\n",
              "  'phenotypic traits'],\n",
              " ['normal decision trees',\n",
              "  'input vector',\n",
              "  'noise input data',\n",
              "  'system Probabilistic decisions',\n",
              "  'Neural Networks understandable humans'],\n",
              " ['BP momentum term BP weight decay',\n",
              "  'online BP',\n",
              "  'cover serial parallel online BP',\n",
              "  'stationary point BP error function',\n",
              "  'BP'],\n",
              " ['Recurrent neural networks',\n",
              "  'secondorder recurrent neural networks',\n",
              "  'neural network',\n",
              "  'secondorder recurrent neural',\n",
              "  'instability internal representation'],\n",
              " ['global asymptotic stability results',\n",
              "  'Lyapunov sufficient condition inputtostate stability',\n",
              "  'Lyapunovtheoretic Techniques Nonlinear Stability ABSTRACT',\n",
              "  'Converse Lyapunov Function Theorem',\n",
              "  'corollary obtained Converse Theorem'],\n",
              " ['learned grammar extracted networks',\n",
              "  'recurrent neural networks',\n",
              "  'direct encoding partial knowledge networks',\n",
              "  'recurrent neural networks Discretetime',\n",
              "  'consistent training set network'],\n",
              " ['previous handengineered system',\n",
              "  'previous work',\n",
              "  'particular task scheduling payload processing NASAs space shuttle program',\n",
              "  'important task manufacturing industries',\n",
              "  'timedelay neural network TDNN architecture'],\n",
              " ['Turing machines neural networks',\n",
              "  'simulation linear time binarytape machines',\n",
              "  'sigmoidal linear combination',\n",
              "  'Such networks',\n",
              "  'previous version'],\n",
              " ['state stationary goal state algorithm',\n",
              "  'stationary goal states',\n",
              "  'stationary moving goal state',\n",
              "  'goal state',\n",
              "  'optimal paths states'],\n",
              " ['function spaces',\n",
              "  'function space linear combination n',\n",
              "  'Center Biological Information Processing Department Brain Cognitive Sciences Artificial Intelligence Laboratory Department Mathematics University',\n",
              "  'function G',\n",
              "  'Gabriele Anzellotti Department Mathematics University Trento Italy'],\n",
              " ['explanationbased learning specific problems solution generalized form',\n",
              "  'recursive iterative concepts',\n",
              "  'recursive rules',\n",
              "  'recursive rule appropriate system',\n",
              "  'iterative recursive process'],\n",
              " ['Gibbs sampler',\n",
              "  'Gibbs',\n",
              "  'uniformly ergodic jagged boundaries sampler',\n",
              "  'convergence properties',\n",
              "  'greatly smoothness boundary R'],\n",
              " ['real functions',\n",
              "  'basic functions background knowledge',\n",
              "  'number test functions',\n",
              "  'useful intermediate concepts class attributes',\n",
              "  'attributevector representation intermediate concepts'],\n",
              " ['chosen heterogeneous approach uncertainty samples',\n",
              "  'classifiers lower error rates random samples',\n",
              "  'previous labeled instances',\n",
              "  'class labels training instances',\n",
              "  'Uncertainty sampling methods'],\n",
              " ['instrumental variables',\n",
              "  'unmeasured variables',\n",
              "  'observed variables',\n",
              "  'general formula inequality constraints',\n",
              "  'exogenous variables'],\n",
              " ['Bayesian confidence intervals sample size smoothing spline',\n",
              "  'Bayesian confidence intervals smoothing spline',\n",
              "  'asymptotic formula sample size calculations',\n",
              "  'Bayesian confidence intervals Approximations simulations special functions',\n",
              "  'Health Grants R EY P DK P HD'],\n",
              " ['new boosting algorithms multiclass classification problems',\n",
              "  'confidences predictions decision trees',\n",
              "  'new method',\n",
              "  'technique growing decision trees',\n",
              "  'Freund Schapires AdaBoost'],\n",
              " ['learning process population level first level',\n",
              "  'learning process metalevel strategy parameters',\n",
              "  'paper algorithms capability adaptation',\n",
              "  'Evolutionary Algorithms direct random search algorithms',\n",
              "  'second level'],\n",
              " ['quality learned networks',\n",
              "  'local structure',\n",
              "  'local structures',\n",
              "  'local structure conditional probability distributions CPDs',\n",
              "  'empirical evaluation proposed learning procedure'],\n",
              " ['method infer bounds classifiers',\n",
              "  'linear programming infer committee error bounds',\n",
              "  'fewer classifiers prospective committees',\n",
              "  'method bound test errors',\n",
              "  'useful error bounds'],\n",
              " ['PI controller neural network',\n",
              "  'steadystate output PI controller',\n",
              "  'PI controller',\n",
              "  'nstep ahead error coil output set point reinforcement learning agent',\n",
              "  'sum squared error time'],\n",
              " ['ordered list classification rules examples',\n",
              "  'usefulness CN inductive tool Comparisons Quinlans C',\n",
              "  'Laplacian error estimate alternative evaluation function',\n",
              "  'short paper',\n",
              "  'entropy search'],\n",
              " ['connectionism parallel distributed processing neural network modeling brainstyle computation',\n",
              "  'need concise introduction theoretical perspective',\n",
              "  'links disciplines statistics control theory',\n",
              "  'perspective physics home discipline authors',\n",
              "  'mission introduction neural network novices'],\n",
              " ['major impediment high performance wideissue superscalar processors',\n",
              "  'microarchitecture PolyPath processor extension aggressive superscalar outoforder architecture',\n",
              "  'Selective Eager Execution SEE execution model',\n",
              "  'misspeculation penalties executing paths diffident branches',\n",
              "  'normal superscalar outoforder speculative execution monopath processor Moreover architectural model elegant practical implement'],\n",
              " ['competitive tree learning algorithm',\n",
              "  'several mature AI statistical families tree learning algorithms',\n",
              "  'show derived Bayesian algorithm',\n",
              "  'illustration second learning algorithm',\n",
              "  'many supervised model learning tasks'],\n",
              " ['previous subset selection algorithms',\n",
              "  'method feature subset selection',\n",
              "  'subset features',\n",
              "  'supervised induction algorithm',\n",
              "  'crossvalidation applicable induction algorithm'],\n",
              " ['machine learning method',\n",
              "  'statistical methods',\n",
              "  'value realvalued function',\n",
              "  'function values',\n",
              "  'competitive existing machine'],\n",
              " ['dual path execution branch prediction',\n",
              "  'branch prediction confidence',\n",
              "  'dynamic branch prediction state tables limited form dual path execution',\n",
              "  'dynamic branch prediction',\n",
              "  'dual path execution'],\n",
              " ['SMT processor hardware contexts',\n",
              "  'multiple paths execution',\n",
              "  'existing hardware Simultaneous Multithreading SMT processor',\n",
              "  'SMT processor',\n",
              "  'single program performance SMT'],\n",
              " ['paper review research machine learning relation computational models',\n",
              "  'concrete computational models',\n",
              "  'point abstract simulation',\n",
              "  'psychological literature growing evidence',\n",
              "  'abstract level'],\n",
              " ['sequences homologous original sequence',\n",
              "  'single query sequence',\n",
              "  'hidden Markov modeling Pair wise sequence comparisons',\n",
              "  'additional homologs pairwise sequence comparisons motif analysis',\n",
              "  'Hidden Markov models'],\n",
              " ['general KDD problem Third exhibit performance experimental results',\n",
              "  'Pattern Theoretic approach',\n",
              "  'search complexity find concept',\n",
              "  'Future research directions Knowledge Discovery Databases',\n",
              "  'Discovery robust pattern'],\n",
              " ['dynamic programming edit distance approach pairwise sequence alignment useful parts',\n",
              "  'Expanded Ex Updated Ex Revised Solution Sheet Ex Marked Exercises',\n",
              "  'challenging problem study approaches',\n",
              "  'Chapter Hypertext Book GNAVSNS Biocomputing Course',\n",
              "  'optimal solution study'],\n",
              " ['good oblique split form hyperplane node decision tree Oblique decision tree methods',\n",
              "  'benefits randomization construction oblique decision trees',\n",
              "  'new system induction oblique decision trees',\n",
              "  'extensive empirical studies',\n",
              "  'real artificial data'],\n",
              " ['ExplanationBased Reinforcement Learning EBRL',\n",
              "  'optimal fashion Hierarchical EBRL',\n",
              "  'ExplanationBased Reinforcement Learning',\n",
              "  'Reinforcement Learning RL',\n",
              "  'individual subgoals'],\n",
              " ['BRACE potential effective efficient method discretization',\n",
              "  'many learning paradigms',\n",
              "  'many objectives',\n",
              "  'data useful necessary tool',\n",
              "  'paradigm'],\n",
              " ['simple Bayesian classifier training examples',\n",
              "  'Naive Bayesian classifiers',\n",
              "  'improvement naive Bayesian classifier',\n",
              "  'Bayesian classifier',\n",
              "  'Bayesian classifier searching dependencies'],\n",
              " ['new flexible method generation multiple sequence alignments',\n",
              "  'Multiple sequence alignment',\n",
              "  'The results studies attempting infer appropriate parameter constraints generation de novo HMMs globin kinase aspartic acid protease ribonuclease H sequences SAM HMMER methods',\n",
              "  'currently available alignment methods',\n",
              "  'The hidden Markov model approach'],\n",
              " ['recurrent network',\n",
              "  'recurrent networks',\n",
              "  'Several recurrent networks',\n",
              "  'finite state machines internal state trajectories',\n",
              "  'illusionary finite state descriptions'],\n",
              " ['select appropriate bias',\n",
              "  'recent years bias',\n",
              "  'bias',\n",
              "  'useful learning algorithm',\n",
              "  'several conditions'],\n",
              " ['paper introduce modelbased reinforcement learning method',\n",
              "  'undiscounted average reward',\n",
              "  'methods parameters',\n",
              "  'time step methods',\n",
              "  'Hlearning robust respect changes domain parameters'],\n",
              " ['Converse Lyapunov Function Theorem',\n",
              "  'arbitrary bounded timevarying parameters',\n",
              "  'stability respect',\n",
              "  'unified natural manner',\n",
              "  'wellknown classical theorems'],\n",
              " ['neural network processors part method',\n",
              "  'Artificial Intelligence grounding systems environment representations',\n",
              "  'simulated robotic agents',\n",
              "  'inherent meaning system',\n",
              "  'neural networks'],\n",
              " ['imperfect domain theory',\n",
              "  'universal weak method domain theory correction different sources knowledge theory correction',\n",
              "  'search space possible domain theories',\n",
              "  'requirement complete correct domain theory',\n",
              "  'Correcting theory'],\n",
              " ['Bayesian network variables',\n",
              "  'maximal posteriori MAP instantiation Bayesian network variables',\n",
              "  'Bayesian network',\n",
              "  'Bolztmann machine neural network architecture sense',\n",
              "  'stochastic approximation algorithm'],\n",
              " ['paper design intelligent autonomous adaptive communication networks',\n",
              "  'messages networks',\n",
              "  'elegant powerful theoretical framework design analysis autonomous adaptive communication networks',\n",
              "  'large network',\n",
              "  'large networks'],\n",
              " ['Technical Report Department Statistics University',\n",
              "  'Adrian E Raftery Professor Statistics',\n",
              "  'Washington Box Seattle WA USA Email',\n",
              "  'Statistics University',\n",
              "  'N N'],\n",
              " ['bit sequence expected number mistakes',\n",
              "  'performance algorithm difference',\n",
              "  'number mistakes',\n",
              "  'minimum achievable difference order square root number mistakes',\n",
              "  'certain kinds pattern recognitionlearning algorithms performance bounds'],\n",
              " ['algebraic approach Similarity relations',\n",
              "  'formalization novel approach structural similarity assessment adaptation',\n",
              "  'structure preserving case modifications modulo underlying algebra equational theory algebra',\n",
              "  'approach',\n",
              "  'foundation systematic evaluation appropriate usage Cases primary repository knowledge'],\n",
              " ['occasional instruction learner form actions learner',\n",
              "  'level trainers interaction learner',\n",
              "  'trainers actions',\n",
              "  'parameter controls learner',\n",
              "  'approach automated training agent'],\n",
              " ['learning algorithm',\n",
              "  'binary case accuracy learning algorithm',\n",
              "  'accuracy algorithms',\n",
              "  'extensions algorithms cases',\n",
              "  'algorithm'],\n",
              " ['model ratio decidendi justification structure',\n",
              "  'particular model shows theory case',\n",
              "  'important set characteristics ratio decidendi',\n",
              "  'account dependency precedential effect theory decision',\n",
              "  'precedential effect'],\n",
              " ['neighbourhood preserving map call topographic homeomorphism',\n",
              "  'topographic maps',\n",
              "  'topographic homeomorphism',\n",
              "  'quality map',\n",
              "  'wellknown class quadratic assignment problems'],\n",
              " ['uniform attribute noise attribute',\n",
              "  'show product random attribute noise attribute',\n",
              "  'small amount noise',\n",
              "  'small amounts noise',\n",
              "  'large amounts noise'],\n",
              " ['behavioral specialization learning robot teams',\n",
              "  'penalized global reinforcement teams',\n",
              "  'agents terms performance policy convergence',\n",
              "  'particular behavioral assemblages',\n",
              "  'common set skills motor schemabased behavioral assemblages'],\n",
              " ['performance transfer functions product units',\n",
              "  'random Boolean logic functions product units',\n",
              "  'required efficient synthesis Boolean logic functions neural networks Product units',\n",
              "  'local minima corresponding networks summation units',\n",
              "  'Product units'],\n",
              " ['NRL Navigation task',\n",
              "  'cognitive model skill acquisition task',\n",
              "  'skills complex cognitive tasks',\n",
              "  'NRL Navigation task depth',\n",
              "  'task guided quality fit human performance data'],\n",
              " ['rational preservation conditional beliefs belief revision',\n",
              "  'belief revision process',\n",
              "  'iterated belief revision',\n",
              "  'belief revision function epistemic states',\n",
              "  'belief'],\n",
              " ['twolayer connectionist system',\n",
              "  'search strategies',\n",
              "  'weak taskspecific strategy finetunes performance',\n",
              "  'ability twolayer network',\n",
              "  'performance onelayer twolayer networks'],\n",
              " ['indirect learning methods',\n",
              "  'direct learning methods',\n",
              "  'direct reinforcement learning method',\n",
              "  'direct method',\n",
              "  'existing indirect method'],\n",
              " ['properties belief',\n",
              "  'general framework study belief change',\n",
              "  'interaction knowledge plausibility show properties',\n",
              "  'belief terms',\n",
              "  'belief'],\n",
              " ['stationary distribution chain',\n",
              "  'Markov chain Monte Carlo',\n",
              "  'framework based concept Markov chain regeneration',\n",
              "  'Markov chain Monte Carlo MCMC',\n",
              "  'careful design transition kernel chain basis detailed preliminary exploratory analysis'],\n",
              " ['interpolation models',\n",
              "  'interpolant choice noise model',\n",
              "  'new models interpolation neuronal spike data',\n",
              "  'Bayesian models',\n",
              "  'single regularization constant ff noise model single parameter'],\n",
              " ['DaimlerBenz applications StatLog',\n",
              "  'real industrial commercial applications',\n",
              "  'different applications',\n",
              "  'Author paper coordinator Machine Learning project',\n",
              "  'Machine Learning ML DaimlerBenz'],\n",
              " ['RL research date Elevator systems',\n",
              "  'RL difficult real world problem elevator',\n",
              "  'addition use team RL agents',\n",
              "  'noisy agent due effects actions agents',\n",
              "  'best heuristic elevator control algorithms'],\n",
              " ['many exploration techniques',\n",
              "  'current state space Experimental',\n",
              "  'statistics space',\n",
              "  'possible shortterm memories',\n",
              "  'Fringe Exploration technique efficient exploration partially observable domains'],\n",
              " ['policy iteration dynamic programming',\n",
              "  'Bairds compute form absolute utility function',\n",
              "  'dynamic programming',\n",
              "  'smooth problems advantages',\n",
              "  'lead appropriate policy improvement'],\n",
              " ['features pool',\n",
              "  'small nonredundant feature sets pools',\n",
              "  'large feature pools',\n",
              "  'parallel approach DTSelect selecting features',\n",
              "  'complex features'],\n",
              " ['Sequential Serial Genetic Algorithms',\n",
              "  'Faculty Sciences Technology New University Lisbon',\n",
              "  'Faculty Sciences Technology New University',\n",
              "  'Andrew Hunter University Sunderland UK',\n",
              "  'Andrew Hunter University Sunderland'],\n",
              " ['novel views objects network',\n",
              "  'several distinct D views stored object',\n",
              "  'simulated psychophysical experiments networks behavior',\n",
              "  'emergence compact representations specific input views',\n",
              "  'unsupervised Hebbian relaxation network'],\n",
              " ['Biomedical Research Support Grant Program Division Research Resources National Institutes Health',\n",
              "  'adaptive systems general particular importance',\n",
              "  'learning algorithms utilized cases',\n",
              "  'learning algorithm',\n",
              "  'ATR Auditory Visual Perception Research Laboratories'],\n",
              " ['incremental induction decision trees',\n",
              "  'decision tree',\n",
              "  'numeric variables new tree revision operator',\n",
              "  'Proceedings Eleventh International Conference Machine Learning Abstract',\n",
              "  'direct metric candidate tree'],\n",
              " ['ONR grant NK Harvard University',\n",
              "  'partial support ONR grants NK NK Address Department Computer Science University',\n",
              "  'Supported ONR grants NK NJ Part research',\n",
              "  'NK NK Address Department Computer Science University',\n",
              "  'ONR grant NK DARPA'],\n",
              " ['efficient set control knowledge training problems',\n",
              "  'utility problem',\n",
              "  'utility control knowledge',\n",
              "  'training problem explanation',\n",
              "  'simple selection strategy'],\n",
              " ['feasible trajectories goal regions',\n",
              "  'high dimensions',\n",
              "  'high resolution critical areas',\n",
              "  'feasible paths trajectories',\n",
              "  'twodimensional ninedimensional statespaces'],\n",
              " ['predictive distribution',\n",
              "  'simplest case predictive distribution',\n",
              "  'joint probability distribution variables',\n",
              "  'set distributions',\n",
              "  'MAP approach'],\n",
              " ['casebased reasoning CBR system search case memory use stored cases',\n",
              "  'rigorous Bayesian probability propagation algorithm',\n",
              "  'efficient casebased reasoning',\n",
              "  'solution adaptation problem',\n",
              "  'neural network architecture'],\n",
              " ['upper bounds',\n",
              "  'new bounds',\n",
              "  'improved general bounds sample complexity agnostic learning',\n",
              "  'general upper bound expected absolute error algorithm terms',\n",
              "  'lower bounds'],\n",
              " ['neural networks intelligent systems',\n",
              "  'Authority An Authority',\n",
              "  'Pre sented architecture type neural expert module',\n",
              "  'answer confidence quotient transmitted levels system hierarchy',\n",
              "  'Minos modules Authority'],\n",
              " ['satisfactory policies problems',\n",
              "  'realistic problems',\n",
              "  'problems',\n",
              "  'brief review pomdps paper',\n",
              "  'study pomdps'],\n",
              " ['new method construction Markov chains',\n",
              "  'auxiliary chain',\n",
              "  'theoretical numerical comparisons characteristics',\n",
              "  'stationary distribution',\n",
              "  'MCMC techniques'],\n",
              " ['new approximation method',\n",
              "  'Markov Decision Process MDP',\n",
              "  'Markov Decision Process',\n",
              "  'inefficient space time',\n",
              "  'optimal courses action policies'],\n",
              " ['alternative semantical view update observations',\n",
              "  'update forms revision reasoning action',\n",
              "  'update operator conforming KM',\n",
              "  'semantics update',\n",
              "  'Abductive Model Update Proc Tenth Canadian Conf'],\n",
              " ['feedbackguided reweighting links',\n",
              "  'Recognition Cone structures',\n",
              "  'architecture brainstructured networks perceptual recognition Results',\n",
              "  'parallelhierarchical Recognition Cone models perception perspective examples',\n",
              "  'mechanisms generationdiscovery feedbackguided growth new links nodes'],\n",
              " ['variety approaches decision tree induction',\n",
              "  'measure tree quality',\n",
              "  'new computational classifier characteristics',\n",
              "  'one incremental tree induction ITI nonincremental tree induction',\n",
              "  'several variants'],\n",
              " ['closed form posterior distribution parameters',\n",
              "  'posterior predictive model',\n",
              "  'logistic regression model',\n",
              "  'latent variable density model',\n",
              "  'closed form posteriors presence missing values'],\n",
              " ['mixture models posterior approximations mixture component factorized distribution',\n",
              "  'mean field approximation cases',\n",
              "  'Mean field methods',\n",
              "  'Simple mean field methods',\n",
              "  'efficient methods'],\n",
              " ['paper present difficult version classic problem cart pole move plane',\n",
              "  'difficult problem',\n",
              "  'neuroevolution system Enforced SubPopulations ESP',\n",
              "  'standard control learning tasks',\n",
              "  'efficiency systems'],\n",
              " ['used networks',\n",
              "  'network structures',\n",
              "  'eg perceptual recognition network',\n",
              "  'learning mechanisms',\n",
              "  'temporal spatiotemporal patterns'],\n",
              " ['complexity bounded number actions',\n",
              "  'previous online Q implementations',\n",
              "  'size stateaction space',\n",
              "  'The method based observation Qvalue updates',\n",
              "  'Qlearning'],\n",
              " ['generative learning algorithms',\n",
              "  'variety learning structures',\n",
              "  'function experience Generative learning algorithms',\n",
              "  'class learning',\n",
              "  'used networks'],\n",
              " ['neural paradigm autonomous road',\n",
              "  'different type simultaneous use different sensors generalization road types',\n",
              "  'neural system drive vehicle',\n",
              "  'neural system',\n",
              "  'many dif ferent types roads'],\n",
              " ['speed prediction accuracy feature detection task oriented incremental learning',\n",
              "  'individual predictions',\n",
              "  'local distance metric adjusting size shape rece p tive field predictions',\n",
              "  'Only prediction query',\n",
              "  'linear experts'],\n",
              " ['previous environment state part feedback imperfect monitoring case available agent reward',\n",
              "  'imperfect monitoring case criterion',\n",
              "  'competitive ratio criterion perfect monitoring case',\n",
              "  'imperfect monitoring case',\n",
              "  'model environment state controlled Nature'],\n",
              " ['n points rectangle',\n",
              "  'unknown product distribution D Q instances',\n",
              "  'D rectangle',\n",
              "  'n elements Q',\n",
              "  'accuracy probability'],\n",
              " ['definition target concept terms',\n",
              "  'new machine learning method',\n",
              "  'intermediate concepts definitions',\n",
              "  'Boolean function decomposition approach',\n",
              "  'method'],\n",
              " ['present mdistribution estimate extension mprobability estimate',\n",
              "  'system automatic induction regression trees',\n",
              "  'successful estimating probabilities events',\n",
              "  'estimation probabilities',\n",
              "  'application construction regression trees'],\n",
              " ['missing data',\n",
              "  'incomplete data',\n",
              "  'highdimensional data',\n",
              "  'National Science Foundation contract ASC Support',\n",
              "  'Center Biological Computational Learning Artificial Intelligence Laboratory Massachusetts Institute Technology Support Center'],\n",
              " ['faulttolerant neural DFA implementations',\n",
              "  'deterministic finitestate automata DFA n states',\n",
              "  'tolerance weight andor neuron stuckatzero faults',\n",
              "  'duplication network resources',\n",
              "  'desired network performance'],\n",
              " ['dasguptabiostatwashingtonedu Adrian E Raftery Professor Statistics Sociology Department Statistics University Washington Box Seattle WA email address',\n",
              "  'Abhijit Dasgupta graduate student Department Biostatistics University Washington Box Seattle WA email address',\n",
              "  'Department Biostatistics University',\n",
              "  'Peter Guttorp Girardeau Henderson Robert Muise helpful discussions',\n",
              "  'Statistics University'],\n",
              " ['best payoff Past solutions bandit problem',\n",
              "  'best arm',\n",
              "  'payoffs slot machines',\n",
              "  'arm K nonidentical slot machines',\n",
              "  'best arm rate OT'],\n",
              " ['probability distributions nodes network',\n",
              "  'conditional probabilities',\n",
              "  'computational speed traditional representation computerbased implementations probabilistic inference',\n",
              "  'Bayesian belief network sensitivities',\n",
              "  'QR matrix representation sensitivities'],\n",
              " ['neural networkspecific features general programmable machine architecture',\n",
              "  'large neural networks',\n",
              "  'mesh network',\n",
              "  'design progress',\n",
              "  'design'],\n",
              " ['number training examples',\n",
              "  'label input part example used signal',\n",
              "  'large number training examples',\n",
              "  'Reuters corpus Reuters STAT Data Manipulation Analysis Programs Perlman',\n",
              "  'used single Winnow learner orders magnitude'],\n",
              " ['technique logic programming framework Covering',\n",
              "  'cases accurate hypotheses',\n",
              "  'larger hypothesis space',\n",
              "  'technique divideandconquer',\n",
              "  'compact hypotheses'],\n",
              " ['Recurrence Surface Approximation inductive learning method',\n",
              "  'censored training examples examples',\n",
              "  'breast cancer prognosis',\n",
              "  'Recurrence Surface Approximation',\n",
              "  'available training output'],\n",
              " ['Snob Wallace Boulton Wallace Wallace Dowe',\n",
              "  'Minimum Message Length MML invariant Bayesian point estimation technique',\n",
              "  'Wallace Boulton Wallace Freeman',\n",
              "  'Snob Wallace Boulton',\n",
              "  'MML theory'],\n",
              " ['VISIT connectionist model covert visual attention',\n",
              "  'known physiological data human attention system Various extensions VISIT',\n",
              "  'cognitive phenomena development efficient exible interfaces low level sensory information high level processes',\n",
              "  'high level vision',\n",
              "  'visual processing researchers'],\n",
              " ['global behavior asymmetric neural networks',\n",
              "  'paradigm neural computation fixed point attractors',\n",
              "  'asymmetric networks',\n",
              "  'brain confined fixed point attractors',\n",
              "  'excitatory inhibitory populations neurons antisymmetric interactions populations'],\n",
              " ['importance sampling bridge sampling ratio importance sampling problems different dimensions',\n",
              "  'global optimal importance sampling bridge sampling ratio importance sampling sense',\n",
              "  'bridge sampling method Meng Wong path sampling method',\n",
              "  'Gelman Meng ratio importance sampling method Chen Shao',\n",
              "  'ratio posterior odds'],\n",
              " ['utility algorithm CaPER casebased planning system',\n",
              "  'novel algorithm efficient associative matching relational structures',\n",
              "  'dependent efficient flexible access large base exemplars cases',\n",
              "  'given probe structure',\n",
              "  'knowledge bases'],\n",
              " ['training sample size procedures',\n",
              "  'large training sample',\n",
              "  'number training examples',\n",
              "  'training examples oneatatime',\n",
              "  'training examples practice'],\n",
              " ['Cbr explainability case selection adaptation',\n",
              "  'structural similarity guidance adaptation',\n",
              "  'retrieval matching similar adaptable cases',\n",
              "  'single numeric value specific structure',\n",
              "  'retrieval matching adaptation group'],\n",
              " ['desired behavior device design results',\n",
              "  'blameassignment task',\n",
              "  'blameassignment tasks',\n",
              "  'design redesign physical devices',\n",
              "  'undesirable behavior specific structural element design'],\n",
              " ['knowledge base design support system',\n",
              "  'knowledge disposal system',\n",
              "  'formal integrated model knowledge design',\n",
              "  'design support system',\n",
              "  'acquisition application knowledge'],\n",
              " ['neural network classifiers',\n",
              "  'unsupervised classifiers',\n",
              "  'Overall statistical classifiers',\n",
              "  'various classifiers',\n",
              "  'unsupervised classification'],\n",
              " ['casebased reasoning',\n",
              "  'AI research casebased reasoning',\n",
              "  'many laboratory casebased systems',\n",
              "  'trace processing problemsolving episode',\n",
              "  'problemsolving trace'],\n",
              " ['way estimate amino acid frequencies',\n",
              "  'based marginal amino acid frequencies',\n",
              "  'true population frequencies',\n",
              "  'observed data Experimental results',\n",
              "  'optimal number pseudocounts'],\n",
              " ['bias specialised models',\n",
              "  'generalist models',\n",
              "  'innateness bias',\n",
              "  'learning beings',\n",
              "  'isotropic bias'],\n",
              " ['attention important features input scene',\n",
              "  'Previous work autonomous lane following system',\n",
              "  'important performing task',\n",
              "  'important task',\n",
              "  'computed expectation contents inputs'],\n",
              " ['MDP value function',\n",
              "  'Production scheduling problem',\n",
              "  'Markov Decision Process MDP formulation production scheduling',\n",
              "  'approximate value function domain',\n",
              "  'deterministic noisy scenarios value function approximation effective technique'],\n",
              " ['new formal model machine learning concept boolean function',\n",
              "  'Such probabilistic concepts pconcepts',\n",
              "  'natural classes pconcepts',\n",
              "  'situations weather prediction measured variables accuracy',\n",
              "  'uncertain probabilistic behaviorthus input'],\n",
              " ['deductive problem solvers',\n",
              "  'tree backtracking mechanism problem',\n",
              "  'approach submit problem solver filter function',\n",
              "  'problem',\n",
              "  'failure branch search tree'],\n",
              " ['ECS ECS Air Force Office Scientific Research Bolling AFB',\n",
              "  'Rich Sutton',\n",
              "  'ECS ECS Air Force Office Scientific Research',\n",
              "  'Rich Yee Vijay Gullapalli',\n",
              "  'Rich Sutton Chris Watkins'],\n",
              " ['twostage selection network',\n",
              "  'special case selection network',\n",
              "  'many objects patterns network',\n",
              "  'neural networks winnertakeall WTA',\n",
              "  'global connectivity WTA networks'],\n",
              " ['RL tasks',\n",
              "  'RL algorithms stochastic approximation methods',\n",
              "  'artificial intelligence RL researchers',\n",
              "  'new algorithms',\n",
              "  'Reinforcement learning RL'],\n",
              " ['second case outputs',\n",
              "  'learner counterexamples',\n",
              "  'polynomial cover time underlying graph target',\n",
              "  'output state',\n",
              "  'target automaton step'],\n",
              " ['robot pebble device place vertex use',\n",
              "  'problem robot',\n",
              "  'upper bound number vertices',\n",
              "  'mapping problem',\n",
              "  'vertex'],\n",
              " ['sample complexity MDL',\n",
              "  'sample complexity results',\n",
              "  'sample complexity loworder polynomial error threshold',\n",
              "  'complexity target distribution',\n",
              "  'number samples'],\n",
              " ['ARL method',\n",
              "  'Bayesian networks approximate value function',\n",
              "  'Averagereward Reinforcement Learning ARL',\n",
              "  'Hlearning address scaleup problem',\n",
              "  'ing function approximation'],\n",
              " ['cluster bound aries data',\n",
              "  'Merge clustering extracts clusters',\n",
              "  'highdimensional clusters related complex ways',\n",
              "  'learning structure data space',\n",
              "  'cluster boundaries discontinuities'],\n",
              " ['composite sequential decision tasks',\n",
              "  'learning agent',\n",
              "  'elemental composite SDTs',\n",
              "  'unknown learning agent',\n",
              "  'structure composite tasks'],\n",
              " ['obstacle avoidance behavior',\n",
              "  'simulation OSCAR robot arm',\n",
              "  'control robot arm',\n",
              "  'neural network controllers',\n",
              "  'single performance measurement entire task grasping object'],\n",
              " ['RL arbitrary fixed soft state aggregation novel intuitive understanding effect state aggregation online RL new heuristic adaptive state aggregation algorithm',\n",
              "  'simple extension state aggregation',\n",
              "  'nondiscrete nature soft state aggregation Preliminary empirical results',\n",
              "  'improved compact representations',\n",
              "  'use compact representations'],\n",
              " ['temporaldifference methods',\n",
              "  'conventional predictionlearning methods',\n",
              "  'less memory less peak computation conventional methods',\n",
              "  'supervisedlearning methods',\n",
              "  'new methods'],\n",
              " ['dynamic programming methods Dyna architectures',\n",
              "  'DynaQ architectures',\n",
              "  'previous work Dyna class architectures intelligent systems',\n",
              "  'simple DynaPI system',\n",
              "  'evolving world model'],\n",
              " ['parameterized function approximators',\n",
              "  'sparsecoarsecoded function approximators CMACs',\n",
              "  'strong theoretical results accuracy convergence computational results',\n",
              "  'paper present positive results control tasks',\n",
              "  'meeting series negative results'],\n",
              " ['expanded representation',\n",
              "  'size random representation increase dimensionality problem',\n",
              "  'simple randomrepresentation methods',\n",
              "  'original input representation higher dimensional representation unsupervised way map representation final answer',\n",
              "  'paper share structure'],\n",
              " ['online prediction model',\n",
              "  'gambling multipleoutcome prediction repeated games prediction points',\n",
              "  'variety problems',\n",
              "  'multiplicative weightupdate rule Littlestone Warmuth',\n",
              "  'model'],\n",
              " ['online learning algorithm',\n",
              "  'MI A novel activation function',\n",
              "  'MI outputs',\n",
              "  'MI',\n",
              "  'number sources'],\n",
              " ['deterioration generalisation performance trained model',\n",
              "  'preserving generalisation performance hiddenunit pruning methods',\n",
              "  'backpropagation learning',\n",
              "  'bpsom hybrid neural network',\n",
              "  'multilayered feedforward network mfn'],\n",
              " ['AGM theory revision account effect revision conditional beliefs agent',\n",
              "  'minimal conditional revision',\n",
              "  'model iterated belief revision',\n",
              "  'uniterated revision',\n",
              "  'revision'],\n",
              " ['reinforcement learning techniques',\n",
              "  'Reinforcement learning techniques address problem',\n",
              "  'theoretical properties combinations',\n",
              "  'theoretical account phenomenon',\n",
              "  'popular function approximators'],\n",
              " ['network nonlinear units',\n",
              "  'network source separation cocktail party problem',\n",
              "  'information maximisation',\n",
              "  'higherorder moments input distributions',\n",
              "  'dependencies information transfer time delays'],\n",
              " ['Wellknown examples graphical models',\n",
              "  'model data analysis',\n",
              "  'Graphical operations',\n",
              "  'graphical framework',\n",
              "  'graphical specification'],\n",
              " ['efficient set control knowledge training problems',\n",
              "  'utility control knowledge',\n",
              "  'training problem explanation',\n",
              "  'utility problem',\n",
              "  'domain characteristics shape learning curve'],\n",
              " ['Local networks',\n",
              "  'distributed networks',\n",
              "  'network size',\n",
              "  'single multilayered perceptrons radialbasis functions',\n",
              "  'local methods'],\n",
              " ['adaptation knowledge',\n",
              "  'adaptation knowledge experience',\n",
              "  'current CBR systems case adaptation',\n",
              "  'library adaptation cases',\n",
              "  'successful adaptation'],\n",
              " ['introspective reasoning memory search',\n",
              "  'effective flexible memory processing rich memories',\n",
              "  'actual behavior information search process',\n",
              "  'memory search illustration general principles',\n",
              "  'introspective reasoning step'],\n",
              " ['multistrategy learning techniques',\n",
              "  'learning techniques',\n",
              "  'rare Most machine learning techniques',\n",
              "  'acquisition knowledge task',\n",
              "  'classification Learning tasks'],\n",
              " ['system performance task systems knowledge organization knowledge',\n",
              "  'performance task declarative representations failures associations failures',\n",
              "  'task particular pieces knowledge',\n",
              "  'performance current task Introspection',\n",
              "  'possible reasoning failures'],\n",
              " ['statistics networks',\n",
              "  'statistics target values weights network',\n",
              "  'neural networks based ideas statistical mechanics',\n",
              "  'networks problems',\n",
              "  'mean field equations'],\n",
              " ['selflearning control system mobile robot Based sensor information control system',\n",
              "  'correct mapping input state vector output steering signal',\n",
              "  'discrete coding state space adaptive algorithm',\n",
              "  'steering signal way collisions',\n",
              "  'available system'],\n",
              " ['Air Force Office Scientific Research AFOSR FJ Advanced Research Projects Agency ONR NJ Office Naval Research ONR NJ z',\n",
              "  'Air Force Office Scientific Research',\n",
              "  'Advanced Research Projects Agency AFOSR',\n",
              "  'Advanced Research Projects Agency',\n",
              "  'ONR'],\n",
              " ['ffi Z',\n",
              "  'smooth L p functions spaces',\n",
              "  'known results case',\n",
              "  'ffi',\n",
              "  'R approximation problem'],\n",
              " ['agnostic learning algorithm learning problem',\n",
              "  'agnostic learning',\n",
              "  'efficient general agnostic learning method',\n",
              "  'target function assumptions',\n",
              "  'obvious generalization PAC model'],\n",
              " ['multigoal problems Cases',\n",
              "  'new problem',\n",
              "  'new problem situation',\n",
              "  'design implementation derivation replay framework dersnlpebl Derivational snlpebl',\n",
              "  'stored subplans individual goals'],\n",
              " ['fast weights',\n",
              "  'deal temporal sequences',\n",
              "  'alternative class gradientbased systems',\n",
              "  'second net',\n",
              "  'Various learning methods'],\n",
              " ['paper new tree reconstruction method call DiskCovering Method',\n",
              "  'Evolutionary tree reconstruction',\n",
              "  'trees subsets',\n",
              "  'evolutionary tree',\n",
              "  'sequence evolution variety trees'],\n",
              " ['useful syntactic semantic categories',\n",
              "  'difficult interesting problem machine',\n",
              "  'searchcontrol heuristics logic program Appropriate control rules',\n",
              "  'semanticgrammar acquisition problem',\n",
              "  'new firstorder induction algorithm'],\n",
              " ['instructions instruction',\n",
              "  'conditional branch Predicated execution',\n",
              "  'Predicating branch',\n",
              "  'multipath execution Predicated architectures',\n",
              "  'likely execution path program execution'],\n",
              " ['signal based visual attention possible explanation auditory plasticity',\n",
              "  'auditory map',\n",
              "  'signal based owls',\n",
              "  'visual attention',\n",
              "  'primary area visual attention'],\n",
              " ['hippocampus old animals',\n",
              "  'bimodality old animals',\n",
              "  'animal removed returned environment',\n",
              "  'hippocampal cells old animals',\n",
              "  'strong unimodality young animals'],\n",
              " ['set target distractor gestures system',\n",
              "  'active camera foveate salient features',\n",
              "  'foveated gesture recognition system',\n",
              "  'foveate based goal successful recognition',\n",
              "  'MIT Media Laboratory Perceptual Computing Section Technical Report'],\n",
              " ['many nearglobal optima possible implicit sharing',\n",
              "  'large enough fitness sharing',\n",
              "  'Implicit sharing',\n",
              "  'implicit sharing',\n",
              "  'large enough species'],\n",
              " ['Modern knowledge systems design',\n",
              "  'experiment legacy knowledge system',\n",
              "  'heterogeneous knowledge system',\n",
              "  'modern knowledge systems',\n",
              "  'Legacy databases'],\n",
              " ['mixture experts ME model',\n",
              "  'ME model',\n",
              "  'Santa Fe competition ME model',\n",
              "  'time series analysis',\n",
              "  'due correct matching noise level model data'],\n",
              " ['view invariant visual representations',\n",
              "  'ICA better representation PCA object recognition',\n",
              "  'independent component ICA representation',\n",
              "  'different views object',\n",
              "  'principal component representation PCA'],\n",
              " ['synchronization numerical parallel efficiency parallel genetic algorithms GAs',\n",
              "  'parallel GAs',\n",
              "  'critique utility traditional parallel performance measures',\n",
              "  'asynchronous GAs',\n",
              "  'high numerical efficiency eg fewer function evaluations'],\n",
              " ['decision tree',\n",
              "  'decision trees',\n",
              "  'respect decision tree',\n",
              "  'simple trees',\n",
              "  'single support vector machines'],\n",
              " ['different classes basis functions',\n",
              "  'use term Generalized Regularization Networks broad class approximation schemes',\n",
              "  'probabilistic interpretation regularization different classes basis functions',\n",
              "  'regularization networks',\n",
              "  'different classes'],\n",
              " ['several neural network',\n",
              "  'GRBF networks equivalent generalized splines',\n",
              "  'several variables terms',\n",
              "  'representation detail approximation linear nonlinear mappings terms simpler functions fewer variables',\n",
              "  'many neural networks'],\n",
              " ['new case situations case',\n",
              "  'better understanding domain experience',\n",
              "  'novel situations',\n",
              "  'new situation',\n",
              "  'casebased story understanding program'],\n",
              " ['simple model',\n",
              "  'implementation genefinding model',\n",
              "  'path model maximum probability',\n",
              "  'statistical model genes',\n",
              "  'GHMM generation nucleotide base'],\n",
              " ['questions optimality domination repeated stage games',\n",
              "  'notion grace period handle problem vengeful strategies',\n",
              "  'optimality domination',\n",
              "  'infinite payoff',\n",
              "  'strategies'],\n",
              " ['play game finite automata probabilistic actions',\n",
              "  'simple boolean formula recent history play games statistical adversaries',\n",
              "  'play game',\n",
              "  'line research playing games',\n",
              "  'recent history adversaries'],\n",
              " ['optimal segmentation DNA sequence coding noncoding regions exons',\n",
              "  'Experimental results database vertebrate DNA sequences',\n",
              "  'site recognition performance benchmark database vertebrate DNA',\n",
              "  'MORGAN system',\n",
              "  'decision trees'],\n",
              " ['PYTHIA exemplar based reasoning system',\n",
              "  'analysis categorization models classes models',\n",
              "  'PDE based application',\n",
              "  'based characteristics',\n",
              "  'based neural networks'],\n",
              " ['Comparison syntactical hypotheses reduction show reduction',\n",
              "  'based reduction',\n",
              "  'reduction',\n",
              "  'semantic interpretation rules',\n",
              "  'approximate correct learning results'],\n",
              " ['effect unit receptive field parameters factors',\n",
              "  'receptive field properties',\n",
              "  'sample density structure target function',\n",
              "  'new learning algorithm',\n",
              "  'analysis'],\n",
              " ['Markov Decision Problems',\n",
              "  'Decision Problems',\n",
              "  'Markov Decision Problems based ideas',\n",
              "  'SemiMarkov Decision Problems continuous time generalizations',\n",
              "  'problem'],\n",
              " ['classification regression statistics',\n",
              "  'HME classification results',\n",
              "  'neural networks communities',\n",
              "  'The Hierarchical Mixture Experts HME successful number regression problems',\n",
              "  'multiple models'],\n",
              " ['time procedure approximate evaluation probabilistic networks',\n",
              "  'probabilistic network cardinality state spaces nodes',\n",
              "  'mation quality computation time',\n",
              "  'simple networks proce dure',\n",
              "  'real time'],\n",
              " ['class particular problem',\n",
              "  'specific learning problems',\n",
              "  'supervised learning problems',\n",
              "  'problems',\n",
              "  'degree generic difficulty'],\n",
              " ['results empirical study statistical bias backpropagation',\n",
              "  'statistical effects',\n",
              "  'existence bias',\n",
              "  'algorithm wide range',\n",
              "  'weakness algorithms ability discount noise'],\n",
              " ['Radial Basis Function RBF networks',\n",
              "  'onestage errordriven learning strategy',\n",
              "  'framework RBF networks studies',\n",
              "  'intrinsic inadequacy onestage errordriven learning strategy',\n",
              "  'RBF networks'],\n",
              " ['approach extracting rules networks',\n",
              "  'neural networks',\n",
              "  'extracted rules',\n",
              "  'artificial neural networks',\n",
              "  'knowledgebased neural networks'],\n",
              " ['specific machine neural network algorithm',\n",
              "  'neural networks Advances Neural Information Processing Systems',\n",
              "  'Artificial Neural Networks Journal',\n",
              "  'IEEE Intern Conf Neural Networks',\n",
              "  'Proc European Symposium Artificial Neural Networks'],\n",
              " ['system performance task',\n",
              "  'task declarative representations associations particular learning strategies',\n",
              "  'task particular pieces knowledge',\n",
              "  'performance current task Introspection',\n",
              "  'appropriate learning strategies order'],\n",
              " ['artificial neural networks',\n",
              "  'obvious deficiency neural network representations',\n",
              "  'rules networks',\n",
              "  'rulelike knowledge Backpropagationstyle neural networks Empirical studies robot arm domain',\n",
              "  'artificial neural networks Its key mechanism validity interval analysis generic tool'],\n",
              " ['method feature subset selection',\n",
              "  'efficient algorithm feature selection computes',\n",
              "  'approximation optimal feature selection criterion',\n",
              "  'remaining features',\n",
              "  'irrelevant redundant features'],\n",
              " ['additional work irrelevant features',\n",
              "  'irrelevant features',\n",
              "  'relevant features',\n",
              "  'previous work attribute selection',\n",
              "  'greedy pruning oblivious decision trees'],\n",
              " ['agents architecture training strategy match structure behavior pattern',\n",
              "  'different types agents',\n",
              "  'simulated real robots',\n",
              "  'classifier systems genetic algorithms',\n",
              "  'vital role development situated agents'],\n",
              " ['close network multiple similar states',\n",
              "  'Probabilistic inference new network',\n",
              "  'computational complexity probabilistic inference networks',\n",
              "  'instantiations nodes network',\n",
              "  'exponential time original network'],\n",
              " ['higher order statistical relations',\n",
              "  'higher order structure',\n",
              "  'stochastic recurrent network ambiguity lowerlevel states',\n",
              "  'Bayesian belief networks Helmholtz machines',\n",
              "  'higher levels'],\n",
              " ['worstcase model errors',\n",
              "  'malicious errors',\n",
              "  'rate error',\n",
              "  'tolerable learning algorithm efficient algorithms',\n",
              "  'Such errors'],\n",
              " ['model class mean group models',\n",
              "  'posterior probability model class',\n",
              "  'series model class selection experiments',\n",
              "  'true posterior approximations',\n",
              "  'order conduct study chosen model family finite mixture distributions'],\n",
              " ['formulation model construction problem Bayesian framework finite mixture models',\n",
              "  'finite mixture models',\n",
              "  'good models',\n",
              "  'best results',\n",
              "  'reported results'],\n",
              " ['hierarchical model balances model generality access implementationspecific details',\n",
              "  'model planning processes',\n",
              "  'repair failures reasoning process',\n",
              "  'selfmodeling knowledge structured evaluation introspective reasoning systems',\n",
              "  'planner response reasoning failures'],\n",
              " ['reinforcement learning algorithms',\n",
              "  'problems criteria',\n",
              "  'insight learning processes',\n",
              "  'theoretical results',\n",
              "  'Computer experiments'],\n",
              " ['Markovequivalence classes class associated unique statistical model Statistical procedures model selection model',\n",
              "  'account equivalence classes',\n",
              "  'dependence Markov model',\n",
              "  'ADG models',\n",
              "  'essential graphs'],\n",
              " ['maximal probability network model',\n",
              "  'good approximative Bayesian network model probability distribution question',\n",
              "  'Bayesian prototype tree model',\n",
              "  'maximal probability model',\n",
              "  'stochastic simulated annealing algorithm searching model space'],\n",
              " ['Evidential Probability',\n",
              "  'probabilities',\n",
              "  'compound experiments events',\n",
              "  'proper knowledge underlying distributions',\n",
              "  'use acceptance rule'],\n",
              " ['state time pressure stochasticity world states',\n",
              "  'depththree memory necessary internal statesfar fewer states',\n",
              "  'shortterm memory selective perception',\n",
              "  'memorybased learning work robust statistical tests',\n",
              "  'problems large perceptual state spaces'],\n",
              " ['monotonic measure exhaustive search',\n",
              "  'measure guaranteed complete exhaustive Experiments',\n",
              "  'general exhaustive search',\n",
              "  'relevant features',\n",
              "  'Feature selection problem'],\n",
              " ['method dialogue agent',\n",
              "  'novel method dialogue agent',\n",
              "  'alternate strategies agent initiative',\n",
              "  'learning algorithm',\n",
              "  'optimal dialogue strategy'],\n",
              " ['Reduced Error Pruning Inductive Logic Programming',\n",
              "  'Incremental Reduced Error Pruning',\n",
              "  'many noisy domains',\n",
              "  'attempts address problems',\n",
              "  'domains specific concept description'],\n",
              " ['wheelchair composing sequences mental states EEG pattern recognition',\n",
              "  'EEG paralyzed person',\n",
              "  'EEG analysis',\n",
              "  'EEG',\n",
              "  'implemented CNAPS server processor SIMD architecture Adaptive Solutions Inc Execution time comparisons'],\n",
              " ['central issues reinforcement learning',\n",
              "  'Reinforcement learning problem faced agent',\n",
              "  'word reinforcement',\n",
              "  'delayed reinforcement',\n",
              "  'resemblance work psychology'],\n",
              " ['XCS adequate guarantee convergence optimal policy XCSM complex nonMarkovian environments',\n",
              "  'XCSM nonMarkovian environments',\n",
              "  'present evidence complex nonMarkovian environments XCSM',\n",
              "  'XCS internal memory',\n",
              "  'optimal solutions simple environments'],\n",
              " ['probability vector',\n",
              "  'probability vector entries',\n",
              "  'probabilities appearance entries nbit vectors',\n",
              "  'vector single entries',\n",
              "  'nbit vector'],\n",
              " ['WeightedGreedy algorithm',\n",
              "  'FOCUS new algorithm',\n",
              "  'MutualInformationGreedy SimpleGreedy WeightedGreedy algorithms',\n",
              "  'algorithms',\n",
              "  'exact approximate implementation MINFEATURES bias'],\n",
              " ['approach decision tree',\n",
              "  'input sequence decisions',\n",
              "  'data sequences temporal dependencies',\n",
              "  'several alternative proposals',\n",
              "  'ML MAP'],\n",
              " ['errorcorrecting code based parity checks original signal inference sequence linear feedback shift register LFSR noisy observation sequence P zjA',\n",
              "  'related continuous optimization problem',\n",
              "  'noisy communication z',\n",
              "  'combinatorial problem',\n",
              "  'continuous representation terms'],\n",
              " ['development visual system',\n",
              "  'development visual perception',\n",
              "  'total visual pattern deprivation',\n",
              "  'neuroanatomical morphological well behavioral studies development visual perception',\n",
              "  'development information processing structures'],\n",
              " ['problem diffusion context credit reduced transition probabilities',\n",
              "  'ergodicity transition probability matrices Markovian models',\n",
              "  'propagation longterm context information',\n",
              "  'longterm context',\n",
              "  'longterm context sequential data'],\n",
              " ['neural networks',\n",
              "  'discussion neural networks projects',\n",
              "  'research group Interactive Planning Research Center Computer Science FZI',\n",
              "  'Interactive Planning Research Center Computer Science',\n",
              "  'paper application areas'],\n",
              " ['corrosion defects regular intervals',\n",
              "  'defect examples',\n",
              "  'NeuroPipe NeuroPipe task',\n",
              "  'pipe pig Research center computer science FZI',\n",
              "  'special ultrasonic based probe'],\n",
              " ['Different models',\n",
              "  'PCA Incorporating tangentplane information',\n",
              "  'tangent vectors sample covariance matrices',\n",
              "  'loglikelihoods model',\n",
              "  'images digits'],\n",
              " ['gated experts',\n",
              "  'performance gated experts',\n",
              "  'nonlinear gating network',\n",
              "  'gated experts softpartition input space',\n",
              "  'conditional mean expert adapts width match noise level regime'],\n",
              " ['machine learning systems',\n",
              "  'machine learning tools',\n",
              "  'standard Hansch method machine learning system Golem',\n",
              "  'two machine learning systems Magnus Assistant Retis data',\n",
              "  'drug design problem'],\n",
              " ['CORAL deductive database system rule processing engine',\n",
              "  'front end evaluated mapping',\n",
              "  'schemas underlying databases rules',\n",
              "  'front end',\n",
              "  'interactive KRITIK multimodal reasoning system combined case based model'],\n",
              " ['temporal credit assignment problem reinforcement',\n",
              "  'applied problem',\n",
              "  'good knowledge transfer goals',\n",
              "  'existing temporal difference methods',\n",
              "  'Temporal difference methods'],\n",
              " ['interesting duality learning cryptography',\n",
              "  'cryptography number theory particular algorithm',\n",
              "  'number wellknown publickey cryptosys tems',\n",
              "  'several classes Boolean functions distributionfree model',\n",
              "  'Boolean formulae deterministic finite automata constantdepth threshold circuits'],\n",
              " ['TraceEvidence method results',\n",
              "  'new method',\n",
              "  'required standard methods',\n",
              "  'consensus sequence',\n",
              "  'consensus sequences'],\n",
              " ['novel words morphological rules',\n",
              "  'natural languages version network',\n",
              "  'morphology natural language capacity',\n",
              "  'reduplication copying portions root network',\n",
              "  'connectionist model acquisition capacity'],\n",
              " ['intractable algorithms ones',\n",
              "  'traditional EBL',\n",
              "  'competing EBL',\n",
              "  'Prolog programs',\n",
              "  'original program'],\n",
              " ['modified Hebblike learning rule',\n",
              "  'trace rule training algorithm model',\n",
              "  'transformation invariant responses natural stimuli',\n",
              "  'constructed model cortical visual processing',\n",
              "  'eg representation objects objects'],\n",
              " ['Gaussian missing variables network attempt model distribution missing variables',\n",
              "  'static data input variables',\n",
              "  'sequential data input variables',\n",
              "  'missing variables',\n",
              "  'observed variables'],\n",
              " ['control network dynamics',\n",
              "  'fixpointpreserving transformations',\n",
              "  'Legendre transformations',\n",
              "  'repeated transformations',\n",
              "  'transformations'],\n",
              " ['parallel development representation cases case memory organisation design knowledge',\n",
              "  'design cases subcases',\n",
              "  'terms content organisation source case memory implementation case recall case adaptation',\n",
              "  'reasoning process model design',\n",
              "  'current design context'],\n",
              " ['current visual recognition state lower level',\n",
              "  'usefulness model',\n",
              "  'ability model',\n",
              "  'internal model spatiotemporal dynamics input stream',\n",
              "  'detailed exposition model present variety experimental results'],\n",
              " ['tradeoff Baldwin effect Hiding effect',\n",
              "  'Hiding effect',\n",
              "  'speeds rate evolution',\n",
              "  'Individual lifetime learning guide',\n",
              "  'high fitness genotype space evolutionary phenomenon'],\n",
              " ['poor parameter settings time',\n",
              "  'good parameters memory based learner show tradeoffs',\n",
              "  'optimization hyperparameters function approximators',\n",
              "  'less time',\n",
              "  'algorithm problem'],\n",
              " ['efficiency feature selection processing',\n",
              "  'selected input features',\n",
              "  'offline Chinese Japanese handwriting recognition system auto',\n",
              "  'use algorithms',\n",
              "  'linear regression'],\n",
              " ['performance overlapping distributions',\n",
              "  'single component distribution',\n",
              "  'length MML criterion',\n",
              "  'MML criterion',\n",
              "  'existing MML estimates'],\n",
              " ['performance range MIMD parallel processor systems neural network simulations',\n",
              "  'model execution time speedup scalability efficiency large MIMD systems',\n",
              "  'dataset network decomposition techniques Agreement model measurements',\n",
              "  'total execution time simulation function execution times small number kernel functions',\n",
              "  'type neural network geometry decomposition connection structure MIMD machine'],\n",
              " ['superior basic nearest neighbor algorithm',\n",
              "  'term prototypes',\n",
              "  'select features prototypes',\n",
              "  'nearest neighbor computation instances',\n",
              "  'prototypes'],\n",
              " ['neural network model',\n",
              "  'new RBF units',\n",
              "  'toperform positioning RBF units',\n",
              "  'suitable network structure size',\n",
              "  'learning method results combination'],\n",
              " ['different environments robot face lifetime COLUMBUS models',\n",
              "  'COLUMBUS autonomous mobile robot COLUMBUS',\n",
              "  'characteristics typical environments robot',\n",
              "  'office building environment',\n",
              "  'instancebased learning technique modeling environment Realworld experiences'],\n",
              " ['ASP ASP',\n",
              "  'Noisy ASP first problem',\n",
              "  'implicit parallelism problem',\n",
              "  'ASP hillclimbing approaches',\n",
              "  'Noisy ASP'],\n",
              " ['combination crossvalidation confidence levels',\n",
              "  'instancebased learning algorithm particular problem',\n",
              "  'learning algorithms',\n",
              "  'distanceweighted voting parameters',\n",
              "  'classifier confidence levels'],\n",
              " ['learning space use behaviors conditions',\n",
              "  'formulation reinforcement learning',\n",
              "  'heterogeneous reinforcement functions progress estimators',\n",
              "  'noisy dynamic environemnts complex concurrent multirobot learning domain',\n",
              "  'credit assignment problem'],\n",
              " ['greedy tree induction',\n",
              "  'decision trees',\n",
              "  'optimal tree',\n",
              "  'corresponding optimal trees turn',\n",
              "  'trees'],\n",
              " ['input state stability',\n",
              "  'Applications certain stabilization problems',\n",
              "  'general type feedback',\n",
              "  'Previous results',\n",
              "  'comparisons'],\n",
              " ['Attractor networks',\n",
              "  'behavior localist attractor nets',\n",
              "  'alternative formulation attractor networks',\n",
              "  'attractor basins',\n",
              "  'spurious attractors'],\n",
              " ['effective generalisation logical impossibility',\n",
              "  'NFL theorems generalisation absence domain knowledge necessarily zerosum enterprise Good generalisation performance',\n",
              "  'bias assumption',\n",
              "  'bad performance',\n",
              "  'theorems'],\n",
              " ['network structure',\n",
              "  'appropriate network structure',\n",
              "  'network structure addition andor removal units andor',\n",
              "  'recognition accuracy train number networks vote responses',\n",
              "  'network complexity'],\n",
              " ['ML MAP mixture trees variety priors',\n",
              "  'probability model mixture trees',\n",
              "  'EM Minimum Spanning Tree algorithm',\n",
              "  'family efficient algorithms',\n",
              "  'Dirichlet MDL priors'],\n",
              " ['regions DNA sequence encode proteins',\n",
              "  'reading frame region',\n",
              "  'E coli DNA sequences',\n",
              "  'DNA sequences',\n",
              "  'Uberbacher Mural identify coding regions'],\n",
              " ['correct mapping discrete sensor input space steering signal',\n",
              "  'correct mapping input state vector output steering signal algorithm',\n",
              "  'selflearning control system mobile robot Based sensor information control system',\n",
              "  'steering signal way collisions',\n",
              "  'basis external reinforcement signal negative case collision'],\n",
              " ['task analysis situates transfer process',\n",
              "  'induction independent procedure',\n",
              "  'number conceptual difficulties',\n",
              "  'learning methods',\n",
              "  'generalised inductive protocol'],\n",
              " ['many types relationships source target networks',\n",
              "  'subproblem target network task goal',\n",
              "  'incorporation information extracted networks',\n",
              "  'target task',\n",
              "  'Our focus utilization weights source networks'],\n",
              " ['Quickprop Cascade Correlation Cascade',\n",
              "  'capable autonomous operation',\n",
              "  'ALVINN Autonomous Land Vehicle Neural Net Backpropagation',\n",
              "  'neural network',\n",
              "  'Applying Advanced Learning Algorithms ALVINN'],\n",
              " ['model class selection phase approach',\n",
              "  'finite mixture models',\n",
              "  'first phase selection model class ie number parameters',\n",
              "  'CheesemanStutz approximation model class evidence',\n",
              "  'model family'],\n",
              " ['classifier algorithm',\n",
              "  'algorithm variants',\n",
              "  'Rosenblatts perceptron algorithm',\n",
              "  'new algorithm',\n",
              "  'algorithm'],\n",
              " ['insufficient TLP processors MP',\n",
              "  'TLP Wideissue superscalar processors',\n",
              "  'ILP TLP program',\n",
              "  'threadlevel parallelism instructionlevel parallelism',\n",
              "  'share processors resources'],\n",
              " ['stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'generalized iterative scaling procedure',\n",
              "  'probabilistic automata',\n",
              "  'contextdependent probabilities'],\n",
              " ['committee machines Performance',\n",
              "  'committee regressors',\n",
              "  'committee machines',\n",
              "  'least equivalent cases',\n",
              "  'fundamental building blocks'],\n",
              " ['neural expert system shell NEULA',\n",
              "  'imprecise incomplete information',\n",
              "  'Current expert systems',\n",
              "  'hand neural networks',\n",
              "  'pattern recognition operations'],\n",
              " ['Red Queen effect',\n",
              "  'appropriate performance measures',\n",
              "  'Red Queen',\n",
              "  'fitness ambiguities improvements performance coevolved individuals',\n",
              "  'artificial life theoretical biology population dynamics'],\n",
              " ['use flexible parametric models',\n",
              "  'Kathryn Roeder Associate Professor Larry Wasserman Professor Department Statistics CarnegieMellon University Pittsburgh PA Carrolls research',\n",
              "  'departures standard parametric models',\n",
              "  'Inferences measurement error models',\n",
              "  'Department Statistics CarnegieMellon University'],\n",
              " ['multiparent operators performance GAs',\n",
              "  'standard uniform crossover diagonal crossover',\n",
              "  'point crossover study effects',\n",
              "  'different number parents',\n",
              "  'tough function optimization problems'],\n",
              " ['Washington USA Susan L Rosenkranz Pew Health Policy Postdoctoral Fellow Institute Health Policy Studies Box University',\n",
              "  'Statistics GN University',\n",
              "  'National Research Service Award TCA National Cancer Institute',\n",
              "  'Washington Seattle WA Rosenkranzs research',\n",
              "  'Paula Diehr Kevin Cain'],\n",
              " ['neural network',\n",
              "  'biological neural networks',\n",
              "  'tutorial overview neural networks',\n",
              "  'vantage point neural networks',\n",
              "  'Neural networks'],\n",
              " ['algorithm classification assign class separate set codebook Gaussians',\n",
              "  'classification strategy codebook vectors',\n",
              "  'Classification pattern',\n",
              "  'various classification algorithms',\n",
              "  'role classification patterns'],\n",
              " ['paper use decision trees lifetime prediction programs',\n",
              "  'time space efficiency dynamic memory management computer programs',\n",
              "  'improvement variety computer programs',\n",
              "  'Predictions lifetimes',\n",
              "  'decision tree'],\n",
              " ['knowledge example problem',\n",
              "  'problem specific domain knowledge',\n",
              "  'efficient problem',\n",
              "  'example problem meta process',\n",
              "  'larger variety problems'],\n",
              " ['previous upper bound coverage Boolean concept learning algorithm',\n",
              "  'upper bound Experimental measurement coverage ID FRINGE algorithms',\n",
              "  'way coverage maximization',\n",
              "  'definition coverage',\n",
              "  'coverage'],\n",
              " ['modified policy iteration algorithm',\n",
              "  'structured representation stochastic actions policies value functions algorithm',\n",
              "  'structured policy iteration',\n",
              "  'temporal Bayesian network representation MDPs',\n",
              "  'large AI planning problems'],\n",
              " ['neural network models attempts',\n",
              "  'inputoutput vectors processing network',\n",
              "  'adaptive set arbitrary vector mappings',\n",
              "  'arbitrary mapping boolean inputoutput vectors',\n",
              "  'time linear depth network'],\n",
              " ['asymptotic MWL variance Evaluation marginal likelihood',\n",
              "  'Maximum working likelihood MWL inference presence',\n",
              "  'large likelihood',\n",
              "  'Maximum likelihood Metropolis',\n",
              "  'Markov chain Monte Carlo MCMC'],\n",
              " ['Natural images',\n",
              "  'natural images',\n",
              "  'sparse codes natural scenes',\n",
              "  'good objective efficient coding natural scenes',\n",
              "  'Many important forms structure'],\n",
              " ['study effects epistasis performance EAs',\n",
              "  'preliminary exploration effects epistasis',\n",
              "  'empirical methodology',\n",
              "  'use ideas',\n",
              "  'simple GAs'],\n",
              " ['average L crossover points strings length',\n",
              "  'point crossover operators',\n",
              "  'Many recent empirical studies',\n",
              "  'present framework understanding',\n",
              "  'L Theoretical results'],\n",
              " ['arbitrary conditional nesting NPcomplete formulas',\n",
              "  'conditional statements decision problem NPcomplete mulas',\n",
              "  'possible decision problem',\n",
              "  'Lewis Stalnaker utilized artificial intelligence',\n",
              "  'several exceptions rule'],\n",
              " ['higherorder connections incremental introduction new units',\n",
              "  'new units',\n",
              "  'useful learning sequential tasks',\n",
              "  'next timestep information previous step temporal tasks',\n",
              "  'recurrent networks'],\n",
              " ['unit remaining units',\n",
              "  'unit filter abstract concepts environmental input concepts',\n",
              "  'factorial codes',\n",
              "  'binary factorial codes',\n",
              "  'Barlow et al ie codes probability occurrence particular input'],\n",
              " ['efficient learning new model',\n",
              "  'efficient learning statistical queries',\n",
              "  'distribution specific algorithms distributions',\n",
              "  'learning PAC',\n",
              "  'statistical queries sufficient condition PAC'],\n",
              " ['inherent learning parameters',\n",
              "  'emergence learning ability',\n",
              "  'learning ability',\n",
              "  'lookup table inherent parameters',\n",
              "  'rate discount rate rewards'],\n",
              " ['witness algorithm compute updated value functions',\n",
              "  'fastest algorithm wide range pomdp sizes',\n",
              "  'crucial operation wide range pomdp solution methods',\n",
              "  'convex value functions',\n",
              "  'witness algorithm'],\n",
              " ['type parallelism parallelism distance',\n",
              "  'limits instruction level parallelism',\n",
              "  'advantage parallelism compiler',\n",
              "  'far parallelism',\n",
              "  'stack remove dependency'],\n",
              " ['stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'generalized iterative scaling procedure',\n",
              "  'probabilistic automata',\n",
              "  'contextdependent probabilities'],\n",
              " ['subtractive enforcement yields',\n",
              "  'subtractive enforcement',\n",
              "  'common target multiplicative enforcement',\n",
              "  'constraints output cells input cells',\n",
              "  'weight configurations principal eigenvector unconstrained operator Multiplicative enforcement yields'],\n",
              " ['ATR Human Information Processing Research Laboratories',\n",
              "  'Jordan NSF Presidential Young Investigator',\n",
              "  'Center Biological Computational Learning MIT',\n",
              "  'NJ Office Naval Research',\n",
              "  'part grant McDonnellPew Foundation'],\n",
              " ['Bayesian learning framework objective functions',\n",
              "  'measure expected informativeness candidate measurements',\n",
              "  'assumption hypothesis space',\n",
              "  'Learning',\n",
              "  'main weakness'],\n",
              " ['cluster structure highdimensional input',\n",
              "  'highdimensional input data unknown distribution Ordinary feature maps',\n",
              "  'structure clusters input',\n",
              "  'D case dimensional input space',\n",
              "  'input distribution overcome problem'],\n",
              " ['class LCI models',\n",
              "  'subclass class graphical Markov models',\n",
              "  'LCI models',\n",
              "  'ADGs Markov equivalent transitive ADG',\n",
              "  'dependent linear regression models'],\n",
              " ['proposed method',\n",
              "  'engineering design Empirical results',\n",
              "  'method',\n",
              "  'search guide exploration',\n",
              "  'efficiency reliability GA optimizer'],\n",
              " ['GA continuous designspace optimization',\n",
              "  'global optimization',\n",
              "  'realistic engineering design optimization',\n",
              "  'classical GA efficiency reliability',\n",
              "  'new GA operators strategies'],\n",
              " ['D E Rumelhart G E Hinton R J Williams Learning Internal Representations Error Propagation D E Rumelhart J L McClelland',\n",
              "  'Parallel Distributed Processing Explorations Microstructure Cognition',\n",
              "  'Vol MIT Press'],\n",
              " ['illustrate situations tree model',\n",
              "  'tree topology model',\n",
              "  'tree example structural functional applications',\n",
              "  'underlying model design algorithms optimization criteria software packages multiple sequence alignment MSA',\n",
              "  'unique tree'],\n",
              " ['Selective suppression transmission feedback synapses',\n",
              "  'suppression layer IV feedforward synapses',\n",
              "  'associative feedback selforganization feedforward synapses',\n",
              "  'cholinergic suppression synaptic transmission layer',\n",
              "  'selforganized representations input'],\n",
              " ['overrelaxed versions slice sampling',\n",
              "  'slice sampling schemes',\n",
              "  'defined current vertical position Variations slice sampling methods',\n",
              "  'uniform sampling vertical direction uniform',\n",
              "  'sampling efficiency'],\n",
              " ['ture MDPs',\n",
              "  'foundations number problems',\n",
              "  'future research sketch alternative methods analysis',\n",
              "  'MDPs',\n",
              "  'large problems'],\n",
              " ['good advice learner',\n",
              "  'subsequent advice result',\n",
              "  'use advice',\n",
              "  'advice',\n",
              "  'several aspects approach show'],\n",
              " ['expected amino acid distributions database search',\n",
              "  'information protein database mixture',\n",
              "  'mathematical foundations Dirichlet mixtures',\n",
              "  'Markov model statistical model',\n",
              "  'amino acid probabilities position profile'],\n",
              " ['new approach derivational analogy',\n",
              "  'derivational analogy',\n",
              "  'Derivational analogy technique',\n",
              "  'common problem solvers',\n",
              "  'new problems'],\n",
              " ['language induced network',\n",
              "  'networks language',\n",
              "  'detailed machine analysis trained networks',\n",
              "  'secondorder recurrent neural networks',\n",
              "  'small network fit training data'],\n",
              " ['multiclass decision trees multivariate',\n",
              "  'small accurate trees',\n",
              "  'COINS Technical Report',\n",
              "  'variables controlled manner',\n",
              "  'algorithm'],\n",
              " ['evolution physical structure lack general framework Evolution creatures simulation',\n",
              "  'physical simulation model twodimensional Lego structures representation encoding',\n",
              "  'evolutionary techniques design structures',\n",
              "  'quicker test simulation physical production test Buildable results',\n",
              "  'dimensional Lego structures'],\n",
              " ['separate knowledge bases',\n",
              "  'knowledge bases',\n",
              "  'knowledge integration',\n",
              "  'methodology knowledge integration',\n",
              "  'example knowledge bases'],\n",
              " ['evolved robot controllers function',\n",
              "  'work variety real physical robot platforms',\n",
              "  'mobile robots',\n",
              "  'discussion application evolutionary techniques problems',\n",
              "  'simulation techniques'],\n",
              " ['reversible jump MCMC application',\n",
              "  'mechanism guiding proposal choice analysis acceptance probabilities',\n",
              "  'reversible jump',\n",
              "  'jump proposals',\n",
              "  'approximation acceptance probability'],\n",
              " ['query search database',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'online local model local average local regression',\n",
              "  'database experiences resolutions interest',\n",
              "  'multiresolution data structure'],\n",
              " ['apple tasting model enhanced standard model false acceptances',\n",
              "  'natural variant model apple tasting learner',\n",
              "  'standard online model learning algorithm',\n",
              "  'standard model',\n",
              "  'strategy trading false acceptances false rejections'],\n",
              " ['algorithm exploits error distribution',\n",
              "  'error distribution',\n",
              "  'learning algorithm order break domain',\n",
              "  'favor lump error measure',\n",
              "  'ridge errors'],\n",
              " ['large amounts data neural networks',\n",
              "  'neural networks',\n",
              "  'neural network simulation programs',\n",
              "  'neurosimulator targeted networks workstations transputer systems',\n",
              "  'high performance MIMD machine transputer system'],\n",
              " ['learning classifier system CS',\n",
              "  'genetic algorithm system',\n",
              "  'steady state Dynamical adjustment classifiers',\n",
              "  'interplay reward system background',\n",
              "  'original features Mutespec new genetic operator'],\n",
              " ['squared error network amount information weights',\n",
              "  'squared error amount information noisy weights network',\n",
              "  'amount information',\n",
              "  'simple penalizing amount information',\n",
              "  'weights neural network'],\n",
              " ['best preference function',\n",
              "  'preference function',\n",
              "  'online learning algorithm based Hedge algorithm',\n",
              "  'conventional means preference function form PREFu v',\n",
              "  'good linear combination ranking experts'],\n",
              " ['new evolutionary classical algorithms',\n",
              "  'features classical evolutionary methods',\n",
              "  'March Abstract Evolutionary algorithms powerful techniques optimisation',\n",
              "  'relation evolutionary techniques numerical classical search methods',\n",
              "  'evolutionary computation cookbook'],\n",
              " ['hierarchical recursive structure symbol strings',\n",
              "  'encode structure symbol strings',\n",
              "  'structure multiple levels architecture capability',\n",
              "  'multilevel structure complex extended sequences',\n",
              "  'reduced descriptions Hinton string symbols'],\n",
              " ['closest Euclidian distance input vector',\n",
              "  'abstracting lowlevel neural parallel distributed processes',\n",
              "  'neighborhood weight adaptation',\n",
              "  'lateral inhibition weights',\n",
              "  'redundant dimension input vectors'],\n",
              " ['expert agent bias exploration promising directions',\n",
              "  'ability agents',\n",
              "  'significant transfer agents',\n",
              "  'imitating agents',\n",
              "  'learning algorithms'],\n",
              " ['map neural network convolutional neural network',\n",
              "  'invariance minor changes image sample convolutional neural network',\n",
              "  'database images individuals',\n",
              "  'map multilayer perceptron place convolutional network',\n",
              "  'quantization image samples topological space inputs'],\n",
              " ['modified policy iteration algorithm',\n",
              "  'new algorithm',\n",
              "  'modified policy iteration',\n",
              "  'asynchronous nature algorithm convergence general conditions',\n",
              "  'state updating policy'],\n",
              " ['marginal posterior densities',\n",
              "  'marginal posterior density estimators',\n",
              "  'full joint posterior density',\n",
              "  'many dependent observations ratio full joint posterior densities',\n",
              "  'timereversible Markov chain posterior distribution'],\n",
              " ['sample complexity PAC learning presence classification noise',\n",
              "  'PAC learning presence classification noise',\n",
              "  'complexity noisetolerant learning PAC model',\n",
              "  'presence classification noise',\n",
              "  'various general upper bounds'],\n",
              " ['shortsighted development virulence',\n",
              "  'adaptive trait Selection particular level virulence',\n",
              "  'parasite virulence harm',\n",
              "  'simulations study effect modifier genes',\n",
              "  'shortsighted withinhost competition'],\n",
              " ['systematic method computing bounding envelope multivariate monotonic function',\n",
              "  'pressure Semiquantitative methods',\n",
              "  'monotonic functions',\n",
              "  'semiquantitative methods',\n",
              "  'numerical envelopes'],\n",
              " ['various unconventional representations word patterns value difference metrics',\n",
              "  'application MemoryBased Learning problem',\n",
              "  'common benchmark dataset show method',\n",
              "  'MemoryBased Learning stores',\n",
              "  'intelligent similarity metrics number'],\n",
              " ['DMS DMS DMS',\n",
              "  'scientific features sensitivity individual synaptic transmission sites electrochemical stimuli',\n",
              "  'Dr Turner Dr Howard V Wheal Southampton University',\n",
              "  'responses electrochemical stimulation individual neurotransmitter release sites',\n",
              "  'Bayesian analysis substantive concrete problem based work'],\n",
              " ['examples modules',\n",
              "  'NLP tasks',\n",
              "  'MBL',\n",
              "  'machine learning techniques',\n",
              "  'conversion ii partofspeech'],\n",
              " ['boolean threshold functions negation',\n",
              "  'boolean threshold functions',\n",
              "  'class readonce formulas',\n",
              "  'generic transformation Angluin Hellerstein Karpinski',\n",
              "  'convert algorithm'],\n",
              " ['decision tree Markov temporal structure',\n",
              "  'layers decision tree',\n",
              "  'time series model',\n",
              "  'single likely state sequence',\n",
              "  'Accepted oral presentation NIPS'],\n",
              " ['Stochastic simulation algorithms likelihood weighting',\n",
              "  'standard simulation algorithms',\n",
              "  'SOF repopulates set trials time step',\n",
              "  'performance algorithm likelihood',\n",
              "  'paper present simulation algorithms'],\n",
              " ['low energy solution',\n",
              "  'energy Changes',\n",
              "  'lower energy',\n",
              "  'high corresponding liquid molten state large changes',\n",
              "  'Simulated Annealing Search technique single trial solution'],\n",
              " ['small disjuncts error',\n",
              "  'small disjuncts',\n",
              "  'impact small disjuncts',\n",
              "  'problem small disjuncts',\n",
              "  'prone large disjuncts'],\n",
              " ['number equivalence queries',\n",
              "  'minimum number equivalence queries',\n",
              "  'transformation number equivalence queries',\n",
              "  'polynomial number membership queries',\n",
              "  'complete characterization tradeoff number membership equivalence queries'],\n",
              " ['exception rules exception rules exception rule',\n",
              "  'good exception rule sets',\n",
              "  'Rippledown rule sets',\n",
              "  'exception rules',\n",
              "  'global ordering rules'],\n",
              " ['smallest consistent representation k levels rules',\n",
              "  'algorithm learning sets rules',\n",
              "  'consistent concept representation size',\n",
              "  'k levels',\n",
              "  'Boolean attributes infinite attribute space model certain concepts'],\n",
              " ['words dense semantic neighborhood faster words',\n",
              "  'change direction effect abstract words slower words',\n",
              "  'representational methodological issues attractor network model mapping orthography semantics',\n",
              "  'Reaction time model',\n",
              "  'insight interaction hidden output units'],\n",
              " ['associated caching cases construction cost model',\n",
              "  'case memory',\n",
              "  'old cases',\n",
              "  'cached cases',\n",
              "  'cases'],\n",
              " ['conventional Generalized Lloyd Algorithm GLA',\n",
              "  'hybrid Genetic Generalized Lloyd Algorithm GGLA',\n",
              "  'Lloyd Algorithm GLA',\n",
              "  'GaussianMarkov processes speech image source data signaltonoise ratio SNR performance measure',\n",
              "  'various alternative design choices'],\n",
              " ['stored cases memory',\n",
              "  'significant domain engineering complex memory indexing schemes',\n",
              "  'similar planning problems',\n",
              "  'CBP system CaPER',\n",
              "  'specific retrieval stored plans'],\n",
              " ['associated cells rectangular uniform grid Load balancing equipartition constraints',\n",
              "  'comparisons methods',\n",
              "  'efficient method',\n",
              "  'mild assumptions problem size',\n",
              "  'computational results high level parallel Genetic Algorithm'],\n",
              " ['certainty equivalence approximation arising form dual control',\n",
              "  'existing uses exploration bonuses reinforcement',\n",
              "  'Bayesian balance exploration exploitation',\n",
              "  'compute suboptimal estimates',\n",
              "  'two components statistical model uncertainty world way'],\n",
              " ['stronger assumptions finiteness set functions',\n",
              "  'critical points quadratic loss function',\n",
              "  'generic regression data general result',\n",
              "  'analytic functions',\n",
              "  'standard sigmoidal activation'],\n",
              " ['generic models central conceptual change science',\n",
              "  'constructive modeling interpretation reasoning',\n",
              "  'generic modeling',\n",
              "  'constructive modeling',\n",
              "  'constructive modeling interpretation'],\n",
              " ['investigation systematic design method',\n",
              "  'adaptive control',\n",
              "  'development adaptive force controller robot manipulator',\n",
              "  'design neural networks',\n",
              "  'realworld control tasks'],\n",
              " ['local weight adaptation rule',\n",
              "  'information input patterns',\n",
              "  'simple data sets',\n",
              "  'data linear discriminants',\n",
              "  'gradient ascent objective'],\n",
              " ['data processing mode ASOCS',\n",
              "  'ASOCS Adaptive',\n",
              "  'new rule',\n",
              "  'Adaptive Algorithm AA details architecture',\n",
              "  'AA significant memory knowledge maintenance advantages'],\n",
              " ['Markov models',\n",
              "  'mixed memory Markov models',\n",
              "  'large state space',\n",
              "  'state space',\n",
              "  'Cartesian product smaller state spaces'],\n",
              " ['genetic algorithms',\n",
              "  'consequence evaluation single individual genetic algorithm',\n",
              "  'implementation parallel genetic algorithm present case studies',\n",
              "  'meaningful estimate quality strategy',\n",
              "  'use machine learning methods'],\n",
              " ['dynamic topologies dynamic ANNs',\n",
              "  'set locationindependent nodes node computes part network output independent nodes',\n",
              "  'LIT dynamic Backpropagation networks single hidden layer',\n",
              "  'dynamic topologies',\n",
              "  'Neural Networks Backpropagation Implementation Design Dynamic Topologies Reconfigurable Architectures'],\n",
              " ['asynchronous parallel genetic algorithm',\n",
              "  'necessary condition genetic algorithm',\n",
              "  'njob mmachine flowshop problem configurates',\n",
              "  'Hard combinatorial problems',\n",
              "  'subset solutions'],\n",
              " ['multichip module MCM substrate Many current hardware implementations neural network learning models direct implementations classical neural network structuresa large number simple computing nodes',\n",
              "  'SelfOrganizing Concurrent System connectionist models',\n",
              "  'learning model',\n",
              "  'VLSI implementation Priority Adaptive',\n",
              "  'dense number weighted links'],\n",
              " ['application genetic algorithm dynamic job shop problem',\n",
              "  'production scheduling First sketch genetic algorithm handle release',\n",
              "  'job shop',\n",
              "  'nondeterministic optimization problem',\n",
              "  'research topic broad interest Population based approaches'],\n",
              " ['pruning step pruning strength',\n",
              "  'pruning method lprune',\n",
              "  'Neural network pruning methods',\n",
              "  'training pruning',\n",
              "  'severe pruning early training process'],\n",
              " ['new similarity assessment approach couples',\n",
              "  'similarity assessment strategies',\n",
              "  'similarity assessment',\n",
              "  'alternative similarity assessment strategies',\n",
              "  'approach context casebased planning system'],\n",
              " ['different learning mechanisms',\n",
              "  'different learning processes',\n",
              "  'multiple learning methods',\n",
              "  'multiple overlapping knowledge sources',\n",
              "  'learning mechanisms'],\n",
              " ['casebased CBR systems CBR systems',\n",
              "  'casebased components CBR system',\n",
              "  'CBR systems',\n",
              "  'CBR method',\n",
              "  'CBR guide case adaptation similarity assessment'],\n",
              " ['successive small linear programs',\n",
              "  'ndimensional space number points orders',\n",
              "  'finite number steps',\n",
              "  'linear programming constraints',\n",
              "  'fast finitelyterminating linearprogramming algorithm'],\n",
              " ['NETtalk system',\n",
              "  'famous NETtalk system',\n",
              "  'training words system',\n",
              "  'pronunciation whole words pronunciation',\n",
              "  'serious error rate whole words'],\n",
              " ['exact penalty problem',\n",
              "  'misclassifications ii Exact penalty formulation',\n",
              "  'quadratic objective linear constraints',\n",
              "  'stationary point global solution Novel aspects approach',\n",
              "  'ndimensional real space formulated linear program equilibrium'],\n",
              " ['replay multiple planning cases',\n",
              "  'storage retrieval replay planning episodes Planning performance',\n",
              "  'multiple past planning cases',\n",
              "  'justifications planning cases',\n",
              "  'annotated derivations planning cases'],\n",
              " ['human planning accumulation userbuilt plans',\n",
              "  'plan rationale',\n",
              "  'ForMAT ProdigyAnalogy realtime messagepassing mixedinitiative planning system',\n",
              "  'Mixedinitiative planning envisions framework automated human planners',\n",
              "  'Stored plans'],\n",
              " ['network weights region weight space',\n",
              "  'neural networks',\n",
              "  'individual networks independent errors',\n",
              "  'networks',\n",
              "  'backpropagation assumption'],\n",
              " ['algorithms empirical comparisons',\n",
              "  'structural equation models data',\n",
              "  'latent variables models',\n",
              "  'PC IC',\n",
              "  'linear multiple regression'],\n",
              " ['hierarchical method',\n",
              "  'neural network based approximation methods',\n",
              "  'parallel implementation method',\n",
              "  'parallel hierarchical meth ods manyparticle simulations',\n",
              "  'root tree global approximation'],\n",
              " ['Orthogonal incremental learning OIL new approach incremental training feedforward network single hidden layer OIL based idea',\n",
              "  'output weights hidden nodes',\n",
              "  'orthogonal representation network output weights domain',\n",
              "  'orthogonal basis functions',\n",
              "  'special relationship orthogonal backpropagation OBP rule'],\n",
              " ['learning model selection',\n",
              "  'number criteria',\n",
              "  'impact metalevel approaches model selection',\n",
              "  'match applications models',\n",
              "  'potential users machine learning technology'],\n",
              " ['object representation continuous attractors',\n",
              "  'fixed points continuous attractors',\n",
              "  'standard depiction networks state space memories objects',\n",
              "  'continuous pattern manifold appropriate represent objects attractive manifolds',\n",
              "  'recurrent neural network associative memory'],\n",
              " ['working graph coloring problems',\n",
              "  'problem independent constraint handling mechanism',\n",
              "  'general problem independent way',\n",
              "  'constrained problems',\n",
              "  'powerful graph coloring heuristic algorithm'],\n",
              " ['independent components',\n",
              "  'several independent components system',\n",
              "  'independent component negative kurtosis others',\n",
              "  'component',\n",
              "  'approach problem point view single neuron'],\n",
              " ['evidence grids place',\n",
              "  'place recognition experience',\n",
              "  'evidence grids',\n",
              "  'casebased classification augmented registration process correct translations',\n",
              "  'distinct places'],\n",
              " ['normal part learning process',\n",
              "  'distinction constructive nonconstructive methods',\n",
              "  'b process CI',\n",
              "  'constructive induction',\n",
              "  'clean distinction'],\n",
              " ['designing deductive database designer',\n",
              "  'example database',\n",
              "  'techniques area inductive logic programming',\n",
              "  'compact database',\n",
              "  'designer task'],\n",
              " ['different formalisms',\n",
              "  'existing formalisms',\n",
              "  'ordered partition possible worlds',\n",
              "  'unifying framework',\n",
              "  'common basis'],\n",
              " ['sparse training data',\n",
              "  'training time',\n",
              "  'based tests',\n",
              "  'advantage sparseness',\n",
              "  'networks'],\n",
              " ['nondecomposable graphical Gaussian model',\n",
              "  'whole class graphical Gaussian models',\n",
              "  'conditional graphical constraints',\n",
              "  'Bayesian model selection',\n",
              "  'new device sample'],\n",
              " ['direct TD residual gradient TD',\n",
              "  'respect error values',\n",
              "  'TD method poor respect metric',\n",
              "  'approximation optimal respect leastsquares error value function approximation',\n",
              "  'direct TD'],\n",
              " ['previous experiences problem learning control',\n",
              "  'complex phenomena autonomous adaptive control complex systems',\n",
              "  'control tasks',\n",
              "  'various forms control tasks',\n",
              "  'Lazy learning methods'],\n",
              " ['trees Symbolic regression determination function dependence',\n",
              "  'GP elegant useful tool',\n",
              "  'GP performance readability solutions',\n",
              "  'Genetic programming GP variant genetic algorithms data structures',\n",
              "  'size trees'],\n",
              " ['binding sites receptor compounds',\n",
              "  'test compounds',\n",
              "  'compound activity chemical properties aspects structure',\n",
              "  'information complicating data analysis inference',\n",
              "  'heterogeneities site binding mechanisms'],\n",
              " ['complexity target function respect hypothesis model estimation rate',\n",
              "  'rigorous general bound error cross validation',\n",
              "  'analysis generalization error cross validation terms',\n",
              "  'extent hypothesis model',\n",
              "  'consideration approximation rate accuracy target function ideally approximated function number hypothesis parameters estimation rate deviation training generalization errors'],\n",
              " ['expected error model integrating error distribution select model',\n",
              "  'distribution true errors empirical minimizers',\n",
              "  'empirical minimizer hypothesis least empirical error',\n",
              "  'expected true error empirical minimizer model',\n",
              "  'function distribution empirical errors'],\n",
              " ['generalizations implication clause generalizations subsumption call expansion original clause',\n",
              "  'generalization clauses',\n",
              "  'implication clauses',\n",
              "  'Timplication clause',\n",
              "  'Timplication decidable clauses'],\n",
              " ['Bayesian probability theory general method machine',\n",
              "  'learning tasks',\n",
              "  'different types data',\n",
              "  'paper uniform application theory',\n",
              "  'many different types'],\n",
              " ['bias variance decomposition analysis',\n",
              "  'classification error comparison',\n",
              "  'error reduction',\n",
              "  'increasing variance',\n",
              "  'errorcorrecting output codes'],\n",
              " ['collective memory search',\n",
              "  'search problem complexity',\n",
              "  'better collective memory search',\n",
              "  'random search engine',\n",
              "  'GP based search engine'],\n",
              " ['context similarity',\n",
              "  'relevance measures',\n",
              "  'relevance',\n",
              "  'Contrary systems',\n",
              "  'similar items'],\n",
              " ['reactive control system',\n",
              "  'schemabased reactive control system',\n",
              "  'improved performance reactive control system tunes environment',\n",
              "  'selfimproving reactive control system autonomous robotic navigation',\n",
              "  'navigation system experience'],\n",
              " ['good approximator model space realworld domains Results',\n",
              "  'algorithm synthesized problem',\n",
              "  'analyzed simple problem',\n",
              "  'classifier trained offsite',\n",
              "  'neighbor classifier show'],\n",
              " ['response treebased genetic programming take value',\n",
              "  'memorybased program response technique improvement problems',\n",
              "  'experimental results',\n",
              "  'memorybased program',\n",
              "  'One alternative treat specific location indexed memory response value program'],\n",
              " ['sense research multilevel decision tree',\n",
              "  'future topdown induction decision trees',\n",
              "  'absolute terms small difference accuracy R C',\n",
              "  'Holtes recentlypublished article',\n",
              "  'detail parts Holtes'],\n",
              " ['phonetic representation language graphemetophoneme conversion system',\n",
              "  'input spelling words',\n",
              "  'performance knowledgebased alternative dataoriented approaches',\n",
              "  'graphemetophoneme conversion languageindependent',\n",
              "  'output phonetic transcription'],\n",
              " ['density parametric form',\n",
              "  'prior space possible density functions',\n",
              "  'density',\n",
              "  'correct corruption magnetic resonance images',\n",
              "  'differential learning rule'],\n",
              " ['function success probabilities experiments',\n",
              "  'optimal search strategies',\n",
              "  'configuration successes failures',\n",
              "  'probabilistic experiments',\n",
              "  'approximately optimal search strategy success probabilities'],\n",
              " ['map explicit state map',\n",
              "  'corresponding lowdimensional map',\n",
              "  'ansatz tesselation data space',\n",
              "  'The phase transition condition orientation map',\n",
              "  'method'],\n",
              " ['precise framework study adaptive load',\n",
              "  'adaptive load',\n",
              "  'context load',\n",
              "  'basic adaptive behavior parameters',\n",
              "  'naive use communication'],\n",
              " ['bitsback coding cost codewords',\n",
              "  'coding application Bayesian network source model',\n",
              "  'bitsback coding cost',\n",
              "  'nonsynthetic data binary Bayesian network source model',\n",
              "  'shortest codeword symbol'],\n",
              " ['proposed expected utility maximization strategy',\n",
              "  'learning program',\n",
              "  'maximin strategy Experiments popular board game Connect',\n",
              "  'stylized adversarial environments study agent learning strategies',\n",
              "  'opponent action probabilities utility maximization framework exploits'],\n",
              " ['combinatorial nature data generation process',\n",
              "  'Gibbs sampling meanfield approximation',\n",
              "  'learning algorithm',\n",
              "  'ExpectationMaximization EM framework',\n",
              "  'Zemel Hintons'],\n",
              " ['nonlinear transformation estimated sources',\n",
              "  'blind identification source separation',\n",
              "  'mixture matrix recurrent InputOutput IO Identification',\n",
              "  'knowledge mixing matrix',\n",
              "  'estimated regular parameter'],\n",
              " ['source separation algorithm',\n",
              "  'Many source separation algorithms',\n",
              "  'Second show performance invariant algorithms',\n",
              "  'Source separation',\n",
              "  'mixture distribution sources'],\n",
              " ['simple local learning rule',\n",
              "  'local online learning rules',\n",
              "  'extraction source signals',\n",
              "  'additive mixture',\n",
              "  'performance robustness separation'],\n",
              " ['several subordinate prediction algorithms',\n",
              "  'online learning algorithms',\n",
              "  'number experts',\n",
              "  'transform algorithms',\n",
              "  'natural experts'],\n",
              " ['naive Bayesian classifier',\n",
              "  'classification unseen instances',\n",
              "  'current ILP systems',\n",
              "  'stateoftheart attributional learners',\n",
              "  'ILP systems'],\n",
              " ['dynamic simulation problems',\n",
              "  'dynamic nonsmooth process simulation',\n",
              "  'Process simulation',\n",
              "  'linear programming LP dealing problems',\n",
              "  'stability efficiency method'],\n",
              " ['new model autoadaptive behavior individuals',\n",
              "  'genetic algorithms domain optimization',\n",
              "  'ordinary genetic algorithm',\n",
              "  'massivelyparallel genetic algorithm',\n",
              "  'model population member active individual'],\n",
              " ['Proben collection problems',\n",
              "  'neural network',\n",
              "  'neural network training',\n",
              "  'easy access data evaluation algorithms networks',\n",
              "  'neural network learning realm pattern classification function approximation'],\n",
              " ['chess board evaluation functions',\n",
              "  'chess final outcome games',\n",
              "  'artificial neural networks',\n",
              "  'inductive neural network',\n",
              "  'NeuroChess program'],\n",
              " ['similar cases upper level',\n",
              "  'large scale memory base',\n",
              "  'cases organised groups',\n",
              "  'simple efficient indexing system structure',\n",
              "  'case hierarchy'],\n",
              " ['PAClearning concept class geometric patterns',\n",
              "  'concept class geometric patterns landmark recognition problem',\n",
              "  'PAClearns class onedimensional geometric patterns',\n",
              "  'geometric pattern configuration k',\n",
              "  'target pattern'],\n",
              " ['classifier maximizing measure function',\n",
              "  'possible state learning problem computational problem',\n",
              "  'measure function',\n",
              "  'measure functions',\n",
              "  'explicit relevant prior knowledge learning problem hand ii'],\n",
              " ['Recurrent attractor networks',\n",
              "  'recurrent networks',\n",
              "  'intermediate output representations Attractor networks',\n",
              "  'feedforward networks',\n",
              "  'serious problems networks'],\n",
              " ['many tree induction algorithms',\n",
              "  'tree simplification',\n",
              "  'good classification accuracy tree simplification',\n",
              "  'application tree induction algorithms case retrieval casebased reasoning systems',\n",
              "  'simpler comprehensible trees data structures'],\n",
              " ['cusum path plot',\n",
              "  'cusum path plot effective tool convergence diagnostics Markov sampler',\n",
              "  'Markov sampler',\n",
              "  'paper propose monitor Markov chain sampler',\n",
              "  'sample space direction summary statistic'],\n",
              " ['Bayesian image restoration Convergence Gibbs sampler Ising model Markov chain Monte Carlo',\n",
              "  'Gibbs sampler',\n",
              "  'precise easy compute bounds convergence time',\n",
              "  'Bayesian image reconstruction',\n",
              "  'proportionality constant easy calculate'],\n",
              " ['deterministic OT CN approximation maximum posterior MAP state estimation',\n",
              "  'OT N C naive Cartesian product exact state clustering stochastic Monte Carlo methods',\n",
              "  'multiple state variables',\n",
              "  'highest probability paths compact state trellis',\n",
              "  'OT N C'],\n",
              " ['Bayesian analysis agricultural field experiments topic',\n",
              "  'hierarchicalt formulations',\n",
              "  'Markov chain Monte Carlo',\n",
              "  'little previous attention',\n",
              "  'fertility patterns'],\n",
              " ['finite Markov chains',\n",
              "  'finite Markov chain',\n",
              "  'paper continuous state space Markov chains',\n",
              "  'parallel chains',\n",
              "  'subsample continuous chain renewal times related small sets'],\n",
              " ['claim crossover operator acting parallel population chains',\n",
              "  'population chains',\n",
              "  'multiple chains parallel Updates individual chains',\n",
              "  'genetic style crossover operator acting parent states',\n",
              "  'Markov chain Monte Carlo MCMC samplers'],\n",
              " ['QMR DT network practical diagnostic tool',\n",
              "  'QMR network',\n",
              "  'diagnostic inference QMRDT database',\n",
              "  'standard diagnostic cases',\n",
              "  'fast diagnostic inference'],\n",
              " ['solution problem RBF networks',\n",
              "  'neural networks topology performance',\n",
              "  'two determinant parameters networks layout number centroids centroids',\n",
              "  'optimal configurations',\n",
              "  'Empirical results'],\n",
              " ['Candidate feature subsets',\n",
              "  'genetic algorithms decision tree learning order',\n",
              "  'useful subsets discriminatory features',\n",
              "  'fitness underlying feature subset',\n",
              "  'decision tree'],\n",
              " ['behavior humancomputer system crisis response',\n",
              "  'INCAs strategy retrieving case case library seeding initial schedule',\n",
              "  'behavior mixedinitiative system experiments',\n",
              "  'intelligent assistant planning scheduling domain relation human users',\n",
              "  'automaticallygenerated schedules'],\n",
              " ['reactive rules',\n",
              "  'high performance reactive rules',\n",
              "  'reactive plans',\n",
              "  'rules',\n",
              "  'adequate simulation model task environment payoff function measures quality partially successful plans'],\n",
              " ['robots highlevel processing planning capabilities',\n",
              "  'route records mobile robot Perception action',\n",
              "  'machine learning robotics',\n",
              "  'action highlevel representation planning',\n",
              "  'communication robot human user'],\n",
              " ['various methods',\n",
              "  'established method',\n",
              "  'particular emphasis implementational issues',\n",
              "  'Markov Chain Monte Carlo algorithms',\n",
              "  'Markov Chain Monte Carlo'],\n",
              " ['use time derivatives position object manipulator controller',\n",
              "  'track moving object',\n",
              "  'approximated feedforward neural network',\n",
              "  'several anticipative controllers',\n",
              "  'next position'],\n",
              " ['covariance information effective heuristic build predictive causal models',\n",
              "  'Covariance information help',\n",
              "  'usual contemporary causal induction',\n",
              "  'difficult regression algorithms',\n",
              "  'predictive causal models'],\n",
              " ['target environment decision rules',\n",
              "  'decision rules',\n",
              "  'genetic algorithms search space decision policies',\n",
              "  'tactical decision',\n",
              "  'differences simulation model learning'],\n",
              " ['learning concept',\n",
              "  'learning method use',\n",
              "  'useful information concepts domain',\n",
              "  'MFOCL Horn clause relational learning algorithm',\n",
              "  'concepts domain'],\n",
              " ['radial basis function networks recurrent networks',\n",
              "  'neural networks statistical perspective choice',\n",
              "  'feedforward neural networks',\n",
              "  'neural network',\n",
              "  'Many issues'],\n",
              " ['inductive causation',\n",
              "  'contrary common folklore genuine causal influences',\n",
              "  'modeltheoretic definition causation',\n",
              "  'complete characterization conditions distinction',\n",
              "  'large class data structures'],\n",
              " ['lower bound run time present algorithm meeting',\n",
              "  'run time model network',\n",
              "  'study points bottleneck network interface',\n",
              "  'performance alternative interface',\n",
              "  'CNS'],\n",
              " ['descriptive contextsensitive knowledge',\n",
              "  'categorical uncertain knowledge network formalism',\n",
              "  'contextsensitive variations',\n",
              "  'basic representation constructs',\n",
              "  'potential applications framework'],\n",
              " ['bootstrap methods',\n",
              "  'number methods',\n",
              "  'delta method',\n",
              "  'based Hessian bootstrap estimators sandwich estimator',\n",
              "  'variability due choice'],\n",
              " ['j j x n j',\n",
              "  'x j j n gaussian noise terms',\n",
              "  'Dirichlet mixture mixtures',\n",
              "  'prior G Dirichlet process',\n",
              "  'Dirichlet process'],\n",
              " ['use time derivatives position object manipulator controller',\n",
              "  'next position object',\n",
              "  'track moving object',\n",
              "  'manipulator lags',\n",
              "  'able position handheld camera'],\n",
              " ['AA Adaptive Algorithm',\n",
              "  'AA Adaptive Algorithm model',\n",
              "  'AA actual data',\n",
              "  'Adaptive Self Organizing Concurrent Systems approach',\n",
              "  'AA'],\n",
              " ['discrete sources',\n",
              "  'discrete source signals',\n",
              "  'noisy mixture independent sources',\n",
              "  'separate sources sensors',\n",
              "  'Gaussian noise covariance matrix additive noise treated parameter'],\n",
              " ['diagnosticrecovery procedure',\n",
              "  'systems health degrades',\n",
              "  'supervised learning procedure empirical riskbenefit measure',\n",
              "  'health system',\n",
              "  'procedure'],\n",
              " ['Case combination',\n",
              "  'case combination',\n",
              "  'subsequent case combination',\n",
              "  'much retrieved case information',\n",
              "  'case constraint satisfaction problem'],\n",
              " ['CBR CSP',\n",
              "  'CSP CBR',\n",
              "  'DCSP case adaptation',\n",
              "  'CSP techniques',\n",
              "  'CaseBased Reasoning CBR community working techniques'],\n",
              " ['PAC analysis determinations type relevance knowledge',\n",
              "  'usefulness analysis based PAC model',\n",
              "  'Prior knowledge bias',\n",
              "  'semantic bias domain theory concept',\n",
              "  'concept speed task'],\n",
              " ['parameter values global vegetation model',\n",
              "  'values free parameters',\n",
              "  'predictive accuracy models',\n",
              "  'structure model',\n",
              "  'new divideandconquer approach subsets parameters'],\n",
              " ['situation learners testing set',\n",
              "  'account frequency virtual seens',\n",
              "  'virtual seens',\n",
              "  'derive normalising baseline generalisation statistics',\n",
              "  'close approximations cases'],\n",
              " ['conversational case libraries',\n",
              "  'Abstract Conversational casebased reasoning CBR systems',\n",
              "  'large case libraries',\n",
              "  'difficult CBR vendors',\n",
              "  'query description userdirected conversation'],\n",
              " ['missing data database',\n",
              "  'possible initial information new information',\n",
              "  'joint probability distribution data case database mixture models',\n",
              "  'system based machine learning domain',\n",
              "  'heart disease database'],\n",
              " ['function weights',\n",
              "  'hidden layers sigmoid transfer function',\n",
              "  'binary vectors',\n",
              "  'sum squared errors',\n",
              "  'local minimum global minimum'],\n",
              " ['credulous version default theory',\n",
              "  'default theory',\n",
              "  'credulous theory highest expected accuracy R',\n",
              "  'accuracy probability answer',\n",
              "  'related credulous theories'],\n",
              " ['short elegant general solutions genetic programming system variable length',\n",
              "  'basis analysis effects suggestions',\n",
              "  'inherent compression pressure',\n",
              "  'visible size complexity solutions',\n",
              "  'negative implications order'],\n",
              " ['optimal populations representations populations',\n",
              "  'recent XCS classifier system',\n",
              "  'optimal populations boolean multiplexer problems',\n",
              "  'XCS systems',\n",
              "  'classifier system'],\n",
              " ['Current rule induction systems',\n",
              "  'separate conquer strategy learning rule',\n",
              "  'systems accuracy',\n",
              "  'Rise system Empirical comparison',\n",
              "  'successive rules'],\n",
              " ['architecture connection weights multilayer feedforward neural networks',\n",
              "  'optimal tradeoff error fitting ability parsimony network',\n",
              "  'complexity study convergence scaling properties',\n",
              "  'principle Occams razor',\n",
              "  'nextascent hillclimbing search'],\n",
              " ['human subjects',\n",
              "  'human subjects judgements',\n",
              "  'human responses emotional expressions',\n",
              "  'American subjects facial expressions',\n",
              "  'categorical nature human responses'],\n",
              " ['inputoutput behaviour process tool based block oriented approach transparent description signal paths',\n",
              "  'tool automatic generation structured models complex dynamic processes',\n",
              "  'basic concept SMOG Structured MOdel Generator',\n",
              "  'genetic programming',\n",
              "  'appropriate arithmetic expression order'],\n",
              " ['simple genetic algorithm',\n",
              "  'degree dynamic ranking induced simple genetic algorithm highly correlated degree static ranking inherent function',\n",
              "  'metric measuring degree ranking',\n",
              "  'role hyperplane ranking search',\n",
              "  'genetic search'],\n",
              " ['roles crossover mutation roles',\n",
              "  'mutation sense',\n",
              "  'important characteristics operator',\n",
              "  'large body conventional wisdom',\n",
              "  'answers questions'],\n",
              " ['discrete continuous attributes',\n",
              "  'discrete continuous form',\n",
              "  'discrete attributes',\n",
              "  'different attributes',\n",
              "  'Tree Augmented Naive Bayes TAN'],\n",
              " ['systems processes',\n",
              "  'natural representation certain system characteristics',\n",
              "  'dynamic Bayesian networks objectoriented Bayesian network framework show language',\n",
              "  'different rate others systems processes',\n",
              "  'many real life systems fact processes'],\n",
              " ['optimal neural network size particular application Constructive destructive methods',\n",
              "  'simple constructive training method',\n",
              "  'subtract neurons layers connections',\n",
              "  'certain finite state automata',\n",
              "  'neurons training'],\n",
              " ['several weighting methods',\n",
              "  'many cases method',\n",
              "  'weighting methods',\n",
              "  'new weighting method based statistical technique',\n",
              "  'numeric attributes'],\n",
              " ['linear systems subject control saturation',\n",
              "  'General Result Stabilization Linear Systems Using Bounded Controls',\n",
              "  'positive real part standard stabilizability rank condition',\n",
              "  'linear maps saturations',\n",
              "  'Bounded Controls ABSTRACT'],\n",
              " ['high dimensional problems complex nonstationary signal space current Seismic Classification problem',\n",
              "  'multiple Ensembles ANNs',\n",
              "  'correct classifications seismic test data Cross Validation evaluations comparisons',\n",
              "  'seismic signals',\n",
              "  'classification problem'],\n",
              " ['hearty hospitality Paris sabbatical part chapter',\n",
              "  'Washington Seattle WA USA Sylvia Richardson Directeur de Recherche INSERM',\n",
              "  'Sylvia Richardson Directeur de Recherche',\n",
              "  'Strangl Adrian E Raftery Professor Statistics Sociology Department',\n",
              "  'excellent research assistance Mariette Gerber Michel Chavance'],\n",
              " ['user static dynamic preferences known system',\n",
              "  'schedule quality incorporating user',\n",
              "  'acquisition user optimization',\n",
              "  'schedule revision guide schedule improvement',\n",
              "  'practical scheduling problems'],\n",
              " ['emphasis evolution fuzzy coordination rules',\n",
              "  'addition approach behavior coordination',\n",
              "  'Realization autonomous behavior mobile robots',\n",
              "  'Such collection rules',\n",
              "  'GP evident performance results'],\n",
              " ['influence combination model show model',\n",
              "  'combination model mixture model principle component analysis',\n",
              "  'combination model examples',\n",
              "  'approximated combination model',\n",
              "  'distribution model binary vectors'],\n",
              " ['simplicity collective action pattern detection collective memory',\n",
              "  'social insects colonies integration actions',\n",
              "  'Dorigo et al Collective memory',\n",
              "  'test role society information center',\n",
              "  'simple redundant individual insects'],\n",
              " ['similar inverse square root bound VapnikChervonenkis theory Tighter nonuniversal learning curve bounds',\n",
              "  'annealed theories',\n",
              "  'universal learning curve',\n",
              "  'concept class finite cardinality',\n",
              "  'onestep replica symmetry breaking'],\n",
              " ['underwater sonar targets nearfield bearing range estimation case large passive arrays',\n",
              "  'method location target',\n",
              "  'genetic algorithm operational requirement acceptable accuracy',\n",
              "  'position maximum weighted sum output sensors',\n",
              "  'problem search optimization'],\n",
              " ['CIbased learning agent',\n",
              "  'constructive inductionbased learning agent CILA',\n",
              "  'CI learning method Selective induction SI learning methods agents',\n",
              "  'useful SIbased learning agent',\n",
              "  'agent domains poor representations'],\n",
              " ['measure amount order selforganising map show',\n",
              "  'computational complexity',\n",
              "  'introduced algorithm',\n",
              "  'Nneuron network N samples',\n",
              "  'N ON'],\n",
              " ['datadriven restriction encoded algorithm modelbased restrictions',\n",
              "  'Inductive learning relational domains',\n",
              "  'hypothesis space',\n",
              "  'Incy inductive learner',\n",
              "  'intractable general Many approaches task'],\n",
              " ['training environment noisy target environment',\n",
              "  'target environment decision rules',\n",
              "  'target environment',\n",
              "  'less noise target environment',\n",
              "  'training environment'],\n",
              " ['important capability autonomous underwater vehicles',\n",
              "  'highperformance reactive strategies navigation collision avoidance',\n",
              "  'realtime performance',\n",
              "  'Navigation obstacles',\n",
              "  'robust behavior'],\n",
              " ['VC theory',\n",
              "  'wellestablished VapnikChervonenkis theory',\n",
              "  'many concrete examples',\n",
              "  'true behavior functional form',\n",
              "  'curve bounds'],\n",
              " ['deterministic contextfree languages eg n b n parenthesis languages examples',\n",
              "  'language inference automata induction',\n",
              "  'nontrivial languages',\n",
              "  'Neural Network Pushdown Automaton NNPDA model',\n",
              "  'knowledge task data'],\n",
              " ['analogous used Boltzmann machines',\n",
              "  'sigmoid feedforward network faster Boltzmann machine',\n",
              "  'feedforward nature connections negative phase Boltzmann machine',\n",
              "  'Boltzmann machines',\n",
              "  'link work connectionist learning work representation expert knowledge'],\n",
              " ['size generalization modularity issues programs',\n",
              "  'size generality issues',\n",
              "  'GP search Size',\n",
              "  'variable size representations programs',\n",
              "  'standard GP GP'],\n",
              " ['relationship Pearls representation cause effect',\n",
              "  'added clarity notion cause',\n",
              "  'canonical form',\n",
              "  'effect terms',\n",
              "  'traditional view causation'],\n",
              " ['fuzzy logic controllers',\n",
              "  'Fuzzy logic evolutionary computation',\n",
              "  'controller mobile robot path',\n",
              "  'intelligent control systems',\n",
              "  'control systems'],\n",
              " ['nonparametric estimation distribution function estimation regression models',\n",
              "  'time semiparametric regression models',\n",
              "  'profile likelihood maximization semiparametric likelihood distributional results maximum likelihood estimators',\n",
              "  'computation regression parameter estimators',\n",
              "  'calculation Fisher information regression parameters'],\n",
              " ['genetic programming statistical inference problem',\n",
              "  'class fitness functions error complexity terms',\n",
              "  'realworld medical diagnosis problem',\n",
              "  'induction sigmapi neural networks',\n",
              "  'neural network synthesis'],\n",
              " ['OSN time algorithm',\n",
              "  'OSN space time N total length observation sequence S state space size time step',\n",
              "  'OS log N space OSN log N time',\n",
              "  'long observation sequences',\n",
              "  'time step'],\n",
              " ['optimism pessimism regard informativeness',\n",
              "  'cases optimism',\n",
              "  'optimism utility derived rules',\n",
              "  'Pessimism implicit hypothesis testing',\n",
              "  'Fisher Schlimmer Schaffer'],\n",
              " ['longterm dependencies sequential data difficult deterministic dynamical systems recurrent networks probabilistic models',\n",
              "  'domain specific apriori knowledge',\n",
              "  'hidden state variables',\n",
              "  'hidden Markov models',\n",
              "  'longterm dependencies'],\n",
              " ['flat minimum error function',\n",
              "  'Gibbs algorithm variant novel way splitting generalization error underfitting overfitting error',\n",
              "  'pseudo code algorithm',\n",
              "  'low complexity neural networks high generalization capability',\n",
              "  'new algorithm'],\n",
              " ['new reactive rules explanations',\n",
              "  'set new reactive rules',\n",
              "  'reactive rules',\n",
              "  'new rules',\n",
              "  'explanation phase'],\n",
              " ['cooperate form neural network problemspecific knowledge',\n",
              "  'chronological backtrack search',\n",
              "  'well domains heuristic information',\n",
              "  'good valueordering strategies',\n",
              "  'random ordering backtracks'],\n",
              " ['case libraries',\n",
              "  'library design guidelines',\n",
              "  'knowledge cases',\n",
              "  'knowledge engineering bottleneck refocus case engineering task',\n",
              "  'design guidelines implementation Clire empirical results'],\n",
              " ['computational model movement skill',\n",
              "  'speedaccuracy tradeoffone robust phenomena human motor behavior',\n",
              "  'human behavior',\n",
              "  'models performance',\n",
              "  'observation improved practice'],\n",
              " ['environment Qlearning classifier systems CS',\n",
              "  'Qlearning classifier systems show experience',\n",
              "  'classifier system',\n",
              "  'discounted max simple classifier system D MAX VSCS',\n",
              "  'CS deriving equivalence Qlearning internal states'],\n",
              " ['forming compact codings data distributions',\n",
              "  'compact coding',\n",
              "  'sparse coding',\n",
              "  'artificial neural network self organises',\n",
              "  'sensitive sparse distributed codes'],\n",
              " ['certain classes analytic functions',\n",
              "  'open sets samples length',\n",
              "  'piecewiseanalytic functions',\n",
              "  'neural networks',\n",
              "  'n parameters'],\n",
              " ['methodology evaluation casebased reasoning systems',\n",
              "  'best system configuration',\n",
              "  'computer system',\n",
              "  'impact performance system',\n",
              "  'system'],\n",
              " ['abstract knowledge planning fit specific planning situations',\n",
              "  'abstract cases',\n",
              "  'incommensurate representations planning situations',\n",
              "  'extent cases memory',\n",
              "  'fit wide range new situations'],\n",
              " ['MLE regression parameter',\n",
              "  'MLE infinite dimensional parameter',\n",
              "  'MLE finite dimensional parameter class semiparametric models',\n",
              "  'MLE baseline cumulative hazard function',\n",
              "  'MLE'],\n",
              " ['PO Box Wellington New Zealand Tel Fax Internet TechReportscompvuwacnz Technical Report CSTR',\n",
              "  'Fax Internet TechReportscompvuwacnz Technical Report CSTR October',\n",
              "  'paper present efficient solution second problem',\n",
              "  'storys recommendations',\n",
              "  'abstract advice'],\n",
              " ['reparameterisation secondary components mixture terms',\n",
              "  'reparameterisation link secondary components',\n",
              "  'need efficient estimation mixture distributions',\n",
              "  'representation modelling stage reparameterisation important bearing',\n",
              "  'paper Bayesian noninformative approach estimation'],\n",
              " ['interfaces document retrieval email servers',\n",
              "  'automatic formprocessing techniques developed email servers',\n",
              "  'load servers',\n",
              "  'interfaces systems inductive rule',\n",
              "  'presentationbased interfaces sophisticated form processing'],\n",
              " ['model uncertainty',\n",
              "  'Survival analysis concerned finding models',\n",
              "  'account model uncertainty',\n",
              "  'standard Bayesian model averaging solution problem',\n",
              "  'single model'],\n",
              " ['best subsets linear model',\n",
              "  'different bootstrap samples',\n",
              "  'individual bootstrap samples',\n",
              "  'bootstrapbased method model',\n",
              "  'model'],\n",
              " ['Arcing algorithms',\n",
              "  'existing arcing algorithms',\n",
              "  'maximum error training',\n",
              "  'generalization error',\n",
              "  'maximum error'],\n",
              " ['approach context CCBR system',\n",
              "  'integrated reasoning approach modelbased reasoning component',\n",
              "  'important inferencing role conversational casebased reasoning CCBR system',\n",
              "  'implications problem description unanswered questions',\n",
              "  'interactive casebased reasoning users'],\n",
              " ['readonce formulas',\n",
              "  'exact identification general readonce formulas',\n",
              "  'exact identification monotone readonce formulas',\n",
              "  'membership queries equivalence queries',\n",
              "  'unknown readonce formula'],\n",
              " ['distributed patterns',\n",
              "  'Recursive AutoAssociative Memory RAAM structures',\n",
              "  'simple Elmanstyle recurrent network Tr aining',\n",
              "  'collection hierarchical structures',\n",
              "  'training patterns'],\n",
              " ['distribution learning algorithm variable memory length',\n",
              "  'applicability algorithm',\n",
              "  'KLdivergence distribution',\n",
              "  'motivated real applications manmachine interaction handwriting speech recognition',\n",
              "  'small high confidence polynomial time sample complexity'],\n",
              " ['focuss semantics logical problem specification claudien discovery algorithm',\n",
              "  'regularities data representative inductive logic programming paradigm',\n",
              "  'first order clausal theories',\n",
              "  'larger attribute value representation claudien',\n",
              "  'aim show claudien'],\n",
              " ['current inductive machine learning algorithms',\n",
              "  'inductive learning algorithms',\n",
              "  'several artificial several real world problems',\n",
              "  'RELIEF algorithm',\n",
              "  'dependencies attributes'],\n",
              " ['case chaotic time series prediction representation',\n",
              "  'chaotic time series prediction',\n",
              "  'previous work GP time series prediction',\n",
              "  'Genetic Programming operators',\n",
              "  'Genetic Programmings flexible tree structure particular problem'],\n",
              " ['variables variable dependency tree',\n",
              "  'significant relationships training objects',\n",
              "  'growth training set',\n",
              "  'ILPR system heuristic',\n",
              "  'beam candidate literals'],\n",
              " ['regressional variant RReliefF deal regression problems',\n",
              "  'ReliefF used estimate utility literals',\n",
              "  'classification problems',\n",
              "  'multiclass problems',\n",
              "  'Kira Rendell Kira Rendell ab'],\n",
              " ['paper present TDLeaf variation TD algorithm',\n",
              "  'rating rating games',\n",
              "  'Free Internet Chess Server FICS ficsonenetnet',\n",
              "  'chess backgammon',\n",
              "  'reasons success relationship'],\n",
              " ['sequential estimator',\n",
              "  'unknown approximated sequential estimator density',\n",
              "  'sequential estimator energy',\n",
              "  'new simulated annealing algorithm',\n",
              "  'MetropolisHastings Kernel'],\n",
              " ['principal component analysis PCA representation face recognition',\n",
              "  'ICA representation greater invariance changes',\n",
              "  'combined temporal filter basic Hebbian update rule',\n",
              "  'independent component analysis ICA',\n",
              "  'visual experience biological system'],\n",
              " ['fitted regression functions',\n",
              "  'smoothing parameter estimation assessment uncertainties regression functions',\n",
              "  'predictive inference flexible class mixture models',\n",
              "  'similar generalised kernel regression estimates',\n",
              "  'theoretical basis semiparametric regression methods'],\n",
              " ['multipoint crossover operators',\n",
              "  'point crossover operators standard mechanisms',\n",
              "  'higher number crossover points',\n",
              "  'traditional theoretical point view',\n",
              "  'average L crossover points strings length L'],\n",
              " ['Mixture Density Networks MDN discriminant analysis MDN models',\n",
              "  'classification interpretive aspects discriminant analysis',\n",
              "  'restricted particular case hand applicable applications discriminant',\n",
              "  'MDN approach',\n",
              "  'viable alternative classification procedure'],\n",
              " ['performance SASAT test suite satisfiability problems',\n",
              "  'satisfiability problems',\n",
              "  'basic SASAT algorithm',\n",
              "  'SASAT GSAT',\n",
              "  'based random walk implemented GSAT Selman et al'],\n",
              " ['discretization method',\n",
              "  'discretization methods',\n",
              "  'existing entropybased discretization algorithm',\n",
              "  'entropybased methods',\n",
              "  'computational complexity method'],\n",
              " ['first n components',\n",
              "  'first output terms',\n",
              "  'last n components',\n",
              "  'equivalent first n output terms',\n",
              "  'inputs outputs'],\n",
              " ['Systems Control',\n",
              "  'ffi N ffi gt N',\n",
              "  'ffi jyj ev N',\n",
              "  'Int J Control',\n",
              "  'controllability linear systems'],\n",
              " ['gross errors data reconciliation',\n",
              "  'data reconciliation dynamic systems appropriate problem formulations',\n",
              "  'vital role parameter estimation data reconciliation dynamic steady state systems',\n",
              "  'measured variables physical model nonredundant variable measured variable estimated measurements',\n",
              "  'paper concentrate robust estimators exploratory statistical methods'],\n",
              " ['class hierarchy',\n",
              "  'given hierarchy base classes',\n",
              "  'worldwideweb documents topic hierarchies',\n",
              "  'hierarchy',\n",
              "  'large number categories'],\n",
              " ['decision tree data',\n",
              "  'decision tree',\n",
              "  'unpruned decision tree',\n",
              "  'First large decision tree',\n",
              "  'overfitting second phase tree'],\n",
              " ['boolean combination polynomial number concepts selected concept class C lt',\n",
              "  'PAClearning general class geometric concepts',\n",
              "  'concept C',\n",
              "  'concepts',\n",
              "  'statistical query version algorithm'],\n",
              " ['new criteria',\n",
              "  'criteria',\n",
              "  'uniform convergence VapnikChervonenkis dimension',\n",
              "  'current method',\n",
              "  'based theoretical concepts'],\n",
              " ['probabilistic methods comparable methods prediction quality',\n",
              "  'global structure Windowbased methods support experimentation',\n",
              "  'framework problem protein secondary structure prediction',\n",
              "  'paper study performance probabilistic networks context protein sequence analysis',\n",
              "  'different networks'],\n",
              " ['bounds error leaveoneout estimate',\n",
              "  'sanitycheck bounds error leaveoneout crossvalidation estimate generalization error bounds',\n",
              "  'new weaker notion error stability',\n",
              "  'worstcase error estimate',\n",
              "  'necessity form error stability'],\n",
              " ['state world',\n",
              "  'similar previous state',\n",
              "  'actor order support',\n",
              "  'behaviour actors',\n",
              "  'simulated world'],\n",
              " ['strict interface definitions roles system',\n",
              "  'Genetic Programming techniques domainindependent problem',\n",
              "  'GP system',\n",
              "  'good underlying software structure',\n",
              "  'loose collection software components'],\n",
              " ['arguments coevolution different adaptive protean behaviors competing species predators',\n",
              "  'proximity sensors predator additional vision module',\n",
              "  'coevolutionary dynamics preys',\n",
              "  'prey maximum speed',\n",
              "  'predators'],\n",
              " ['networks radial basis units',\n",
              "  'arbitrary activation functions networks error functions instance connections',\n",
              "  'h number hidden units network',\n",
              "  'connectionist networks elimination',\n",
              "  'second derivatives'],\n",
              " ['treat programs syntactical structures',\n",
              "  'Structure Mapping Engine existing system',\n",
              "  'functional program synthesis',\n",
              "  'structures',\n",
              "  'metric determining distance'],\n",
              " ['accurate generalization training set data wide variety applications',\n",
              "  'several generalization styles',\n",
              "  'potential provide accurate generalization',\n",
              "  'prototype styles generalization',\n",
              "  'several realworld applications'],\n",
              " ['continuoustime recurrent dynamic neural networks sigmoidal activation',\n",
              "  'universal approximation properties Known characterizations controllability observability parameter identifiability',\n",
              "  'fl Supported part US Air Force Grant AFOSR',\n",
              "  'computational power recurrent nets',\n",
              "  'US Air Force'],\n",
              " ['set locationindependent nodes node computes part network output independent nodes',\n",
              "  'Location Independent ASOCS LIA model',\n",
              "  'dynamic topologies',\n",
              "  'basic ASOCS mechanisms definitions',\n",
              "  'fixed topology learning'],\n",
              " ['optimal solution prediction Markov chains',\n",
              "  'single optimal solution Bellman equation',\n",
              "  'Markov chains MDPs infinite states',\n",
              "  'case Bellman equation',\n",
              "  'Bellman equation'],\n",
              " ['structural indices design cases',\n",
              "  'vocabulary structural indexing design cases',\n",
              "  'prior design cases',\n",
              "  'appropriate cases memory',\n",
              "  'knowledge Irrespective type indexing structural functional hierarchical organization case memory'],\n",
              " ['abstract movement concepts appropriate component structure',\n",
              "  'components single complex movement',\n",
              "  'movement',\n",
              "  'movements',\n",
              "  'OXBOW unsupervised learning system'],\n",
              " ['best representation space',\n",
              "  'better representation space',\n",
              "  'original representation space predictive accuracy rule simplicity',\n",
              "  'best hypothesis space',\n",
              "  'datadriven constructive induction'],\n",
              " ['small subset data base',\n",
              "  'small subsets data base',\n",
              "  'data important solution',\n",
              "  'available data',\n",
              "  'classifier best generalization ability'],\n",
              " ['representative example reconstruction problem different methods',\n",
              "  'minimal achievable reconstruction errors',\n",
              "  'Physical variables orientation line visual field location body space coded activity levels populations neurons Reconstruction',\n",
              "  'different methods',\n",
              "  'reconstruction analysis'],\n",
              " ['slight asymmetry weights activity profile shift',\n",
              "  'static activity profile network dynamic shift mechanism',\n",
              "  'synaptic weight distribution components',\n",
              "  'specific onedimensional example computational mechanism',\n",
              "  'instantaneous head direction animal horizontal plane'],\n",
              " ['zeroone misclassification loss functions',\n",
              "  'practice naive frequencybased estimation decomposition terms',\n",
              "  'loss function',\n",
              "  'decomposition',\n",
              "  'learning algorithms'],\n",
              " ['f g u r b l e f e l programmable gate arrays FPGAs',\n",
              "  'p r b l e w h evolutionary algorithms task',\n",
              "  'possiblity e b n g individual evolving population hardware purpose',\n",
              "  'r e c',\n",
              "  'n n'],\n",
              " ['Ax b p k',\n",
              "  'Ax b p k Numerical tests',\n",
              "  'optimal solution specific number nonzero elements',\n",
              "  'Ax b p corruption p',\n",
              "  'superior orders magnitude solutions'],\n",
              " ['Foldiak feedforward system recurrent system',\n",
              "  'interaction temporal smoothing activity',\n",
              "  'Hopfield network lowpass temporal filter unit activities',\n",
              "  'different views object face',\n",
              "  'close temporal proximity'],\n",
              " ['Neural networks',\n",
              "  'neural networks',\n",
              "  'data mining neural networks',\n",
              "  'wide range supervised unsupervised learning applications Neuralnetwork methods',\n",
              "  'simple easytounderstand networks'],\n",
              " ['crossvalidation stopping answer question',\n",
              "  'asymptotic gain generalization error',\n",
              "  'CM nice agreement analytical findings',\n",
              "  'KullbackLeibler loss asymptotic case',\n",
              "  'generalization error'],\n",
              " ['new problems',\n",
              "  'improved generalization leaner models',\n",
              "  'lean model',\n",
              "  'useful tool knowledge discovery databases',\n",
              "  'better new unseen data Computational results'],\n",
              " ['search space',\n",
              "  'stochastic search space concept descriptions',\n",
              "  'stochastic search method',\n",
              "  'search space concept descriptions',\n",
              "  'heuristic pruning search space method'],\n",
              " ['local selection algorithms',\n",
              "  'particular type local selection algorithm',\n",
              "  'local neighborhood models',\n",
              "  'parallel small overlapping neighborhoods',\n",
              "  'variety evolutionary algorithms EAs population'],\n",
              " ['ambiguous qualitative relationships',\n",
              "  'qualitative relationship nodes',\n",
              "  'qualitative relationships question',\n",
              "  'random variables tighter bounds qualitative relationships',\n",
              "  'qualitative numeric probabilistic reasoning'],\n",
              " ['cooperative distribution',\n",
              "  'Gaussian constrained nonnegative enabling use nonconvex energy functions',\n",
              "  'potential rectified Gaussian modeling pattern',\n",
              "  'translations pattern',\n",
              "  'Gaussian'],\n",
              " ['novel fast algorithm',\n",
              "  'new algorithm',\n",
              "  'algorithm',\n",
              "  'blind source separation feature extraction',\n",
              "  'neural network learning rule'],\n",
              " ['seminal work minimal entropy codes',\n",
              "  'optimal minimal entropy',\n",
              "  'BCM learning rule',\n",
              "  'probability events',\n",
              "  'suspicious events'],\n",
              " ['best representation space',\n",
              "  'better representation space',\n",
              "  'original representation space predictive accuracy rule simplicity',\n",
              "  'best hypothesis space',\n",
              "  'datadriven constructive induction'],\n",
              " ['attribute quality regression classification',\n",
              "  'quality attributes',\n",
              "  'adaptation regression continuous class problems',\n",
              "  'quality',\n",
              "  'domains strong dependencies'],\n",
              " ['Inductive Logic Programming',\n",
              "  'Logic Programming Machine Learning',\n",
              "  'new area',\n",
              "  'RLGG framework',\n",
              "  'Relative Least General Generalisation RLGG'],\n",
              " ['conventional frequentist model training selection',\n",
              "  'applied neural network models',\n",
              "  'Bayesian methods',\n",
              "  'Bayesian inference',\n",
              "  'preferable traditional approaches'],\n",
              " ['belief network close underlying model time',\n",
              "  'Bayesian belief networks databases',\n",
              "  'efficient algorithm',\n",
              "  'belief network structure output',\n",
              "  'Section probability distribution algorithm'],\n",
              " ['Bayesian belief networks databases',\n",
              "  'probability distribution algorithm',\n",
              "  'belief network structure output',\n",
              "  'time complexity O N conditional independence',\n",
              "  'efficient algorithm'],\n",
              " ['compare performances different approximation techniques',\n",
              "  'polynomial rational approximation local polynomial techniques',\n",
              "  'Support Vector Machine SVM',\n",
              "  'particular time series variability performance respect free parameters',\n",
              "  'new insight function approximation'],\n",
              " ['dense interconnect artificial neural network systems',\n",
              "  'MCM implementation artificial neural networks',\n",
              "  'dense interconnect technology effective implementation requirement',\n",
              "  'neural network connectionist models',\n",
              "  'MCM technology'],\n",
              " ['correct specialization positive examples logical consequences original program finite number derivations positive negative examples',\n",
              "  'negative examples order',\n",
              "  'set positive examples',\n",
              "  'negative example',\n",
              "  'negative examples'],\n",
              " ['positive negative examples computation rule',\n",
              "  'positive negative examples',\n",
              "  'program wrt positive negative examples',\n",
              "  'negative examples refutations',\n",
              "  'positive examples'],\n",
              " ['Cognitive mapping qualitative decision modeling technique',\n",
              "  'recent formalisms qualitative decision modeling',\n",
              "  'development powerful inference procedures',\n",
              "  'social science decisionaiding applications',\n",
              "  'extensions expressiveness models'],\n",
              " ['continuous performance continuous sensorimotor interaction environment continuous adaptation',\n",
              "  'new method continuous casebased reasoning',\n",
              "  'highlevel reasoning problem domains',\n",
              "  'general discussion casebased reasoning issues',\n",
              "  'continuous representations'],\n",
              " ['WestEast Challenge competition machine learning programs',\n",
              "  'learning programs',\n",
              "  'stimulating challenge learning programs',\n",
              "  'Prolog program',\n",
              "  'Donald Michie Stephen Muggleton David Page Ashwin Srinivasan Oxford University'],\n",
              " ['non CI test based method Results evaluation algorithm number databases',\n",
              "  'Previous algorithms recovery Bayesianbelief network structures data',\n",
              "  'algorithm performance issues',\n",
              "  'ordering nodes database',\n",
              "  'CI tests'],\n",
              " ['new criterion model selection prediction problems',\n",
              "  'covariance inflation criterion model selection procedures',\n",
              "  'regression classification general prediction rules',\n",
              "  'training error average covariance predictions responses prediction rule',\n",
              "  'general prediction problems'],\n",
              " ['magnetic neural gas MNG algorithm',\n",
              "  'thyroid data set Results',\n",
              "  'unsupervised competitive learning class information',\n",
              "  'number data sets',\n",
              "  'associated neuron migration'],\n",
              " ['National Science Foundation Office Naval Research',\n",
              "  'implied National Science Foundation Office Naval Research United States government',\n",
              "  'Dario Salvucci Office Naval Research grant N',\n",
              "  'National Science Foundation Fellowship',\n",
              "  'document authors'],\n",
              " ['estimating model parameters',\n",
              "  'associated measurement errors',\n",
              "  'case regressor variables error',\n",
              "  'standard errors',\n",
              "  'applied models'],\n",
              " ['simulations model',\n",
              "  'learned contextual pathways',\n",
              "  'learning rules cortical selforganization',\n",
              "  'case model',\n",
              "  'plasticity contextual stream explore variations architecture'],\n",
              " ['large amount memory required store hypotheses',\n",
              "  'subset hypotheses',\n",
              "  'composite hypothesis',\n",
              "  'many individual hypotheses',\n",
              "  'ensemble learning approaches'],\n",
              " ['Bear et al Clothiaux et al Miller',\n",
              "  'opposed previous models Bear et al Miller et al Reiter Stryker afferent pathways',\n",
              "  'model plasticity afferent pathways neurons',\n",
              "  'synaptic plasticity rules Marshall',\n",
              "  'postsynaptic hyperpolarization Bear et al Dudek Bear Goda Stevens Kirkwood et al'],\n",
              " ['polynomial log n constant Further equivalence queries',\n",
              "  'time membership queries',\n",
              "  'membership equivalence queries',\n",
              "  'union discretized axisparallel boxes',\n",
              "  'time queries'],\n",
              " ['neural network design training topology optimization',\n",
              "  'associated network training',\n",
              "  'neural networks',\n",
              "  'behavior stochastic topology optimizer Enhancements',\n",
              "  'topology searches'],\n",
              " ['belief revision update networks',\n",
              "  'belief update belief revision',\n",
              "  'steady state beliefs',\n",
              "  'belief revision convergence',\n",
              "  'optimal beliefs'],\n",
              " ['low cost schedules',\n",
              "  'hand coded heuris tics',\n",
              "  'South Wales',\n",
              "  'order permutation chromosome combined hand',\n",
              "  'combination Genetic Algorithm'],\n",
              " ['search space search mechanism',\n",
              "  'semantic information constrain representation space',\n",
              "  'redundant space exploration',\n",
              "  'limit space',\n",
              "  'Search mechanisms'],\n",
              " ['Forte FirstOrder Revision Theories',\n",
              "  'possible errors theory',\n",
              "  'Forte FirstOrder Revision Theories Examples refines',\n",
              "  'propositional theory refinement',\n",
              "  'theory refinement'],\n",
              " ['existing representations sequence data',\n",
              "  'major impact task absence background knowledge good representation',\n",
              "  'future unlabeled sequences',\n",
              "  'feature generation method',\n",
              "  'superiority FGEN'],\n",
              " ['Genetic algorithms',\n",
              "  'genetic algorithm',\n",
              "  'genetic algorithms',\n",
              "  'parallel implementation genetic algorithm',\n",
              "  'algorithm'],\n",
              " ['conflict data base precedent cases',\n",
              "  'data base international conflicts',\n",
              "  'political military territorial outcome solution modalities conflict intensity',\n",
              "  'CaseBased Reasoning',\n",
              "  'classification various outcome variables'],\n",
              " ['CB H weak general learning algorithm',\n",
              "  'reasoners learning systems',\n",
              "  'chosen target concept',\n",
              "  'improved choosing similarity measure appropriate concept',\n",
              "  'chosen concept space space monomial functions'],\n",
              " ['evolutionary computation landscape',\n",
              "  'important open issues',\n",
              "  'various research groups',\n",
              "  'Emerging activity beginnings',\n",
              "  'annoying bewildering oldtimers'],\n",
              " ['real artificial data',\n",
              "  'MBR algorithm',\n",
              "  'MBR algorithms',\n",
              "  'artificial data',\n",
              "  'metric popular Bayesian classifier'],\n",
              " ['metric used deflne distance object',\n",
              "  'object unknown class plurality class',\n",
              "  'metric distance Euclidean space input measurement variables',\n",
              "  'problem location unknown object space',\n",
              "  'respective class distributions input measurement space'],\n",
              " ['hybrid genetic algorithms',\n",
              "  'traditional hybrid genetic algorithm',\n",
              "  'genetic search',\n",
              "  'applied local search',\n",
              "  'The traditional hybrid genetic algorithm'],\n",
              " ['immune system model',\n",
              "  'model explicit fitness sharing techniques genetic algorithms',\n",
              "  'model implements',\n",
              "  'GA central component model',\n",
              "  'relevant natural immune systems'],\n",
              " ['method accurate representation highdimensional unknown functions random samples',\n",
              "  'representations function',\n",
              "  'input space smaller subspaces',\n",
              "  'learning process good generalisation',\n",
              "  'input space'],\n",
              " ['precise final hidden state L linear Boltzmann chain',\n",
              "  'linear Boltzmann chain',\n",
              "  'identical hidden Markov model',\n",
              "  'exp linear Boltzmann chains',\n",
              "  'linear Boltzmann chain model statestate transition energies A ii going state state symbol emission energies B'],\n",
              " ['coevolutionary approach',\n",
              "  'noncoevolutionary approach simulated robot domain',\n",
              "  'alternative evolving complex behavior',\n",
              "  'intermediate training steps',\n",
              "  'significant learning rate speedup'],\n",
              " ['IDBD algorithm gradient descent space learningrate parameters',\n",
              "  'IDBD algorithm',\n",
              "  'learningrate parameters important form bias system',\n",
              "  'previous learning experience appropriate testbeds',\n",
              "  'previous learning experience'],\n",
              " ['pruning method lprune',\n",
              "  'pruning step pruning strength',\n",
              "  'Neural network pruning methods',\n",
              "  'autoprune new method lprune well backpropagation',\n",
              "  'severe pruning early training process'],\n",
              " ['necessary specializing behaviour General user interface classes',\n",
              "  'homogeneous structured connectionist nets',\n",
              "  'uniform customized graphic presentation nets',\n",
              "  'ICSIM connectionist net simulator',\n",
              "  'offtheshelf library classes'],\n",
              " ['new elements old solutions',\n",
              "  'computational feasibility sufficiency method design adaptation',\n",
              "  'task context design physical devices',\n",
              "  'class nonroutine caseadaptation tasks',\n",
              "  'new problems'],\n",
              " ['casebased reasoning systems resistant utility problem controlrule learning systems',\n",
              "  'utility problem',\n",
              "  'methodology analysis utility problems',\n",
              "  'systems performance',\n",
              "  'controlrule learning systems'],\n",
              " ['first stage',\n",
              "  'SME compute true structural match probe output',\n",
              "  'structured representations content vectors',\n",
              "  'capable modeling patterns access',\n",
              "  'memory items'],\n",
              " ['constant factor respect bounds sum squared errors',\n",
              "  'loss bounds adaptive filter theory',\n",
              "  'linear functions',\n",
              "  'constant factor',\n",
              "  'worst case sequence trials'],\n",
              " ['input case descriptions cases',\n",
              "  'new cases description approach call constructive similarity assessment',\n",
              "  'new cases',\n",
              "  'new retrieved cases',\n",
              "  'new cases memory'],\n",
              " ['memory search strategies',\n",
              "  'memory processes',\n",
              "  'Much recent research modeling memory processes',\n",
              "  'useful indices retrieval strategies',\n",
              "  'issues directions refining model'],\n",
              " ['exact algorithms probability computation tractable substructures combined variational methods',\n",
              "  'probability distribution',\n",
              "  'probability distributions',\n",
              "  'tured variational approximations exponential family distributions',\n",
              "  'structured variational approximations'],\n",
              " ['data processing mode ASOCS',\n",
              "  'previous ASOCS models',\n",
              "  'ASOCS',\n",
              "  'adaptive algorithm',\n",
              "  'mode rules'],\n",
              " ['genetic hill climbing algorithms dynamic hill climbing ability',\n",
              "  'genetic algorithms hill climbing techniques',\n",
              "  'Dynamic hill climbing',\n",
              "  'dynamic hill climbing',\n",
              "  'performance genetic algorithm'],\n",
              " ['controller autonomous vehicle',\n",
              "  'intelligent controller autonomous vehicle',\n",
              "  'noteworthy performance vehicle controller',\n",
              "  'sophisticated software controllers',\n",
              "  'Autonomous vehicles'],\n",
              " ['congenial learning sequential problem',\n",
              "  'notion batch problem',\n",
              "  'usergiven set problems',\n",
              "  'new theoretical model',\n",
              "  'problem'],\n",
              " ['density function',\n",
              "  'density n sample points',\n",
              "  'applications discriminant analysis cluster analysis flow calculations',\n",
              "  'Nonparametric density estimation problem',\n",
              "  'sequence special weight functions'],\n",
              " ['firstorder Horn programs entailment',\n",
              "  'Horn programs constant arity',\n",
              "  'alence entailment membership queries',\n",
              "  'Horn programs',\n",
              "  'constant arity'],\n",
              " ['canonical NPcomplete problem GAs',\n",
              "  'Boolean Satisfiability Problem SAT GAeffective canonical problem',\n",
              "  'NPcomplete problems',\n",
              "  'canonical problem',\n",
              "  'SAT problems'],\n",
              " ['coordinated strategies stochastic domains agents actions',\n",
              "  'effects rates convergence effect action failure probabilities asymmetries',\n",
              "  'Bayesian learning perspective general problem equilibrium selection',\n",
              "  'actions',\n",
              "  'consideration aim convergence conventional equilibrium point learning deliberation cease'],\n",
              " ['generic mechanisms design experiences',\n",
              "  'abstractions common source target domains',\n",
              "  'familiar domain',\n",
              "  'expertise familiar domain',\n",
              "  'generic mechanisms'],\n",
              " ['variation mutation rate useful cases fitness function multimodal pseudoboolean function multimodality',\n",
              "  'objective functions',\n",
              "  'unimodal objective functions',\n",
              "  'objective function well encoding mechanism',\n",
              "  'iterated mutation selection best Genetic Algorithm'],\n",
              " ['real world simulation general',\n",
              "  'real world environment',\n",
              "  'useful behaviors simulations',\n",
              "  'real world',\n",
              "  'learning algorithm'],\n",
              " ['startling progress management uncertainty',\n",
              "  'exact state students',\n",
              "  'accurate student modeling',\n",
              "  'uncertainty',\n",
              "  'Conventional Intelligent Tutoring Systems ITS'],\n",
              " ['difficult traditional satisfiability algorithms Results',\n",
              "  'least many hard SAT problems',\n",
              "  'satisfiability problems',\n",
              "  'neural network algorithm',\n",
              "  'Satisfiability SAT'],\n",
              " ['Artificial Life Neural Networks',\n",
              "  'Neural Networks Artificial Life',\n",
              "  'Artificial Life Neural Networks ALNNs',\n",
              "  'Neural Networks Artificial Life perspective number consequences',\n",
              "  'Artificial Life Mobile Robotics'],\n",
              " ['D object category',\n",
              "  'D object category nodes',\n",
              "  'preprocessed representations D view categories',\n",
              "  'D object prediction',\n",
              "  'multiple D views'],\n",
              " ['FIR case derivation performance New algorithms',\n",
              "  'present short unifying account different algorithms',\n",
              "  'finite impulse response FIR infinite impulse response',\n",
              "  'benchmark algorithms',\n",
              "  'MackeyGlass chaotic time series number methods'],\n",
              " ['function number hidden units number learning samples',\n",
              "  'asymptotical behavior approximation error asymptotical model error function AMEF introduced parameters',\n",
              "  'total approximation error',\n",
              "  'computational complexity learning rule optimal learning set size number hidden units',\n",
              "  'optimal number learning samples'],\n",
              " ['methodology Bayesian model determination decomposable graphical Gaussian models',\n",
              "  'dropping edge graph',\n",
              "  'conditional complete graph',\n",
              "  'junction tree representation graph sweep',\n",
              "  'decomposability graph'],\n",
              " ['relevant suspended goals',\n",
              "  'opportunistic behavior opportunity recognition recognition conditions',\n",
              "  'suspended goal Opportunity recognition special case situation assessment process',\n",
              "  'real world opportunity recognition',\n",
              "  'suspended problem contexts'],\n",
              " ['optimal solution c degree noise training data',\n",
              "  'task known optimal training error',\n",
              "  'lower training generalization error',\n",
              "  'better training generalization error',\n",
              "  'committee ensemble techniques beneficial level noise training data'],\n",
              " ['convergence optimal network size',\n",
              "  'weights trained networks excess degrees freedom',\n",
              "  'interpolation characteristics multilayer perceptron neural networks MLPs polynomial models',\n",
              "  'known optimal training error',\n",
              "  'lower training generalization error'],\n",
              " ['learning system',\n",
              "  'rule sets',\n",
              "  'classification rules',\n",
              "  'novel induction algorithm',\n",
              "  'robust presence noisy data'],\n",
              " ['CaseBased Reasoning case retrieval case representation',\n",
              "  'search useful cases',\n",
              "  'requested case',\n",
              "  'required number cases',\n",
              "  'stored large scaled case base'],\n",
              " ['PGA deceptive problems',\n",
              "  'PGA based small number active intelligent individuals',\n",
              "  'PGA tries',\n",
              "  'PGA',\n",
              "  'optimization problem fitness landscape'],\n",
              " ['focusing alternative performance tasks',\n",
              "  'recent ML conferences',\n",
              "  'classifying cases',\n",
              "  'recent literature',\n",
              "  'additional research'],\n",
              " ['application approach number lexical acquisition disambiguation',\n",
              "  'computational lexicology language technology',\n",
              "  'particular performanceoriented approach Natural Language Processing',\n",
              "  'severe complexity acquisition reusability bottlenecks',\n",
              "  'specific formalisms domains applications'],\n",
              " ['H n',\n",
              "  'convergence law algorithm',\n",
              "  'stepwise estimators',\n",
              "  'H',\n",
              "  'mild conditions'],\n",
              " ['complete data matrix relative model class',\n",
              "  'select different complete data matrices',\n",
              "  'data estimation multivariate categorical data',\n",
              "  'model class assumption',\n",
              "  'data completion minimal stochastic complexity'],\n",
              " ['general optimization problems',\n",
              "  'paper new evolutionary procedure',\n",
              "  'National Hockey League',\n",
              "  'Open Shop Scheduling',\n",
              "  'interaction phases'],\n",
              " ['symbol symbol alphabet',\n",
              "  'PFSA models incremental addition substrings',\n",
              "  'optimal pfsa model',\n",
              "  'behavioural data',\n",
              "  'data structures'],\n",
              " ['Green address problem model order uncertainty autoregressive AR time series',\n",
              "  'Bayesian framework Efficient model jumping',\n",
              "  'full conditional density AR parameters',\n",
              "  'synthetic audio time series',\n",
              "  'new parameters'],\n",
              " ['propose applicability casebased planning methodology task planning',\n",
              "  'problem planning series modifications memory',\n",
              "  'flexible planning',\n",
              "  'planning learn framework',\n",
              "  'casebased reasoning'],\n",
              " ['relevant study instancebased learners',\n",
              "  'constituent parts instancebased learner',\n",
              "  'V SCBR simple instancebased learning algorithm',\n",
              "  'difficulty target concepts learner',\n",
              "  'overall behaviour behaviour constituent parts V SCBR'],\n",
              " ['admissible heuristic exhaustive search',\n",
              "  'partial determinations',\n",
              "  'efficient preprocessingbased approach',\n",
              "  'functional dependencies',\n",
              "  'known MDL formula'],\n",
              " ['information theoretic measure finite state machine explanations',\n",
              "  'optimal finite state machine explanation symbol strings',\n",
              "  'general probabilistic finite state machines explanations',\n",
              "  'explanations',\n",
              "  'evaluation candidate explanations'],\n",
              " ['discovered synchronization algorithm terms embedded particles interactions',\n",
              "  'emergent collective behavior natural systems automatic programming',\n",
              "  'underlying mediums potential form embedded particles',\n",
              "  'evolutionary sequence solution',\n",
              "  'decentralized distributed system order'],\n",
              " ['recent infinitedimensional Ztheorem',\n",
              "  'Arcones Gine Lele Newton Raftery',\n",
              "  'finitedimensional results type bootstrap',\n",
              "  'general bootstrap theorem',\n",
              "  'applicatons general theorem'],\n",
              " ['recurrence times',\n",
              "  'predicted recurrence',\n",
              "  'accurate predicted rates recurrence',\n",
              "  'problem breast cancer recurrence',\n",
              "  'Survival Curve RSA SCRSA extension RSA approach'],\n",
              " ['informative queries',\n",
              "  'selective sampling query',\n",
              "  'twomember committee algorithm',\n",
              "  'query committee algorithm method',\n",
              "  'query'],\n",
              " ['input space nonlinear map instance space possible pixel products',\n",
              "  'nonlinear form Principal Component Analysis',\n",
              "  'derivation method',\n",
              "  'first experimental results',\n",
              "  'Principal Component Analysis'],\n",
              " ['decision model',\n",
              "  'decision problem',\n",
              "  'general knowledge probabilistic relationships',\n",
              "  'relevant factors decision problem',\n",
              "  'resurgence interest computational decision systems'],\n",
              " ['best learners region example space',\n",
              "  'best learners prediction part example space',\n",
              "  'learners predictions',\n",
              "  'space defined prediction patterns learners',\n",
              "  'learning algorithm example'],\n",
              " ['Marvin example concept',\n",
              "  'new concepts',\n",
              "  'new concepts extent learner',\n",
              "  'belong target concept',\n",
              "  'concept'],\n",
              " ['environmental complexity effects collective behaviors',\n",
              "  'Energy Environments LEE model',\n",
              "  'adaptive behaviors',\n",
              "  'role environmental complexity',\n",
              "  'careful characterization environments different forms energy'],\n",
              " ['notion determinate clauses',\n",
              "  'Horn clauses ILPproblem',\n",
              "  'klocal Horn clauses',\n",
              "  'linked Horn clauses',\n",
              "  'efficiency subsumption basic provability relation ILP'],\n",
              " ['multidimensional Kalman filter list manipulation function NTH list manipulation function MAPCAR',\n",
              "  'classes functions generic data types',\n",
              "  'values data type provision data type value',\n",
              "  'arguments functions values',\n",
              "  'STGP variables constants arguments'],\n",
              " ['finite discrete deterministic transfer function used units',\n",
              "  'sigmoidal hardthreshold transfer functions',\n",
              "  'RCC network finitestate automata FSA network model',\n",
              "  'Recurrent Cascade Correlation RCC Network Fahlman',\n",
              "  'results units'],\n",
              " ['additional prior knowledge substitution space small fraction search space',\n",
              "  'relation subsumption clique problem',\n",
              "  'important inductive logic programming theorem',\n",
              "  'decidable incomplete approximation logic implication',\n",
              "  'certain superset determinate clauses'],\n",
              " ['new algorithm',\n",
              "  'algorithm',\n",
              "  'sparse perceptrons input representations',\n",
              "  'concept descriptions',\n",
              "  'good generalization performance'],\n",
              " ['Current inductive machine learning algorithms',\n",
              "  'several artificial several real world problems results',\n",
              "  'Assistant system top induction decision trees',\n",
              "  'significant conditional dependencies attributes',\n",
              "  'RELIEFF extension RELIEF'],\n",
              " ['hierarchical reinforcement learning',\n",
              "  'hierarchical credit assignment problem nonhierarchical execution MAXQ',\n",
              "  'previous work hierarchical reinforcement',\n",
              "  'hierarchical Q learning algorithm',\n",
              "  'The MAXQ decomposition procedural semanticsas subroutine hierarchyand declarative semanticsas representation value function hierarchical policy MAXQ'],\n",
              " ['concept causality Genetic Programming GP',\n",
              "  'GP architecture evolution',\n",
              "  'GP search',\n",
              "  'bottomup GP',\n",
              "  'Genetic Programming GP'],\n",
              " ['meansquared error voting methods',\n",
              "  'different methods variants',\n",
              "  'bias variance unstable methods',\n",
              "  'voting methods',\n",
              "  'bias variance decomposition error'],\n",
              " ['intelligence Productive research AI practical theoretical benefits notion intelligence',\n",
              "  'closer informal conception intelligence',\n",
              "  'formal conception rationality',\n",
              "  'gap theory practice',\n",
              "  'future research'],\n",
              " ['circular convolution associate items',\n",
              "  'separate associative memory good reconstructive properties',\n",
              "  'convolution memories',\n",
              "  'compositional structure',\n",
              "  'compositional structures'],\n",
              " ['random prefixclosed samples algorithm',\n",
              "  'Incorporating opponent models adversary search Technical Report CIS report Technion March Carmel Markovitch D Carmel S Markovitch Unsupervised',\n",
              "  'Technical Report CIS report',\n",
              "  'DFA general prefixclosed sample',\n",
              "  'compact models'],\n",
              " ...]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textrank_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyGmMdsZOT1x",
        "outputId": "ce6a7c27-c4b5-49d9-c984-cb7e1f7725ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Several computer algorithms',\n",
              "  'patterns groups protein sequences',\n",
              "  'based fitting parameters statistical model group related sequences',\n",
              "  'part statistical model',\n",
              "  'Gibbs sampler algorithms'],\n",
              " ['learning strategies',\n",
              "  'colposuspension cure rate',\n",
              "  'differences cure rate',\n",
              "  'risk factors',\n",
              "  'useful role large scale medical problem'],\n",
              " ['cellular communication systems important problem',\n",
              "  'cellular telephone systems',\n",
              "  'large cellular system',\n",
              "  'communication resource channels',\n",
              "  'channel available call'],\n",
              " ['techniques operations research bear problem',\n",
              "  'paper',\n",
              "  'optimal actions',\n",
              "  'pomdps line show cases',\n",
              "  'mdps pomdps'],\n",
              " ['Graphical models',\n",
              "  'graphical models',\n",
              "  'applicability graphical models',\n",
              "  'representational power probability models',\n",
              "  'variational methods'],\n",
              " ['test domain realtime decision algorithms',\n",
              "  'broader applicability algorithms',\n",
              "  'Incremental Probabilisitic Inference DAmbrosio variant algorithm',\n",
              "  'influence diagrams',\n",
              "  'decisionevaluation variant'],\n",
              " ['Speedup learning',\n",
              "  'computational efficiency problem',\n",
              "  'random problems solutions',\n",
              "  'efficient problem',\n",
              "  'formal framework'],\n",
              " ['paper show results',\n",
              "  'previous paper',\n",
              "  'objective functions',\n",
              "  'cost functions',\n",
              "  'finite automata'],\n",
              " ['known offline model sequence elements',\n",
              "  'offline model',\n",
              "  'offline variant mistakebound model',\n",
              "  'constant number mistakes sequence',\n",
              "  'offline learner'],\n",
              " ['Wahba Wang Gu Klein Klein',\n",
              "  'ANalysis VAriance SS ANOVA method data exponential families',\n",
              "  'SS ANOVA',\n",
              "  'Bayesian confidence intervals SS ANOVA',\n",
              "  'Smoothing Spline'],\n",
              " ['evolutionary approach incremental approach',\n",
              "  'evolutionary approach potential solutions',\n",
              "  'learning rules problems',\n",
              "  'hill climbing strategy incremental coding potential solutions',\n",
              "  'simple supervised learning problems'],\n",
              " ['Bayesian hypothesis testing model selection marginal likelihood model',\n",
              "  'basic LaplaceMetropolis estimator models',\n",
              "  'integrated likelihood marginal probability data',\n",
              "  'models',\n",
              "  'marginal likelihoods'],\n",
              " ['empirical learning utility problem',\n",
              "  'knowledge course learning performance response',\n",
              "  'general utility problem',\n",
              "  'mechanisms different learning paradigms model',\n",
              "  'similar phenomenon degradation performance due increase amount'],\n",
              " ['Hidden Markov Models HMMs',\n",
              "  'multiple sequence alignment protein families protein domains',\n",
              "  'HMMs HMM',\n",
              "  'problems statistical modeling database',\n",
              "  'multiple alignment training sequences'],\n",
              " ['effect initial weight selection feedforward networks',\n",
              "  'Monte Carlo techniques magnitude initial condition vector weight space',\n",
              "  'simple functions backpropagation technique',\n",
              "  'extreme sensitivity back propagation initial weight configuration',\n",
              "  'significant parameter convergence time variability'],\n",
              " ['medial temporal lobe',\n",
              "  'consolidation responsible transfer memory medial temporal lobe neocortex',\n",
              "  'brain memory capacity',\n",
              "  'brain structures',\n",
              "  'proper functioning system'],\n",
              " ['eyes',\n",
              "  'investigation dependence pattern stripes degree correlation eyes',\n",
              "  'neighbouring points',\n",
              "  'The map eye brain vertebrates',\n",
              "  'previous models'],\n",
              " ['average variance test error rates',\n",
              "  'validation data average test error rate',\n",
              "  'test error rate',\n",
              "  'test example inputs variance',\n",
              "  'classifier random example'],\n",
              " ['formal model',\n",
              "  'formal models',\n",
              "  'combinations noise models',\n",
              "  'possible model',\n",
              "  'answer questions development investigation formal models'],\n",
              " ['decision tree based approach function approximation reinforcement',\n",
              "  'decision tree',\n",
              "  'better learning performance neural network function approximation',\n",
              "  'neural network function approximator',\n",
              "  'approach table'],\n",
              " ['new game playing strategies',\n",
              "  'discover strategies',\n",
              "  'evolutionary neural networks',\n",
              "  'neural networks',\n",
              "  'first standard positional strategy subsequently mobility strategy advanced strategy'],\n",
              " ['general bounds complexity',\n",
              "  'general upper bounds',\n",
              "  'Statistical Query model PAC model classification noise',\n",
              "  'model classification noise',\n",
              "  'general framework efficient PAC learning presence classification noise'],\n",
              " ['applications classes',\n",
              "  'class applications',\n",
              "  'closer scrutiny real world application potential models',\n",
              "  'model applications',\n",
              "  'features applications'],\n",
              " ['dominant philosophical foundation Bayesian inference',\n",
              "  'socalled noninformative priors priors',\n",
              "  'practical philosophical issues',\n",
              "  'Bayesian analyses',\n",
              "  'noninformative priors'],\n",
              " ['recurrent network models',\n",
              "  'eXogenous inputs neural network models popular subclass recurrent networks',\n",
              "  'Recurrent neural networks',\n",
              "  'NARX Nonlinear AutoRegressive',\n",
              "  'embedded memory'],\n",
              " ['incremental concept learning approach identiflcation concepts',\n",
              "  'concepts original stochastic complexity formula',\n",
              "  'Many traditional inductive algorithms disjunctive version space family',\n",
              "  'approach',\n",
              "  'central problem'],\n",
              " ['creative design',\n",
              "  'inherent creative reasoning',\n",
              "  'CBR systems',\n",
              "  'standard CBR framework',\n",
              "  'CBR'],\n",
              " ['probabilistic automata',\n",
              "  'contextdependent probabilities',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'Gibbs distributions',\n",
              "  'stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model'],\n",
              " ['design problems',\n",
              "  'new designs',\n",
              "  'demex interactive computeraided design system',\n",
              "  'applied domain structural design buildings',\n",
              "  'Another characteristic design phenomenon exploration early stages'],\n",
              " ['algorithm recognition models',\n",
              "  'generative model',\n",
              "  'generative models',\n",
              "  'neural network generative models',\n",
              "  'generative model examples'],\n",
              " ['certain vision processing techniques index case base surfaces',\n",
              "  'strong features',\n",
              "  'exploitation',\n",
              "  'Such features',\n",
              "  'relevant surface'],\n",
              " ['different machine learning algorithms system',\n",
              "  'genetic algorithm bootstrapping method',\n",
              "  'genetic algorithm',\n",
              "  'genetic algorithms',\n",
              "  'difficult class delayed reinforcement learning problems'],\n",
              " ['hierarchical generative model',\n",
              "  'nonlinear generalization factor analysis',\n",
              "  'neural network',\n",
              "  'demon strate network',\n",
              "  'bottomup topdown lateral connections'],\n",
              " ['neuroevolution individual population',\n",
              "  'complete neural network Recent work SANE system',\n",
              "  'evolving individual neurons',\n",
              "  'neuronbased search networkbased search',\n",
              "  'efficient genetic search'],\n",
              " ['Reinforcement learning addresses',\n",
              "  'successful discovery structure reinforcement',\n",
              "  'select actions order',\n",
              "  'reinforcement',\n",
              "  'compactness action policies'],\n",
              " ['generalization mistakebound model',\n",
              "  'f gvalued functions learner',\n",
              "  'general constraint number M incorrect predictions number M incorrect predictions',\n",
              "  'mistakebound',\n",
              "  'situations learner wishes'],\n",
              " ['Markov Chain Monte Carlo MCMC methods',\n",
              "  'Markov Chain Monte Carlo',\n",
              "  'users',\n",
              "  'accelerating MCMC sampler convergence',\n",
              "  'theoretical convergence bounds'],\n",
              " ['detection invariant structure',\n",
              "  'set input patterns',\n",
              "  'many recognition tasks',\n",
              "  'direct approach',\n",
              "  'high variance principal components'],\n",
              " ['Instancebased learning methods',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'instance based methods',\n",
              "  'phase prediction time',\n",
              "  'multiresolution data structure'],\n",
              " ['Discrete Bayesian models',\n",
              "  'model uncertainty mobilerobot navigation question actions',\n",
              "  'optimal control policy',\n",
              "  'optimal solution problem',\n",
              "  'variety heuristic control strategies'],\n",
              " ['implementation note',\n",
              "  'NRL NCARAI',\n",
              "  'Salzbergs NGE',\n",
              "  'This NRL NCARAI technical note',\n",
              "  'algorithm run case studies'],\n",
              " ['Technical Report No Department Statistics University',\n",
              "  'recentlydeveloped method simulated tempering tempered transition method',\n",
              "  'distribution interest distribution sampling',\n",
              "  'distribution easilysampled distribution',\n",
              "  'tempering tempered transitions'],\n",
              " ['adaptive training system ATS',\n",
              "  'uncertainty student model',\n",
              "  'students solution',\n",
              "  'student',\n",
              "  'students'],\n",
              " ['knowledge cognition',\n",
              "  'Metacognition addresses',\n",
              "  'cognition',\n",
              "  'previous regulation processes',\n",
              "  'regulation process'],\n",
              " ['Markov property chain graphs',\n",
              "  'direct extension ADG Markov property LWF property chain graph',\n",
              "  'Graphical Markov models',\n",
              "  'Applications undirected graphs UDGs',\n",
              "  'mixed graphs'],\n",
              " ['fault hierarchies',\n",
              "  'theory revision algorithm',\n",
              "  'correctness diagnoses returns set tests',\n",
              "  'widely used expert systems diagnosis complex mechanical devices',\n",
              "  'diagnoses'],\n",
              " ['Machine learning game strategies',\n",
              "  'new strategies',\n",
              "  'repeated use strategy learning component',\n",
              "  'total number strategies',\n",
              "  'strategies'],\n",
              " ['Most work attempts',\n",
              "  'generalization error hypothesis',\n",
              "  'algorithm learning algorithms',\n",
              "  'different approach bounding generalization error data',\n",
              "  'apriori bounds'],\n",
              " ['new framework',\n",
              "  'Markov decision',\n",
              "  'paper',\n",
              "  'based ideas statistical mechanics',\n",
              "  'energy landscape policy space Methods'],\n",
              " ['neural networks',\n",
              "  'continuous activation functions',\n",
              "  'least large square number weights',\n",
              "  'VC dimension',\n",
              "  'general sigmoidal nets Implications number samples'],\n",
              " ['Novel online learning algorithms',\n",
              "  'self adaptive learning rates parameters',\n",
              "  'new learning rules',\n",
              "  'learning algorithms',\n",
              "  'associated learning algorithms'],\n",
              " ['modular network architecture',\n",
              "  'single learning agent',\n",
              "  'composite tasks',\n",
              "  'unknown architecture',\n",
              "  'multiple Markovian decision tasks'],\n",
              " ['Scientists engineers',\n",
              "  'numerical simulation programs',\n",
              "  'numerical simulators',\n",
              "  'order address problem developed system',\n",
              "  'engineer'],\n",
              " ['Bayesian networks',\n",
              "  'Bayesian network structure independencies',\n",
              "  'conditional independence properties distribution',\n",
              "  'resulting network',\n",
              "  'network'],\n",
              " ['conventional trace',\n",
              "  'trace assign credit',\n",
              "  'trace analyze',\n",
              "  'traces',\n",
              "  'method corresponding replacetrace TD'],\n",
              " ['functional theory complete reading process',\n",
              "  'intensive reading known creative reading',\n",
              "  'decades variety cognitive disciplines',\n",
              "  'framework developed theory',\n",
              "  'creative reading aspect'],\n",
              " ['propositional knowledgebases Intuitively update',\n",
              "  'special instance theory',\n",
              "  'counterfactual conditionals',\n",
              "  'reasonable update',\n",
              "  'updates'],\n",
              " ['Many neural net learning algorithms',\n",
              "  'unmatchable previous neural net algorithms',\n",
              "  'simple nets',\n",
              "  'optimal universal search algorithm',\n",
              "  'algorithmically simple neural networks low Kolmogorov complexity high generalization capability'],\n",
              " ['expressive musical performances context tenor saxophone interpretations',\n",
              "  'inferred expressive transformations new phrase',\n",
              "  'several expressive parameters',\n",
              "  'possible expressive transformations',\n",
              "  'background musical knowledge new phrase'],\n",
              " ['paper show phenomenon related distribution margins training examples respect',\n",
              "  'margin distribution test error',\n",
              "  'test error',\n",
              "  'especially effective increasing margins training examples',\n",
              "  'One surprising recurring phenomena'],\n",
              " ['Realworld learning tasks',\n",
              "  'missing data',\n",
              "  'highdimensional data',\n",
              "  'data sets',\n",
              "  'data'],\n",
              " ['input story instance particular script',\n",
              "  'taxonomy maps',\n",
              "  'ordinary singlelevel feature mapping',\n",
              "  'unique memory location script instantiation',\n",
              "  'scripts'],\n",
              " ['static neural approaches adaptive target detection',\n",
              "  'artificial fovea controlled adaptive neural controller',\n",
              "  'adaptive model',\n",
              "  'adaptive attentive systems general',\n",
              "  'sequential generation fovea trajectories'],\n",
              " ['treestructured architecture',\n",
              "  'parameters architecture',\n",
              "  'particular present ExpectationMaximization EM algorithm',\n",
              "  'generalized linear models',\n",
              "  'online learning algorithm parameters'],\n",
              " ['maximum likelihood estimation data variables',\n",
              "  'incremental variant EM algorithm',\n",
              "  'wide range variant algorithms',\n",
              "  'unobserved variables',\n",
              "  'faster convergence mixture estimation problem'],\n",
              " ['WilsonCowan oscillators',\n",
              "  'linear approximation WilsonCowan oscillator',\n",
              "  'desynchronize oscillator groups',\n",
              "  'different oscillator groups',\n",
              "  'feedback oscillator matrix'],\n",
              " ['implementation probabilistic regression model BUGS BUGS program',\n",
              "  'BUGS BUGS',\n",
              "  'Bayesian inference statistical problems',\n",
              "  'paper',\n",
              "  'simultaneous inference'],\n",
              " ['hand complex data',\n",
              "  'unseen data',\n",
              "  'classifying process',\n",
              "  'long difficult task quantity data classify amount training',\n",
              "  'psychology experiments'],\n",
              " ['neural network literature',\n",
              "  'The estimation training methods',\n",
              "  'suitable implementation hardware',\n",
              "  'usually simple form gradient descent algorithm',\n",
              "  'fit neural networks'],\n",
              " ['right reference class',\n",
              "  'right interval',\n",
              "  'conflicting candidates',\n",
              "  'subset style dominance problem',\n",
              "  'Kyburgs Evidential Probability system Various methods'],\n",
              " ['reinforcement learning methods',\n",
              "  'reinforcement learning',\n",
              "  'new method',\n",
              "  'new scheduling problems',\n",
              "  'domainspecific heuristics job shop scheduling'],\n",
              " ['A neural network approach classic inverted pendulum task',\n",
              "  'cart free fall plane',\n",
              "  'effective realtime control small selfcontained minirobot specially outfitted task Origins details',\n",
              "  'great cart',\n",
              "  'difficult control problem parameters cartpole system'],\n",
              " ['Platts resourceallocation network RAN Platt b',\n",
              "  'RAN Platt',\n",
              "  'Qlearning network',\n",
              "  'faster average restart algorithm',\n",
              "  'hidden units'],\n",
              " ['new processing paradigm',\n",
              "  'Expandable Split Window ESW paradigm',\n",
              "  'Expandable Split Window ESW',\n",
              "  'implementation Expandable Split Window execution model preliminary performance results',\n",
              "  'finegrain parallelism'],\n",
              " ['Nested Generalized Exemplar NGE theory',\n",
              "  'axisparallel NGE approach',\n",
              "  'NGE',\n",
              "  'Algorithms',\n",
              "  'new data points computing distance'],\n",
              " ['good model',\n",
              "  'good model data',\n",
              "  'bad models',\n",
              "  'helpful searching space models',\n",
              "  'applicable class model selection problems'],\n",
              " ['many learning problems',\n",
              "  'algorithm learning determinations functional dependencies',\n",
              "  'binary value specifying value target feature vector binary values',\n",
              "  'benefits determination learning show',\n",
              "  'minimal determi Define MINFEATURES problem'],\n",
              " ['generative connections recognition connections',\n",
              "  'multilayer neural networks',\n",
              "  'successive hidden layers topdown generative connections',\n",
              "  'Bottomup recognition connections',\n",
              "  'An unsupervised learning algorithm multilayer network stochastic neurons'],\n",
              " ['structure software library',\n",
              "  'actual user software library',\n",
              "  'semantic relationship stored software components',\n",
              "  'crucial success software',\n",
              "  'functional similarity stored software components order'],\n",
              " ['inductive analytical learning architecture',\n",
              "  'learning EBNN',\n",
              "  'fundamental component intelligence key consideration',\n",
              "  'rich variety learning capabilities',\n",
              "  'cognitive architectures'],\n",
              " ['important contribution simulation',\n",
              "  'Many simulation algorithms',\n",
              "  'important role stochastic geometry related fields',\n",
              "  'perfect say exact simulations',\n",
              "  'Simulation'],\n",
              " ['casebased reasoning',\n",
              "  'recent years',\n",
              "  'whole problem space',\n",
              "  'rules particular context ie problem',\n",
              "  'CBR induction techniques'],\n",
              " ['tandem use finite automata',\n",
              "  'DFA model adversarial robot use automaton',\n",
              "  'robot reasoning model object machine',\n",
              "  'algorithm utility planner adversarial robotic domain',\n",
              "  'many applications robot agents'],\n",
              " ['Claudia Cargnoni Dipartimento Statistico Universita di Firenze Firenze Italy Peter Muller Assistant Professor Mike West Professor Institute Statistics Decision Sciences Duke University Durham NC Research Cargnoni',\n",
              "  'Dipartimento Statistico Universita',\n",
              "  'Firenze Firenze',\n",
              "  'Claudia Cargnoni',\n",
              "  'ISDS Muller West'],\n",
              " ['genetic algorithms GAs',\n",
              "  'Our theoretical understanding properties',\n",
              "  'transient Markov chain analysis model',\n",
              "  'Traditional schema analysis',\n",
              "  'function optimization'],\n",
              " ['application training noise multilayer perceptron input variables',\n",
              "  'paper',\n",
              "  'Noise injection modified order',\n",
              "  'penalization inputs',\n",
              "  'single parameter'],\n",
              " ['COINS Technical Report',\n",
              "  'January',\n",
              "  'present new multivariate decision tree algorithm LMDT',\n",
              "  'linear machines decision trees LMDT',\n",
              "  'test decision tree training linear machine'],\n",
              " ['RL methods',\n",
              "  'type control task reinforcement',\n",
              "  'RL system',\n",
              "  'RL modelfree tuning adaptation method',\n",
              "  'RL'],\n",
              " ['neural network modifiable lateral connections',\n",
              "  'experimental observations development lateral connections cortical feature maps',\n",
              "  'input information Predictions algorithm',\n",
              "  'The lateral interaction weights',\n",
              "  'Mexican hat shape'],\n",
              " ['statistical causal foundations',\n",
              "  'social scientists epidemiologists',\n",
              "  'formal natural explication relations graphical methods',\n",
              "  'Some main users statistical methods',\n",
              "  'economists'],\n",
              " ['new method',\n",
              "  'bottomup method',\n",
              "  'logic programs examples attempts',\n",
              "  'method predicate invention similar Champ elegant solution noisy oracle problem',\n",
              "  'Systematic experimental comparisons Golem Foil range problems'],\n",
              " ['deterministic techniques',\n",
              "  'upper lower bounds marginal probabilities',\n",
              "  'useful size network clique size',\n",
              "  'sigmoid noisyOR networks',\n",
              "  'tightness bounds numerical experi ments'],\n",
              " ['MIT Computational Cognitive Science Technical Report',\n",
              "  'recursive nodeelimination formalism',\n",
              "  'large probabilistic networks',\n",
              "  'network topologies',\n",
              "  'Boltzmann machines sigmoid belief networks combination'],\n",
              " ['distributionfree learning concept class C VCdimC VapnikChervonenkis dimension ffi accuracy confidence parameters',\n",
              "  'ffi',\n",
              "  'many interesting concept classes',\n",
              "  'previous best lower bound ln ffi VCdimC',\n",
              "  'number random examples'],\n",
              " ['measure temporal variation signal Tau Net',\n",
              "  'Tau Nets ability',\n",
              "  'dynamic signals application speech',\n",
              "  'realworld dynamic signals',\n",
              "  'dynamic signals'],\n",
              " ['material BPSOM extension BP',\n",
              "  'BP Kohonens',\n",
              "  'BP',\n",
              "  'serious limitations',\n",
              "  'BPSOM combination multilayered feedforward network MFN'],\n",
              " ['MLP Learning Vector Quantisation',\n",
              "  'MLP network',\n",
              "  'The discrimination powers Multilayer perceptron MLP Learning Vector Quantisation LVQ networks',\n",
              "  'MLP',\n",
              "  'Multilayer'],\n",
              " ['article approximate rate convergence Gibbs sampler normal approximation target distribution',\n",
              "  'Gibbs',\n",
              "  'approximation illustrate methods',\n",
              "  'many implementational issues',\n",
              "  'approximation'],\n",
              " ['Instancebased learning methods',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'instance based methods',\n",
              "  'phase prediction time',\n",
              "  'multiresolution data structure'],\n",
              " ['reinforcement learning architecture reactive component two layer control system simulated race car',\n",
              "  'reinforcement',\n",
              "  'control system',\n",
              "  'test tuning decomposition coordination low level behaviors',\n",
              "  'layers'],\n",
              " ['training data background knowledge',\n",
              "  'irrelevant information',\n",
              "  'information',\n",
              "  'relevant solving learning problem',\n",
              "  'data'],\n",
              " ['Hierarchical genetic programming HGP approaches',\n",
              "  'HGP approach',\n",
              "  'HGP',\n",
              "  'analysis evolution process dual perspective diversity causality',\n",
              "  'exploration exploitation genetic search'],\n",
              " ['multilevel hierarchy recurrent networks',\n",
              "  'construction neural architectures',\n",
              "  'many fewer training sequences conventional training algorithms recurrent nets',\n",
              "  'descriptions event sequences',\n",
              "  'sequences'],\n",
              " ['lateral connections',\n",
              "  'lateral connection patterns',\n",
              "  'A neural network model selforganization ocular dominance lateral connections',\n",
              "  'network',\n",
              "  'Similar selforganization cortical structures'],\n",
              " ['analysis relaxation oscillations singular limit',\n",
              "  'singular limit method',\n",
              "  'large systems relaxation oscillators',\n",
              "  'Relaxation oscillations',\n",
              "  'limit system evolution'],\n",
              " ['model spiking neurons',\n",
              "  'model afferent structures lateral connections',\n",
              "  'model image segmentation binding synchronization desynchronization neuronal activity',\n",
              "  'unified model development',\n",
              "  'selforganize inputdriven Hebbian'],\n",
              " ['integrated MCMC methods',\n",
              "  'Carlo MCMC methods',\n",
              "  'neural networks prediction problem',\n",
              "  'idea classification problems',\n",
              "  'realworld problems'],\n",
              " ['exact sampling algorithm',\n",
              "  'Propp Wilson',\n",
              "  'algorithm',\n",
              "  'partial order mixture model state space',\n",
              "  'Coupling Past'],\n",
              " ['visual cortex selective ocular dominance orientation input',\n",
              "  'visual cortex',\n",
              "  'orientation ocular dominance',\n",
              "  'Hebbian selforganization receptive fields different sizes',\n",
              "  'sparse coding visual input recurrent lateral interactions'],\n",
              " ['practical application artificial neural networks',\n",
              "  'neural critic',\n",
              "  'cycle position dependent error observed attitude',\n",
              "  'approach estimated cost function',\n",
              "  'controller cost function'],\n",
              " ['generic ILP problem',\n",
              "  'E positive negative examples target',\n",
              "  'k nonrecursive local clauses',\n",
              "  'nonrecursive local clauses',\n",
              "  'new results'],\n",
              " ['simple derivation algorithm',\n",
              "  'Dempster et al',\n",
              "  'MAP estimation problems',\n",
              "  'considerable popularity',\n",
              "  'ExpectationMaximization'],\n",
              " ['problem framework regularization theory',\n",
              "  'invariance constraint regularization theory framework',\n",
              "  'problem',\n",
              "  'prior knowledge',\n",
              "  'approximated function radial symmetry'],\n",
              " ['simple computational experiment new methods',\n",
              "  'gainadaptation algorithms based part connectionist learning methods',\n",
              "  'computational results',\n",
              "  'respect classical methods',\n",
              "  'least squares classical parameterestimation methods'],\n",
              " ['Windowing proposed procedure efficient memory use ID decision tree learning algorithm',\n",
              "  'present new windowing algorithm',\n",
              "  'appropriate windowing divideandconquer algorithms',\n",
              "  'noisy data windowing present preliminary ideas',\n",
              "  'extension algorithm'],\n",
              " ['comprehensive approach automatic theory revision',\n",
              "  'imperfect theory approach',\n",
              "  'theory fault',\n",
              "  'approximate domain theory',\n",
              "  'failing portions theory'],\n",
              " ['sample density',\n",
              "  'joint distribution',\n",
              "  'Monte Carlo',\n",
              "  'new auxiliary variable method',\n",
              "  'An auxiliary variable u conditional distribution ujx'],\n",
              " ['theoretical properties',\n",
              "  'paper',\n",
              "  'algorithm',\n",
              "  'extremely robust geometric ergodicity properties',\n",
              "  'case'],\n",
              " ['simulated annealing ADFs',\n",
              "  'GP results suite simulated annealing run ADFs problem size',\n",
              "  'ADFs evenparity problem GP',\n",
              "  'suite composed evenkparity problems k analyses performance simulated annealing ADFs',\n",
              "  'genetic programming GP style program discovery problems'],\n",
              " ['Most learning algorithms',\n",
              "  'values attributes',\n",
              "  'irrelevant attribute values',\n",
              "  'values critical attributes handicap learner paper',\n",
              "  'data'],\n",
              " ['based hierarchy discovered functions',\n",
              "  'This paper presents approach automatic discovery functions',\n",
              "  'new functions',\n",
              "  'problems fitness function Preliminary empirical results',\n",
              "  'discovery useful building blocks'],\n",
              " ['fundamental nonconvex model',\n",
              "  'latter model',\n",
              "  'nonconvex piecewiselinear function',\n",
              "  'norm',\n",
              "  'The fundamental problem'],\n",
              " ['metrical structure musical expectancy',\n",
              "  'perception metrical structure dynamic process temporal organization external musical events',\n",
              "  'perception musical meter',\n",
              "  'Many connectionist',\n",
              "  'perception metrical structure'],\n",
              " ['generational steadystate genetic algorithms particular problem',\n",
              "  'several packages',\n",
              "  'workbench genetic algorithm',\n",
              "  'Most packages',\n",
              "  'variety genetic operators reproduction crossover mutation'],\n",
              " ['Human episodic memory',\n",
              "  'neural network model hippocampal episodic memory',\n",
              "  'large capacity hippocampal memory',\n",
              "  'memory encoding areas',\n",
              "  'fast temporary storage hippocampus slow longterm storage'],\n",
              " ['results testing theory space search component POLLYANNA',\n",
              "  'results testing theory space search',\n",
              "  'Theory space search',\n",
              "  'Empirical Learning Results',\n",
              "  'empirical testing feasible candidate approximate theories'],\n",
              " ['generalsum stochastic games framework multiagent reinforcement',\n",
              "  'Littman zerosum stochastic games broader framework',\n",
              "  'unique Nash equilibrium game',\n",
              "  'multiagent Qlearning method framework',\n",
              "  'paper'],\n",
              " ['Rising operating costs',\n",
              "  'structural transformations',\n",
              "  'globalization companies',\n",
              "  'important part knowledge management initiatives company',\n",
              "  'emerging discipline knowledge management'],\n",
              " ['reasoning failures knowledge system',\n",
              "  'wrong system',\n",
              "  'knowledge operation knowledge',\n",
              "  'systems',\n",
              "  'RAPTER story understanding system'],\n",
              " ['initial theory accurate theory',\n",
              "  'Theory revision',\n",
              "  'theory revision',\n",
              "  'various theory revision systems',\n",
              "  'accurate theory'],\n",
              " ['experiment',\n",
              "  'degree replicability neural computing experiment',\n",
              "  'excess heat electrolysis experiments',\n",
              "  'paper address issue replicability experiments',\n",
              "  'complete abstract specification neural computing experiment'],\n",
              " ['neural network',\n",
              "  'paper propose',\n",
              "  'new neural conditioning rule PCR',\n",
              "  'neural architecture',\n",
              "  'real maze experiment mobile robot'],\n",
              " ['framework analysis synthesis acoustical instruments',\n",
              "  'general inference framework ClusterWeighted Modeling',\n",
              "  'realtime synthesis audio sequences new input data',\n",
              "  'datadriven probabilistic inference',\n",
              "  'nonlinear mapping control data audio space'],\n",
              " ['many realworld domains task machine learning algorithms',\n",
              "  'several realworld domains',\n",
              "  'particular several standard test domains',\n",
              "  'numerical value leaf SRT',\n",
              "  'numerical values'],\n",
              " ['Bayesian framework regularisation model comparison',\n",
              "  'error bars network parameters network output objective comparisons',\n",
              "  'Bayesian interpolation',\n",
              "  'Bayesian',\n",
              "  'Gull Skilling Gull Bayesian evidence'],\n",
              " ['simultaneous multithreading',\n",
              "  'Simultaneous multithreading technique',\n",
              "  'performance potential simultaneous multithreading',\n",
              "  'multiple independent threads',\n",
              "  'multiple threads'],\n",
              " ['deficient domain theory',\n",
              "  'paper present approach theory revision problem',\n",
              "  'probabilities associated domain theory elements',\n",
              "  'awed elements theory',\n",
              "  'converge theory'],\n",
              " ['analysis univariate normal mixtures',\n",
              "  'New methodology',\n",
              "  'improper priors mixture context',\n",
              "  'fully Bayesian mixture analysis',\n",
              "  'posterior distribution'],\n",
              " ['Northeastern University College Computer Science Technical Report',\n",
              "  'Grant IRI National Science Foundation U S Air Force',\n",
              "  'substantial contributions effort',\n",
              "  'NUCCS',\n",
              "  'Andy Barto'],\n",
              " ['Active learning',\n",
              "  'passive learning examples',\n",
              "  'better generalization fixed number training examples',\n",
              "  'part input domain',\n",
              "  'oracle parts domain'],\n",
              " ['High performance architectures',\n",
              "  'impact branch operations Microprocessor',\n",
              "  'negative impact branch operations',\n",
              "  'branch instructions',\n",
              "  'branch operations'],\n",
              " ['model complementarity rules',\n",
              "  'model precedents',\n",
              "  'antecedents precedents level generality cases generality gap',\n",
              "  'abstract rule antecedents',\n",
              "  'rule antecedents'],\n",
              " ['modelbased average reward Reinforcement Learning method',\n",
              "  'extension Hlearning',\n",
              "  'Adaptive RealTime Dynamic Programming simulated robot scheduling task',\n",
              "  'Reinforcement Learning',\n",
              "  'Autoexploratory Hlearning'],\n",
              " ['Dynamic Parametric GA GA',\n",
              "  'fuzzy logic techniques',\n",
              "  'fuzzy knowledgebase system',\n",
              "  'Dynamic Parametric GA',\n",
              "  'GA parameters'],\n",
              " ['Olshausen Field algorithm',\n",
              "  'previous work',\n",
              "  'Olshausen Field',\n",
              "  'formal relationship algorithm',\n",
              "  'algorithm'],\n",
              " ['layered belief networks binary random variables',\n",
              "  'parents node network Bounds marginal probabilities',\n",
              "  'large networks methods',\n",
              "  'networks',\n",
              "  'rates convergence accuracy bounds function network size'],\n",
              " ['Feature selection',\n",
              "  'implementation sequential feature selection algorithm',\n",
              "  'feature selection absence class labels',\n",
              "  'valuable technique',\n",
              "  'existing conceptual clustering system'],\n",
              " ['different learning paradigms symbol processing systems connectionist networks statistical syntactic pattern recognition systems possible candidates',\n",
              "  'Robust flexible sufficiently general vision systems recognition description complex dimensional objects',\n",
              "  'adequate armamentarium representations learning mechanisms',\n",
              "  'strengths weaknesses',\n",
              "  'several promising directions'],\n",
              " ['neural network sequence classification',\n",
              "  'successful mapping arbitrary sequences binary real numbers',\n",
              "  'isolated spoken word recognition cognitive science models sequence processing',\n",
              "  'SARDNET',\n",
              "  'Kohonen Feature Map architecture activation retention decay order'],\n",
              " ['LIACC Technical Report Abstract',\n",
              "  'LIACC Technical Report',\n",
              "  'knowledge integration',\n",
              "  'paper address problem',\n",
              "  'methodology knowledge integration present concrete results'],\n",
              " ['framework bias selection search bias',\n",
              "  'define term bias',\n",
              "  'Recent research field machine learning bias',\n",
              "  'selecting biases',\n",
              "  'machine learning systems'],\n",
              " ['conventional decision trees compact trees',\n",
              "  'decision tree',\n",
              "  'decision trees',\n",
              "  'compact decision trees',\n",
              "  'conventional decision trees compact mode'],\n",
              " ['OGI CSE Technical Report Abstract',\n",
              "  'OGI CSE Technical Report',\n",
              "  'regularizers networks projective basis functions',\n",
              "  'Abstract Smoothing',\n",
              "  'radial basis functions'],\n",
              " ['problem musical variation identification',\n",
              "  'different musical sequences variations',\n",
              "  'musical variation natural result reductionist mechanism',\n",
              "  'structural importance musical events',\n",
              "  'Analyses musical events'],\n",
              " ['variational free energy minimization tool',\n",
              "  'described terms optimization ensemble parameter vectors',\n",
              "  'evidence approximation optimization regularization constants',\n",
              "  'Hinton van Camp',\n",
              "  'linear regression model parameters hyperparameters'],\n",
              " ['auxiliary chain stationary distribution Elements auxiliary chain',\n",
              "  'chain stationary distribution Sahu Zhigljavsky',\n",
              "  'stationary distribution',\n",
              "  'knowledge stationary distribution',\n",
              "  'Markov chain'],\n",
              " ['Conceptual analogy CA approach',\n",
              "  'CA standard',\n",
              "  'CBR AR First CA',\n",
              "  'CA',\n",
              "  'memory organization analogical reasoning'],\n",
              " ['various dynamic confidenceprediction schemes gauge likelihood branch mispredictions',\n",
              "  'mispredictions',\n",
              "  'imperfect branch predictors processor',\n",
              "  'Even sophisticated branchprediction techniques',\n",
              "  'performance face'],\n",
              " ['algorithms robust inference',\n",
              "  'Robust Bayesian inference calculation',\n",
              "  'Bayesian networks global neighborhoods',\n",
              "  'robustness analysis',\n",
              "  'contaminated constant density ratio constant density bounded total variation classes distributions'],\n",
              " ['selflearning control system mobile robot',\n",
              "  'local sensor data robot',\n",
              "  'scratch system',\n",
              "  'correct mapping input sensor space output steering signal space',\n",
              "  'external reinforcement signal'],\n",
              " ['trained feedforward networks',\n",
              "  'network output decisions',\n",
              "  'feedforward networks',\n",
              "  'mechanism orders rules',\n",
              "  'rule evaluation'],\n",
              " ['standard network induction methods',\n",
              "  'Standard methods',\n",
              "  'recurrent networks',\n",
              "  'recurrent neural networks fit',\n",
              "  'genetic algorithms inappropriate network acquisition'],\n",
              " ['aspects network structure',\n",
              "  'A new mechanism genetic encoding neural networks',\n",
              "  'genetic algorithms',\n",
              "  'number nodes connectivity',\n",
              "  'loosely based marker structure biological DNA'],\n",
              " ['multivariate smoothing spline estimate function',\n",
              "  'main effect functions',\n",
              "  'polynomial thin plate spline main effects model',\n",
              "  'small Monte Carlo study',\n",
              "  'Bayesian confidence intervals components decomposition'],\n",
              " ['Cowan J Tesauro G Alspector J',\n",
              "  'Advances Neural Information Processing Systems',\n",
              "  'Conference Neural Information Processing',\n",
              "  'Neural Information Processing Systems San Francisco',\n",
              "  'poster session Conference Neural Information Processing SystemsNatural'],\n",
              " ['sequencing projects increases',\n",
              "  'automatic sequenceassembly programs aid determination DNA sequences',\n",
              "  'essential improve quality automated assemblies',\n",
              "  'quality assemblies',\n",
              "  'fragment assembly'],\n",
              " ['extract instruction level parallelism',\n",
              "  'Extensive research',\n",
              "  'new architecture partitioning instructions',\n",
              "  'level parallelism',\n",
              "  'multiple instruction stream design addressing limitations'],\n",
              " ['single chip Multiple Instruction Stream Computer MISC',\n",
              "  'Multiple Instruction Stream Computer MISC',\n",
              "  'alternative approach single instruction stream multiissue machines',\n",
              "  'increased machine parallelism minimal code expansion',\n",
              "  'separate program streams'],\n",
              " ['The first variant bridge problem determistic model agent',\n",
              "  'paper',\n",
              "  'second variant transitions',\n",
              "  'define',\n",
              "  'probabilities transitions'],\n",
              " ['several mental states',\n",
              "  'wheelchair composing sequencesof mental states',\n",
              "  'EEG paralyzed person',\n",
              "  'article report study',\n",
              "  'EEG'],\n",
              " ['Recurrent perceptron classifiers',\n",
              "  'classical perceptron model',\n",
              "  'fitting models',\n",
              "  'account correlations dependences',\n",
              "  'tight bounds sample complexity'],\n",
              " ['general taxonomy neural net architectures',\n",
              "  'several promising architectures',\n",
              "  'many existing architectures literature',\n",
              "  'timevarying patterns',\n",
              "  'temporal pattern recognition'],\n",
              " ['artificial neural network model mental lexicon',\n",
              "  'different lexical modalities lexical semantics',\n",
              "  'model',\n",
              "  'separate feature maps',\n",
              "  'model orthographic phonological semantic feature maps associations'],\n",
              " ['new selforganizing decomposition technique',\n",
              "  'Problem decomposition',\n",
              "  'paper',\n",
              "  'unsupervised learning scheme Feature Maps Koh',\n",
              "  'highdimensional mappings'],\n",
              " ['search feature subset abstract search problem probabilistic estimates',\n",
              "  'recent feature subset selection algorithms machine',\n",
              "  'comprehensibility accuracy concepts',\n",
              "  'supervised learning algorithms',\n",
              "  'trading accuracy estimates'],\n",
              " ['Genetic Programming GP',\n",
              "  'parallel GP',\n",
              "  'parallel implementations',\n",
              "  'Genetic Programming',\n",
              "  'GP'],\n",
              " ['Reinforcement learning problem',\n",
              "  'reinforcementlearning problems',\n",
              "  'optimal behavior sequential decisionmaking environment',\n",
              "  'modelbased reinforcement',\n",
              "  'reinforcementlearning algorithms'],\n",
              " ['Hyperspectral image sensors',\n",
              "  'method mineral data',\n",
              "  'contextual ICA context hyperspectral data analysis',\n",
              "  'large number contiguous spectral channels',\n",
              "  'images'],\n",
              " ['bounds value function control problems',\n",
              "  'dynamic optimization problem value function',\n",
              "  'one model complex dynamic decision control problems',\n",
              "  'maze navigation problem',\n",
              "  'Markov'],\n",
              " ['energy loads series',\n",
              "  'prediction series',\n",
              "  'environmental input',\n",
              "  'irrelevant inputs output conventional neural network',\n",
              "  'regularisation constants junk inputs'],\n",
              " ['Several different approaches',\n",
              "  'casebased reasoning approaches',\n",
              "  'incremental neural networks',\n",
              "  'learning tasks',\n",
              "  'concepts'],\n",
              " ['extract instruction level parallelism',\n",
              "  'Extensive research',\n",
              "  'new architecture partitioning instructions',\n",
              "  'level parallelism',\n",
              "  'multiple instruction stream design addressing limitations'],\n",
              " ['larger processor system',\n",
              "  'performance range MIMD parallel processor systems neural network simulations The total execution time parallel application modeled sum calculation communication',\n",
              "  'A performance prediction method',\n",
              "  'GCel transputer system Agreement model measurements',\n",
              "  'one processor one communication link performance speedup efficiency'],\n",
              " ['classification trees',\n",
              "  'smoothing tree',\n",
              "  'tree learning algorithm',\n",
              "  'artificial intelligence statistics',\n",
              "  'Bayesian statistics'],\n",
              " ['pomdps general models sequential decisions actions',\n",
              "  'formulated solved pomdps',\n",
              "  'pomdps general models',\n",
              "  'interest formulated pomdps',\n",
              "  'classification pomdps'],\n",
              " ['arbitrary learning situation',\n",
              "  'appropriate learning strategy',\n",
              "  'appropriate learning strategies order',\n",
              "  'general representation processing framework introspective reasoning strategy selection',\n",
              "  'reasoning failure'],\n",
              " ['adaptive training system ATS',\n",
              "  'uncertainty student model',\n",
              "  'students solution',\n",
              "  'student',\n",
              "  'students'],\n",
              " ['Many algorithms parameters',\n",
              "  'machine learning algorithms parameter',\n",
              "  'nontrivial task influence knowledge model',\n",
              "  'background knowledge target problem',\n",
              "  'characteristics target problem'],\n",
              " ['explicit negative examples',\n",
              "  'negative examples',\n",
              "  'pasttense learning',\n",
              "  'pasttense learning illustrate advantages',\n",
              "  'logic programs'],\n",
              " ['Instancebased learning methods',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'instance based methods',\n",
              "  'phase prediction time',\n",
              "  'multiresolution data structure'],\n",
              " ['new agglomerative clustering algorithm pattern cluster',\n",
              "  'Such agglomerative scheme',\n",
              "  'realworld clustering problems',\n",
              "  'hyperboxes hierarchial manner',\n",
              "  'pattern samples'],\n",
              " ['randomized technique partitioning examples',\n",
              "  'Small trees',\n",
              "  'oblique hyperplanes',\n",
              "  'axisparallel hyperplanes',\n",
              "  'ID descendants partition set points'],\n",
              " ['new algorithm',\n",
              "  'genetic algorithm',\n",
              "  'ICET',\n",
              "  'costsensitive classification',\n",
              "  'ICET variety conditions'],\n",
              " ['linear programming',\n",
              "  'This paper highlights role mathematical programming',\n",
              "  'particularly linear programming training neural networks',\n",
              "  'leads use unconstrained minimization techniques training neural network',\n",
              "  'planes input space'],\n",
              " ['Dissatisfaction existing standard casebased reasoning',\n",
              "  'interesting kind casebased reasoning',\n",
              "  'CBR creative problem',\n",
              "  'CBR systems',\n",
              "  'CBR research paradigm'],\n",
              " ['application machine',\n",
              "  'important property natural DNA sequences',\n",
              "  'DNA sequences',\n",
              "  'present technique DNA segmentation',\n",
              "  'hidden Markov models'],\n",
              " ['Weight modifications traditional neural nets',\n",
              "  'weight change',\n",
              "  'efficient introspective selfreferential weight change algorithm show algorithms',\n",
              "  'previous weight change',\n",
              "  'weight matrix'],\n",
              " ['manytomany multiassociative mapping',\n",
              "  'paper',\n",
              "  'multiassociative memory',\n",
              "  'connectionist models',\n",
              "  'multiassociative'],\n",
              " ['Human visual systems',\n",
              "  'dynamic shifts receptive field RF neurons visual system',\n",
              "  'stable internal representation scene',\n",
              "  'eye movements',\n",
              "  'direction gaze eye position signals'],\n",
              " ['rules factors',\n",
              "  'decision trees prediction rules',\n",
              "  'simple patterns rules',\n",
              "  'predictive outcome international conflict management attempts',\n",
              "  'outcome conflict management attempt'],\n",
              " ['c fl UWCC COMMA Technical Report',\n",
              "  'unimodal function optimization methods',\n",
              "  'subsequent iterations regions problem space solutions',\n",
              "  'commercial purposes',\n",
              "  'optima multimodal problems'],\n",
              " ['paper examine intuition',\n",
              "  'TD several domains state Using VI',\n",
              "  'classical algorithms problem classes',\n",
              "  'DAGSP algorithm',\n",
              "  'asynchronous value iteration'],\n",
              " ['performance automatic design optimization',\n",
              "  'interactive formulation testing reformulation design optimization strategies',\n",
              "  'yacht design jet engine nozzle design',\n",
              "  'computational cost optimization quality resulting design',\n",
              "  'optimization strategies'],\n",
              " ['verification neural network',\n",
              "  'The classification performance neural network combined sixband',\n",
              "  'LandsatTM oneband ERSSAR',\n",
              "  'available ground truth polygons training test sets',\n",
              "  'PRI imagery scene'],\n",
              " ['complicated data sequences DNA speech',\n",
              "  'observed sequence direct output underlying generation process',\n",
              "  'model class',\n",
              "  'particular show class Markov chains variable memory length',\n",
              "  'Markov models variable memory length probabilistic finite suffix automata'],\n",
              " ['implemented system',\n",
              "  'advice language advice',\n",
              "  'approximate advice functions',\n",
              "  'intelligent software agents',\n",
              "  'appealing middle ground nonadaptive agent programming languages systems'],\n",
              " ['attribute set concepts',\n",
              "  'concept learning objects domain',\n",
              "  'usefulness concepts limited task attributes',\n",
              "  'Existing concept learners',\n",
              "  'capability concept learning system'],\n",
              " ['Bayesian inference data modeled mixture distribution',\n",
              "  'true Bayesian predictive distribution',\n",
              "  'prior distribution mixing proportions',\n",
              "  'Bayesian',\n",
              "  'correct number components'],\n",
              " ['new reinforcement learning method',\n",
              "  'approach broad range reinforcement learning problems',\n",
              "  'SANE Symbiotic Adaptive NeuroEvolution',\n",
              "  'SANE',\n",
              "  'population neurons genetic algorithms'],\n",
              " ['probabilistic evaluation plans presence unmeasured variables plan',\n",
              "  'probability plan',\n",
              "  'plan',\n",
              "  'passive observations measured variables',\n",
              "  'several concurrent sequential actions'],\n",
              " ['control flow prediction',\n",
              "  'potential control flow prediction abstract machine dynamic ILP processing model',\n",
              "  'dynamic ILP processors',\n",
              "  'dynamic window',\n",
              "  'information control flow graph program'],\n",
              " ['mean field theory sigmoid belief networks based ideas statistical mechanics',\n",
              "  'tractable approximation true probability distribution networks',\n",
              "  'Our mean field theory',\n",
              "  'utility framework benchmark problem statistical pattern',\n",
              "  'lower bound likelihood evidence'],\n",
              " ['Many learning experience systems',\n",
              "  'performance element PE',\n",
              "  'performance element',\n",
              "  'learning system context general class performance elements',\n",
              "  'distribution problems'],\n",
              " ['QLearning Watkins planning tasks',\n",
              "  'composite tasks',\n",
              "  'decomposition composite task',\n",
              "  'elemental tasks',\n",
              "  'several elemental tasks'],\n",
              " ['feedforward neural network',\n",
              "  'use decision hyperplanes',\n",
              "  'paper dynamics decision hyperplanes',\n",
              "  'dynamics hyperplanes',\n",
              "  'Hyperplane inertia'],\n",
              " ['Recursive AutoAssociative Memory',\n",
              "  'deeper complex data structures',\n",
              "  'Modifications',\n",
              "  'data',\n",
              "  'extra layers'],\n",
              " ['efficient algorithm',\n",
              "  'efficient implementation algorithm',\n",
              "  'formal framework problem',\n",
              "  'new boosting algorithm',\n",
              "  'RankBoost nearest neighbor regression algorithms'],\n",
              " ['decision tree',\n",
              "  'decision trees',\n",
              "  'hybrid approach decision trees',\n",
              "  'performance CBL systems',\n",
              "  'CBL systems'],\n",
              " ['Technical Report No Department Statistics University',\n",
              "  'linear network models correlations',\n",
              "  'Toronto',\n",
              "  'recognition model',\n",
              "  'analysis model'],\n",
              " ['Bayesian method',\n",
              "  'amino acid distributions',\n",
              "  'Markov model HMM protein family columns',\n",
              "  'Dirichlet mixture densities',\n",
              "  'Bayesian'],\n",
              " ['simple cost model machine learning applications',\n",
              "  'systems confusion matrix cash flow matrix application cost',\n",
              "  'machine learning system prototype stage',\n",
              "  'models',\n",
              "  'convex hull method present model'],\n",
              " ['independenices formal language communicating processing causal information statistical analysis',\n",
              "  'complex information external interventions',\n",
              "  'graphical interpretation Rubins model causal effects',\n",
              "  'quantitative predictions effects interventions',\n",
              "  'external interventions'],\n",
              " ['casebased design adaptation design case',\n",
              "  'new designs',\n",
              "  'new design requirements',\n",
              "  'similar example case lie focus search',\n",
              "  'If sufficient adapt predefined set design parameters task'],\n",
              " ['novel nonlinear model time series analysis',\n",
              "  'nonlinear models',\n",
              "  'linear models',\n",
              "  'parameterization model',\n",
              "  'prediction results benchmark time series'],\n",
              " ['previous upper bound coverage Boolean concept learning algorithm',\n",
              "  'coverage',\n",
              "  'upper bound Experimental measurement coverage ID FRINGE algorithms',\n",
              "  'definition coverage',\n",
              "  'way coverage maximization'],\n",
              " ['previous FOGA workshop',\n",
              "  'initial results',\n",
              "  'Markov model',\n",
              "  'Markov models',\n",
              "  'FOGA'],\n",
              " ['emergent behaviour coevolutionary model design',\n",
              "  'coevolutionary design process',\n",
              "  'An important aspect creative design concept emergence',\n",
              "  'design process',\n",
              "  'behaviour space active participant behaviour'],\n",
              " ['learnability PAC model data',\n",
              "  'attribute noise learnability results',\n",
              "  'learnable attribute noise attribute noise rate',\n",
              "  'simultaneous attribute noise classification noise',\n",
              "  'classification noise Classes results'],\n",
              " ['new Hidden Markov Model HMM system',\n",
              "  'Hidden Markov Model HMM',\n",
              "  'Separate HMM modules',\n",
              "  'HMM',\n",
              "  'uncharacterized genomic DNA sequences'],\n",
              " ['multiple learning tasks',\n",
              "  'new learning task',\n",
              "  'relatedness individual learning tasks order',\n",
              "  'tasks',\n",
              "  'tasks classes'],\n",
              " ['Belief revision belief update',\n",
              "  'belief revision belief update',\n",
              "  'Belief revision',\n",
              "  'belief change',\n",
              "  'new information static world Belief update'],\n",
              " ['Bayesian framework regression problems',\n",
              "  'regression problems',\n",
              "  'Bayesian',\n",
              "  'infinite dimension limit',\n",
              "  'function approximation'],\n",
              " ['sparse neural networks',\n",
              "  'sparse network',\n",
              "  'efficient mapping',\n",
              "  'parallel vector code',\n",
              "  'memory systems'],\n",
              " ['nature genotype',\n",
              "  'diploid genotypes',\n",
              "  'haploid genotypes',\n",
              "  'diploid populations ecological neural networks',\n",
              "  'variability fitness population'],\n",
              " ['set beliefs language beliefs',\n",
              "  'belief change',\n",
              "  'unreasonable agents beliefs',\n",
              "  'beliefs',\n",
              "  'set beliefs'],\n",
              " ['novel approach belief change',\n",
              "  'previous beliefs',\n",
              "  'earlier beliefs',\n",
              "  'surprising observation indication world',\n",
              "  'active area philosophy'],\n",
              " ['frequently necessary resort approximation true optimal value function',\n",
              "  'search trajectory way current state goal state',\n",
              "  'value function',\n",
              "  'online search',\n",
              "  'online search cases'],\n",
              " ['Probabilistic contextfree grammars',\n",
              "  'simple way',\n",
              "  'particular queries',\n",
              "  'PCFGs',\n",
              "  'particular class distributions'],\n",
              " ['recent developments',\n",
              "  'logic formalism',\n",
              "  'logic probabilities',\n",
              "  'formalism',\n",
              "  'useful properties'],\n",
              " ['Clay evolutionary architecture autonomous robots',\n",
              "  'motor schemabased control reinforcement learning Robots',\n",
              "  'Clay benefit realtime performance motor schemas continuous dynamic environments',\n",
              "  'Clay',\n",
              "  'adaptive reinforcement'],\n",
              " ['parallel online learning algorithm',\n",
              "  'dynamic neural networks nonstationary environments',\n",
              "  'local time space',\n",
              "  'feasability algorithm',\n",
              "  'hidden units units'],\n",
              " ['contexts creativity',\n",
              "  'Creativity',\n",
              "  'creativity',\n",
              "  'particular creativity essential part',\n",
              "  'generative component comprehension component'],\n",
              " ['creative mechanical design',\n",
              "  'design problems',\n",
              "  'Creative designers',\n",
              "  'serendipitous recognition solutions',\n",
              "  'new functions purposes common design pieces process'],\n",
              " ['different measures',\n",
              "  'several different trees',\n",
              "  'selection decision tree induction informativity gini index',\n",
              "  'different probability estimation methods',\n",
              "  'decision tree'],\n",
              " ['learning situations',\n",
              "  'adversarial model present model success',\n",
              "  'several models situations',\n",
              "  'oblivious models switches',\n",
              "  'adversarial models'],\n",
              " ['cases case base',\n",
              "  'Case based systems',\n",
              "  'identification opportunities parallelisation case base retrieval',\n",
              "  'similarity measures',\n",
              "  'toolbox systematic construction similarity measures'],\n",
              " ['real world applications software engineers',\n",
              "  'data structures software',\n",
              "  'simple abstract data structures',\n",
              "  'abstract data structures',\n",
              "  'software'],\n",
              " ['ABSTRACT',\n",
              "  'SYCON',\n",
              "  'exponential time computation',\n",
              "  'analog devices',\n",
              "  'classical digital computation'],\n",
              " ['convergence diagnostic procedure MCMC',\n",
              "  'total variation distances distribution algorithm',\n",
              "  'applicability utility computational expense interpretability',\n",
              "  'utility interpretability',\n",
              "  'MCMC'],\n",
              " ['distance skull brain',\n",
              "  'electroencephalographic EEG data',\n",
              "  'EEG data volume conduction',\n",
              "  'large brain area',\n",
              "  'EEG'],\n",
              " ['Miller G',\n",
              "  'capacity processing information',\n",
              "  'Miller',\n",
              "  'The magical number',\n",
              "  'Technical Report'],\n",
              " ['large number decision trees quality decision trees',\n",
              "  'trees accurate trees',\n",
              "  'greedy approach trees',\n",
              "  'trees',\n",
              "  'greedy approach'],\n",
              " ['supervised machine learning model',\n",
              "  'machine learning model',\n",
              "  'discrete classifications',\n",
              "  'continuous valued input',\n",
              "  'discrete classes'],\n",
              " ['multiple tasks',\n",
              "  'optimal solution task isolation paper',\n",
              "  'good solutions tasks',\n",
              "  'task isolation paper',\n",
              "  'optimal solution entire set tasks'],\n",
              " ['additive tree T k T D k',\n",
              "  'n fi n distance matrix D tree',\n",
              "  'problem',\n",
              "  'metric T',\n",
              "  'algorithm'],\n",
              " ['CaseBased Planning CBP',\n",
              "  'general CBP',\n",
              "  'CBP',\n",
              "  'current CBP methodology',\n",
              "  'domainindependent planning'],\n",
              " ['form speculation control balance benefits speculation',\n",
              "  'instruction level parallelism speculation',\n",
              "  'Modern processors',\n",
              "  'architects speculation control',\n",
              "  'appropriate speculation control'],\n",
              " ['Relational learning',\n",
              "  'special interest members machine learning community',\n",
              "  'relational representations',\n",
              "  'used algorithms',\n",
              "  'supervised learning tasks'],\n",
              " ['new approximate learning algorithm',\n",
              "  'use gradient descent procedure learning process',\n",
              "  'Boltzmann Machines',\n",
              "  'fixed point equation learning rules',\n",
              "  'Boltzmann Machines based mean field theory linear response theorem'],\n",
              " ['combinatorial optimization problem',\n",
              "  'combinatorial optimization problems application reinforcement learning methods',\n",
              "  'methodology NASA scheduling problem show',\n",
              "  'training problem instances',\n",
              "  'search control policy'],\n",
              " ['important class problems decision control',\n",
              "  'Markov decision',\n",
              "  'undiscounted rewards',\n",
              "  'MDPs',\n",
              "  'exploration time T'],\n",
              " ['predicated execution',\n",
              "  'partial predicated execution support conditional moves',\n",
              "  'execution',\n",
              "  'execution high tradeoffs',\n",
              "  'partial full predication'],\n",
              " ['learning models',\n",
              "  'learning algorithms',\n",
              "  'variant online learning model learner',\n",
              "  'relationship complexity',\n",
              "  'model'],\n",
              " ['genetic algorithm',\n",
              "  'new genetic algorithm',\n",
              "  'lowerbound',\n",
              "  'ideal behavior algorithm main task',\n",
              "  'class monotonic functions algorithm'],\n",
              " ['paper study forecasting model based mixture experts',\n",
              "  'nonlinear regression model mixture Gaussians',\n",
              "  'first model',\n",
              "  'nonlinear autoregression model',\n",
              "  'performance models'],\n",
              " ['represen tation',\n",
              "  'represen tations',\n",
              "  'represen tation cost function',\n",
              "  'Suttons TD metho',\n",
              "  'represen tation optimal resp ect'],\n",
              " ['vary case case',\n",
              "  'reasoning cases',\n",
              "  'Casebased reasoning',\n",
              "  'new cases',\n",
              "  'graphstructured representations'],\n",
              " ['regression tree',\n",
              "  'regression trees',\n",
              "  'linear regression',\n",
              "  'construction pruning interpretation regression tree',\n",
              "  'trees'],\n",
              " ['General Theory Quantitative Results',\n",
              "  'human brain',\n",
              "  'Many brain structures',\n",
              "  'microscopic neurosynaptic dynamics stochastic dynamics',\n",
              "  'transformation collective dynamics'],\n",
              " ['Abstract Theory revision systems',\n",
              "  'A Methodology Evaluating Theory Revision Systems Results',\n",
              "  'revisions theory',\n",
              "  'computing distance original theory',\n",
              "  'small changes original theory'],\n",
              " ['novel data mining approach based decomposition',\n",
              "  'dataset method',\n",
              "  'realworld housing loans allocation dataset',\n",
              "  'decomposition',\n",
              "  'relatively complex dataset datasets'],\n",
              " ['case studies',\n",
              "  'Authors case studies',\n",
              "  'results case studies example application',\n",
              "  'multiple algorithms',\n",
              "  'Most empirical evaluations machine learning algorithms case studies'],\n",
              " ['generalization error amount error reduction',\n",
              "  'multiple descriptions class data',\n",
              "  'degree descriptions class',\n",
              "  'multiple descriptions',\n",
              "  'errors'],\n",
              " ['Plannett system',\n",
              "  'volcanos radar images surface planet Venus Plannett',\n",
              "  'Venus Plannett',\n",
              "  'classification module threestage image analysis system',\n",
              "  'Plannett'],\n",
              " ['actions control planning',\n",
              "  'macro actions',\n",
              "  'Macro actions',\n",
              "  'primitive actions',\n",
              "  'approach problem based mathematical framework Markov decision processes reinforcement'],\n",
              " ['McNemars test test',\n",
              "  'show test',\n",
              "  'tests',\n",
              "  'best test',\n",
              "  'test difference two proportions b paireddifferences test'],\n",
              " ['passive assign classlabel instance',\n",
              "  'wrong classification',\n",
              "  'active classifier cost',\n",
              "  'additional attribute values penalty',\n",
              "  'active classifier'],\n",
              " ['eliminationtype algorithm',\n",
              "  'algorithms',\n",
              "  'principle common many algorithms',\n",
              "  'nonserial dynamic programming algorithms',\n",
              "  'probable explanation maximum aposteriori hypothesis maximum expected utility updating belief'],\n",
              " ['Sociological Methodology',\n",
              "  'Peter V Marsden',\n",
              "  'Peter Marsden Bruce',\n",
              "  'Robert Hauser Michael Hout Steven Lewis Scott Long Diane Lye Peter Marsden',\n",
              "  'Adrian E Raftery Professor Statistics Sociology Department'],\n",
              " ['Such algorithms useful reasoning probabilistic deterministic networks',\n",
              "  'possible select spectrum algorithm',\n",
              "  'treeclustering conditioning trade space time',\n",
              "  'paper',\n",
              "  'problem structure'],\n",
              " ['new approach probabilistic inference belief networks global conditioning simple generalization Pearls b method loopcutset conditioning',\n",
              "  'loopcutset conditioning Jensens method',\n",
              "  'new opportunities',\n",
              "  'global conditioning',\n",
              "  'approach'],\n",
              " ['feedback networks',\n",
              "  'potential computational role subthreshold oscillations',\n",
              "  'underlying subthreshold oscillation',\n",
              "  'cortical neurons',\n",
              "  'network'],\n",
              " ['new method',\n",
              "  'methods',\n",
              "  'subpopulation individual',\n",
              "  'standard generational evolutionary algorithm',\n",
              "  'concept distance individuals tag bits'],\n",
              " ['changes output input transformed group',\n",
              "  'constant output inputs',\n",
              "  'changes output inputs',\n",
              "  'transformed distorted examples training data',\n",
              "  'training data'],\n",
              " ['VE Bayesian network inference',\n",
              "  'finergrain factorization joint probability',\n",
              "  'factorization joint probability multiplication',\n",
              "  'CPCS networks medical diagnosis show method',\n",
              "  'conditional probability variable'],\n",
              " ['hybrid cognitive model humans',\n",
              "  'skills complex cognitive tasks',\n",
              "  'human learning task reinforcement',\n",
              "  'hybrid computational architectures',\n",
              "  'NRL Navigation task'],\n",
              " ['statistical query model',\n",
              "  'new variant statistical query model',\n",
              "  'complexity statistical query',\n",
              "  'statistical query',\n",
              "  'relative error statistical queries PAC simulation'],\n",
              " ['Reduced Error Pruning relational learning algorithms',\n",
              "  'Incremental Reduced Error Pruning',\n",
              "  'attempts address problems',\n",
              "  'problems',\n",
              "  'use algorithm'],\n",
              " ['music language meter',\n",
              "  'metrical structure',\n",
              "  'language metrical Meter',\n",
              "  'data music speech',\n",
              "  'appropriate pulses model applicable metrical structure speech'],\n",
              " ['model abduction based revision epistemic state agent Explanations',\n",
              "  'deductive relationship explanation observation',\n",
              "  'explanations',\n",
              "  'predictive explanations',\n",
              "  'semantic preferences explanations'],\n",
              " ['Report R ISRN SICSRSE',\n",
              "  'Karlssons modifi cation Jaeckels',\n",
              "  'ISSN Abstract',\n",
              "  'Sparse Distributed Memory',\n",
              "  'hard locations Karlssons case masks storage addresses'],\n",
              " ['Report R ISRN SICSRSE',\n",
              "  'sparse distributed memory',\n",
              "  'unknown number T random data vectors',\n",
              "  'hard locations',\n",
              "  'memory'],\n",
              " ['rankedmodel semantics ifthen rules',\n",
              "  'Rule priorities',\n",
              "  'ifthen',\n",
              "  'coherent framework',\n",
              "  'causal reasoning'],\n",
              " ['EM algorithms',\n",
              "  'ExpectationMaximization EM',\n",
              "  'mathematical connection',\n",
              "  'EM terms',\n",
              "  'EM step parameter space'],\n",
              " ['first order concept description background knowledge',\n",
              "  'realvalued continuous variables',\n",
              "  'realvalued class discrete realvalued variables',\n",
              "  'first',\n",
              "  'A first order regression algorithm'],\n",
              " ['degree hemispheric organization asymmetry organization computational model bihemispheric cerebral cortex',\n",
              "  'organization measures',\n",
              "  'degree organization symmetry lateralization topographic map formation',\n",
              "  'resulting measures',\n",
              "  'several topographic maps'],\n",
              " ['Learning structure temporallyextended sequences',\n",
              "  'global structure structure',\n",
              "  'Figure map sequence inputs sequence outputs Learning structure temporallyextended sequences difficult computational problem input pattern',\n",
              "  'musical structure',\n",
              "  'musical phrasebut structure'],\n",
              " ['incremental introduction new units',\n",
              "  'neuralnetworks higherorder connections',\n",
              "  'new units',\n",
              "  'higherorder',\n",
              "  'recurrent connections'],\n",
              " ['hidden Markov chains',\n",
              "  'hidden Markov chains convergence MCMC algorithms',\n",
              "  'independence startup distribution stability Markov chain',\n",
              "  'Markov',\n",
              "  'complex models'],\n",
              " ['various categories',\n",
              "  'data training networks discriminant classifier',\n",
              "  'neural networks attractive alternative traditional statistical techniques',\n",
              "  'liver disease',\n",
              "  'additional independent data identical statistical properties'],\n",
              " ['multiunit Principal Component Analysis PCA neural networks',\n",
              "  'Nonlinear extensions',\n",
              "  'Projection Pursuit PP Independent Component Analysis ICA Separation',\n",
              "  'The networks nonlinear Hebbian learning rules related signal expansions',\n",
              "  'earlier authors'],\n",
              " ['Many hormones physiological processes',\n",
              "  'circadian pattern',\n",
              "  'model patterns',\n",
              "  'circadian rhythms',\n",
              "  'functional form appropriate asymmetry peak nadir phases'],\n",
              " ['highlevel decompositionbased algorithms largescale blockangular optimization problems',\n",
              "  'effectiveness solution largescale graph partitioning problems',\n",
              "  'widelyused graph partitioning techniques',\n",
              "  'blockangular',\n",
              "  'integer variables'],\n",
              " ['Maps regional morbidity mortality rates useful tools',\n",
              "  'useful smoothing crude maps disease risk',\n",
              "  'spatial patterns disease',\n",
              "  'dataset countyspecific lung cancer rates state Ohio period',\n",
              "  'Bayes empirical Bayes methods'],\n",
              " ['backpropagation network',\n",
              "  'connection exploratory projection pursuit methods',\n",
              "  'The importance dimensionality reduction principle',\n",
              "  'Bienenstock Cooper Munro BCM',\n",
              "  'new statistical insight synaptic modification equations'],\n",
              " ['Computational Learning Theory Natural Learning Systems',\n",
              "  'T Petsche S Hanson J Shavlik',\n",
              "  'effect input representation generalization performance realworld problem',\n",
              "  'constructive induction mediate effect input representation accuracy',\n",
              "  'representation'],\n",
              " ['selection schemes',\n",
              "  'parent selection schemes',\n",
              "  'common selection schemes',\n",
              "  'short reference standard advanced selection schemes',\n",
              "  'role selection'],\n",
              " ['Selfsupervised backpropagation',\n",
              "  'competitive version selfsupervised backpropagation',\n",
              "  'case selfsupervised backpropagation version',\n",
              "  'backpropagation simulator CLONES',\n",
              "  'backpropagation'],\n",
              " ['pattern patterns',\n",
              "  'evolving computational model perception production simple rhythmic patterns',\n",
              "  'simple rhythmic pattern',\n",
              "  'meter Rests rhythmic patterns',\n",
              "  'couple input patterns Oscillators'],\n",
              " ['uniform approximation orders radial basis functions',\n",
              "  'several results',\n",
              "  'radial basis functions',\n",
              "  'Buhmann Dyn Levin Dyn Ron L p approximation orders',\n",
              "  'Examples results'],\n",
              " ['L IR norm approximations space',\n",
              "  'basis function Attention restricted functions',\n",
              "  'IR many optimal quasioptimal approximation schemes',\n",
              "  'approximation schemes',\n",
              "  'types radial basis functions'],\n",
              " ['L p',\n",
              "  'An upper bound L p approximation power',\n",
              "  'principal shiftinvariant spaces',\n",
              "  'p',\n",
              "  'exponential box splines polyharmonic splines'],\n",
              " ['full descriptions',\n",
              "  'speeduplearning problems',\n",
              "  'RL standard EBL',\n",
              "  'propagation statebystate basis EBL',\n",
              "  'weakest preconditions operators'],\n",
              " ['present extensions',\n",
              "  'efficient use image segmentation pattern classification tasks',\n",
              "  'vector quantization',\n",
              "  'paper',\n",
              "  'kmeans'],\n",
              " ['VQ MDS time',\n",
              "  'VQ MDS',\n",
              "  'topology comprehensive empirical study',\n",
              "  'SOM',\n",
              "  'recent empirical findings'],\n",
              " ['RL agent',\n",
              "  'While exploring find better solutions agent',\n",
              "  'suboptimal solution',\n",
              "  'agents',\n",
              "  'number failures exploration'],\n",
              " ['connectionist network',\n",
              "  'unneeded weights network',\n",
              "  'simple toy problem',\n",
              "  'finite sized training',\n",
              "  'input variables'],\n",
              " ['genetic algorithms populations',\n",
              "  'genetic information phenotype',\n",
              "  'paper review literature use diploidy dominance operators genetic algorithms',\n",
              "  'work',\n",
              "  'nature information'],\n",
              " ['processor organization tasklevel speculation',\n",
              "  'processor organization',\n",
              "  'tasklevel speculation compiler task selection point view performance',\n",
              "  'speculation data communication data dependence speculation load imbalance task',\n",
              "  'key implications architectural features'],\n",
              " ['Technical Report',\n",
              "  'January',\n",
              "  'interaction training agent learning agent',\n",
              "  'learning agent',\n",
              "  'Introspection Approach method'],\n",
              " ['method feature construction selection',\n",
              "  'appropriate method',\n",
              "  'The application method search minimal multilevel boolean expressions',\n",
              "  'higher classification accuracy',\n",
              "  'classification task'],\n",
              " ['addition standard toolbox exploratory data analysis educational data',\n",
              "  'exploratory data analysis',\n",
              "  'latent classes data',\n",
              "  'underlying structure data',\n",
              "  'data'],\n",
              " ['hierarchical mixture experts HME architecture',\n",
              "  'likelihood splitting criteria expert HME',\n",
              "  'HME',\n",
              "  'probable path tree',\n",
              "  'tree'],\n",
              " ['interacting realworld data',\n",
              "  'realworld data',\n",
              "  'data random errors',\n",
              "  'imperfect data',\n",
              "  'possible presence errors observations'],\n",
              " ['task evolving general iterative sorting algorithms',\n",
              "  'evolved algorithms',\n",
              "  'Genetic Programming',\n",
              "  'differing problem formulations',\n",
              "  'sort problem formulation'],\n",
              " ['Irrelevant redundant features',\n",
              "  'value feature subsets',\n",
              "  'task feature subset selection',\n",
              "  'relevant features',\n",
              "  'predictive accuracy comprehensibility induced concepts'],\n",
              " ['problem classification accuracy decision list',\n",
              "  'homogeneous rules',\n",
              "  'rule',\n",
              "  'rules',\n",
              "  'decision lists'],\n",
              " ['fuzzy graphs example data',\n",
              "  'function approximators',\n",
              "  'quick insights structure example data underlying model',\n",
              "  'data',\n",
              "  'resulting fuzzy graphs'],\n",
              " ['intelligent teaching system',\n",
              "  'offline learning methodology',\n",
              "  'superior hand coding teaching strategies',\n",
              "  'associate superior teaching actions',\n",
              "  'high level strategy decisions'],\n",
              " ['system',\n",
              "  'human robotic',\n",
              "  'neural model',\n",
              "  'patterns',\n",
              "  'basic primitive temporal elements'],\n",
              " ['EEG performance auditory monitoring task',\n",
              "  'electroencephalographic EEG power spectrum accompany fluctuations',\n",
              "  'tasks',\n",
              "  'operators global level alertness',\n",
              "  'level alertness'],\n",
              " ['exact solutions convergent approximations inferences',\n",
              "  'exact inference algorithms',\n",
              "  'exact inference',\n",
              "  'Robust Bayesian inference calculation',\n",
              "  'robust inference problem estimation probabilistic parameters'],\n",
              " ['best perceptron different minimization problems',\n",
              "  'different methods training perceptron',\n",
              "  'benign malignant tumors',\n",
              "  'new tumors',\n",
              "  'new examples'],\n",
              " ['latent variable model form neural network target outputs',\n",
              "  'latent variable space lower dimensionality',\n",
              "  'preliminary results application models protein data',\n",
              "  'simple probability distribution unknown inputs',\n",
              "  'probability data'],\n",
              " ['relevance generalization role loss function',\n",
              "  'summary paper',\n",
              "  'unifying formalism types information',\n",
              "  'posterior maximization subsequent risk minimization analyses empirical risk minimization aspect nonlocal information',\n",
              "  'generalization'],\n",
              " ['cellular encoding edge encoding',\n",
              "  'alternative cellular encoding technique',\n",
              "  'edge encoding',\n",
              "  'node operators cellular encoding',\n",
              "  'edge operators'],\n",
              " ['geometric comparison rule sets',\n",
              "  'geometric class descriptions',\n",
              "  'different algorithms different numbers classes',\n",
              "  'classifications',\n",
              "  'technique'],\n",
              " ['interested adept utilisation waste materials',\n",
              "  'natural resources',\n",
              "  'bear ploy',\n",
              "  'Truth Trash model',\n",
              "  'fortuitous sensory predispositions sensory trash useful information vehicles'],\n",
              " ['probabilistic evaluation effects actions',\n",
              "  'causal effect',\n",
              "  'singleton variable X set variables',\n",
              "  'presence unmeasured variables',\n",
              "  'polynomial number variables graph'],\n",
              " ['VISOR large connectionist system',\n",
              "  'VISOR robust noise variations inputs parameters',\n",
              "  'robust highlevel vision systems',\n",
              "  'VISOR',\n",
              "  'natural neural networks Processing VISOR'],\n",
              " ['Bayesian classification methods',\n",
              "  'spectrum show tradeoffs model accuracy',\n",
              "  'framework',\n",
              "  'full Bayesian networks',\n",
              "  'traversal spectrum'],\n",
              " ['level learning population',\n",
              "  'population lifetime adaptive processes',\n",
              "  'Traits',\n",
              "  'traits',\n",
              "  'supply selection pressure genetic assimilation'],\n",
              " ['phenotypic space adaptive processes',\n",
              "  'genotypic space evolution',\n",
              "  'phenotypic traits',\n",
              "  'phenotypic space',\n",
              "  'Baldwin Effect speed evolutionary process traits'],\n",
              " ['Decision Trees',\n",
              "  'normal decision trees',\n",
              "  'system Probabilistic decisions',\n",
              "  'classificationregression tasks',\n",
              "  'Neural Networks understandable humans'],\n",
              " ['BP momentum term BP weight decay',\n",
              "  'online BP',\n",
              "  'BP',\n",
              "  'cover serial parallel online BP',\n",
              "  'stationary point BP error function'],\n",
              " ['Recurrent neural networks',\n",
              "  'secondorder recurrent neural networks',\n",
              "  'neural network',\n",
              "  'secondorder recurrent neural',\n",
              "  'deterministic finitestate automata DFAs show deteriorating performance'],\n",
              " ['Recent Results',\n",
              "  'global asymptotic stability results',\n",
              "  'Lyapunovtheoretic Techniques Nonlinear Stability ABSTRACT',\n",
              "  'Lyapunov sufficient condition inputtostate stability',\n",
              "  'Report'],\n",
              " ['UMIACSTR University Maryland College Park',\n",
              "  'Technical Report CSTR',\n",
              "  'direct encoding partial knowledge networks',\n",
              "  'recurrent neural networks',\n",
              "  'learned grammar extracted networks'],\n",
              " ['important task manufacturing industries',\n",
              "  'particular task scheduling payload processing NASAs space shuttle program',\n",
              "  'Jobshop',\n",
              "  'previous work',\n",
              "  'previous handengineered system'],\n",
              " ['Turing machines neural networks',\n",
              "  'simulation linear time binarytape machines',\n",
              "  'SYCON',\n",
              "  'Such networks',\n",
              "  'sigmoidal linear combination'],\n",
              " ['state stationary goal state algorithm',\n",
              "  'new LRTAbased algorithms variety tasks',\n",
              "  'realtime search algorithm',\n",
              "  'LRTAbased algorithms',\n",
              "  'stationary goal states'],\n",
              " ['function spaces',\n",
              "  'function space linear combination n',\n",
              "  'function G',\n",
              "  'function',\n",
              "  'paper'],\n",
              " ['University Wisconsin Computer Sciences Technical Report',\n",
              "  'University Wisconsin Computer Sciences Technical Report September',\n",
              "  'explanationbased learning specific problems solution generalized form',\n",
              "  'recursive iterative concepts',\n",
              "  'recursive rules'],\n",
              " ['Gibbs sampler',\n",
              "  'Gibbs',\n",
              "  'uniformly ergodic jagged boundaries sampler',\n",
              "  'convergence properties',\n",
              "  'greatly smoothness boundary R'],\n",
              " ['useful intermediate concepts class attributes',\n",
              "  'attributevector representation intermediate concepts',\n",
              "  'learning problem',\n",
              "  'develop technique',\n",
              "  'comprehensibility induced descriptions'],\n",
              " ['Uncertainty sampling methods',\n",
              "  'class labels training instances',\n",
              "  'previous labeled instances',\n",
              "  'chosen heterogeneous approach uncertainty samples',\n",
              "  'classifiers lower error rates random samples'],\n",
              " ['instrumental variables',\n",
              "  'Certain causal models',\n",
              "  'unmeasured variables',\n",
              "  'observed variables',\n",
              "  'exogenous variables'],\n",
              " ['Bayesian confidence intervals smoothing spline',\n",
              "  'Bayesian confidence intervals sample size smoothing spline',\n",
              "  'Bayesian confidence intervals Approximations simulations special functions',\n",
              "  'asymptotic formula sample size calculations',\n",
              "  'Bayesian'],\n",
              " ['Freund Schapires AdaBoost',\n",
              "  'Freund Schapires',\n",
              "  'several improvements',\n",
              "  'Freund Schapire',\n",
              "  'new boosting algorithms multiclass classification problems'],\n",
              " ['Evolutionary Algorithms direct random search algorithms',\n",
              "  'paper algorithms capability adaptation',\n",
              "  'learning process population level first level',\n",
              "  'learning process metalevel strategy parameters',\n",
              "  'principles natural evolution method'],\n",
              " ['novel addition known methods',\n",
              "  'quality learned networks',\n",
              "  'Bayesian networks data',\n",
              "  'local structure',\n",
              "  'local structures'],\n",
              " ['method bound test errors',\n",
              "  'method infer bounds classifiers',\n",
              "  'linear programming infer committee error bounds',\n",
              "  'fewer classifiers prospective committees',\n",
              "  'useful error bounds'],\n",
              " ['PI controller neural network',\n",
              "  'steadystate output PI controller',\n",
              "  'PI controller',\n",
              "  'nstep ahead error coil output set point reinforcement learning agent',\n",
              "  'neural network'],\n",
              " ['ordered list classification rules examples',\n",
              "  'usefulness CN inductive tool Comparisons Quinlans C',\n",
              "  'short paper',\n",
              "  'entropy search',\n",
              "  'Laplacian error estimate alternative evaluation function'],\n",
              " ['connectionism parallel distributed processing neural network modeling brainstyle computation',\n",
              "  'Neural computation',\n",
              "  'mission introduction neural network novices',\n",
              "  'need concise introduction theoretical perspective',\n",
              "  'perspective physics home discipline authors'],\n",
              " ['major impediment high performance wideissue superscalar processors',\n",
              "  'Controlflow misprediction',\n",
              "  'Controlflow',\n",
              "  'microarchitecture PolyPath processor extension aggressive superscalar outoforder architecture',\n",
              "  'Selective Eager Execution SEE execution model'],\n",
              " ['competitive tree learning algorithm',\n",
              "  'several mature AI statistical families tree learning algorithms',\n",
              "  'show derived Bayesian algorithm',\n",
              "  'illustration second learning algorithm',\n",
              "  'algorithms'],\n",
              " ['subset features',\n",
              "  'method feature subset selection',\n",
              "  'previous subset selection algorithms',\n",
              "  'supervised induction algorithm',\n",
              "  'crossvalidation applicable induction algorithm'],\n",
              " ['machine learning method',\n",
              "  'statistical methods',\n",
              "  'value realvalued function',\n",
              "  'function values',\n",
              "  'competitive existing machine'],\n",
              " ['dual path execution branch prediction',\n",
              "  'branch prediction confidence',\n",
              "  'dynamic branch prediction',\n",
              "  'hybrid branch predictor scheme',\n",
              "  'dynamic branch predictor'],\n",
              " ['Threaded MultiPath Execution TME',\n",
              "  'SMT processor hardware contexts',\n",
              "  'multiple paths execution',\n",
              "  'existing hardware Simultaneous Multithreading SMT processor',\n",
              "  'multipath execution'],\n",
              " ['paper review research machine learning relation computational models',\n",
              "  'machine',\n",
              "  'concrete computational models',\n",
              "  'psychological literature growing evidence',\n",
              "  'point abstract simulation'],\n",
              " ['sequences homologous original sequence',\n",
              "  'single query sequence',\n",
              "  'hidden Markov modeling Pair wise sequence comparisons',\n",
              "  'additional homologs pairwise sequence comparisons motif analysis',\n",
              "  'The function unknown biological sequence'],\n",
              " ['Future research directions Knowledge Discovery Databases',\n",
              "  'Knowledge Discovery Databases',\n",
              "  'Discovery robust pattern',\n",
              "  'search complexity find concept',\n",
              "  'Pattern Theoretic approach'],\n",
              " ['dynamic programming edit distance approach pairwise sequence alignment useful parts',\n",
              "  'challenging problem study approaches',\n",
              "  'Multiple Alignment',\n",
              "  'Prerequisites',\n",
              "  'multiple alignments'],\n",
              " ['new system induction oblique decision trees',\n",
              "  'good oblique split form hyperplane node decision tree Oblique decision tree methods',\n",
              "  'benefits randomization construction oblique decision trees',\n",
              "  'oblique trees smaller accurate axisparallel counterparts',\n",
              "  'OC'],\n",
              " ['ExplanationBased Reinforcement Learning EBRL',\n",
              "  'ExplanationBased Reinforcement Learning',\n",
              "  'Reinforcement Learning RL',\n",
              "  'ExplanationBased Learning EBL',\n",
              "  'optimal fashion Hierarchical EBRL'],\n",
              " ['BRACE potential effective efficient method discretization',\n",
              "  'data useful necessary tool',\n",
              "  'many learning paradigms',\n",
              "  'Discretization',\n",
              "  'many objectives'],\n",
              " ['Naive Bayesian classifiers',\n",
              "  'improvement naive Bayesian classifier',\n",
              "  'Bayesian classifier',\n",
              "  'simple Bayesian classifier training examples',\n",
              "  'Bayesian classifier searching dependencies'],\n",
              " ['Multiple sequence alignment',\n",
              "  'new flexible method generation multiple sequence alignments',\n",
              "  'The results studies attempting infer appropriate parameter constraints generation de novo HMMs globin kinase aspartic acid protease ribonuclease H sequences SAM HMMER methods',\n",
              "  'currently available alignment methods',\n",
              "  'distantly related viral proteins'],\n",
              " ['Several recurrent networks',\n",
              "  'recurrent network',\n",
              "  'recurrent networks',\n",
              "  'network',\n",
              "  'finite state machines internal state trajectories'],\n",
              " ['useful learning algorithm',\n",
              "  'algorithm',\n",
              "  'recent years bias',\n",
              "  'select appropriate bias',\n",
              "  'order'],\n",
              " ['paper introduce modelbased reinforcement learning method',\n",
              "  'undiscounted average reward',\n",
              "  'methods parameters',\n",
              "  'time step methods',\n",
              "  'total reward'],\n",
              " ['Converse Lyapunov Function Theorem',\n",
              "  'wellknown classical theorems',\n",
              "  'various aspects',\n",
              "  'unified natural manner',\n",
              "  'arbitrary bounded timevarying parameters'],\n",
              " ['Technical Report',\n",
              "  'Artificial Intelligence grounding systems environment representations',\n",
              "  'inherent meaning system',\n",
              "  'Artificial Intelligence',\n",
              "  'neural network processors part method'],\n",
              " ['ExplanationBased Learning Mitchell et al DeJong Mooney',\n",
              "  'ExplanationBased Learning Mitchell',\n",
              "  'research area Past characterizations problem eg Mitchell et al Rajamoney',\n",
              "  'al DeJong Mooney',\n",
              "  'al Rajamoney DeJong'],\n",
              " ['maximal posteriori MAP instantiation Bayesian network variables',\n",
              "  'Bayesian network variables',\n",
              "  'MAP task',\n",
              "  'Bayesian network',\n",
              "  'task'],\n",
              " ['elegant powerful theoretical framework design analysis autonomous adaptive communication networks',\n",
              "  'Parameterized heuristics',\n",
              "  'paper design intelligent autonomous adaptive communication networks',\n",
              "  'messages networks',\n",
              "  'large network'],\n",
              " ['Technical Report Department Statistics University',\n",
              "  'Statistics University',\n",
              "  'Adrian E Raftery Professor Statistics',\n",
              "  'Graduate Research Assistant',\n",
              "  'Washington Box Seattle WA USA Email'],\n",
              " ['performance algorithm difference',\n",
              "  'bit sequence expected number mistakes',\n",
              "  'efficient algorithms',\n",
              "  'algorithms',\n",
              "  'several prediction strategies'],\n",
              " ['formalization novel approach structural similarity assessment adaptation',\n",
              "  'algebraic approach Similarity relations',\n",
              "  'approach',\n",
              "  'exemplified implemented domain industrial building design Borner',\n",
              "  'structure preserving case modifications modulo underlying algebra equational theory algebra'],\n",
              " ['approach automated training agent',\n",
              "  'occasional instruction learner form actions learner',\n",
              "  'level trainers interaction learner',\n",
              "  'reinforcement learning',\n",
              "  'significant reductions average number training trials'],\n",
              " ['learning algorithm',\n",
              "  'accuracy algorithms',\n",
              "  'binary case accuracy learning algorithm',\n",
              "  'algorithm',\n",
              "  'algorithms'],\n",
              " ['model ratio decidendi justification structure',\n",
              "  'important set characteristics ratio decidendi',\n",
              "  'particular model shows theory case',\n",
              "  'purely exemplarbased model ratio decidendi',\n",
              "  'abstract predicates'],\n",
              " ['paper abstract computational principles',\n",
              "  'topographic maps',\n",
              "  'neighbourhood preserving map call topographic homeomorphism',\n",
              "  'topographic homeomorphism',\n",
              "  'quality map'],\n",
              " ['robustness pac learning algorithms instance space f g n examples',\n",
              "  'show product random attribute noise attribute',\n",
              "  'pac',\n",
              "  'uniform attribute noise attribute',\n",
              "  'small amount noise'],\n",
              " ['behavioral specialization learning robot teams',\n",
              "  'particular behavioral assemblages',\n",
              "  'common set skills motor schemabased behavioral assemblages',\n",
              "  'behavioral diversity',\n",
              "  'research'],\n",
              " ['Product units',\n",
              "  'product units',\n",
              "  'performance transfer functions product units',\n",
              "  'random Boolean logic functions product units',\n",
              "  'required efficient synthesis Boolean logic functions neural networks Product units'],\n",
              " ['cognitive model skill acquisition task',\n",
              "  'skills complex cognitive tasks',\n",
              "  'cognitive model humans',\n",
              "  'NRL Navigation task',\n",
              "  'NRL Navigation task depth'],\n",
              " ['rational preservation conditional beliefs belief revision',\n",
              "  'belief revision process',\n",
              "  'iterated belief revision',\n",
              "  'belief revision function epistemic states',\n",
              "  'paper AGM'],\n",
              " ['search strategies',\n",
              "  'twolayer connectionist system',\n",
              "  'weak taskspecific strategy finetunes performance',\n",
              "  'finetuning behavior',\n",
              "  'connectionist mechanisms'],\n",
              " ['indirect learning methods',\n",
              "  'direct learning methods',\n",
              "  'direct reinforcement learning method',\n",
              "  'direct method',\n",
              "  'existing indirect method'],\n",
              " ['general framework study belief change',\n",
              "  'properties belief',\n",
              "  'belief terms',\n",
              "  'interaction knowledge plausibility show properties',\n",
              "  'belief'],\n",
              " ['Markov chain Monte Carlo',\n",
              "  'Markov chain Monte Carlo MCMC',\n",
              "  'stationary distribution chain',\n",
              "  'framework based concept Markov chain regeneration',\n",
              "  'Monte Carlo'],\n",
              " ['interpolation models',\n",
              "  'interpolant choice noise model',\n",
              "  'Bayesian models',\n",
              "  'new models interpolation neuronal spike data',\n",
              "  'single regularization constant ff noise model single parameter'],\n",
              " ['Author paper coordinator Machine Learning project',\n",
              "  'DaimlerBenz applications StatLog',\n",
              "  'Machine Learning ML DaimlerBenz',\n",
              "  'Machine Learning',\n",
              "  'real industrial commercial applications'],\n",
              " ['application reinforcement',\n",
              "  'RL difficult real world problem elevator',\n",
              "  'RL research date Elevator systems',\n",
              "  'global reinforcement signal',\n",
              "  'addition use team RL agents'],\n",
              " ['many exploration techniques',\n",
              "  'Fringe Exploration',\n",
              "  'Fringe Exploration technique efficient exploration partially observable domains',\n",
              "  'statistics space',\n",
              "  'current state space Experimental'],\n",
              " ['policy iteration dynamic programming',\n",
              "  'dynamic programming',\n",
              "  'lead appropriate policy improvement',\n",
              "  'Bairds compute form absolute utility function',\n",
              "  'advantages actions'],\n",
              " ['parallel approach DTSelect selecting features',\n",
              "  'features pool',\n",
              "  'small nonredundant feature sets pools',\n",
              "  'large feature pools',\n",
              "  'protein secondary structure DTSelect'],\n",
              " ['extension package',\n",
              "  'Faculty Sciences Technology New University',\n",
              "  'Faculty Sciences Technology New University Lisbon',\n",
              "  'extension',\n",
              "  'Basic Sugal system'],\n",
              " ['several distinct D views stored object',\n",
              "  'representation D',\n",
              "  'novel views objects network',\n",
              "  'emergence compact representations specific input views',\n",
              "  'representations'],\n",
              " ['Internal models',\n",
              "  'internal models',\n",
              "  'adaptive systems general particular importance',\n",
              "  'adaptive system',\n",
              "  'learning algorithm'],\n",
              " ['February updated April',\n",
              "  'Technical Report',\n",
              "  'February',\n",
              "  'Proceedings Eleventh International Conference Machine Learning Abstract',\n",
              "  'incremental induction decision trees'],\n",
              " ['ONR grant NK Harvard University',\n",
              "  'Supported ONR grants NK NJ Part research',\n",
              "  'partial support ONR grants NK NK Address Department Computer Science University',\n",
              "  'ONR grant NK DARPA',\n",
              "  'NK NK Address Department Computer Science University'],\n",
              " ['utility problem',\n",
              "  'Many recent approaches',\n",
              "  'utility control knowledge',\n",
              "  'efficient set control knowledge training problems',\n",
              "  'sophisticated utility measures'],\n",
              " ['Partigame new algorithm',\n",
              "  'feasible trajectories goal regions',\n",
              "  'feasible paths trajectories',\n",
              "  'goal regions',\n",
              "  'high dimensions'],\n",
              " ['predictive distribution',\n",
              "  'simplest case predictive distribution',\n",
              "  'Predictive inference',\n",
              "  'set distributions',\n",
              "  'joint probability distribution variables'],\n",
              " ['casebased reasoning CBR system search case memory use stored cases',\n",
              "  'efficient casebased reasoning',\n",
              "  'solution adaptation problem',\n",
              "  'efficient indexing problem',\n",
              "  'Bayesian reasoning'],\n",
              " ['new bounds',\n",
              "  'general upper bound expected absolute error algorithm terms',\n",
              "  'upper bounds',\n",
              "  'improved general bounds sample complexity agnostic learning',\n",
              "  'lower bounds'],\n",
              " ['neural networks intelligent systems',\n",
              "  'ultimate connectionist objective',\n",
              "  'workable system',\n",
              "  'networks modular structure',\n",
              "  'second step'],\n",
              " ['Partially observable Markov decision processes pomdps model decision problems agent',\n",
              "  'study pomdps',\n",
              "  'satisfactory policies problems',\n",
              "  'brief review pomdps paper',\n",
              "  'realistic problems'],\n",
              " ['new method construction Markov chains',\n",
              "  'auxiliary chain',\n",
              "  'stationary distribution',\n",
              "  'The proposed method',\n",
              "  'theoretical numerical comparisons characteristics'],\n",
              " ['optimal decisions',\n",
              "  'optimal courses action policies',\n",
              "  'uncertain conditions',\n",
              "  'central Artificial Intelligence',\n",
              "  'inefficient space time'],\n",
              " ['update operator conforming KM',\n",
              "  'Mendelzon KM',\n",
              "  'The Katsuno Mendelzon KM theory belief update',\n",
              "  'alternative semantical view update observations',\n",
              "  'semantics update'],\n",
              " ['main features',\n",
              "  'Brainlike Neuronal Connectionist',\n",
              "  'Neuronal Connectionist models',\n",
              "  'parallelhierarchical Recognition Cone models perception perspective examples',\n",
              "  'Recognition Cone structures'],\n",
              " ['variety approaches decision tree induction',\n",
              "  'measure tree quality',\n",
              "  'one incremental tree induction ITI nonincremental tree induction',\n",
              "  'The ability restructure decision tree',\n",
              "  'quality DMTI'],\n",
              " ['logistic regression model',\n",
              "  'posterior predictive model',\n",
              "  'closed form posterior distribution parameters',\n",
              "  'latent variable density model',\n",
              "  'dual regression problem'],\n",
              " ['Mean field methods',\n",
              "  'Simple mean field methods',\n",
              "  'mean field approximation cases',\n",
              "  'mixture models posterior approximations mixture component factorized distribution',\n",
              "  'efficient methods'],\n",
              " ['standard control learning tasks',\n",
              "  'paper present difficult version classic problem cart pole move plane',\n",
              "  'The success evolutionary methods',\n",
              "  'difficult problem',\n",
              "  'new benchmarks'],\n",
              " ['representational biases',\n",
              "  'learning mechanisms',\n",
              "  'used networks',\n",
              "  'temporal spatiotemporal patterns',\n",
              "  'network structures'],\n",
              " ['complexity bounded number actions',\n",
              "  'Qlearning',\n",
              "  'previous online Q implementations',\n",
              "  'The method based observation Qvalue updates',\n",
              "  'size stateaction space'],\n",
              " ['simple computing elements',\n",
              "  'used networks',\n",
              "  'generative learning algorithms',\n",
              "  'networks',\n",
              "  'variety learning structures'],\n",
              " ['artificial neural networks',\n",
              "  'neural paradigm autonomous road',\n",
              "  'different type simultaneous use different sensors generalization road types',\n",
              "  'neural system drive vehicle',\n",
              "  'neural system'],\n",
              " ['constructive incremental learning system regression problems',\n",
              "  'speed prediction accuracy feature detection task oriented incremental learning',\n",
              "  'linear experts',\n",
              "  'individual predictions',\n",
              "  'expert'],\n",
              " ['model environment state controlled Nature',\n",
              "  'nonBayesian agent',\n",
              "  'repeated game incomplete information Nature appropriate tool modeling general agentenvironment interactions',\n",
              "  'previous environment state part feedback imperfect monitoring case available agent reward',\n",
              "  'imperfect monitoring case criterion'],\n",
              " ['n points rectangle',\n",
              "  'polynomialtime algorithm',\n",
              "  'unknown product distribution D Q instances',\n",
              "  'D rectangle',\n",
              "  'axisaligned rectangles Q respect product distributions multipleinstance examples PAC model Here example'],\n",
              " ['new machine learning method',\n",
              "  'method',\n",
              "  'definition target concept terms',\n",
              "  'set training examples',\n",
              "  'intermediate concepts definitions'],\n",
              " ['successful estimating probabilities events',\n",
              "  'Bayesian approach',\n",
              "  'present mdistribution estimate extension mprobability estimate',\n",
              "  'estimation probabilities',\n",
              "  'probability distributions'],\n",
              " ['Realworld learning tasks',\n",
              "  'missing data',\n",
              "  'highdimensional data',\n",
              "  'incomplete data',\n",
              "  'data'],\n",
              " ['deterministic finitestate automata DFA n states',\n",
              "  'faulttolerant neural DFA implementations',\n",
              "  'DFA',\n",
              "  'sparse secondorder recurrent neural network SORNN n state neurons',\n",
              "  'analog implementation neurons weights'],\n",
              " ['dasguptabiostatwashingtonedu Adrian E Raftery Professor Statistics Sociology Department Statistics University Washington Box Seattle WA email address',\n",
              "  'Department Biostatistics University',\n",
              "  'Statistics University',\n",
              "  'Abhijit Dasgupta graduate student Department Biostatistics University Washington Box Seattle WA email address',\n",
              "  'Washington Box'],\n",
              " ['multiarmed bandit problem gambler',\n",
              "  'best payoff Past solutions bandit problem',\n",
              "  'solution bandit problem adversary',\n",
              "  'arm K nonidentical slot machines',\n",
              "  'best arm'],\n",
              " ['Bayesian belief network sensitivities',\n",
              "  'probability distributions nodes network',\n",
              "  'conditional probabilities',\n",
              "  'QR matrix representation sensitivities',\n",
              "  'alternative way'],\n",
              " ['large neural networks',\n",
              "  'mesh network',\n",
              "  'design progress',\n",
              "  'design',\n",
              "  'neural networkspecific features general programmable machine architecture'],\n",
              " ['many realworld domains',\n",
              "  'text categorization',\n",
              "  'number training examples',\n",
              "  'large number training examples',\n",
              "  'label input part example used signal'],\n",
              " ['work divideandconquer technique',\n",
              "  'technique divideandconquer',\n",
              "  'technique logic programming framework Covering',\n",
              "  'compact hypotheses',\n",
              "  'divideandconquer'],\n",
              " ['Recurrence Surface Approximation inductive learning method',\n",
              "  'Recurrence Surface Approximation',\n",
              "  'censored training examples examples',\n",
              "  'linear programming',\n",
              "  'linear programming generalizer'],\n",
              " ['Minimum Message Length MML invariant Bayesian point estimation technique',\n",
              "  'message lengths',\n",
              "  'Snob Wallace Boulton Wallace Wallace Dowe',\n",
              "  'Wallace Boulton Wallace Freeman',\n",
              "  'MML theory'],\n",
              " ['cognitive phenomena development efficient exible interfaces low level sensory information high level processes',\n",
              "  'VISIT connectionist model covert visual attention',\n",
              "  'high level vision',\n",
              "  'visual processing researchers',\n",
              "  'known physiological data human attention system Various extensions VISIT'],\n",
              " ['excitatory inhibitory populations neurons antisymmetric interactions populations',\n",
              "  'global behavior asymmetric neural networks',\n",
              "  'asymmetric networks',\n",
              "  'excitatory inhibitory neurons antisymmetric interactions',\n",
              "  'symmetric interactions'],\n",
              " ['importance sampling bridge sampling ratio importance sampling problems different dimensions',\n",
              "  'ratio posterior odds',\n",
              "  'global optimal importance sampling bridge sampling ratio importance sampling sense',\n",
              "  'prior odds posterior odds',\n",
              "  'Bayes factor'],\n",
              " ['knowledge bases',\n",
              "  'utility algorithm CaPER casebased planning system',\n",
              "  'novel algorithm efficient associative matching relational structures',\n",
              "  'dependent efficient flexible access large base exemplars cases',\n",
              "  'massively parallel knowledge representation system'],\n",
              " ['number training examples',\n",
              "  'online stopping rules',\n",
              "  'training examples oneatatime',\n",
              "  'training sample size procedures',\n",
              "  'training examples practice'],\n",
              " ['novel approach',\n",
              "  'structural similarity guidance adaptation',\n",
              "  'structural similarity assessment',\n",
              "  'Cbr explainability case selection adaptation',\n",
              "  'retrieval matching adaptation group'],\n",
              " ['blameassignment task',\n",
              "  'blameassignment tasks',\n",
              "  'design redesign physical devices',\n",
              "  'desired behavior device design results',\n",
              "  'undesirable behavior specific structural element design'],\n",
              " ['framework taskdriven knowledge acquisition development design support systems',\n",
              "  'knowledge base design support system',\n",
              "  'design support system',\n",
              "  'knowledge disposal system',\n",
              "  'formal integrated model knowledge design'],\n",
              " ['objects classes',\n",
              "  'omniscient supervisor',\n",
              "  'unsupervised classification',\n",
              "  'unsupervised classifiers',\n",
              "  'neural network classifiers'],\n",
              " ['AI research casebased reasoning',\n",
              "  'casebased reasoning',\n",
              "  'many laboratory casebased systems',\n",
              "  'systems work environments',\n",
              "  'AI'],\n",
              " ['Statistical decision theory',\n",
              "  'way estimate amino acid frequencies',\n",
              "  'based marginal amino acid frequencies',\n",
              "  'true population frequencies',\n",
              "  'optimal number pseudocounts'],\n",
              " ['bias specialised models',\n",
              "  'innateness bias',\n",
              "  'The purpose paper propose refinement notion innateness',\n",
              "  'poor characterisation notion',\n",
              "  'isotropic bias'],\n",
              " ['Reliable visionbased control autonomous vehicle',\n",
              "  'Previous work autonomous lane following system',\n",
              "  'attention important features input scene',\n",
              "  'ALVINN system',\n",
              "  'taskspecific focus attention'],\n",
              " ['Production scheduling problem',\n",
              "  'Markov Decision Process MDP formulation production scheduling',\n",
              "  'unpredictable demand stochastic factory output',\n",
              "  'standard scheduling models',\n",
              "  'critical problem'],\n",
              " ['new formal model machine learning concept boolean function',\n",
              "  'Valiant model',\n",
              "  'Such probabilistic concepts pconcepts',\n",
              "  'paper',\n",
              "  'uncertain probabilistic behaviorthus input'],\n",
              " ['deductive problem solvers',\n",
              "  'tree backtracking mechanism problem',\n",
              "  'problem',\n",
              "  'approach submit problem solver filter function',\n",
              "  'knowledge part use'],\n",
              " ['Rich Yee Vijay Gullapalli',\n",
              "  'Rich Yee Vijay',\n",
              "  'Rich Sutton',\n",
              "  'Rich Sutton Chris Watkins',\n",
              "  'Brian Pinette Jonathan Bachrach'],\n",
              " ['Technical Report',\n",
              "  'neural networks winnertakeall WTA',\n",
              "  'global connectivity WTA networks',\n",
              "  'twostage selection network',\n",
              "  'special case selection network'],\n",
              " ['Reinforcement learning RL',\n",
              "  'RL tasks',\n",
              "  'artificial intelligence RL researchers',\n",
              "  'RL',\n",
              "  'RL algorithms stochastic approximation methods'],\n",
              " ['learner counterexamples',\n",
              "  'unknown environments',\n",
              "  'second case outputs',\n",
              "  'algorithms',\n",
              "  'learner'],\n",
              " ['problem robot',\n",
              "  'unknown environment',\n",
              "  'mapping problem',\n",
              "  'model environment',\n",
              "  'versions problem'],\n",
              " ['learning procedure',\n",
              "  'learning procedures',\n",
              "  'recent years',\n",
              "  'Bayesian networks',\n",
              "  'sample complexity MDL'],\n",
              " ['Averagereward Reinforcement Learning ARL',\n",
              "  'ARL method',\n",
              "  'ARL',\n",
              "  'tablebased methods',\n",
              "  'large state spaces'],\n",
              " ['highdimensional real world data',\n",
              "  'highdimensional clusters related complex ways',\n",
              "  'learning structure data space',\n",
              "  'cluster bound aries data',\n",
              "  'Merge clustering extracts clusters'],\n",
              " ['sophisticated learning agents',\n",
              "  'learning agent',\n",
              "  'unknown learning agent',\n",
              "  'composite sequential decision tasks',\n",
              "  'multiple tasks applications'],\n",
              " ['Existing approaches',\n",
              "  'control robot arm',\n",
              "  'simulation OSCAR robot arm',\n",
              "  'obstacle avoidance behavior',\n",
              "  'supervised methods'],\n",
              " ['use compact representations',\n",
              "  'improved compact representations',\n",
              "  'RL arbitrary fixed soft state aggregation novel intuitive understanding effect state aggregation online RL new heuristic adaptive state aggregation algorithm',\n",
              "  'lookup table representations',\n",
              "  'simple extension state aggregation'],\n",
              " ['class incremental learning procedures',\n",
              "  'temporaldifference methods',\n",
              "  'conventional predictionlearning methods',\n",
              "  'new methods',\n",
              "  'supervisedlearning methods'],\n",
              " ['previous work Dyna class architectures intelligent systems',\n",
              "  'dynamic programming methods Dyna architectures',\n",
              "  'DynaQ architectures',\n",
              "  'paper',\n",
              "  'dynamic programmings policy iteration method'],\n",
              " ['large problems',\n",
              "  'parameterized function approximators',\n",
              "  'sparsecoarsecoded function approximators CMACs',\n",
              "  'reinforcement learning systems',\n",
              "  'paper present positive results control tasks'],\n",
              " ['online learninglearning',\n",
              "  'requirements',\n",
              "  'simple randomrepresentation methods',\n",
              "  'abundance methods',\n",
              "  'expanded representation'],\n",
              " ['online prediction model',\n",
              "  'variety problems',\n",
              "  'problem',\n",
              "  'online framework',\n",
              "  'set options'],\n",
              " ['online learning algorithm',\n",
              "  'A new online learning algorithm',\n",
              "  'MI outputs',\n",
              "  'MI A novel activation function',\n",
              "  'statistical dependency'],\n",
              " ['deterioration generalisation performance trained model',\n",
              "  'bpsom hybrid neural network',\n",
              "  'problem',\n",
              "  'preserving generalisation performance hiddenunit pruning methods',\n",
              "  'multilayered feedforward network mfn'],\n",
              " ['model iterated belief revision',\n",
              "  'AGM theory revision account effect revision conditional beliefs agent',\n",
              "  'minimal conditional revision',\n",
              "  'revision',\n",
              "  'uniterated revision'],\n",
              " ['reinforcement learning techniques',\n",
              "  'Reinforcement learning techniques address problem',\n",
              "  'select actions',\n",
              "  'complex domains',\n",
              "  'function approximation methods'],\n",
              " ['new selforganising learning algorithm',\n",
              "  'information maximisation',\n",
              "  'dependencies information transfer time delays',\n",
              "  'network nonlinear units',\n",
              "  'information'],\n",
              " ['Wellknown examples graphical models',\n",
              "  'model data analysis',\n",
              "  'This paper multidisciplinary review empirical statistical learning graphical model perspective',\n",
              "  'graphical framework',\n",
              "  'Graphical operations'],\n",
              " ['utility problem',\n",
              "  'utility control knowledge',\n",
              "  'learning method',\n",
              "  'efficient set control knowledge training problems',\n",
              "  'training problem explanation'],\n",
              " ['kernel estimators',\n",
              "  'single multilayered perceptrons radialbasis functions',\n",
              "  'Local networks',\n",
              "  'linear perceptron multilayer perceptrons',\n",
              "  'linear perceptron'],\n",
              " ['current CBR systems case adaptation',\n",
              "  'CBR systems',\n",
              "  'adaptation knowledge',\n",
              "  'library adaptation cases',\n",
              "  'adaptation knowledge experience'],\n",
              " ['introspective reasoning memory search',\n",
              "  'introspective reasoning',\n",
              "  'introspective reasoning step',\n",
              "  'memory search illustration general principles',\n",
              "  'effective flexible memory processing rich memories'],\n",
              " ['rare Most machine learning techniques',\n",
              "  'learning techniques',\n",
              "  'multistrategy learning techniques',\n",
              "  'acquisition knowledge task',\n",
              "  'context knowledge acquisition'],\n",
              " ['system performance task systems knowledge organization knowledge',\n",
              "  'task particular pieces knowledge',\n",
              "  'performance task declarative representations failures associations failures',\n",
              "  'appropriate learning strategies order',\n",
              "  'knowledge world'],\n",
              " ['neural networks based ideas statistical mechanics',\n",
              "  'learning algorithm',\n",
              "  'statistics networks',\n",
              "  'networks problems',\n",
              "  'statistics target values weights network'],\n",
              " ['selflearning control system mobile robot Based sensor information control system',\n",
              "  'available system',\n",
              "  'steering signal way collisions',\n",
              "  'correct mapping input state vector output steering signal',\n",
              "  'discrete coding state space adaptive algorithm'],\n",
              " ['Air Force Office Scientific Research AFOSR FJ Advanced Research Projects Agency ONR NJ Office Naval Research ONR NJ z',\n",
              "  'Advanced Research Projects Agency AFOSR',\n",
              "  'Air Force Office Scientific Research',\n",
              "  'Advanced Research Projects Agency',\n",
              "  'ONR'],\n",
              " ['smooth L p functions spaces',\n",
              "  'R approximation problem',\n",
              "  'L p',\n",
              "  'symmetric function',\n",
              "  'ffi Z'],\n",
              " ['obvious generalization PAC model',\n",
              "  'investigation generalizations',\n",
              "  'agnostic learning algorithm learning problem',\n",
              "  'agnostic learning',\n",
              "  'efficient general agnostic learning method'],\n",
              " ['design implementation derivation replay framework dersnlpebl Derivational snlpebl',\n",
              "  'previous plan derivations',\n",
              "  'derivations',\n",
              "  'partial order planner dersnlpebl',\n",
              "  'new problem'],\n",
              " ['Previous algorithms',\n",
              "  'deal temporal sequences',\n",
              "  'based dynamic recurrent networks',\n",
              "  'sequence',\n",
              "  'fast weights'],\n",
              " ['Evolutionary tree reconstruction',\n",
              "  'evolutionary tree',\n",
              "  'paper new tree reconstruction method call DiskCovering Method',\n",
              "  'large trees',\n",
              "  'trees subsets'],\n",
              " ['semantic grammars',\n",
              "  'difficult interesting problem machine',\n",
              "  'useful syntactic semantic categories',\n",
              "  'semanticgrammar acquisition problem',\n",
              "  'construction'],\n",
              " ['conditional branch Predicated execution',\n",
              "  'multipath execution Predicated architectures',\n",
              "  'Predicating branch',\n",
              "  'likely execution path program execution',\n",
              "  'instructions instruction'],\n",
              " ['barn owl visual field modified prisms',\n",
              "  'signal based owls',\n",
              "  'signal based visual attention possible explanation auditory plasticity',\n",
              "  'auditory map',\n",
              "  'visual attention'],\n",
              " ['hippocampal cells old animals',\n",
              "  'hippocampus old animals',\n",
              "  'bimodality old animals',\n",
              "  'animal removed returned environment',\n",
              "  'strong unimodality young animals'],\n",
              " ['MIT Media Laboratory Perceptual Computing Section Technical Report',\n",
              "  'MIT Media Laboratory Perceptual Computing Section Technical Report No Appeared th IEEE Intl Conference Pattern Recognition',\n",
              "  'foveated gesture recognition system',\n",
              "  'active camera foveate salient features',\n",
              "  'No Appeared th IEEE Intl Conference Pattern Recognition ICPR'],\n",
              " ['Genetic Algorithm GA attempt',\n",
              "  'Genetic Algorithm GA',\n",
              "  'Various extensions',\n",
              "  'many nearglobal optima possible implicit sharing',\n",
              "  'Implicit sharing'],\n",
              " ['Modern knowledge systems design',\n",
              "  'modern knowledge systems',\n",
              "  'heterogeneous knowledge system',\n",
              "  'experiment legacy knowledge system',\n",
              "  'kinds knowledge'],\n",
              " ['mixture experts ME model',\n",
              "  'ME model',\n",
              "  'Santa Fe competition ME model',\n",
              "  'time series analysis',\n",
              "  'mixture noisefree process quadratic map noisy process composition'],\n",
              " ['different views object',\n",
              "  'view invariant visual representations',\n",
              "  'natural visual experience',\n",
              "  'ICA better representation PCA object recognition',\n",
              "  'successive views'],\n",
              " ['synchronization numerical parallel efficiency parallel genetic algorithms GAs',\n",
              "  'parallel GAs',\n",
              "  'due decreased synchronization',\n",
              "  'critique utility traditional parallel performance measures',\n",
              "  'high numerical efficiency eg fewer function evaluations'],\n",
              " ['Key ideas statistical learning theory support vector machines',\n",
              "  'single support vector machines',\n",
              "  'decision tree',\n",
              "  'decision trees',\n",
              "  'respect decision tree'],\n",
              " ['regularization networks',\n",
              "  'subclass regularization networks',\n",
              "  'use term Generalized Regularization Networks broad class approximation schemes',\n",
              "  'regularization principles',\n",
              "  'approximation schemes'],\n",
              " ['Learning inputoutput mapping set examples',\n",
              "  'many neural networks',\n",
              "  'several neural network',\n",
              "  'representation detail approximation linear nonlinear mappings terms simpler functions fewer variables',\n",
              "  'approximation multidimensional function'],\n",
              " ['new case situations case',\n",
              "  'better understanding domain experience',\n",
              "  'novel situations',\n",
              "  'understanding case',\n",
              "  'reasoners memory'],\n",
              " ['statistical model genes',\n",
              "  'simple model',\n",
              "  'implementation genefinding model',\n",
              "  'path model maximum probability',\n",
              "  'human DNA genefinding system'],\n",
              " ['questions optimality domination repeated stage games',\n",
              "  'optimality domination',\n",
              "  'notion grace period handle problem vengeful strategies',\n",
              "  'strategies',\n",
              "  'infinite payoff'],\n",
              " ['play game',\n",
              "  'play game finite automata probabilistic actions',\n",
              "  'simple boolean formula recent history play games statistical adversaries',\n",
              "  'line research playing games',\n",
              "  'entire history play'],\n",
              " ['MORGAN integrated system',\n",
              "  'MORGAN system',\n",
              "  'MORGAN',\n",
              "  'decision trees',\n",
              "  'decision tree routines'],\n",
              " ['based neural networks',\n",
              "  'based characteristics',\n",
              "  'PYTHIA exemplar based reasoning system',\n",
              "  'PDE based application',\n",
              "  'paper report'],\n",
              " ['Comparison syntactical hypotheses reduction show reduction',\n",
              "  'based reduction',\n",
              "  'reduction',\n",
              "  'hypotheses',\n",
              "  'semantic interpretation rules'],\n",
              " ['effect unit receptive field parameters factors',\n",
              "  'receptive field properties',\n",
              "  'sample density structure target function',\n",
              "  'new learning algorithm',\n",
              "  'three principle factors'],\n",
              " ['SemiMarkov Decision Problems continuous time generalizations',\n",
              "  'Markov Decision Problems',\n",
              "  'SemiMarkov Decision Problems',\n",
              "  'Decision Problems',\n",
              "  'Markov Decision Problems based ideas'],\n",
              " ['classification regression statistics',\n",
              "  'multiple models',\n",
              "  'HME classification results',\n",
              "  'neural networks communities',\n",
              "  'The Hierarchical Mixture Experts HME successful number regression problems'],\n",
              " ['computa tional complexity',\n",
              "  'probabilistic network cardinality state spaces nodes',\n",
              "  'time procedure approximate evaluation probabilistic networks',\n",
              "  'simple networks proce dure',\n",
              "  'real time'],\n",
              " ['Existing complexity measures',\n",
              "  'specific learning problems',\n",
              "  'contemporary learning theory',\n",
              "  'supervised learning problems',\n",
              "  'class particular problem'],\n",
              " ['statistical effects',\n",
              "  'results empirical study statistical bias backpropagation',\n",
              "  'effects',\n",
              "  'existence bias',\n",
              "  'backpropagation specific bias general direction statistical rather relational effects'],\n",
              " ['Radial Basis Function RBF networks',\n",
              "  'Image segmentation',\n",
              "  'RBF networks',\n",
              "  'framework RBF networks studies',\n",
              "  'segmentation'],\n",
              " ['approach extracting rules networks',\n",
              "  'artificial neural networks',\n",
              "  'neural networks',\n",
              "  'knowledgebased neural networks',\n",
              "  'symbolic rules'],\n",
              " ['parallel algorithm',\n",
              "  'specific machine neural network algorithm',\n",
              "  'neural networks',\n",
              "  'single training algorithm',\n",
              "  'neural network models'],\n",
              " ['system performance task',\n",
              "  'task particular pieces knowledge',\n",
              "  'task declarative representations associations particular learning strategies',\n",
              "  'appropriate learning strategies order',\n",
              "  'performance current task Introspection'],\n",
              " ['artificial neural networks',\n",
              "  'obvious deficiency neural network representations',\n",
              "  'rules networks',\n",
              "  'rulelike knowledge Backpropagationstyle neural networks Empirical studies robot arm domain',\n",
              "  'artificial neural networks Its key mechanism validity interval analysis generic tool'],\n",
              " ['method feature subset selection',\n",
              "  'efficient algorithm feature selection computes',\n",
              "  'approximation optimal feature selection criterion',\n",
              "  'feature',\n",
              "  'remaining features'],\n",
              " ['paper address problem',\n",
              "  'additional work irrelevant features',\n",
              "  'irrelevant features',\n",
              "  'learning presence',\n",
              "  'previous work attribute selection'],\n",
              " ['vital role development situated agents',\n",
              "  'paper explore use reinforcement learning shape robot',\n",
              "  'Learning',\n",
              "  'different types agents',\n",
              "  'agents architecture training strategy match structure behavior pattern'],\n",
              " ['Probabilistic inference new network',\n",
              "  'computational complexity probabilistic inference networks',\n",
              "  'probabilistic inference',\n",
              "  'close network multiple similar states',\n",
              "  'Bayesian belief network NPhard'],\n",
              " ['Bayesian belief networks Helmholtz machines',\n",
              "  'Multilayer architectures',\n",
              "  'higher order structure',\n",
              "  'higher order statistical relations',\n",
              "  'stochastic recurrent network ambiguity lowerlevel states'],\n",
              " ['worstcase model errors',\n",
              "  'malicious errors',\n",
              "  'rate error',\n",
              "  'tolerable learning algorithm efficient algorithms',\n",
              "  'Such errors'],\n",
              " ['posterior probability model class',\n",
              "  'model class mean group models',\n",
              "  'true posterior approximations',\n",
              "  'series model class selection experiments',\n",
              "  'realworld problem domains'],\n",
              " ['FirstnameLastnamecsHelsinkiFI Report C University Helsinki Department Computer Science Abstract',\n",
              "  'Report C University',\n",
              "  'formulation model construction problem Bayesian framework finite mixture models',\n",
              "  'finite mixture models',\n",
              "  'good models'],\n",
              " ['repair failures reasoning process',\n",
              "  'model planning processes',\n",
              "  'hierarchical model balances model generality access implementationspecific details',\n",
              "  'transferability models',\n",
              "  'planner response reasoning failures'],\n",
              " ['problems criteria',\n",
              "  'reinforcement learning algorithms',\n",
              "  'insight learning processes',\n",
              "  'Computer experiments',\n",
              "  'theoretical results'],\n",
              " ['Acyclic digraphs',\n",
              "  'Markovequivalence classes class associated unique statistical model Statistical procedures model selection model',\n",
              "  'dependence Markov model',\n",
              "  'family ADGs',\n",
              "  'ADGs'],\n",
              " ['maximal probability network model',\n",
              "  'good approximative Bayesian network model probability distribution question',\n",
              "  'maximal probability model',\n",
              "  'unknown probability distribution study problem',\n",
              "  'Bayesian prototype tree model'],\n",
              " ['simple illustrative example',\n",
              "  'Evidential Probability',\n",
              "  'use acceptance rule',\n",
              "  'use intervals',\n",
              "  'main ideas'],\n",
              " ['UTree reinforcement learning algorithm',\n",
              "  'memorybased learning work robust statistical tests',\n",
              "  'UTree',\n",
              "  'shortterm memory selective perception',\n",
              "  'state time pressure stochasticity world states'],\n",
              " ['monotonic measure exhaustive search',\n",
              "  'relevant features',\n",
              "  'Feature selection problem',\n",
              "  'general exhaustive search',\n",
              "  'measure guaranteed complete exhaustive Experiments'],\n",
              " ['novel method dialogue agent',\n",
              "  'method dialogue agent',\n",
              "  'optimal dialogue strategy',\n",
              "  'alternate strategies agent initiative',\n",
              "  'agents choices'],\n",
              " ['Reduced Error Pruning Inductive Logic Programming',\n",
              "  'Incremental Reduced Error Pruning',\n",
              "  'attempts address problems',\n",
              "  'problems',\n",
              "  'many noisy domains'],\n",
              " ['EEG analysis',\n",
              "  'EEG',\n",
              "  'EEG paralyzed person',\n",
              "  'wheelchair composing sequences mental states EEG pattern recognition',\n",
              "  'key role modeling'],\n",
              " ['central issues reinforcement learning',\n",
              "  'word reinforcement',\n",
              "  'delayed reinforcement',\n",
              "  'Reinforcement learning problem faced agent',\n",
              "  'foundations field'],\n",
              " ['XCS internal memory',\n",
              "  'internal memory',\n",
              "  'XCS adequate guarantee convergence optimal policy XCSM complex nonMarkovian environments',\n",
              "  'XCSM nonMarkovian environments',\n",
              "  'XCS classifier system'],\n",
              " ['Simple modification standard hill climbing optimization algorithm',\n",
              "  'probability vector',\n",
              "  'probability vector entries',\n",
              "  'probabilities appearance entries nbit vectors',\n",
              "  'vector single entries'],\n",
              " ['efficient methods',\n",
              "  'exact approximate implementation MINFEATURES bias',\n",
              "  'efficient heuristics',\n",
              "  'WeightedGreedy algorithm',\n",
              "  'excellent efficient approximation MIN'],\n",
              " ['approach decision tree',\n",
              "  'input sequence decisions',\n",
              "  'A statistical approach decision tree modeling',\n",
              "  'data sequences temporal dependencies',\n",
              "  'A hidden Markov version tree'],\n",
              " ['z A',\n",
              "  'noisy communication z',\n",
              "  'statistical properties',\n",
              "  'errorcorrecting code based parity checks original signal inference sequence linear feedback shift register LFSR noisy observation sequence P zjA',\n",
              "  'related continuous optimization problem'],\n",
              " ['development visual system',\n",
              "  'synthetic system comparable abilities',\n",
              "  'early development sensory systems general visual system',\n",
              "  'development visual perception',\n",
              "  'perceptual interactions surroundings'],\n",
              " ['ergodicity transition probability matrices Markovian models',\n",
              "  'problem diffusion context credit reduced transition probabilities',\n",
              "  'paper',\n",
              "  'longterm context',\n",
              "  'Markov models HMMs'],\n",
              " ['flexible adaptive faulttolerant methods',\n",
              "  'Modern industry',\n",
              "  'neural networks',\n",
              "  'today',\n",
              "  'discussion neural networks projects'],\n",
              " ['Gas oil pipelines',\n",
              "  'corrosion defects regular intervals',\n",
              "  'defect examples',\n",
              "  'defects',\n",
              "  'application Pipetronix GmbH'],\n",
              " ['Different models',\n",
              "  'loglikelihoods model',\n",
              "  'images digits',\n",
              "  'new images',\n",
              "  'mixture'],\n",
              " ['International Journal Neural Systems p URL paper',\n",
              "  'International Journal Neural Systems',\n",
              "  'httpwwwcscoloradoeduandreasTimeSeriesMyPapersexpertspsZ University Colorado Computer Science Technical Report CUCS',\n",
              "  'Colorado Computer Science Technical Report CUCS',\n",
              "  'httpwwwcscoloradoeduandreasTimeSeriesMyPapersexpertspsZ University'],\n",
              " ['machine learning systems',\n",
              "  'machine learning tools',\n",
              "  'standard Hansch method machine learning system Golem',\n",
              "  'drug activity',\n",
              "  'two machine learning systems Magnus Assistant Retis data'],\n",
              " ['design problem',\n",
              "  'paper',\n",
              "  'design engineering devices',\n",
              "  'interactive KRITIK multimodal reasoning system combined case based model',\n",
              "  'CORAL deductive database system rule processing engine'],\n",
              " ['Temporal difference methods',\n",
              "  'existing temporal difference methods',\n",
              "  'temporal credit assignment problem reinforcement',\n",
              "  'applied problem',\n",
              "  'dynamic goals'],\n",
              " ['interesting duality learning cryptography',\n",
              "  'several classes Boolean functions distributionfree model',\n",
              "  'strong intractability results',\n",
              "  'cryptography number theory particular algorithm',\n",
              "  'intractability'],\n",
              " ['new method',\n",
              "  'TraceEvidence method results',\n",
              "  'required standard methods',\n",
              "  'consensus sequence',\n",
              "  'consensus sequences'],\n",
              " ['morphology natural language capacity',\n",
              "  'natural languages version network',\n",
              "  'connectionist model acquisition capacity',\n",
              "  'novel words morphological rules',\n",
              "  'production receptive morphology'],\n",
              " ['intractable algorithms ones',\n",
              "  'traditional EBL',\n",
              "  'competing EBL',\n",
              "  'EBL',\n",
              "  'This paper presents algorithm'],\n",
              " ['Neurons ventral stream primate visual system exhibit responses images',\n",
              "  'neurons',\n",
              "  'transformation invariant responses natural stimuli',\n",
              "  'constructed model cortical visual processing',\n",
              "  'invariant respect natural transformations translation size'],\n",
              " ['propose recurrent neural networks feedback input units',\n",
              "  'Gaussian missing variables network attempt model distribution missing variables',\n",
              "  'static data input variables',\n",
              "  'sequential data input variables',\n",
              "  'paper'],\n",
              " ['Many neural networks',\n",
              "  'control network dynamics',\n",
              "  'networks',\n",
              "  'network cost increase',\n",
              "  'standard reduction winnertakeall network'],\n",
              " ['reasoning process model design',\n",
              "  'design cases subcases',\n",
              "  'parallel development representation cases case memory organisation design knowledge',\n",
              "  'intended use information represented project information',\n",
              "  'particular problemsolving domain'],\n",
              " ['ability model',\n",
              "  'usefulness model',\n",
              "  'current visual recognition state lower level',\n",
              "  'internal model spatiotemporal dynamics input stream',\n",
              "  'recognition state'],\n",
              " ['Individual lifetime learning guide',\n",
              "  'tradeoff Baldwin effect Hiding effect',\n",
              "  'evolving population areas',\n",
              "  'Hiding effect',\n",
              "  'selection pressure individuals'],\n",
              " ['optimization hyperparameters function approximators',\n",
              "  'continuous optimization problems',\n",
              "  'algorithm problem',\n",
              "  'poor parameter settings time',\n",
              "  'racing algorithm'],\n",
              " ['Based analysis experiments',\n",
              "  'efficiency feature selection processing',\n",
              "  'realworld datasets',\n",
              "  'selected input features',\n",
              "  'use algorithms'],\n",
              " ['performance overlapping distributions',\n",
              "  'single component distribution',\n",
              "  'aspect mixture',\n",
              "  'much data',\n",
              "  'insufficient data'],\n",
              " ['paper present performance prediction model',\n",
              "  'performance range MIMD parallel processor systems neural network simulations',\n",
              "  'model execution time speedup scalability efficiency large MIMD systems',\n",
              "  'dataset network decomposition techniques Agreement model measurements',\n",
              "  'performances'],\n",
              " ['computational costs',\n",
              "  'superior basic nearest neighbor algorithm',\n",
              "  'goal',\n",
              "  'predictive accuracy',\n",
              "  'term prototypes'],\n",
              " ['neural network model',\n",
              "  'new RBF units',\n",
              "  'small networks',\n",
              "  'learning method results combination',\n",
              "  'suitable network structure size'],\n",
              " ['COLUMBUS autonomous mobile robot COLUMBUS',\n",
              "  'different environments robot face lifetime COLUMBUS models',\n",
              "  'exploration COLUMBUS',\n",
              "  'COLUMBUS',\n",
              "  'characteristics typical environments robot'],\n",
              " ['ASP ASP',\n",
              "  'Noisy ASP first problem',\n",
              "  'Genetic Algorithm GA',\n",
              "  'Genetic Algorithm',\n",
              "  'Genetic Type Algorithm'],\n",
              " ['Many extensions',\n",
              "  'learning algorithms',\n",
              "  'instancebased learning algorithm particular problem',\n",
              "  'Learning FIBL algorithm',\n",
              "  'combination crossvalidation confidence levels'],\n",
              " ['formulation reinforcement learning',\n",
              "  'noisy dynamic environemnts complex concurrent multirobot learning domain',\n",
              "  'heterogeneous reinforcement functions progress estimators',\n",
              "  'learning space use behaviors conditions',\n",
              "  'credit assignment problem'],\n",
              " ['decision trees',\n",
              "  'Most existing decision tree systems',\n",
              "  'greedy tree induction',\n",
              "  'optimal tree',\n",
              "  'trees'],\n",
              " ['input state stability',\n",
              "  'Previous results',\n",
              "  'ABSTRACT',\n",
              "  'SYCON',\n",
              "  'Applications certain stabilization problems'],\n",
              " ['Attractor networks',\n",
              "  'alternative formulation attractor networks',\n",
              "  'attractor basins',\n",
              "  'spurious attractors',\n",
              "  'set attractors'],\n",
              " ['NFL theorems generalisation absence domain knowledge necessarily zerosum enterprise Good generalisation performance',\n",
              "  'effective generalisation logical impossibility',\n",
              "  'theorems',\n",
              "  'NFL',\n",
              "  'Wolperts'],\n",
              " ['Learning limited modification parameters limited scope capability',\n",
              "  'network structure',\n",
              "  'appropriate network structure',\n",
              "  'network structure addition andor removal units andor',\n",
              "  'artificial neural networks'],\n",
              " ['probability model mixture trees',\n",
              "  'ML MAP mixture trees variety priors',\n",
              "  'EM Minimum Spanning Tree algorithm',\n",
              "  'family efficient algorithms',\n",
              "  'ML MAP'],\n",
              " ['regions DNA sequence encode proteins',\n",
              "  'DNA sequences',\n",
              "  'E coli DNA sequences',\n",
              "  'human DNA',\n",
              "  'reading frame region'],\n",
              " ['selflearning control system mobile robot Based sensor information control system',\n",
              "  'correct mapping discrete sensor input space steering signal',\n",
              "  'correct mapping input state vector output steering signal algorithm',\n",
              "  'steering signal way collisions',\n",
              "  'available system'],\n",
              " ['learning methods',\n",
              "  'task analysis situates transfer process',\n",
              "  'induction independent procedure',\n",
              "  'Work',\n",
              "  'transfer'],\n",
              " ['subproblem target network task goal',\n",
              "  'many types relationships source target networks',\n",
              "  'incorporation information extracted networks',\n",
              "  'target task',\n",
              "  'Our focus utilization weights source networks'],\n",
              " ['ALVINN Autonomous Land Vehicle Neural Net Backpropagation',\n",
              "  'Advanced Learning Algorithms ALVINN',\n",
              "  'Applying Advanced Learning Algorithms ALVINN',\n",
              "  'ALVINN',\n",
              "  'neural network'],\n",
              " ['paper motivated need building decision support systems realworld problem domains',\n",
              "  'model class selection phase approach',\n",
              "  'finite mixture models',\n",
              "  'complexity model',\n",
              "  'reason models'],\n",
              " ['new algorithm',\n",
              "  'Rosenblatts perceptron algorithm',\n",
              "  'classifier algorithm',\n",
              "  'algorithm',\n",
              "  'algorithm variants'],\n",
              " ['ACM Transactions Computer Systems August Permission',\n",
              "  'ACM Transactions Computer Systems',\n",
              "  'ACM',\n",
              "  'digital copies part',\n",
              "  'distributed profit commercial advantage copies'],\n",
              " ['probabilistic automata',\n",
              "  'contextdependent probabilities',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'Gibbs distributions',\n",
              "  'stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model'],\n",
              " ['committee regressors',\n",
              "  'regression context',\n",
              "  'regression trees',\n",
              "  'committee machines Performance',\n",
              "  'committee machines'],\n",
              " ['Current expert systems',\n",
              "  'neural expert system shell NEULA',\n",
              "  'imprecise incomplete information',\n",
              "  'hand neural networks',\n",
              "  'information'],\n",
              " ['Red Queen effect',\n",
              "  'Red Queen',\n",
              "  'illustrate use simulation coevolution',\n",
              "  'Coevolution',\n",
              "  'appropriate performance measures'],\n",
              " ['Inferences measurement error models',\n",
              "  'use flexible parametric models',\n",
              "  'sensitive modeling assumptions',\n",
              "  'efficiency parametric inference',\n",
              "  'departures standard parametric models'],\n",
              " ['multiparent operators performance GAs',\n",
              "  'point crossover study effects',\n",
              "  'phenomenon multiparent reproduction ie study recombination mechanisms',\n",
              "  'different number parents',\n",
              "  'standard uniform crossover diagonal crossover'],\n",
              " ['TECHNICAL REPORT',\n",
              "  'Statistics GN University',\n",
              "  'Washington USA Susan L Rosenkranz Pew Health Policy Postdoctoral Fellow Institute Health Policy Studies Box University',\n",
              "  'Statistics Sociology Department',\n",
              "  'Adrian E Raftery Professor Statistics Sociology Department'],\n",
              " ['Neural networks',\n",
              "  'neural network',\n",
              "  'Introduction Networks',\n",
              "  'biological neural networks',\n",
              "  'A Brief Introduction Neural Networks Richard D De Veaux Lyle H Ungar Williams College University Pennsylvania Abstract Artificial neural networks'],\n",
              " ['algorithm classification assign class separate set codebook Gaussians',\n",
              "  'various classification algorithms',\n",
              "  'Classification pattern',\n",
              "  'classification strategy codebook vectors',\n",
              "  'role classification patterns'],\n",
              " ['paper use decision trees lifetime prediction programs',\n",
              "  'Predictions lifetimes',\n",
              "  'time space efficiency dynamic memory management computer programs',\n",
              "  'improvement variety computer programs',\n",
              "  'simple lifetime predictor'],\n",
              " ['Evolutionary systems',\n",
              "  'evolutionary system variable length coding',\n",
              "  'variety applications turbine design scheduling problems',\n",
              "  'larger variety problems',\n",
              "  'efficient problem'],\n",
              " ['previous upper bound coverage Boolean concept learning algorithm',\n",
              "  'coverage',\n",
              "  'upper bound Experimental measurement coverage ID FRINGE algorithms',\n",
              "  'definition coverage',\n",
              "  'way coverage maximization'],\n",
              " ['Markov decision',\n",
              "  'MDPs',\n",
              "  'temporal Bayesian network representation MDPs',\n",
              "  'large AI planning problems',\n",
              "  'structured representation stochastic actions policies value functions algorithm'],\n",
              " ['new class multilayer connectionist architectures',\n",
              "  'selforganization new rule',\n",
              "  'neural network models attempts',\n",
              "  'ASOCS Adaptive',\n",
              "  'inputoutput vectors processing network'],\n",
              " ['Maximum working likelihood MWL inference presence',\n",
              "  'Maximum likelihood Metropolis',\n",
              "  'asymptotic MWL variance Evaluation marginal likelihood',\n",
              "  'large likelihood',\n",
              "  'MWL estimator'],\n",
              " ['Natural images',\n",
              "  'natural images',\n",
              "  'sparse codes natural scenes',\n",
              "  'good objective efficient coding natural scenes',\n",
              "  'characteristic statistical regularities'],\n",
              " ['empirical methodology',\n",
              "  'study effects epistasis performance EAs',\n",
              "  'paper',\n",
              "  'preliminary exploration effects epistasis',\n",
              "  'behavior'],\n",
              " ['point crossover operators',\n",
              "  'average L crossover points strings length',\n",
              "  'Many recent empirical studies',\n",
              "  'higher numbers',\n",
              "  'Some intriguing recent work focused uniform crossover'],\n",
              " ['Conditional logics',\n",
              "  'arbitrary conditional nesting NPcomplete formulas',\n",
              "  'Lewis Stalnaker utilized artificial intelligence',\n",
              "  'conditional statements decision problem NPcomplete mulas',\n",
              "  'Lewis Stalnaker'],\n",
              " ['higherorder connections incremental introduction new units',\n",
              "  'new units',\n",
              "  'useful learning sequential tasks',\n",
              "  'recurrent networks',\n",
              "  'An incremental higherorder nonrecurrent network'],\n",
              " ['novel general principle',\n",
              "  'novel principle potential',\n",
              "  'unit remaining units',\n",
              "  'nonredundant internal representations input patterns',\n",
              "  'unit filter abstract concepts environmental input concepts'],\n",
              " ['learning PAC',\n",
              "  'efficient learning new model',\n",
              "  'efficient learning statistical queries',\n",
              "  'statistical queries sufficient condition PAC',\n",
              "  'PAC model'],\n",
              " ['first stage study evolution',\n",
              "  'first',\n",
              "  'learning ability',\n",
              "  'inherent learning parameters',\n",
              "  'emergence learning ability'],\n",
              " ['intractable perform updates',\n",
              "  'exact dynamicprogramming updates partially observable Markov decision processes',\n",
              "  'witness algorithm compute updated value functions',\n",
              "  'problem',\n",
              "  'convex value functions'],\n",
              " ['limits instruction level parallelism',\n",
              "  'type parallelism parallelism distance',\n",
              "  'advantage parallelism compiler',\n",
              "  'far parallelism',\n",
              "  'programs particular SPEC benchmark suite'],\n",
              " ['probabilistic automata',\n",
              "  'contextdependent probabilities',\n",
              "  'model state transitions output generation parameter estimation',\n",
              "  'Gibbs distributions',\n",
              "  'stochastic feedforward neural networks geometric interpretation parameter estimation simple example statistical language model'],\n",
              " ['correlationbased Hebbian synaptic plasticity',\n",
              "  'total synaptic strength cell',\n",
              "  'strength synapses',\n",
              "  'Models',\n",
              "  'Hebbian'],\n",
              " ['part grant McDonnellPew Foundation',\n",
              "  'ATR Human Information Processing Research Laboratories',\n",
              "  'NJ Office Naval Research',\n",
              "  'McDonnellPew Foundation',\n",
              "  'Jordan NSF Presidential Young Investigator'],\n",
              " ['Bayesian learning framework objective functions',\n",
              "  'Learning',\n",
              "  'measure expected informativeness candidate measurements',\n",
              "  'Bayesian',\n",
              "  'particularly salient data points'],\n",
              " ['cluster structure highdimensional input',\n",
              "  'structure clusters input',\n",
              "  'Knowledge clusters',\n",
              "  'highdimensional input data unknown distribution Ordinary feature maps',\n",
              "  'cluster boundaries'],\n",
              " ['LCI models',\n",
              "  'class LCI models',\n",
              "  'Lattice conditional independence',\n",
              "  'subclass class graphical Markov models',\n",
              "  'dependent linear regression models'],\n",
              " ['proposed method',\n",
              "  'method',\n",
              "  'geneticalgorithmbased optimization',\n",
              "  'paper',\n",
              "  'search guide exploration'],\n",
              " ['Genetic algorithms GAs',\n",
              "  'global optimization',\n",
              "  'GA continuous designspace optimization',\n",
              "  'realistic engineering design optimization',\n",
              "  'GAs'],\n",
              " ['D E Rumelhart G E Hinton R J Williams Learning Internal Representations Error Propagation D E Rumelhart J L McClelland',\n",
              "  'Parallel Distributed Processing Explorations Microstructure Cognition',\n",
              "  'Vol MIT Press'],\n",
              " ['tree topology model',\n",
              "  'illustrate situations tree model',\n",
              "  'Evolutionary trees',\n",
              "  'suitability trees',\n",
              "  'unique tree'],\n",
              " ['Selective suppression transmission feedback synapses',\n",
              "  'suppression layer IV feedforward synapses',\n",
              "  'cholinergic suppression synaptic transmission layer',\n",
              "  'associative feedback selforganization feedforward synapses',\n",
              "  'recall suppression'],\n",
              " ['Technical Report No Department Statistics University',\n",
              "  'slice sampling schemes',\n",
              "  'overrelaxed versions slice sampling',\n",
              "  'Toronto',\n",
              "  'uniform sampling vertical direction uniform'],\n",
              " ['Markov decision problems',\n",
              "  'foundations number problems',\n",
              "  'large problems',\n",
              "  'MDPs',\n",
              "  'ture MDPs'],\n",
              " ['Learning reinforcements',\n",
              "  'Subsequent reinforcement learning',\n",
              "  'intelligent agents',\n",
              "  'large number training episodes',\n",
              "  'several aspects approach show'],\n",
              " ['mathematical foundations Dirichlet mixtures',\n",
              "  'information protein database mixture',\n",
              "  'expected amino acid distributions database search',\n",
              "  'homologous sequences variable number sequences protein family domain',\n",
              "  'database search'],\n",
              " ['derivational analogy',\n",
              "  'Derivational analogy technique',\n",
              "  'new approach derivational analogy',\n",
              "  'new problems',\n",
              "  'common problem solvers'],\n",
              " ['secondorder recurrent neural networks',\n",
              "  'networks language',\n",
              "  'language induced network',\n",
              "  'networks',\n",
              "  'detailed machine analysis trained networks'],\n",
              " ['COINS Technical Report',\n",
              "  'January',\n",
              "  'multiclass decision trees multivariate',\n",
              "  'small accurate trees',\n",
              "  'algorithm'],\n",
              " ['Funes P Pollack J Computer Evolution Buildable Objects',\n",
              "  'Computer Evolution Buildable Objects',\n",
              "  'Fourth European Conference Artificial Life P Husbands',\n",
              "  'evolution physical structure lack general framework Evolution creatures simulation',\n",
              "  'Evolution'],\n",
              " ['knowledge integration',\n",
              "  'separate knowledge bases',\n",
              "  'knowledge bases',\n",
              "  'methodology knowledge integration',\n",
              "  'example knowledge bases'],\n",
              " ['Many arthropods',\n",
              "  'cases behaviours',\n",
              "  'input hundreds thousands pixels',\n",
              "  'behaviour environments',\n",
              "  'evolved robot controllers function'],\n",
              " ['reversible jump MCMC application',\n",
              "  'reversible jump',\n",
              "  'jump proposals',\n",
              "  'mechanism guiding proposal choice analysis acceptance probabilities',\n",
              "  'MCMC'],\n",
              " ['Instancebased learning methods',\n",
              "  'sacrificed explicit retention data applicable instancebased predictions',\n",
              "  'instance based methods',\n",
              "  'phase prediction time',\n",
              "  'multiresolution data structure'],\n",
              " ['standard online model learning algorithm',\n",
              "  'apple tasting model enhanced standard model false acceptances',\n",
              "  'standard model',\n",
              "  'natural variant model apple tasting learner',\n",
              "  'strategy trading false acceptances false rejections'],\n",
              " ['algorithm exploits error distribution',\n",
              "  'error distribution',\n",
              "  'learning algorithm order break domain',\n",
              "  'algorithm',\n",
              "  'ridge errors'],\n",
              " ['Parallel Research Execution Environment Neural Systems',\n",
              "  'neural networks',\n",
              "  'neurosimulator targeted networks workstations transputer systems',\n",
              "  'large amounts data neural networks',\n",
              "  'neural network simulation programs'],\n",
              " ['learning classifier system CS',\n",
              "  'genetic algorithm system',\n",
              "  'steady state Dynamical adjustment classifiers',\n",
              "  'interplay reward system background',\n",
              "  'number problems'],\n",
              " ['squared error network amount information weights',\n",
              "  'squared error amount information noisy weights network',\n",
              "  'Supervised neural networks',\n",
              "  'weights neural network',\n",
              "  'amount information'],\n",
              " ['desirable order',\n",
              "  'many applications',\n",
              "  'best preference function',\n",
              "  'order',\n",
              "  'preference function'],\n",
              " ['March Abstract Evolutionary algorithms powerful techniques optimisation',\n",
              "  'Technical Report CSRP',\n",
              "  'new evolutionary classical algorithms',\n",
              "  'features classical evolutionary methods',\n",
              "  'relation evolutionary techniques numerical classical search methods'],\n",
              " ['neural net architecture',\n",
              "  'hierarchical recursive structure symbol strings',\n",
              "  'structure multiple levels architecture capability',\n",
              "  'encode structure symbol strings',\n",
              "  'formal languages architecture'],\n",
              " ['abstracting lowlevel neural parallel distributed processes',\n",
              "  'feature maps',\n",
              "  'process',\n",
              "  'closest Euclidian distance input vector',\n",
              "  'neighborhood weight adaptation'],\n",
              " ['learning algorithms',\n",
              "  'ability agents',\n",
              "  'imitating agents',\n",
              "  'expert agent bias exploration promising directions',\n",
              "  'significant transfer agents'],\n",
              " ['complex multidimensional meaningful visual stimuli',\n",
              "  'computational model face recognition',\n",
              "  'Faces',\n",
              "  'map neural network convolutional neural network',\n",
              "  'hybrid neural network solution'],\n",
              " ['new algorithm',\n",
              "  'modified policy iteration algorithm',\n",
              "  'algorithm',\n",
              "  'asynchronous nature algorithm convergence general conditions',\n",
              "  'modified policy iteration'],\n",
              " ['timereversible Markov chain posterior distribution',\n",
              "  'Monte Carlo methods',\n",
              "  'marginal posterior densities',\n",
              "  'posterior distribution',\n",
              "  'Monte Carlo'],\n",
              " ['sample complexity PAC learning presence classification noise',\n",
              "  'complexity noisetolerant learning PAC model',\n",
              "  'PAC learning presence classification noise',\n",
              "  'presence classification noise',\n",
              "  'PAC'],\n",
              " ['parasite virulence harm',\n",
              "  'adaptive trait Selection particular level virulence',\n",
              "  'shortsighted development virulence',\n",
              "  'parasites',\n",
              "  'shortsighted withinhost competition'],\n",
              " ['Much work qualitative physics',\n",
              "  'pressure Semiquantitative methods',\n",
              "  'model precision',\n",
              "  'physical systems',\n",
              "  'semiquantitative methods'],\n",
              " ['application MemoryBased Learning problem',\n",
              "  'MemoryBased Learning',\n",
              "  'MemoryBased Learning stores',\n",
              "  'paper',\n",
              "  'intelligent similarity metrics number'],\n",
              " ['mammalian central nervous systems Mixture structures',\n",
              "  'context data analysis inference',\n",
              "  'scientific features sensitivity individual synaptic transmission sites electrochemical stimuli',\n",
              "  'responses electrochemical stimulation individual neurotransmitter release sites',\n",
              "  'Hierarchical Mixture'],\n",
              " ['examples modules',\n",
              "  'NLP tasks',\n",
              "  'The need software modules',\n",
              "  'rapid development',\n",
              "  'MBL'],\n",
              " ['membership equivalence queries',\n",
              "  'class readonce formulas',\n",
              "  'membership query',\n",
              "  'boolean threshold functions negation',\n",
              "  'boolean threshold functions'],\n",
              " ['time series model',\n",
              "  'decision tree Markov temporal structure',\n",
              "  'layers decision tree',\n",
              "  'Markov chain',\n",
              "  'one decision tree calculations'],\n",
              " ['Stochastic simulation algorithms likelihood weighting',\n",
              "  'standard simulation algorithms',\n",
              "  'paper present simulation algorithms',\n",
              "  'performance algorithm likelihood',\n",
              "  'stochastic reproduction rate weighted likelihood evidence'],\n",
              " ['Simulated Annealing Search technique single trial solution',\n",
              "  'low energy solution',\n",
              "  'best solution',\n",
              "  'good solution',\n",
              "  'energy Changes'],\n",
              " ['small disjuncts error',\n",
              "  'small disjuncts',\n",
              "  'impact small disjuncts',\n",
              "  'problem small disjuncts',\n",
              "  'prone large disjuncts'],\n",
              " ['number equivalence queries',\n",
              "  'transformation number equivalence queries',\n",
              "  'minimum number equivalence queries',\n",
              "  'polynomial number membership queries',\n",
              "  'complete characterization tradeoff number membership equivalence queries'],\n",
              " ['exception rules exception rules exception rule',\n",
              "  'Rippledown rule sets',\n",
              "  'exception rules',\n",
              "  'good exception rule sets',\n",
              "  'learning algorithm'],\n",
              " ['algorithm learning sets rules',\n",
              "  'smallest consistent representation k levels rules',\n",
              "  'k levels',\n",
              "  'lower levels',\n",
              "  'arbitrary number rules'],\n",
              " ['representational methodological issues attractor network model mapping orthography semantics',\n",
              "  'words dense semantic neighborhood faster words',\n",
              "  'paper',\n",
              "  'Reaction time model',\n",
              "  'change direction effect abstract words slower words'],\n",
              " ['associated caching cases construction cost model',\n",
              "  'case memory',\n",
              "  'Casebased reasoning',\n",
              "  'cached cases',\n",
              "  'old cases'],\n",
              " ['hybrid Genetic Generalized Lloyd Algorithm GGLA',\n",
              "  'conventional Generalized Lloyd Algorithm GLA',\n",
              "  'Lloyd Algorithm GLA',\n",
              "  'Genetic',\n",
              "  'A Genetic Algorithmic GA approach vector quantizer design'],\n",
              " ['casebased planning',\n",
              "  'similar planning problems',\n",
              "  'considerable time planning scratch generative planning',\n",
              "  'future CBP',\n",
              "  'stored cases memory'],\n",
              " ['efficient method',\n",
              "  'comparisons methods',\n",
              "  'number processors tasks',\n",
              "  'method',\n",
              "  'associated cells rectangular uniform grid Load balancing equipartition constraints'],\n",
              " ['Bayesian balance exploration exploitation',\n",
              "  'existing uses exploration bonuses reinforcement',\n",
              "  'certainty equivalence approximation arising form dual control',\n",
              "  'compute suboptimal estimates',\n",
              "  'Sutton'],\n",
              " ['nonlinear leastsquares problems',\n",
              "  'fitting data',\n",
              "  'generic regression data general result',\n",
              "  'analytic functions',\n",
              "  'stronger assumptions finiteness set functions'],\n",
              " ['ONR Grant',\n",
              "  'part',\n",
              "  'generic modeling',\n",
              "  'generic models central conceptual change science',\n",
              "  'constructive modeling'],\n",
              " ['design neural networks',\n",
              "  'investigation systematic design method',\n",
              "  'adaptive control',\n",
              "  'specific problems',\n",
              "  'typical problems'],\n",
              " ['informationtheoretic derivation',\n",
              "  'algorithm clusters',\n",
              "  'data linear discriminants',\n",
              "  'contrast methods',\n",
              "  'information input patterns'],\n",
              " ['ASOCS Adaptive',\n",
              "  'data processing mode ASOCS',\n",
              "  'ASOCS',\n",
              "  'Adaptive Algorithm AA',\n",
              "  'Adaptive Algorithm AA details architecture'],\n",
              " ['Markov models',\n",
              "  'coupled time series',\n",
              "  'mixed memory Markov models',\n",
              "  'state space',\n",
              "  'large state space'],\n",
              " ['use machine learning methods',\n",
              "  'genetic algorithms',\n",
              "  'knowledge simulations',\n",
              "  'consequence evaluation single individual genetic algorithm',\n",
              "  'implementation parallel genetic algorithm present case studies'],\n",
              " ['Most Artificial Neural Networks ANNs',\n",
              "  'Artificial Neural Networks',\n",
              "  'dynamic topologies dynamic ANNs',\n",
              "  'Neural Networks Backpropagation Implementation Design Dynamic Topologies Reconfigurable Architectures',\n",
              "  'Keywords Neural Networks Backpropagation Implementation Design Dynamic Topologies Reconfigurable Architectures'],\n",
              " ['Hard combinatorial problems',\n",
              "  'njob mmachine flowshop problem configurates',\n",
              "  'necessary condition genetic algorithm',\n",
              "  'asynchronous parallel genetic algorithm',\n",
              "  'subset solutions'],\n",
              " ['VLSI implementation Priority Adaptive',\n",
              "  'multichip module MCM substrate Many current hardware implementations neural network learning models direct implementations classical neural network structuresa large number simple computing nodes',\n",
              "  'SelfOrganizing Concurrent System connectionist models',\n",
              "  'learning model',\n",
              "  'SelfOrganizing Concurrent System'],\n",
              " ['application genetic algorithm dynamic job shop problem',\n",
              "  'scheduling manufacturing systems',\n",
              "  'nondeterministic optimization problem',\n",
              "  'research topic broad interest Population based approaches',\n",
              "  'production scheduling First sketch genetic algorithm handle release'],\n",
              " ['Neural network pruning methods',\n",
              "  'pruning method lprune',\n",
              "  'pruning step pruning strength',\n",
              "  'training pruning',\n",
              "  'individual network parameters'],\n",
              " ['similarity assessment',\n",
              "  'new similarity assessment approach couples',\n",
              "  'similarity assessment strategies',\n",
              "  'Casebased problemsolving systems',\n",
              "  'alternative similarity assessment strategies'],\n",
              " ['different learning processes',\n",
              "  'multiple learning methods',\n",
              "  'multiple overlapping knowledge sources',\n",
              "  'different learning mechanisms',\n",
              "  'casebased reasoning'],\n",
              " ['casebased CBR systems CBR systems',\n",
              "  'CBR systems',\n",
              "  'casebased components CBR system',\n",
              "  'multiple knowledge sources',\n",
              "  'CBR guide case adaptation similarity assessment'],\n",
              " ['successive small linear programs',\n",
              "  'linear programming constraints',\n",
              "  'fast finitelyterminating linearprogramming algorithm',\n",
              "  'A linear support vector machine formulation',\n",
              "  'ndimensional space number points orders'],\n",
              " ['famous NETtalk system',\n",
              "  'NETtalk system',\n",
              "  'Sejnowski Rosenberg',\n",
              "  'training words system',\n",
              "  'extends initial NETtalk work'],\n",
              " ['exact penalty problem',\n",
              "  'number misclassified points plane',\n",
              "  'stationary point global solution Novel aspects approach',\n",
              "  'quadratic objective linear constraints',\n",
              "  'misclassifications ii Exact penalty formulation'],\n",
              " ['analogical reasoning learning method',\n",
              "  'storage retrieval replay planning episodes Planning performance',\n",
              "  'replay multiple planning cases',\n",
              "  'multiple past planning cases',\n",
              "  'justifications planning cases'],\n",
              " ['Mixedinitiative planning envisions framework automated human planners',\n",
              "  'human planning accumulation userbuilt plans',\n",
              "  'planning experience',\n",
              "  'ForMAT ProdigyAnalogy realtime messagepassing mixedinitiative planning system',\n",
              "  'paper report work engineering robust mixedinitiative planning system'],\n",
              " ['neural networks',\n",
              "  'network weights region weight space',\n",
              "  'correct output future inputs',\n",
              "  'individual networks independent errors',\n",
              "  'networks'],\n",
              " ['algorithms empirical comparisons',\n",
              "  'structural equation models data',\n",
              "  'latent variables models',\n",
              "  'PC IC',\n",
              "  'linear multiple regression'],\n",
              " ['neural network based approximation methods',\n",
              "  'hierarchical method',\n",
              "  'parallel implementation method',\n",
              "  'root tree global approximation',\n",
              "  'local global basis functions'],\n",
              " ['Orthogonal incremental learning OIL new approach incremental training feedforward network single hidden layer OIL based idea',\n",
              "  'orthogonal representation network output weights domain',\n",
              "  'orthogonal basis functions',\n",
              "  'output weights hidden nodes',\n",
              "  'special relationship orthogonal backpropagation OBP rule'],\n",
              " ['potential users machine learning technology',\n",
              "  'learning model selection',\n",
              "  'large everincreasing number available tools',\n",
              "  'number criteria',\n",
              "  'impact metalevel approaches model selection'],\n",
              " ['object representation continuous attractors',\n",
              "  'standard depiction networks state space memories objects',\n",
              "  'recurrent neural network associative memory',\n",
              "  'continuous pattern manifold appropriate represent objects attractive manifolds',\n",
              "  'fixed points continuous attractors'],\n",
              " ['problem independent constraint handling mechanism',\n",
              "  'general problem independent way',\n",
              "  'working graph coloring problems',\n",
              "  'constrained problems',\n",
              "  'Stepwise Adaptation Weights SAW'],\n",
              " ['several independent components system',\n",
              "  'independent components',\n",
              "  'independent component negative kurtosis others',\n",
              "  'several neural algorithms',\n",
              "  'several neurons'],\n",
              " ['evidence grids place',\n",
              "  'task place',\n",
              "  'distinct places',\n",
              "  'place recognition experience',\n",
              "  'evidence grids'],\n",
              " ['constructive induction',\n",
              "  'distinction constructive nonconstructive methods',\n",
              "  'b process CI',\n",
              "  'normal part learning process',\n",
              "  'CI learners'],\n",
              " ['designing deductive database designer',\n",
              "  'example database',\n",
              "  'compact database',\n",
              "  'designer task',\n",
              "  'relation'],\n",
              " ['work information multiple sources',\n",
              "  'different formalisms',\n",
              "  'existing formalisms',\n",
              "  'formalism',\n",
              "  'handle uncertainty'],\n",
              " ['technique',\n",
              "  'networks',\n",
              "  'sparsely connected feedforward neural networks',\n",
              "  'sparse training data',\n",
              "  'training time'],\n",
              " ['paper propose method',\n",
              "  'nondecomposable graphical Gaussian model',\n",
              "  'whole class graphical Gaussian models',\n",
              "  'posterior probability',\n",
              "  'conditional graphical constraints'],\n",
              " ['Markov chain reinforcement transition',\n",
              "  'direct TD residual gradient TD',\n",
              "  'respect error values',\n",
              "  'approximation optimal respect leastsquares error value function approximation',\n",
              "  'TD method poor respect metric'],\n",
              " ['Lazy learning methods',\n",
              "  'complex phenomena autonomous adaptive control complex systems',\n",
              "  'previous experiences problem learning control',\n",
              "  'control tasks',\n",
              "  'useful representations training algorithms'],\n",
              " ['Genetic programming GP variant genetic algorithms data structures',\n",
              "  'trees Symbolic regression determination function dependence',\n",
              "  'data points',\n",
              "  'GP',\n",
              "  'size trees'],\n",
              " ['study mixture modeling problems',\n",
              "  'structured mixture models',\n",
              "  'assessment chemical structureactivity relationships drug design discovery Pharmaceutical research laboratories',\n",
              "  'analysis drug design',\n",
              "  'test compounds'],\n",
              " ['analysis generalization error cross validation terms',\n",
              "  'rigorous general bound error cross validation',\n",
              "  'complexity target function respect hypothesis model estimation rate',\n",
              "  'consideration approximation rate accuracy target function ideally approximated function number hypothesis parameters estimation rate deviation training generalization errors',\n",
              "  'number hypothesis parameters'],\n",
              " ['expected error model integrating error distribution select model',\n",
              "  'expected true error empirical minimizer model',\n",
              "  'true error empirical minimizer model turn',\n",
              "  'distribution true errors empirical minimizers',\n",
              "  'empirical minimizer hypothesis least empirical error'],\n",
              " ['generalizations implication clause generalizations subsumption call expansion original clause',\n",
              "  'generalization clauses',\n",
              "  'inductive learning generalization main operation usual definition induction',\n",
              "  'generalization subsumption',\n",
              "  'implication clauses'],\n",
              " ['Bayesian probability theory general method machine',\n",
              "  'paper uniform application theory',\n",
              "  'learning tasks',\n",
              "  'different types data',\n",
              "  'unknown machine'],\n",
              " ['bias variance decomposition analysis',\n",
              "  'increasing variance',\n",
              "  'bias',\n",
              "  'classification error comparison',\n",
              "  'error reduction'],\n",
              " ['collective memory search',\n",
              "  'search problem complexity',\n",
              "  'better collective memory search',\n",
              "  'random search engine',\n",
              "  'GP based search engine'],\n",
              " ['context similarity',\n",
              "  'relevance measures',\n",
              "  'relevance',\n",
              "  'Contrary systems',\n",
              "  'Contrary'],\n",
              " ['reactive control system',\n",
              "  'schemabased reactive control system',\n",
              "  'selfimproving reactive control system autonomous robotic navigation',\n",
              "  'improved performance reactive control system tunes environment',\n",
              "  'navigation system experience'],\n",
              " ['good approximator model space realworld domains Results',\n",
              "  'hard patterns',\n",
              "  'easy ones',\n",
              "  'querybased filtering methods',\n",
              "  'algorithm synthesized problem'],\n",
              " ['response treebased genetic programming take value',\n",
              "  'alternate methods',\n",
              "  'memorybased program response technique improvement problems',\n",
              "  'genetic programming',\n",
              "  'One alternative treat specific location indexed memory response value program'],\n",
              " ['Holtes recentlypublished article',\n",
              "  'Holtes recentlypublished',\n",
              "  'detail parts Holtes',\n",
              "  'future topdown induction decision trees',\n",
              "  'Holtes'],\n",
              " ['phonetic representation language graphemetophoneme conversion system',\n",
              "  'graphemetophoneme conversion languageindependent',\n",
              "  'performance knowledgebased alternative dataoriented approaches',\n",
              "  'input spelling words',\n",
              "  'graphemetophoneme'],\n",
              " ['density parametric form',\n",
              "  'density',\n",
              "  'prior space possible density functions',\n",
              "  'entropy',\n",
              "  'differential learning rule'],\n",
              " ['optimal search strategies',\n",
              "  'function success probabilities experiments',\n",
              "  'probabilistic experiments',\n",
              "  'configuration successes failures',\n",
              "  'approximately optimal search strategy success probabilities'],\n",
              " ['map explicit state map',\n",
              "  'method',\n",
              "  'phase',\n",
              "  'highdimensional variant',\n",
              "  'corresponding lowdimensional map'],\n",
              " ['process multiagent reinforcement',\n",
              "  'precise framework study adaptive load',\n",
              "  'context load',\n",
              "  'adaptive load',\n",
              "  'naive use communication'],\n",
              " ['Brendan J Frey Geoffrey E Hinton Efficient stochastic source',\n",
              "  'Brendan J Frey Geoffrey E Hinton',\n",
              "  'coding application Bayesian network source model',\n",
              "  'bitsback coding cost codewords',\n",
              "  'given onetomany source code show algorithm'],\n",
              " ['stylized adversarial environments study agent learning strategies',\n",
              "  'learning program',\n",
              "  'Agents',\n",
              "  'agents',\n",
              "  'distinct advantage competitive situations'],\n",
              " ['Many real world',\n",
              "  'learning algorithm',\n",
              "  'problems',\n",
              "  'combinatorial nature data generation process',\n",
              "  'interaction'],\n",
              " ['blind identification source separation',\n",
              "  'nonlinear transformation estimated sources',\n",
              "  'knowledge mixing matrix',\n",
              "  'estimation mixing matrix andor separation mixture stochastically independent sources',\n",
              "  'mixture matrix recurrent InputOutput IO Identification'],\n",
              " ['source separation algorithm',\n",
              "  'Source separation',\n",
              "  'Many source separation algorithms',\n",
              "  'mixture distribution sources',\n",
              "  'set n independent signals'],\n",
              " ['multilayer network',\n",
              "  'paper neural network approach reconstruction natural highly correlated images',\n",
              "  'additive mixture',\n",
              "  'local online learning rules',\n",
              "  'simple local learning rule'],\n",
              " ['online learning algorithms',\n",
              "  'several subordinate prediction algorithms',\n",
              "  'transform algorithms',\n",
              "  'number experts',\n",
              "  'natural experts'],\n",
              " ['current ILP systems',\n",
              "  'classification problems',\n",
              "  'ILP systems',\n",
              "  'classification unseen instances',\n",
              "  'classification accuracy average information score'],\n",
              " ['Process simulation',\n",
              "  'dynamic nonsmooth process simulation',\n",
              "  'valuable tool process design analysis operation',\n",
              "  'dynamic simulation problems',\n",
              "  'linear programming LP dealing problems'],\n",
              " ['genetic algorithms domain optimization',\n",
              "  'massivelyparallel genetic algorithm',\n",
              "  'ordinary genetic algorithm',\n",
              "  'new model autoadaptive behavior individuals',\n",
              "  'model population member active individual'],\n",
              " ['Proben collection problems',\n",
              "  'neural network',\n",
              "  'neural network training',\n",
              "  'neural network learning realm pattern classification function approximation',\n",
              "  'rule collection'],\n",
              " ['NeuroChess program',\n",
              "  'chess final outcome games',\n",
              "  'chess board evaluation functions',\n",
              "  'NeuroChess',\n",
              "  'artificial neural networks'],\n",
              " ['major role',\n",
              "  'CBR CaseBased Reasoning system complexity accuracy retrieval phase Both flat memory inductive approaches',\n",
              "  'performances',\n",
              "  'indexing system',\n",
              "  'simple efficient indexing system structure'],\n",
              " ['landmark visual image robots current location fundamental problem robotics',\n",
              "  'Developing ability',\n",
              "  'concept class geometric patterns landmark recognition problem',\n",
              "  'PAClearning concept class geometric patterns',\n",
              "  'geometric pattern configuration k'],\n",
              " ['classifier maximizing measure function',\n",
              "  'measure function',\n",
              "  'measure functions',\n",
              "  'possible state learning problem computational problem',\n",
              "  'The concept measure functions generalization performance'],\n",
              " ['Recurrent attractor networks',\n",
              "  'recurrent networks',\n",
              "  'feedforward networks',\n",
              "  'serious problems networks',\n",
              "  'intermediate output representations Attractor networks'],\n",
              " ['Induced decision trees',\n",
              "  'many tree induction algorithms',\n",
              "  'tree simplification',\n",
              "  'good classification accuracy tree simplification',\n",
              "  'trees'],\n",
              " ['paper propose monitor Markov chain sampler',\n",
              "  'cusum path plot effective tool convergence diagnostics Markov sampler',\n",
              "  'Markov sampler',\n",
              "  'cusum path plot',\n",
              "  'Markov'],\n",
              " ['precise easy compute bounds convergence time',\n",
              "  'proportionality constant easy calculate',\n",
              "  'Gibbs sampler',\n",
              "  'Bayesian image restoration Convergence Gibbs sampler Ising model Markov chain Monte Carlo',\n",
              "  'Gibbs distribution'],\n",
              " ['c flMIT Media Lab Perceptual Computing Learning Common Sense Technical Report',\n",
              "  'nov',\n",
              "  'hmms model systems',\n",
              "  'multiple state variables',\n",
              "  'hidden Markov models'],\n",
              " ['Bayesian analysis agricultural field experiments topic',\n",
              "  'Adoption Bayesian paradigm',\n",
              "  'little previous attention',\n",
              "  'Bayesian',\n",
              "  'vast frequentist literature'],\n",
              " ['paper continuous state space Markov chains',\n",
              "  'finite state spaces',\n",
              "  'finite Markov chains',\n",
              "  'finite Markov chain',\n",
              "  'subsample continuous chain renewal times related small sets'],\n",
              " ['Markov chain Monte Carlo MCMC samplers',\n",
              "  'multiple chains parallel Updates individual chains',\n",
              "  'population chains',\n",
              "  'claim crossover operator acting parallel population chains',\n",
              "  'Monte Carlo'],\n",
              " ['MIT Computational Cognitive Science Technical Report',\n",
              "  'variational approximation methods',\n",
              "  'QMR DT network practical diagnostic tool',\n",
              "  'efficient probabilistic reasoning applying methods',\n",
              "  'diagnostic inference QMRDT database'],\n",
              " ['neural networks topology performance',\n",
              "  'solution problem RBF networks',\n",
              "  'optimal configurations',\n",
              "  'two determinant parameters networks layout number centroids centroids',\n",
              "  'computationally efficient approximation RBF networks'],\n",
              " ['hybrid methodology',\n",
              "  'genetic algorithms decision tree learning order',\n",
              "  'decision tree',\n",
              "  'Candidate feature subsets',\n",
              "  'useful subsets discriminatory features'],\n",
              " ['behavior humancomputer system crisis response',\n",
              "  'behavior mixedinitiative system experiments',\n",
              "  'paper',\n",
              "  'intelligent assistant planning scheduling domain relation human users',\n",
              "  'INCAs strategy retrieving case case library seeding initial schedule'],\n",
              " ['adequate simulation model task environment payoff function measures quality partially successful plans',\n",
              "  'high performance reactive rules',\n",
              "  'reactive rules',\n",
              "  'reactive plans',\n",
              "  'competitionbased heuristics'],\n",
              " ['machine learning robotics',\n",
              "  'flexibility efficiency robot applications',\n",
              "  'Machine',\n",
              "  'robots highlevel processing planning capabilities',\n",
              "  'route records mobile robot Perception action'],\n",
              " ['diagnostic techniques',\n",
              "  'Markov Chain Monte Carlo algorithms',\n",
              "  'Markov Chain Monte Carlo',\n",
              "  'convergence',\n",
              "  'various methods'],\n",
              " ['track moving object',\n",
              "  'use time derivatives position object manipulator controller',\n",
              "  'target',\n",
              "  'several anticipative controllers',\n",
              "  'next position'],\n",
              " ['covariance information effective heuristic build predictive causal models',\n",
              "  'Covariance information help',\n",
              "  'usual contemporary causal induction',\n",
              "  'predictive causal models',\n",
              "  'conditional independence constraints'],\n",
              " ['decision rules',\n",
              "  'target environment decision rules',\n",
              "  'tactical decision',\n",
              "  'genetic algorithms search space decision policies',\n",
              "  'problem'],\n",
              " ['learning concept',\n",
              "  'learning method use',\n",
              "  'MFOCL Horn clause relational learning algorithm',\n",
              "  'examples nonexamples concept',\n",
              "  'concepts domain'],\n",
              " ['feedforward neural networks',\n",
              "  'neural network',\n",
              "  'radial basis function networks recurrent networks',\n",
              "  'neural networks statistical perspective choice',\n",
              "  'Many issues'],\n",
              " ['modeltheoretic definition causation',\n",
              "  'inductive causation',\n",
              "  'contrary common folklore genuine causal influences',\n",
              "  'modeltheoretic',\n",
              "  'large class data structures'],\n",
              " ['study points bottleneck network interface',\n",
              "  'lower bound run time present algorithm meeting',\n",
              "  'run time model network',\n",
              "  'performance alternative interface',\n",
              "  'CNS'],\n",
              " ['Automated decision',\n",
              "  'descriptive contextsensitive knowledge',\n",
              "  'Much complexity',\n",
              "  'categorical uncertain knowledge network formalism',\n",
              "  'contextsensitive variations'],\n",
              " ['number methods',\n",
              "  'bootstrap methods',\n",
              "  'delta method',\n",
              "  'based Hessian bootstrap estimators sandwich estimator',\n",
              "  'number examples'],\n",
              " ['j j x n j',\n",
              "  'Dirichlet mixture mixtures',\n",
              "  'Discrete mixtures normal distributions',\n",
              "  'x j j n gaussian noise terms',\n",
              "  'prior G Dirichlet process'],\n",
              " ['use time derivatives position object manipulator controller',\n",
              "  'next position object',\n",
              "  'able position handheld camera',\n",
              "  'approximated feedforward neural networks',\n",
              "  'several predictive controllers'],\n",
              " ['AA Adaptive Algorithm',\n",
              "  'AA Adaptive Algorithm model',\n",
              "  'Adaptive Self Organizing Concurrent Systems approach',\n",
              "  'AA actual data',\n",
              "  'AA'],\n",
              " ['noisy mixture independent sources',\n",
              "  'discrete sources',\n",
              "  'discrete source signals',\n",
              "  'separate sources sensors',\n",
              "  'separation'],\n",
              " ['robust statistical model',\n",
              "  'health system',\n",
              "  'systems health degrades',\n",
              "  'diagnosticrecovery procedure',\n",
              "  'The diagnosticrecovery procedure applicable classifier known robust applied neural network traditional parametric pattern classifiers'],\n",
              " ['Case combination',\n",
              "  'case combination',\n",
              "  'subsequent case combination',\n",
              "  'previous work formalized case combination',\n",
              "  'case constraint satisfaction problem'],\n",
              " ['valuable often necessary extension static CSP framework Dynamic Constraint Satisfaction',\n",
              "  'CSP techniques',\n",
              "  'CBR CSP',\n",
              "  'CSP CBR',\n",
              "  'The Dynamic Constraint Satisfaction Problem DCSP'],\n",
              " ['Prior knowledge bias',\n",
              "  'prior knowledge',\n",
              "  'semantic bias domain theory concept',\n",
              "  'concept speed task',\n",
              "  'PAC analysis determinations type relevance knowledge'],\n",
              " ['Computational models natural systems',\n",
              "  'parameter values global vegetation model',\n",
              "  'predictive accuracy models',\n",
              "  'structure model',\n",
              "  'values free parameters'],\n",
              " ['situation learners testing set',\n",
              "  'account frequency virtual seens',\n",
              "  'virtual seens',\n",
              "  'close approximations cases',\n",
              "  'Such cases'],\n",
              " ['Abstract Conversational casebased reasoning CBR systems',\n",
              "  'conversational case libraries',\n",
              "  'Initial Results',\n",
              "  'large case libraries',\n",
              "  'difficult CBR vendors'],\n",
              " ['Diagnosis process',\n",
              "  'disorders machine patient',\n",
              "  'sequential manner diagnosis',\n",
              "  'possible initial information new information',\n",
              "  'diagnosis'],\n",
              " ['hidden layers sigmoid transfer function',\n",
              "  'neural net',\n",
              "  'example',\n",
              "  'function weights',\n",
              "  'binary vectors'],\n",
              " ['default theory',\n",
              "  'credulous version default theory',\n",
              "  'different subsets defaults',\n",
              "  'credulous theory highest expected accuracy R',\n",
              "  'total ordering defaults'],\n",
              " ['inherent compression pressure',\n",
              "  'short elegant general solutions genetic programming system variable length',\n",
              "  'hypothesis',\n",
              "  'visible size complexity solutions',\n",
              "  'The built parsimony pressure effects'],\n",
              " ['recent XCS classifier system',\n",
              "  'XCS systems',\n",
              "  'classifier system',\n",
              "  'XCS Optimality Hypothesis',\n",
              "  'Wilsons Generalization Hypothesis XCS tendency'],\n",
              " ['Current rule induction systems',\n",
              "  'separate conquer strategy learning rule',\n",
              "  'successive rules',\n",
              "  'rules',\n",
              "  'systems accuracy'],\n",
              " ['architecture connection weights multilayer feedforward neural networks',\n",
              "  'particular application specifically defined genetic operators',\n",
              "  'A genetic programming method',\n",
              "  'optimal tradeoff error fitting ability parsimony network',\n",
              "  'nextascent hillclimbing search'],\n",
              " ['neural network',\n",
              "  'neural networks',\n",
              "  'human subjects',\n",
              "  'human subjects judgements',\n",
              "  'American subjects facial expressions'],\n",
              " ['tool automatic generation structured models complex dynamic processes',\n",
              "  'inputoutput behaviour process tool based block oriented approach transparent description signal paths',\n",
              "  'genetic programming',\n",
              "  'appropriate arithmetic expression order',\n",
              "  'The article hand'],\n",
              " ['role hyperplane ranking search',\n",
              "  'simple genetic algorithm',\n",
              "  'genetic search',\n",
              "  'dynamic ranking hyperplanes',\n",
              "  'degree dynamic ranking induced simple genetic algorithm highly correlated degree static ranking inherent function'],\n",
              " ['roles crossover mutation roles',\n",
              "  'Genetic algorithms',\n",
              "  'mutation sense',\n",
              "  'important characteristics operator',\n",
              "  'large body conventional wisdom'],\n",
              " ['recent paper',\n",
              "  'Friedman Geiger Goldszmidt',\n",
              "  'discrete continuous attributes',\n",
              "  'Friedman Geiger',\n",
              "  'discrete attributes'],\n",
              " ['complex systems',\n",
              "  'systems processes',\n",
              "  'different rate others systems processes',\n",
              "  'many real life systems fact processes',\n",
              "  'natural representation certain system characteristics'],\n",
              " ['optimal neural network size particular application Constructive destructive methods',\n",
              "  'simple constructive training method',\n",
              "  'subtract neurons layers connections',\n",
              "  'neurons training',\n",
              "  'one method Recurrent Cascade Correlation due topology fundamental limitations representation'],\n",
              " ['important topic',\n",
              "  'Indexing',\n",
              "  'MemoryBased',\n",
              "  'many cases method',\n",
              "  'several weighting methods'],\n",
              " ['General Result Stabilization Linear Systems Using Bounded Controls',\n",
              "  'Bounded Controls ABSTRACT',\n",
              "  'A General Result Stabilization Linear Systems',\n",
              "  'linear systems subject control saturation',\n",
              "  'linear maps saturations'],\n",
              " ['classification scheme',\n",
              "  'classification problem',\n",
              "  'multiple Ensembles ANNs',\n",
              "  'correct classifications seismic test data Cross Validation evaluations comparisons',\n",
              "  'seismic signals'],\n",
              " ['Bayesian Biostatistics',\n",
              "  'Donald A Berry',\n",
              "  'hearty hospitality Paris sabbatical part chapter',\n",
              "  'first',\n",
              "  'Strangl Adrian E Raftery Professor Statistics Sociology Department'],\n",
              " ['acquisition user optimization',\n",
              "  'practical scheduling problems',\n",
              "  'ProductionManufacturing scheduling',\n",
              "  'user static dynamic preferences known system',\n",
              "  'schedule quality incorporating user'],\n",
              " ['Realization autonomous behavior mobile robots',\n",
              "  'addition approach behavior coordination',\n",
              "  'emphasis evolution fuzzy coordination rules',\n",
              "  'fuzzy logic control',\n",
              "  'autonomous navigation'],\n",
              " ['influence combination model show model',\n",
              "  'distribution model binary vectors',\n",
              "  'combination model mixture model principle component analysis',\n",
              "  'approximated combination model',\n",
              "  'combination model examples'],\n",
              " ['Complex group behavior',\n",
              "  'social insects colonies integration actions',\n",
              "  'simple redundant individual insects',\n",
              "  'simplicity collective action pattern detection collective memory',\n",
              "  'Adler Gordon Oster Wilson'],\n",
              " ['annealed theories',\n",
              "  'similar inverse square root bound VapnikChervonenkis theory Tighter nonuniversal learning curve bounds',\n",
              "  'concept class finite cardinality',\n",
              "  'universal learning curve',\n",
              "  'The naive annealed theory'],\n",
              " ['numerical method',\n",
              "  'method location target',\n",
              "  'underwater sonar targets nearfield bearing range estimation case large passive arrays',\n",
              "  'problem search optimization',\n",
              "  'targets'],\n",
              " ['CIbased learning agent',\n",
              "  'new type intelligent agent',\n",
              "  'constructive inductionbased learning agent CILA',\n",
              "  'useful SIbased learning agent',\n",
              "  'CI learning method Selective induction SI learning methods agents'],\n",
              " ['computational complexity',\n",
              "  'method',\n",
              "  'partitioning neurons',\n",
              "  'measure amount order selforganising map show',\n",
              "  'N ON'],\n",
              " ['Inductive learning relational domains',\n",
              "  'Incy inductive learner',\n",
              "  'intractable general Many approaches task',\n",
              "  'datadriven restriction encoded algorithm modelbased restrictions',\n",
              "  'hypothesis space'],\n",
              " ['target environment decision rules',\n",
              "  'training environment noisy target environment',\n",
              "  'decision rules',\n",
              "  'target environment',\n",
              "  'less noise target environment'],\n",
              " ['Navigation obstacles',\n",
              "  'important capability autonomous underwater vehicles',\n",
              "  'highperformance reactive strategies navigation collision avoidance',\n",
              "  'robust behavior',\n",
              "  'truly autonomous vehicle robust reactive rules'],\n",
              " ['VC theory',\n",
              "  'wellestablished VapnikChervonenkis theory',\n",
              "  'paper',\n",
              "  'curve bounds',\n",
              "  'based ideas statistical mechanics'],\n",
              " ['language inference automata induction',\n",
              "  'deterministic contextfree languages eg n b n parenthesis languages examples',\n",
              "  'nontrivial languages',\n",
              "  'considerable interest',\n",
              "  'recurrent neural networks success models'],\n",
              " ['Connectionist learning procedures',\n",
              "  'sigmoid noisyOR varieties',\n",
              "  'stochastic feedforward network',\n",
              "  'sigmoid feedforward network faster Boltzmann machine',\n",
              "  'link work connectionist learning work representation expert knowledge'],\n",
              " ['standard GP GP',\n",
              "  'Genetic Programming GP',\n",
              "  'variable size representations programs',\n",
              "  'size generality issues',\n",
              "  'size generalization modularity issues programs'],\n",
              " ['effect terms',\n",
              "  'relationship Pearls representation cause effect',\n",
              "  'decisiontheoretic primitives',\n",
              "  'added clarity notion cause',\n",
              "  'traditional view causation'],\n",
              " ['Fuzzy logic evolutionary computation',\n",
              "  'fuzzy logic controllers',\n",
              "  'convenient tools',\n",
              "  'intelligent control systems',\n",
              "  'controller mobile robot path'],\n",
              " ['nonparametric estimation distribution function estimation regression models',\n",
              "  'estimation interval censoring models',\n",
              "  'time semiparametric regression models',\n",
              "  'computation regression parameter estimators',\n",
              "  'profile likelihood maximization semiparametric likelihood distributional results maximum likelihood estimators'],\n",
              " ['Genetic programming',\n",
              "  'genetic programming statistical inference problem',\n",
              "  'tree representations variable size',\n",
              "  'evolutionary algorithms',\n",
              "  'neural network synthesis'],\n",
              " ['Dynamic probabilistic networks DPNs useful tool',\n",
              "  'hindsight DPNs',\n",
              "  'DPNs',\n",
              "  'OSN time algorithm',\n",
              "  'OSN space time N total length observation sequence S state space size time step'],\n",
              " ['optimism pessimism regard informativeness',\n",
              "  'cases optimism',\n",
              "  'Learning methods',\n",
              "  'optimism utility derived rules',\n",
              "  'Pessimism implicit hypothesis testing'],\n",
              " ['longterm dependencies',\n",
              "  'longterm dependencies sequential data difficult deterministic dynamical systems recurrent networks probabilistic models',\n",
              "  'hidden Markov models',\n",
              "  'hidden state variables',\n",
              "  'domain specific apriori knowledge'],\n",
              " ['new algorithm',\n",
              "  'algorithm',\n",
              "  'low complexity neural networks high generalization capability',\n",
              "  'Gibbs algorithm variant novel way splitting generalization error underfitting overfitting error',\n",
              "  'pseudo code algorithm'],\n",
              " ['new reactive rules explanations',\n",
              "  'set new reactive rules',\n",
              "  'reactive rules',\n",
              "  'primary focus paper rule generation phase',\n",
              "  'explanation phase'],\n",
              " ['Technical Report',\n",
              "  'good valueordering strategies',\n",
              "  'cooperate form neural network problemspecific knowledge',\n",
              "  'chronological backtrack search',\n",
              "  'satisfaction search'],\n",
              " ['conversational CBR performance',\n",
              "  'Inferences CBR Express',\n",
              "  'Conversational casebased reasoning CBR shells eg Inferences CBR Express commercially successful tools',\n",
              "  'CBR',\n",
              "  'case libraries'],\n",
              " ['computational model movement skill',\n",
              "  'models performance',\n",
              "  'speedaccuracy tradeoffone robust phenomena human motor behavior',\n",
              "  'movements',\n",
              "  'human behavior'],\n",
              " ['Reinforcement Learning class problems',\n",
              "  'learning problems',\n",
              "  'environment Qlearning classifier systems CS',\n",
              "  'reinforcement',\n",
              "  'autonomous agent'],\n",
              " ['compact coding',\n",
              "  'forming compact codings data distributions',\n",
              "  'sparse coding',\n",
              "  'sensitive sparse distributed codes',\n",
              "  'dichotomy'],\n",
              " ['certain classes analytic functions',\n",
              "  'classes concepts',\n",
              "  'piecewiseanalytic functions',\n",
              "  'n parameters',\n",
              "  'open sets samples length'],\n",
              " ['methodology evaluation casebased reasoning systems',\n",
              "  'behavior system terms theory',\n",
              "  'impact performance system',\n",
              "  'computer system',\n",
              "  'system'],\n",
              " ['casebased reasoner',\n",
              "  'powerful case adapter',\n",
              "  'abstract knowledge planning fit specific planning situations',\n",
              "  'abstract cases',\n",
              "  'extent cases memory'],\n",
              " ['MLE regression parameter',\n",
              "  'MLE infinite dimensional parameter',\n",
              "  'MLE',\n",
              "  'MLE baseline cumulative hazard function',\n",
              "  'MLE finite dimensional parameter class semiparametric models'],\n",
              " ['PO Box Wellington New Zealand Tel Fax Internet TechReportscompvuwacnz Technical Report CSTR',\n",
              "  'New Zealand',\n",
              "  'PO Box',\n",
              "  'Fax Internet TechReportscompvuwacnz Technical Report CSTR October',\n",
              "  'Wellington'],\n",
              " ['need efficient estimation mixture distributions',\n",
              "  'reparameterisation secondary components mixture terms',\n",
              "  'paper Bayesian noninformative approach estimation',\n",
              "  'normal mixtures',\n",
              "  'reparameterisation link secondary components'],\n",
              " ['interfaces document retrieval email servers',\n",
              "  'load servers',\n",
              "  'automatic formprocessing techniques developed email servers',\n",
              "  'Common LISP order',\n",
              "  'A WorldWide Web WWW server'],\n",
              " ['Survival analysis concerned finding models',\n",
              "  'survival analysis',\n",
              "  'survival patients',\n",
              "  'model uncertainty',\n",
              "  'account model uncertainty'],\n",
              " ['bootstrapbased method model',\n",
              "  'best subsets linear model',\n",
              "  'model',\n",
              "  'individual bootstrap samples',\n",
              "  'different bootstrap samples'],\n",
              " ['Technical Report December Statistics Department University',\n",
              "  'Statistics Department University',\n",
              "  'California Berkeley',\n",
              "  'CA Abstract',\n",
              "  'Arcing algorithms'],\n",
              " ['important inferencing role conversational casebased reasoning CCBR system',\n",
              "  'Conversational casebased reasoning',\n",
              "  'integrated reasoning approach modelbased reasoning component',\n",
              "  'interactive casebased reasoning users',\n",
              "  'approach context CCBR system'],\n",
              " ['readonce formulas',\n",
              "  'exact identification monotone readonce formulas',\n",
              "  'exact identification general readonce formulas',\n",
              "  'unknown readonce formula',\n",
              "  'Such formulas'],\n",
              " ['Recursive AutoAssociative Memory RAAM structures',\n",
              "  'sequential RAAM',\n",
              "  'collection hierarchical structures',\n",
              "  'distributed patterns',\n",
              "  'RAAM'],\n",
              " ['distribution learning algorithm variable memory length',\n",
              "  'KLdivergence distribution',\n",
              "  'distributions',\n",
              "  'applicability algorithm',\n",
              "  'algorithm'],\n",
              " ['first order clausal theories',\n",
              "  'focuss semantics logical problem specification claudien discovery algorithm',\n",
              "  'larger attribute value representation claudien',\n",
              "  'search space clausal',\n",
              "  'regularities data representative inductive logic programming paradigm'],\n",
              " ['current inductive machine learning algorithms',\n",
              "  'context machine',\n",
              "  'inductive learning algorithms',\n",
              "  'dependencies attributes',\n",
              "  'quality attributes'],\n",
              " ['Genetic Programming operators',\n",
              "  'Genetic Programming',\n",
              "  'chaotic time series prediction',\n",
              "  'case chaotic time series prediction representation',\n",
              "  'Genetic Programmings flexible tree structure particular problem'],\n",
              " ['Current ILP algorithms',\n",
              "  'heuristic based RELIEF guidance',\n",
              "  'ILP',\n",
              "  'variants extensions',\n",
              "  'greedy search'],\n",
              " ['myopic impurity functions',\n",
              "  'ReliefF used estimate utility literals',\n",
              "  'ReliefF heuristic guidance',\n",
              "  'ReliefF',\n",
              "  'regressional variant RReliefF deal regression problems'],\n",
              " ['paper present TDLeaf variation TD algorithm',\n",
              "  'TDLeaf',\n",
              "  'conjunction minimax search',\n",
              "  'TD',\n",
              "  'chess backgammon'],\n",
              " ['asymptotic properties',\n",
              "  'unknown approximated sequential estimator density',\n",
              "  'sequential estimator',\n",
              "  'sequential estimator energy',\n",
              "  'MetropolisHastings Kernel'],\n",
              " ['principal component analysis PCA representation face recognition',\n",
              "  'ICA representation greater invariance changes',\n",
              "  'independent component analysis ICA',\n",
              "  'faces',\n",
              "  'changes'],\n",
              " ['smoothing parameter estimation assessment uncertainties regression functions',\n",
              "  'fitted regression functions',\n",
              "  'formal analysis addresses problems',\n",
              "  'predictive inference flexible class mixture models',\n",
              "  'similar generalised kernel regression estimates'],\n",
              " ['multipoint crossover operators',\n",
              "  'point crossover operators standard mechanisms',\n",
              "  'higher number crossover points',\n",
              "  'traditional theoretical point view',\n",
              "  'genetic algorithms'],\n",
              " ['methodological issues',\n",
              "  'class neural networks',\n",
              "  'Mixture Density Networks MDN discriminant analysis MDN models',\n",
              "  'paper',\n",
              "  'classification interpretive aspects discriminant analysis'],\n",
              " ['satisfiability problems',\n",
              "  'Satisfiability SAT',\n",
              "  'task finding truth assignment',\n",
              "  'performance SASAT test suite satisfiability problems',\n",
              "  'arbitrary boolean expression'],\n",
              " ['discretization method',\n",
              "  'discretization methods',\n",
              "  'entropybased methods',\n",
              "  'existing entropybased discretization algorithm',\n",
              "  'discretization criterion'],\n",
              " ['similar construction multipleoutput systems modifications',\n",
              "  'first n components',\n",
              "  'last n components',\n",
              "  'first output terms',\n",
              "  'equivalent first n output terms'],\n",
              " ['ffi jyj ev N', 'ffi N ffi gt N', 'jyj ev L ffi', 'N N L', 'jyj ev M ffi'],\n",
              " ['gross errors data reconciliation',\n",
              "  'Gross error detection',\n",
              "  'vital role parameter estimation data reconciliation dynamic steady state systems',\n",
              "  'data reconciliation dynamic systems appropriate problem formulations',\n",
              "  'Data errors'],\n",
              " ['Many significant realworld classification tasks',\n",
              "  'large number categories',\n",
              "  'subject categories library congress scheme',\n",
              "  'worldwideweb documents topic hierarchies',\n",
              "  'categories'],\n",
              " ['decision tree data',\n",
              "  'decision tree',\n",
              "  'unpruned decision tree',\n",
              "  'First large decision tree',\n",
              "  'overfitting second phase tree'],\n",
              " ['PAClearning general class geometric concepts',\n",
              "  'boolean combination polynomial number concepts selected concept class C lt',\n",
              "  'efficient algorithm',\n",
              "  'concept C',\n",
              "  'statistical query version algorithm'],\n",
              " ['new criteria',\n",
              "  'criteria',\n",
              "  'pessimistic decision tree',\n",
              "  'current method',\n",
              "  'uniform convergence VapnikChervonenkis dimension'],\n",
              " ['paper study performance probabilistic networks context protein sequence analysis',\n",
              "  'probabilistic methods comparable methods prediction quality',\n",
              "  'different networks',\n",
              "  'probabilistic approach',\n",
              "  'framework problem protein secondary structure prediction'],\n",
              " ['sanitycheck bounds error leaveoneout crossvalidation estimate generalization error bounds',\n",
              "  'bounds error leaveoneout estimate',\n",
              "  'worstcase error estimate',\n",
              "  'sanitycheck bounds leaveoneout classes',\n",
              "  'necessity form error stability'],\n",
              " ['state world',\n",
              "  'behaviour actors',\n",
              "  'program',\n",
              "  'simulated world',\n",
              "  'actor order support'],\n",
              " ['Genetic Programming techniques domainindependent problem',\n",
              "  'Genetic Programming',\n",
              "  'Widespread adoption',\n",
              "  'new problem domain',\n",
              "  'good underlying software structure'],\n",
              " ['arguments coevolution different adaptive protean behaviors competing species predators',\n",
              "  'Coevolution competitive species',\n",
              "  'unpredictable dynamic environments',\n",
              "  'pursuit behavior',\n",
              "  'interesting testbed study role adaptive behavior'],\n",
              " ['second derivatives',\n",
              "  'networks radial basis units',\n",
              "  'connectionist networks elimination',\n",
              "  'second derivative numerical differentiation',\n",
              "  'h number hidden units network'],\n",
              " ['principles problem',\n",
              "  'functional program synthesis',\n",
              "  'treat programs syntactical structures',\n",
              "  'paper',\n",
              "  'analogy'],\n",
              " ['accurate generalization training set data wide variety applications',\n",
              "  'potential provide accurate generalization',\n",
              "  'several generalization styles',\n",
              "  'prototype styles generalization',\n",
              "  'training set data'],\n",
              " ['exposition recent research',\n",
              "  'continuoustime recurrent dynamic neural networks sigmoidal activation',\n",
              "  'systemtheoretic aspects',\n",
              "  'computational power recurrent nets',\n",
              "  'universal approximation properties Known characterizations controllability observability parameter identifiability'],\n",
              " ['Most Artificial Neural Networks ANNs',\n",
              "  'Artificial Neural Networks',\n",
              "  'fixed topology learning',\n",
              "  'dynamic topologies',\n",
              "  'ANNs'],\n",
              " ['Reinforcement learning algorithms',\n",
              "  'single optimal solution Bellman equation',\n",
              "  'Bellman equation',\n",
              "  'case Bellman equation',\n",
              "  'optimal solution prediction Markov chains'],\n",
              " ['appropriate cases memory',\n",
              "  'structural indices design cases',\n",
              "  'prior design cases',\n",
              "  'vocabulary structural indexing design cases',\n",
              "  'case'],\n",
              " ['components single complex movement',\n",
              "  'abstract movement concepts appropriate component structure',\n",
              "  'movement',\n",
              "  'movements',\n",
              "  'OXBOW unsupervised learning system'],\n",
              " ['datadriven constructive induction',\n",
              "  'Constructive induction',\n",
              "  'best representation space',\n",
              "  'better representation space',\n",
              "  'best hypothesis space'],\n",
              " ['small subset data base',\n",
              "  'small subsets data base',\n",
              "  'novel possibility',\n",
              "  'possibility compressing data bases',\n",
              "  'data important solution'],\n",
              " ['inverse problem physical variables',\n",
              "  'Physical variables orientation line visual field location body space coded activity levels populations neurons Reconstruction',\n",
              "  'much information physical variables',\n",
              "  'representative example reconstruction problem different methods',\n",
              "  'accurately physical variable encoded neuronal population sense'],\n",
              " ['limbic system',\n",
              "  'instantaneous head direction animal horizontal plane',\n",
              "  'The headdirection HD cells',\n",
              "  'modalityindependence internal representation',\n",
              "  'selfmotion information'],\n",
              " ['zeroone misclassification loss functions',\n",
              "  'loss function',\n",
              "  'biasvariance decomposition',\n",
              "  'misclassification rate',\n",
              "  'decomposition'],\n",
              " ['n n',\n",
              "  'f g u r b l e f e l programmable gate arrays FPGAs',\n",
              "  'r e c',\n",
              "  'possiblity e b n g individual evolving population hardware purpose',\n",
              "  'p r b l e w h evolutionary algorithms task'],\n",
              " ['Ax b p k',\n",
              "  'Ax b p k Numerical tests',\n",
              "  'linear system',\n",
              "  'Ax b p corruption p',\n",
              "  'parsimonious solution'],\n",
              " ['natural visual experience',\n",
              "  'different views object face',\n",
              "  'close temporal proximity',\n",
              "  'temporal relationships',\n",
              "  'interaction temporal smoothing activity'],\n",
              " ['Neural networks',\n",
              "  'neural networks',\n",
              "  'data mining neural networks',\n",
              "  'wide range supervised unsupervised learning applications Neuralnetwork methods',\n",
              "  'simple easytounderstand networks'],\n",
              " ['stochastic neural networks',\n",
              "  'KullbackLeibler loss asymptotic case',\n",
              "  'asymptotic gain generalization error',\n",
              "  'A statistical theory',\n",
              "  'generalization error'],\n",
              " ['Mathematical programming',\n",
              "  'new problems',\n",
              "  'feature selection',\n",
              "  'KDD A mathematical programming formulation problem',\n",
              "  'irrelevant redundant features'],\n",
              " ['search space concept descriptions',\n",
              "  'stochastic search space concept descriptions',\n",
              "  'search space',\n",
              "  'stochastic search method',\n",
              "  'heuristic pruning search space method'],\n",
              " ['local selection algorithms',\n",
              "  'parallel small overlapping neighborhoods',\n",
              "  'particular type local selection algorithm',\n",
              "  'variety evolutionary algorithms EAs population',\n",
              "  'local neighborhood models'],\n",
              " ['ambiguous qualitative relationships',\n",
              "  'qualitative relationship nodes',\n",
              "  'Qualitative probabilistic reasoning',\n",
              "  'qualitative relationships question',\n",
              "  'qualitative numeric probabilistic reasoning'],\n",
              " ['cooperative distribution',\n",
              "  'A simple powerful modification standard Gaussian distribution',\n",
              "  'potential rectified Gaussian modeling pattern',\n",
              "  'Gaussian',\n",
              "  'Gaussian constrained nonnegative enabling use nonconvex energy functions'],\n",
              " ['Neural Computation',\n",
              "  'novel fast algorithm',\n",
              "  'new algorithm',\n",
              "  'algorithm',\n",
              "  'Independent Component Analysis'],\n",
              " ['seminal work minimal entropy codes',\n",
              "  'optimal minimal entropy',\n",
              "  'BCM learning rule',\n",
              "  'Barlows',\n",
              "  'probability events'],\n",
              " ['datadriven constructive induction',\n",
              "  'Constructive induction',\n",
              "  'best representation space',\n",
              "  'better representation space',\n",
              "  'best hypothesis space'],\n",
              " ['attribute quality regression classification',\n",
              "  'quality attributes',\n",
              "  'quality',\n",
              "  'Heuristic measures',\n",
              "  'domains strong dependencies'],\n",
              " ['Inductive Logic Programming',\n",
              "  'new area',\n",
              "  'Logic Programming Machine Learning',\n",
              "  'invention new predicates',\n",
              "  'Logic Statistics'],\n",
              " ['Bayesian methods',\n",
              "  'Bayesian inference',\n",
              "  'Bayesian',\n",
              "  'complex modeling tasks',\n",
              "  'review principles'],\n",
              " ['efficient algorithm',\n",
              "  'Bayesian belief networks databases',\n",
              "  'algorithm',\n",
              "  'large enough algorithm',\n",
              "  'belief network structure output'],\n",
              " ['efficient algorithm',\n",
              "  'Bayesian belief networks databases',\n",
              "  'algorithm',\n",
              "  'probability distribution algorithm',\n",
              "  'belief network structure output'],\n",
              " ['V Vapnik',\n",
              "  'A novel method regression',\n",
              "  'Support Vector Machine SVM',\n",
              "  'compare performances different approximation techniques',\n",
              "  'polynomial rational approximation local polynomial techniques'],\n",
              " ['dense interconnect technology effective implementation requirement',\n",
              "  'dense interconnect artificial neural network systems',\n",
              "  'MCM implementation artificial neural networks',\n",
              "  'highdensity interconnect technologies',\n",
              "  'neural network connectionist models'],\n",
              " ['negative examples order',\n",
              "  'set positive examples',\n",
              "  'correct specialization positive examples logical consequences original program finite number derivations positive negative examples',\n",
              "  'negative example',\n",
              "  'negative examples'],\n",
              " ['program wrt positive negative examples',\n",
              "  'positive negative examples',\n",
              "  'positive negative examples computation rule',\n",
              "  'negative examples refutations',\n",
              "  'positive examples'],\n",
              " ['Cognitive mapping qualitative decision modeling technique',\n",
              "  'recent formalisms qualitative decision modeling',\n",
              "  'cognitive maps',\n",
              "  'social science decisionaiding applications',\n",
              "  'political scientists'],\n",
              " ['highlevel reasoning problem domains',\n",
              "  'Casebased reasoning systems',\n",
              "  'new method continuous casebased reasoning',\n",
              "  'Such problem domains',\n",
              "  'general discussion casebased reasoning issues'],\n",
              " ['WestEast Challenge competition machine learning programs',\n",
              "  'The EastWest Challenge title second international competition machine learning programs',\n",
              "  'learning programs',\n",
              "  'stimulating challenge learning programs',\n",
              "  'competition'],\n",
              " ['Previous algorithms recovery Bayesianbelief network structures data',\n",
              "  'non CI test based method Results evaluation algorithm number databases',\n",
              "  'algorithm',\n",
              "  'algorithm performance issues',\n",
              "  'underlying Bayesian network structure'],\n",
              " ['new criterion model selection prediction problems',\n",
              "  'covariance inflation criterion model selection procedures',\n",
              "  'training error average covariance predictions responses prediction rule',\n",
              "  'general prediction problems',\n",
              "  'regression classification general prediction rules'],\n",
              " ['magnetic neural gas MNG algorithm',\n",
              "  'kind magnetic effect',\n",
              "  'MNG',\n",
              "  'unsupervised competitive learning class information',\n",
              "  'associated neuron migration'],\n",
              " ['National Science Foundation Office Naval Research',\n",
              "  'National Science Foundation Fellowship',\n",
              "  'implied National Science Foundation Office Naval Research United States government',\n",
              "  'Dario Salvucci Office Naval Research grant N',\n",
              "  'Dario Salvucci'],\n",
              " ['estimating model parameters',\n",
              "  'Efficient algorithms',\n",
              "  'applied models',\n",
              "  'incidental parameters',\n",
              "  'approximate confidence contours parameters'],\n",
              " ['learning rules cortical selforganization',\n",
              "  'learned contextual pathways',\n",
              "  'plasticity contextual stream explore variations architecture',\n",
              "  'simulations model',\n",
              "  'case model'],\n",
              " ['C weak algorithm',\n",
              "  'ensemble learning approaches',\n",
              "  'AdaBoost',\n",
              "  'Freund Schapire',\n",
              "  'outstanding performance'],\n",
              " ['Infusion GABA agonist Reiter Stryker infusion NMDA receptor antagonist',\n",
              "  'Bear et al Clothiaux et al Miller',\n",
              "  'opposed previous models Bear et al Miller et al Reiter Stryker afferent pathways',\n",
              "  'infusion region monocular deprivation',\n",
              "  'infusion site'],\n",
              " ['polynomial log n constant Further equivalence queries',\n",
              "  'time membership queries',\n",
              "  'membership equivalence queries',\n",
              "  'time queries',\n",
              "  'union discretized axisparallel boxes'],\n",
              " ['genetic algorithms',\n",
              "  'neural networks',\n",
              "  'neural network design training topology optimization',\n",
              "  'associated network training',\n",
              "  'Approaches'],\n",
              " ['belief update belief revision',\n",
              "  'belief revision update networks',\n",
              "  'optimal beliefs',\n",
              "  'steady state beliefs',\n",
              "  'belief revision convergence'],\n",
              " ['combination Genetic Algorithm',\n",
              "  'Previous work',\n",
              "  'Genetic Algorithm',\n",
              "  'Genetic Programming',\n",
              "  'order permutation chromosome combined hand'],\n",
              " ['search space search mechanism',\n",
              "  'Search mechanisms',\n",
              "  'searches',\n",
              "  'semantic information constrain representation space',\n",
              "  'redundant space exploration'],\n",
              " ['Knowledge acquisition difficult errorprone timeconsuming task',\n",
              "  'existing knowledge base',\n",
              "  'Forte FirstOrder Revision Theories',\n",
              "  'Forte FirstOrder Revision Theories Examples refines',\n",
              "  'learning methods'],\n",
              " ['existing representations sequence data',\n",
              "  'future unlabeled sequences',\n",
              "  'major impact task absence background knowledge good representation',\n",
              "  'The problem sequence categorization',\n",
              "  'three domains DNA sequences'],\n",
              " ['Genetic algorithms',\n",
              "  'genetic algorithm',\n",
              "  'genetic algorithms',\n",
              "  'parallel implementation genetic algorithm',\n",
              "  'algorithm'],\n",
              " ['CaseBased Reasoning',\n",
              "  'data base international conflicts',\n",
              "  'conflict data base precedent cases',\n",
              "  'interactive usermodifiable tool intelli',\n",
              "  'political military territorial outcome solution modalities conflict intensity'],\n",
              " ['reasoners learning systems',\n",
              "  'CB H weak general learning algorithm',\n",
              "  'second casebased learning algorithm',\n",
              "  'naive casebased learning algorithm',\n",
              "  'improved choosing similarity measure appropriate concept'],\n",
              " ['evolutionary computation landscape',\n",
              "  'past years',\n",
              "  'various research groups',\n",
              "  'new ideas',\n",
              "  'annoying bewildering oldtimers'],\n",
              " ['MBR algorithm',\n",
              "  'MBR algorithms',\n",
              "  'memorybased reasoning',\n",
              "  'MBR',\n",
              "  'particular MBR system'],\n",
              " ['object unknown class plurality class',\n",
              "  'problem location unknown object space',\n",
              "  'metric used deflne distance object',\n",
              "  'Knearestneighbor procedures',\n",
              "  'K labeled training objects'],\n",
              " ['Seismic data interpretation problems',\n",
              "  'hybrid genetic algorithms',\n",
              "  'traditional hybrid genetic algorithm',\n",
              "  'genetic search',\n",
              "  'applied local search'],\n",
              " ['immune system model',\n",
              "  'immune system',\n",
              "  'relevant natural immune systems',\n",
              "  'model explicit fitness sharing techniques genetic algorithms',\n",
              "  'model implements'],\n",
              " ['method accurate representation highdimensional unknown functions random samples',\n",
              "  'representations function',\n",
              "  'input space smaller subspaces',\n",
              "  'input space',\n",
              "  'The representations function levels'],\n",
              " ['identical hidden Markov model',\n",
              "  'precise final hidden state L linear Boltzmann chain',\n",
              "  'Several authors',\n",
              "  'linear Boltzmann chain',\n",
              "  'Luttrell Williams Saul Jordan Saul Jordan'],\n",
              " ['coevolutionary approach',\n",
              "  'noncoevolutionary approach simulated robot domain',\n",
              "  'sequential decision rules',\n",
              "  'number advantages',\n",
              "  'The coevolutionary approach'],\n",
              " ['Appropriate bias',\n",
              "  'appropriate biases',\n",
              "  'previous learning experience appropriate testbeds',\n",
              "  'learningrate parameters important form bias system',\n",
              "  'IDBD algorithm'],\n",
              " ['Neural network pruning methods',\n",
              "  'pruning method lprune',\n",
              "  'pruning step pruning strength',\n",
              "  'individual network parameters eg connection weights',\n",
              "  'severe pruning early training process'],\n",
              " ['ICSIM connectionist net simulator',\n",
              "  'homogeneous structured connectionist nets',\n",
              "  'uniform customized graphic presentation nets',\n",
              "  'ICSIM',\n",
              "  'meet requirements flexibility'],\n",
              " ['experiencebased casebased reasoning',\n",
              "  'experiencebased reasoning',\n",
              "  'new problems',\n",
              "  'knowledge reasoning',\n",
              "  'new elements old solutions'],\n",
              " ['utility problem',\n",
              "  'casebased reasoning systems resistant utility problem controlrule learning systems',\n",
              "  'methodology analysis utility problems',\n",
              "  'systems performance',\n",
              "  'computational models problem'],\n",
              " ['similaritybased retrieval attempts',\n",
              "  'model',\n",
              "  'psychological data',\n",
              "  'first stage',\n",
              "  'Superficial remindings'],\n",
              " ['constant factor respect bounds sum squared errors',\n",
              "  'linear functions',\n",
              "  'loss bounds adaptive filter theory',\n",
              "  'constant factor',\n",
              "  'algorithm'],\n",
              " ['reasoning similarity assessment',\n",
              "  'new cases description approach call constructive similarity assessment',\n",
              "  'input case descriptions cases',\n",
              "  'similarity assessment',\n",
              "  'Constructive similarity assessment'],\n",
              " ['Much recent research modeling memory processes',\n",
              "  'memory processes',\n",
              "  'memory search strategies',\n",
              "  'useful indices retrieval strategies',\n",
              "  'retrieval criteria'],\n",
              " ['probability distribution',\n",
              "  'probability distributions',\n",
              "  'exact algorithms probability computation tractable substructures combined variational methods',\n",
              "  'tured variational approximations exponential family distributions',\n",
              "  'structured variational approximations'],\n",
              " ['data processing mode ASOCS',\n",
              "  'previous ASOCS models',\n",
              "  'ASOCS',\n",
              "  'adaptive algorithm',\n",
              "  'adaptive network'],\n",
              " ['novel search algorithm',\n",
              "  'genetic hill climbing algorithms dynamic hill climbing ability',\n",
              "  'Dynamic hill climbing',\n",
              "  'dynamic hill climbing',\n",
              "  'genetic algorithms hill climbing techniques'],\n",
              " ['controller autonomous vehicle',\n",
              "  'intelligent controller autonomous vehicle',\n",
              "  'noteworthy performance vehicle controller',\n",
              "  'Autonomous vehicles',\n",
              "  'sophisticated software controllers'],\n",
              " ['Speedup learning',\n",
              "  'congenial learning sequential problem',\n",
              "  'usergiven set problems',\n",
              "  'notion batch problem',\n",
              "  'problem'],\n",
              " ['Nonparametric density estimation problem',\n",
              "  'density function',\n",
              "  'density n sample points',\n",
              "  'associated distribution Nonparametric estimation',\n",
              "  'applications discriminant analysis cluster analysis flow calculations'],\n",
              " ['firstorder Horn programs entailment',\n",
              "  'Horn programs constant arity',\n",
              "  'Horn programs',\n",
              "  'alence entailment membership queries',\n",
              "  'constant arity'],\n",
              " ['canonical NPcomplete problem GAs',\n",
              "  'NPcomplete problems',\n",
              "  'Boolean Satisfiability Problem SAT GAeffective canonical problem',\n",
              "  'canonical problem',\n",
              "  'SAT problems'],\n",
              " ['coordinated strategies stochastic domains agents actions',\n",
              "  'individual agents',\n",
              "  'Fully cooperative multiagent systemsthose agents',\n",
              "  'joint utility',\n",
              "  'special problems'],\n",
              " ['new domain',\n",
              "  'expertise familiar domain',\n",
              "  'familiar domain',\n",
              "  'abstractions common source target domains',\n",
              "  'problems'],\n",
              " ['iterated mutation selection best Genetic Algorithm',\n",
              "  'variation mutation rate useful cases fitness function multimodal pseudoboolean function multimodality',\n",
              "  'bit string length recommendable results',\n",
              "  'standard binary encoded integer Gray',\n",
              "  'objective functions'],\n",
              " ['useful behaviors simulations',\n",
              "  'learning algorithm',\n",
              "  'real world simulation general',\n",
              "  'navigation collision avoidance behaviors robots',\n",
              "  'behaviors robots'],\n",
              " ['Conventional Intelligent Tutoring Systems ITS',\n",
              "  'Conventional Intelligent Tutoring Systems',\n",
              "  'exact state students',\n",
              "  'startling progress management uncertainty',\n",
              "  'accurate student modeling'],\n",
              " ['Satisfiability SAT',\n",
              "  'satisfiability problems',\n",
              "  'difficult traditional satisfiability algorithms Results',\n",
              "  'task finding truth assignment',\n",
              "  'least many hard SAT problems'],\n",
              " ['Artificial Life Neural Networks',\n",
              "  'Neural Networks Artificial Life',\n",
              "  'Artificial Life Neural Networks ALNNs',\n",
              "  'Artificial Life Mobile Robotics',\n",
              "  'Artificial Life Mobile Robotics community'],\n",
              " ['D object category',\n",
              "  'D object category nodes',\n",
              "  'D object prediction',\n",
              "  'multiple D views',\n",
              "  'preprocessed representations D view categories'],\n",
              " ['various neural network architectures',\n",
              "  'Recent interest',\n",
              "  'FIR case derivation performance New algorithms',\n",
              "  'finite impulse response FIR infinite impulse response',\n",
              "  'present short unifying account different algorithms'],\n",
              " ['function number hidden units number learning samples',\n",
              "  'optimal number learning samples',\n",
              "  'computational complexity learning rule optimal learning set size number hidden units',\n",
              "  'methodology estimate',\n",
              "  'asymptotical behavior approximation error asymptotical model error function AMEF introduced parameters'],\n",
              " ['methodology Bayesian model determination decomposable graphical Gaussian models',\n",
              "  'models',\n",
              "  'Model determination',\n",
              "  'particular dimensionchanging move propose',\n",
              "  'conditional complete graph'],\n",
              " ['opportunistic behavior opportunity recognition recognition conditions',\n",
              "  'real world opportunity recognition',\n",
              "  'suspended goal Opportunity recognition special case situation assessment process',\n",
              "  'relevant suspended goals',\n",
              "  'opportunities'],\n",
              " ['Technical Report UMIACSTR CSTR Institute Advanced Computer Studies University Maryland College Park MD Abstract One important aspects machine learning paradigm scales',\n",
              "  'task known optimal training error',\n",
              "  'optimal solution c degree noise training data',\n",
              "  'lower training generalization error',\n",
              "  'better training generalization error'],\n",
              " ['neural networks',\n",
              "  'popular AI machine learning models',\n",
              "  'many reasons',\n",
              "  'convergence optimal network size',\n",
              "  'interpolation characteristics multilayer perceptron neural networks MLPs polynomial models'],\n",
              " ['novel induction algorithm',\n",
              "  'classification rules',\n",
              "  'learning system',\n",
              "  'rule sets',\n",
              "  'rather explicit map guide search rule space'],\n",
              " ['CaseBased Reasoning case retrieval case representation',\n",
              "  'search useful cases',\n",
              "  'requested case',\n",
              "  'required number cases',\n",
              "  'stored large scaled case base'],\n",
              " ['PGA deceptive problems',\n",
              "  'PGA',\n",
              "  'genetic algorithm',\n",
              "  'PGA tries',\n",
              "  'PGA based small number active intelligent individuals'],\n",
              " ['recent ML conferences',\n",
              "  'recent literature',\n",
              "  'additional research',\n",
              "  'focusing alternative performance tasks',\n",
              "  'classifying cases'],\n",
              " ['computational lexicology language technology',\n",
              "  'computational lexicology',\n",
              "  'application approach number lexical acquisition disambiguation',\n",
              "  'specific formalisms domains applications',\n",
              "  'particular performanceoriented approach Natural Language Processing'],\n",
              " ['H n',\n",
              "  'H',\n",
              "  'stepwise estimators',\n",
              "  'explicitly defined approximable sequence H n n functional estimators',\n",
              "  'convergence law algorithm'],\n",
              " ['paper study',\n",
              "  'complete data matrix relative model class',\n",
              "  'data estimation multivariate categorical data',\n",
              "  'select different complete data matrices',\n",
              "  'data problem'],\n",
              " ['paper new evolutionary procedure',\n",
              "  'general optimization problems',\n",
              "  'paper',\n",
              "  'Open Shop Scheduling',\n",
              "  'optimization'],\n",
              " ['symbol symbol alphabet',\n",
              "  'behavioural data',\n",
              "  'Behavioural observations',\n",
              "  'sequence symbols',\n",
              "  'null symbol alphabet'],\n",
              " ['reversible jump',\n",
              "  'Green address problem model order uncertainty autoregressive AR time series',\n",
              "  'Monte Carlo',\n",
              "  'Bayesian framework Efficient model jumping',\n",
              "  'synthetic audio time series'],\n",
              " ['problem planning series modifications memory',\n",
              "  'propose applicability casebased planning methodology task planning',\n",
              "  'flexible planning',\n",
              "  'planning learn framework',\n",
              "  'casebased reasoning'],\n",
              " ['V SCBR simple instancebased learning algorithm',\n",
              "  'PAC analysis V SCBR motivated PAC learning framework',\n",
              "  'overall behaviour behaviour constituent parts V SCBR',\n",
              "  'constituent parts instancebased learner',\n",
              "  'relevant study instancebased learners'],\n",
              " ['partial determinations',\n",
              "  'functional dependencies',\n",
              "  'known MDL formula',\n",
              "  'admissible heuristic exhaustive search',\n",
              "  'efficient preprocessingbased approach'],\n",
              " ['optimal finite state machine explanation symbol strings',\n",
              "  'information theoretic measure finite state machine explanations',\n",
              "  'general probabilistic finite state machines explanations',\n",
              "  'explanations',\n",
              "  'evaluation candidate explanations'],\n",
              " ['evolutionary process',\n",
              "  'decentralized distributed system order',\n",
              "  'evolutionary sequence solution',\n",
              "  'emergent collective behavior natural systems automatic programming',\n",
              "  'discovered synchronization algorithm terms embedded particles interactions'],\n",
              " ['general bootstrap theorem',\n",
              "  'recent infinitedimensional Ztheorem',\n",
              "  'applicatons general theorem',\n",
              "  'finitedimensional results type bootstrap',\n",
              "  'possibly infinitedimensional Zestimators'],\n",
              " ['recurrence times',\n",
              "  'predicted recurrence',\n",
              "  'problem breast cancer recurrence',\n",
              "  'accurate predicted rates recurrence',\n",
              "  'The prediction survival time recurrence time'],\n",
              " ['query committee algorithm method',\n",
              "  'twomember committee algorithm',\n",
              "  'informative queries',\n",
              "  'query',\n",
              "  'selective sampling query'],\n",
              " ['nonlinear form Principal Component Analysis',\n",
              "  'input space nonlinear map instance space possible pixel products',\n",
              "  'derivation method',\n",
              "  'Principal Component Analysis',\n",
              "  'first experimental results'],\n",
              " ['uncertain reasoning communities',\n",
              "  'Modeling techniques',\n",
              "  'general knowledge probabilistic relationships',\n",
              "  'probabilistic knowledge',\n",
              "  'decision model'],\n",
              " ['learning algorithm example',\n",
              "  'learning algorithm',\n",
              "  'dynamic learning algorithms',\n",
              "  'DS method dynamic selection learning algorithms',\n",
              "  'multiple learning algorithms'],\n",
              " ['new concepts',\n",
              "  'Marvin example concept',\n",
              "  'new concepts extent learner',\n",
              "  'belong target concept',\n",
              "  'concept'],\n",
              " ['Adaptation ecological systems environments',\n",
              "  'Energy Environments LEE model',\n",
              "  'Ecological simulations',\n",
              "  'neural networks simple sensorymotor systems variations behaviors',\n",
              "  'environmental complexity effects collective behaviors'],\n",
              " ['efficiency subsumption basic provability relation ILP',\n",
              "  'notion determinate clauses',\n",
              "  'linked Horn clauses',\n",
              "  'klocal Horn clauses',\n",
              "  'Horn clauses ILPproblem'],\n",
              " ['BBN Technical Report Abstract Genetic',\n",
              "  'Abstract Genetic programming powerful method',\n",
              "  'BBN Technical Report',\n",
              "  'variation genetic programming',\n",
              "  'initialization process genetic operators'],\n",
              " ['Category algorithms architectures',\n",
              "  'recurrent networks',\n",
              "  'RCC network finitestate automata FSA network model',\n",
              "  'finite discrete deterministic transfer function used units',\n",
              "  'sigmoidal hardthreshold transfer functions'],\n",
              " ['decidable incomplete approximation logic implication',\n",
              "  'important inductive logic programming theorem',\n",
              "  'relation subsumption clique problem',\n",
              "  'subsumption',\n",
              "  'certain superset determinate clauses'],\n",
              " ['new algorithm',\n",
              "  'algorithm',\n",
              "  'sparse perceptrons input representations',\n",
              "  'three problem domains algorithm',\n",
              "  'concept descriptions'],\n",
              " ['Current inductive machine learning algorithms',\n",
              "  'several artificial several real world problems results',\n",
              "  'greedy search limited lookahead',\n",
              "  'well known machine learning algorithms',\n",
              "  'significant conditional dependencies attributes'],\n",
              " ['hierarchical reinforcement learning',\n",
              "  'previous work hierarchical reinforcement',\n",
              "  'hierarchical Q learning algorithm',\n",
              "  'hierarchical credit assignment problem nonhierarchical execution MAXQ',\n",
              "  'paper'],\n",
              " ['concept causality Genetic Programming GP',\n",
              "  'weak causality',\n",
              "  'Causality',\n",
              "  'causality perspective',\n",
              "  'GP search'],\n",
              " ['bias variance unstable methods',\n",
              "  'meansquared error voting methods',\n",
              "  'unstable methods',\n",
              "  'different methods variants',\n",
              "  'voting methods'],\n",
              " ['intelligence Productive research AI practical theoretical benefits notion intelligence',\n",
              "  'closer informal conception intelligence',\n",
              "  'The longterm goal field creation',\n",
              "  'future research',\n",
              "  'gap theory practice'],\n",
              " ['compositional structure',\n",
              "  'compositional structures',\n",
              "  'circular convolution associate items',\n",
              "  'distributed representations',\n",
              "  'convolution memories'],\n",
              " ['Angluins L fl',\n",
              "  'based Angluins',\n",
              "  'L fl',\n",
              "  'random prefixclosed samples algorithm',\n",
              "  'prefixclosed samples behavior'],\n",
              " ...]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positionrank_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e9cHOlKOT1x",
        "outputId": "bb72cb5b-77ee-42e0-8cee-5179b48a9dea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Several computer algorithms',\n",
              "  'form heuristic',\n",
              "  'statistical model produced situation convex combination',\n",
              "  'megaprior',\n",
              "  'convex combinations'],\n",
              " ['colposuspension cure rate',\n",
              "  'risk factors',\n",
              "  'machine',\n",
              "  'algorithmsR FOIL',\n",
              "  'set rules'],\n",
              " ['disjoint cells cell',\n",
              "  'channel',\n",
              "  'calls',\n",
              "  'large cellular system',\n",
              "  'service'],\n",
              " ['pomdps line show cases',\n",
              "  'novel algorithm',\n",
              "  'previous work complexity',\n",
              "  'techniques operations research bear problem',\n",
              "  'discussion approach'],\n",
              " ['variational methods',\n",
              "  'Graphical models',\n",
              "  'mere approximations',\n",
              "  'information',\n",
              "  'representations'],\n",
              " ['results',\n",
              "  'algorithms',\n",
              "  'decisionevaluation variant',\n",
              "  'Goldszmidt',\n",
              "  'implications'],\n",
              " ['formal framework',\n",
              "  'paper',\n",
              "  'sufficient conditions',\n",
              "  'representation',\n",
              "  'different representations'],\n",
              " ['previous paper',\n",
              "  'objective functions',\n",
              "  'Hischbergs',\n",
              "  'linear space algorithm Hir',\n",
              "  'result'],\n",
              " ['mistakes',\n",
              "  'possible elements',\n",
              "  'studied online model learner offline model',\n",
              "  'offline variant mistakebound model',\n",
              "  'online model'],\n",
              " ['SS ANOVA',\n",
              "  'Gaussian data',\n",
              "  'RKPACK',\n",
              "  'GRKPACK collection Fortran',\n",
              "  'ANalysis VAriance SS ANOVA method data exponential families'],\n",
              " ['learning rules',\n",
              "  'larger size codings potential solutions ability generalisation testing',\n",
              "  'usefulness encoding schema',\n",
              "  'results',\n",
              "  'model'],\n",
              " ['basic LaplaceMetropolis estimator models',\n",
              "  'random effects',\n",
              "  'posterior simulation output',\n",
              "  'models',\n",
              "  'data World Fertility Survey'],\n",
              " ['empirical learning utility problem',\n",
              "  'knowledge Plotting performance',\n",
              "  'common trend',\n",
              "  'several learning methods',\n",
              "  'peak performance'],\n",
              " ['HMM',\n",
              "  'unaligned sequences',\n",
              "  'multiple alignments',\n",
              "  'discrimination tests',\n",
              "  'produced programs'],\n",
              " ['additional deterministic experiments',\n",
              "  'order',\n",
              "  'effect initial weight selection feedforward networks',\n",
              "  'results experiments',\n",
              "  'paper'],\n",
              " ['medial temporal lobe',\n",
              "  'network model',\n",
              "  'recall recent events',\n",
              "  'hippocampus',\n",
              "  'process'],\n",
              " ['eyes', 'target structure', 'addition', 'mechanisms', 'phenomena'],\n",
              " ['classifier random example',\n",
              "  'average variance test error rates',\n",
              "  'process',\n",
              "  'Next',\n",
              "  'examples'],\n",
              " ['correct model',\n",
              "  'classification noise',\n",
              "  'learner attempts',\n",
              "  'f gvalued target function',\n",
              "  'example oracle'],\n",
              " ['neural network function approximator',\n",
              "  'approach table',\n",
              "  'decision tree based approach function approximation reinforcement',\n",
              "  'problems well known mountain car pole balance problems',\n",
              "  'simulated automobile race car'],\n",
              " ['neural networks',\n",
              "  'discover strategies',\n",
              "  'Evolution',\n",
              "  'Othello randommoving opponent',\n",
              "  'artificial evolution'],\n",
              " ['PAC',\n",
              "  'accuracy',\n",
              "  'weak learning algorithms',\n",
              "  'general bounds complexity',\n",
              "  'new model'],\n",
              " ['applications classes',\n",
              "  'tremendous current effort',\n",
              "  'computation forces',\n",
              "  'Neural network features',\n",
              "  'problem solutions'],\n",
              " ['priors', 'work authors', 'Jeffreyss rules', 'formal rule', 'Jim Berger'],\n",
              " ['eXogenous inputs neural network models popular subclass recurrent networks',\n",
              "  'embedded memory',\n",
              "  'many applications',\n",
              "  'prominent NARX models',\n",
              "  'intelligent memory order selection'],\n",
              " ['approach',\n",
              "  'central problem',\n",
              "  'experiments',\n",
              "  'combinations',\n",
              "  'suitable developing incremental learning algorithms'],\n",
              " ['CBR', 'creative design', 'problem', 'paper', 'types behavior'],\n",
              " ['certain classes',\n",
              "  'relations',\n",
              "  'Mstep',\n",
              "  'Gibbs distributions',\n",
              "  'generalized iterative scaling procedure'],\n",
              " ['experience order',\n",
              "  'memorybased techniques artificial intelligence help store',\n",
              "  'characteristics design designers',\n",
              "  'design problems',\n",
              "  'users'],\n",
              " ['topdown connections',\n",
              "  'hidden variables',\n",
              "  'patterns',\n",
              "  'Uppropagation algorithm',\n",
              "  'error signal'],\n",
              " ['strong features',\n",
              "  'interaction system environment',\n",
              "  'paper',\n",
              "  'exploitation',\n",
              "  'certain vision processing techniques index case base surfaces'],\n",
              " ['series experiments',\n",
              "  'genetic algorithms',\n",
              "  'examples',\n",
              "  'kNN great difficulty',\n",
              "  'system'],\n",
              " ['hierarchical generative model',\n",
              "  'Bayesian perceptual inference',\n",
              "  'bottomup topdown lateral connections',\n",
              "  'extract',\n",
              "  'connection strengths'],\n",
              " ['SANE',\n",
              "  'neuroevolution individual population',\n",
              "  'paper',\n",
              "  'easy tasks',\n",
              "  'applications'],\n",
              " ['skills partially defined action policies',\n",
              "  'reinforcement',\n",
              "  'unknown environments',\n",
              "  'complex realworld tasks',\n",
              "  'ones'],\n",
              " ['situations learner wishes',\n",
              "  'f gvalued functions learner',\n",
              "  'several applications general results',\n",
              "  'linear inequalities M M',\n",
              "  'generalization mistakebound model'],\n",
              " ['critical issue users', 'work', 'simple models', 'part', 'performance'],\n",
              " ['high variance principal components',\n",
              "  'method',\n",
              "  'competitive setting',\n",
              "  'directions',\n",
              "  'dichotomy'],\n",
              " ['data',\n",
              "  'paper review advantages',\n",
              "  'query search database',\n",
              "  'new algorithm',\n",
              "  'database'],\n",
              " ['optimal solution problem',\n",
              "  'paper',\n",
              "  'intractable general',\n",
              "  'optimal control policy',\n",
              "  'observable Markov decision process'],\n",
              " ['Salzbergs NGE', 'purpose note', 'work', 'AIC', 'curious result'],\n",
              " ['series distributions',\n",
              "  'recentlydeveloped method simulated tempering tempered transition method',\n",
              "  'inefficiency random walk advantage',\n",
              "  'distribution interest distribution sampling',\n",
              "  'simulated tempering tedious estimate'],\n",
              " ['student',\n",
              "  'students',\n",
              "  'methods',\n",
              "  'plausible hypotheses',\n",
              "  'detailed example system'],\n",
              " ['growing experience',\n",
              "  'introspection plans',\n",
              "  'knowledge cognition',\n",
              "  'requirement',\n",
              "  'casebased approach Introspection Planning'],\n",
              " ['graphs',\n",
              "  'Graphical Markov models',\n",
              "  'ADGs especially convenient statistical analysis',\n",
              "  'Markov property chain graphs',\n",
              "  'spatial dependence image analysis'],\n",
              " ['paper', 'reports', 'experiments', 'addresses', 'fl'],\n",
              " ['competitive methods',\n",
              "  'new strategies',\n",
              "  'games',\n",
              "  'Machine learning game strategies',\n",
              "  'performance'],\n",
              " ['bounds',\n",
              "  'generalization error hypothesis',\n",
              "  'learning algorithm based methods theory',\n",
              "  'distribution examples',\n",
              "  'calculated data'],\n",
              " ['policies',\n",
              "  'MDPs',\n",
              "  'based ideas statistical mechanics',\n",
              "  'local reward mining state space',\n",
              "  'shortterm'],\n",
              " ['VC dimension',\n",
              "  'neural networks',\n",
              "  'continuous activation functions',\n",
              "  'least large square number weights',\n",
              "  'result'],\n",
              " ['Novel online learning algorithms',\n",
              "  'different time',\n",
              "  'various outputs',\n",
              "  'neural network models',\n",
              "  'convergence speed'],\n",
              " ['modular network architecture',\n",
              "  'tasks',\n",
              "  'concatenating number simpler elemental MDTs',\n",
              "  'class MDTs',\n",
              "  'incremental dynamic programming'],\n",
              " ['system',\n",
              "  'simulators',\n",
              "  'executable dataflow language',\n",
              "  'numerical simulation programs',\n",
              "  'construction programs'],\n",
              " ['certain independencies',\n",
              "  'particular qualitative representation',\n",
              "  'effective inference algorithms',\n",
              "  'contextspecific independence CSI',\n",
              "  'network'],\n",
              " ['trace analyze', 'method', 'results', 'show methods', 'trace assign credit'],\n",
              " ['theory',\n",
              "  'complete task',\n",
              "  'set tasks',\n",
              "  'realworld texts',\n",
              "  'particular type knowledge'],\n",
              " ['VCU',\n",
              "  'decidable logic',\n",
              "  'special instance theory',\n",
              "  'knowledge',\n",
              "  'counterfactual conditionals'],\n",
              " ['probabilistic method',\n",
              "  'optimal universal search algorithm',\n",
              "  'Kolmogorov complexity Solomonoffs',\n",
              "  'problem',\n",
              "  'training data'],\n",
              " ['set cases examples',\n",
              "  'new phrase',\n",
              "  'several recordings tenor',\n",
              "  'several expressive parameters',\n",
              "  'information'],\n",
              " ['test error',\n",
              "  'size',\n",
              "  'classifier',\n",
              "  'experiments',\n",
              "  'large often observed decrease even training error'],\n",
              " ['highdimensional data',\n",
              "  'paper present framework',\n",
              "  'density estimates',\n",
              "  'mixture models',\n",
              "  'estimation mixture components'],\n",
              " ['taxonomy maps',\n",
              "  'memory organization',\n",
              "  'recognition taxonomy',\n",
              "  'process',\n",
              "  'incomplete stories'],\n",
              " ['adaptive model',\n",
              "  'system',\n",
              "  'inputs',\n",
              "  'targets',\n",
              "  'artificial fovea controlled adaptive neural controller'],\n",
              " ['project',\n",
              "  'treestructured architecture',\n",
              "  'ECS',\n",
              "  'support Initiative Intelligent Control MIT Michael',\n",
              "  'I'],\n",
              " ['EM algorithm',\n",
              "  'M step',\n",
              "  'unobserved variables',\n",
              "  'respect distribution',\n",
              "  'perspective'],\n",
              " ['network',\n",
              "  'network twodimensional matrix oscillator',\n",
              "  'different oscillator groups',\n",
              "  'global separator',\n",
              "  'WilsonCowan oscillators'],\n",
              " ['simulation technique',\n",
              "  'Gibbs sampling',\n",
              "  'simultaneous inference',\n",
              "  'implementation probabilistic regression model BUGS BUGS program',\n",
              "  'complex regression models environment'],\n",
              " ['automatic classifier',\n",
              "  'unseen data',\n",
              "  'humans',\n",
              "  'classifying process',\n",
              "  'machine learning techniques'],\n",
              " ['parallel computations', 'R', 'fl', 'ordinary computers', 'talk'],\n",
              " ['possibility',\n",
              "  'conflicting candidates',\n",
              "  'subset style dominance problem',\n",
              "  'right interval',\n",
              "  'scheme proposed paper'],\n",
              " ['new scheduling problems',\n",
              "  'evaluation function',\n",
              "  'repairbased scheduler',\n",
              "  'reinforcement learning methods',\n",
              "  'results'],\n",
              " ['cart', 'position', 'rigid pole', 'plane', 'maximum distance'],\n",
              " ['resulting restart algorithm',\n",
              "  'hidden units',\n",
              "  'backpropagation',\n",
              "  'Solutions',\n",
              "  'inverted pendulum problem'],\n",
              " ['new processing paradigm',\n",
              "  'finegrain parallelism',\n",
              "  'window instructions',\n",
              "  'Expandable Split Window ESW paradigm',\n",
              "  'execution'],\n",
              " ['implementation NGE',\n",
              "  'weights',\n",
              "  'Salzberg',\n",
              "  'domains decision boundaries',\n",
              "  'algorithms'],\n",
              " ['good model',\n",
              "  'paper',\n",
              "  'better ones',\n",
              "  'computational effort',\n",
              "  'special case leaveoneout cross validation'],\n",
              " ['MINFEATURES',\n",
              "  'FOCUS algorithm',\n",
              "  'V edges',\n",
              "  'values',\n",
              "  'Almuallim Dietterich'],\n",
              " ['input representations',\n",
              "  'Bottomup recognition connections',\n",
              "  'goal',\n",
              "  'problems',\n",
              "  'phase neurons'],\n",
              " ['application artificial neural network technology',\n",
              "  'structure software library',\n",
              "  'detail',\n",
              "  'semantic relationship stored software components',\n",
              "  'structured library'],\n",
              " ['methods',\n",
              "  'question',\n",
              "  'chapter',\n",
              "  'general laws',\n",
              "  'large set training examples'],\n",
              " ['Markov chain',\n",
              "  'equilibrium distribution',\n",
              "  'simplest random set models',\n",
              "  'Propp Wilson',\n",
              "  'seminal work'],\n",
              " ['useful problem',\n",
              "  'indexing purposes',\n",
              "  'similarity assessment order',\n",
              "  'rules',\n",
              "  'casebased reasoning'],\n",
              " ['next move adversary',\n",
              "  'location',\n",
              "  'path',\n",
              "  'project',\n",
              "  'DFA model adversarial robot use automaton'],\n",
              " ['NSF',\n",
              "  'DMS',\n",
              "  'ISDS Muller West',\n",
              "  'Claudia Cargnoni Dipartimento Statistico Universita di Firenze Firenze Italy Peter Muller Assistant Professor Mike West Professor Institute Statistics Decision Sciences Duke University Durham NC Research Cargnoni'],\n",
              " ['finite population GAFOs',\n",
              "  'steady states',\n",
              "  'transition',\n",
              "  'Markov chain theory',\n",
              "  'behavior'],\n",
              " ['single parameter',\n",
              "  'Noise injection modified order',\n",
              "  'determination',\n",
              "  'penalization inputs',\n",
              "  'complexity model'],\n",
              " ['present new multivariate decision tree algorithm LMDT',\n",
              "  'LMDT',\n",
              "  'paper',\n",
              "  'Abstract',\n",
              "  'good generalizations present results'],\n",
              " ['RL',\n",
              "  'reinforcement',\n",
              "  'dynamic systems',\n",
              "  'overall controller performance',\n",
              "  'comprehensive overview'],\n",
              " ['time', 'neuron', 'selforganization bootstrap', 'algorithm', 'selforganize'],\n",
              " ['social scientists epidemiologists',\n",
              "  'economists',\n",
              "  'fields',\n",
              "  'statistical causal foundations',\n",
              "  'knowledgerich applications'],\n",
              " ['new method',\n",
              "  'existing ILP',\n",
              "  'best aspects',\n",
              "  'recursive programs',\n",
              "  'system'],\n",
              " ['deterministic techniques',\n",
              "  'useful size network clique size',\n",
              "  'sigmoid noisyOR networks',\n",
              "  'upper lower bounds marginal probabilities',\n",
              "  'exact computations'],\n",
              " ['accuracy methods',\n",
              "  'framework',\n",
              "  'constraints',\n",
              "  'network topologies',\n",
              "  'quantities'],\n",
              " ['number random examples',\n",
              "  'ffi',\n",
              "  'distributionfree learning concept class C VCdimC VapnikChervonenkis dimension ffi accuracy confidence parameters',\n",
              "  'kCNF',\n",
              "  'many interesting concept classes'],\n",
              " ['Tau Net neural network',\n",
              "  'realworld dynamic signals',\n",
              "  'time scales',\n",
              "  'synthetic speech data',\n",
              "  'Tau Nets'],\n",
              " ['effects',\n",
              "  'serious limitations',\n",
              "  'SOM',\n",
              "  'generalisation performance',\n",
              "  'training MFNs'],\n",
              " ['MLP network',\n",
              "  'hyperplanes',\n",
              "  'curves',\n",
              "  'M M training set size',\n",
              "  'Monte Carlo studies'],\n",
              " ['approximation',\n",
              "  'many implementational issues',\n",
              "  'Gibbs',\n",
              "  'theoretical results',\n",
              "  'strategy parameterization'],\n",
              " ['data',\n",
              "  'paper review advantages',\n",
              "  'query search database',\n",
              "  'new algorithm',\n",
              "  'database'],\n",
              " ['collisions',\n",
              "  'ability',\n",
              "  'experiments',\n",
              "  'test tuning decomposition coordination low level behaviors',\n",
              "  'best design'],\n",
              " ['information',\n",
              "  'elimination',\n",
              "  'irrelevant features',\n",
              "  'data',\n",
              "  'hybrid genetic algorithm'],\n",
              " ['HGP approach',\n",
              "  'paper',\n",
              "  'qualitative explanation',\n",
              "  'evolution',\n",
              "  'improved behavior'],\n",
              " ['construction neural architectures',\n",
              "  'descriptions event sequences',\n",
              "  'multilevel hierarchy recurrent networks',\n",
              "  'first functions',\n",
              "  'insight'],\n",
              " ['afferent weights neuron',\n",
              "  'network',\n",
              "  'lateral connections',\n",
              "  'cortex',\n",
              "  'eye preference'],\n",
              " ['fast dynamics',\n",
              "  'place intervals',\n",
              "  'method',\n",
              "  'singular limit method',\n",
              "  'slow dynamics'],\n",
              " ['model spiking neurons',\n",
              "  'connected twodimensional network',\n",
              "  'research modeling visual cortex',\n",
              "  'lateral excitatory inhibitory connections',\n",
              "  'selforganization segmentation'],\n",
              " ['Carlo MCMC methods',\n",
              "  'necessary integrals',\n",
              "  'weight space',\n",
              "  'Gaussian processes',\n",
              "  'small number hyperparameters'],\n",
              " ['Gibbs sampling',\n",
              "  'algorithm',\n",
              "  'bivariate point process penetrable spheres mixture model',\n",
              "  'Coupling Past',\n",
              "  'use'],\n",
              " ['receptive field sizes',\n",
              "  'visual cortex selective ocular dominance orientation input',\n",
              "  'lateral connectivity',\n",
              "  'patterns',\n",
              "  'visual cortex'],\n",
              " ['function parameters',\n",
              "  'neural critic',\n",
              "  'controller cost function',\n",
              "  'A Reinforcement Learning method',\n",
              "  'linear controller'],\n",
              " ['Predicates',\n",
              "  'nonrecursive local clauses',\n",
              "  'PAClearnable distribution',\n",
              "  'previous result',\n",
              "  'first theoretical framework'],\n",
              " ['ExpectationMaximization algorithm',\n",
              "  'note',\n",
              "  'examples',\n",
              "  'data multiple noisy sources',\n",
              "  'Luttrell'],\n",
              " ['approximated function radial symmetry',\n",
              "  'problem framework regularization theory',\n",
              "  'problem',\n",
              "  'case',\n",
              "  'alternative ways'],\n",
              " ['new algorithms',\n",
              "  'Kalman',\n",
              "  'dimensions asymptotic error computational complexity',\n",
              "  'least squares classical parameterestimation methods',\n",
              "  'leastsquares'],\n",
              " ['algorithm',\n",
              "  'previous work',\n",
              "  'suitable redundant noisefree data sets',\n",
              "  'problem',\n",
              "  'noisy data windowing present preliminary ideas'],\n",
              " ['system',\n",
              "  'comprehensive approach automatic theory revision',\n",
              "  'classification systems',\n",
              "  'approximate domain theory',\n",
              "  'corrections'],\n",
              " ['SwendsenWang algorithm generalizations paper',\n",
              "  'joint distribution x u',\n",
              "  'addition',\n",
              "  'Bayesian image analysis',\n",
              "  'applications'],\n",
              " ['algorithm',\n",
              "  'auxiliary variable',\n",
              "  'case',\n",
              "  'robust geometric ergodicity properties',\n",
              "  'theoretical properties'],\n",
              " ['GP results suite simulated annealing run ADFs problem size',\n",
              "  'simulated annealing ADFs',\n",
              "  'contrast',\n",
              "  'GP algorithm',\n",
              "  'ADFs'],\n",
              " ['values attributes',\n",
              "  'blockers',\n",
              "  'attributes learner',\n",
              "  'data',\n",
              "  'model blocking process'],\n",
              " ['blocks',\n",
              "  'new functions',\n",
              "  'based hierarchy discovered functions',\n",
              "  'feasibility approaches',\n",
              "  'evolution trace'],\n",
              " ['fundamental nonconvex model',\n",
              "  'measurements',\n",
              "  'decision problem',\n",
              "  'points',\n",
              "  'fine needle aspirates'],\n",
              " ['perception metrical structure dynamic process temporal organization external musical events',\n",
              "  'article',\n",
              "  'rhythmic patterns Networks units selforganize',\n",
              "  'Many connectionist',\n",
              "  'discussion implications approach theories'],\n",
              " ['orderbased problems',\n",
              "  'LibGA',\n",
              "  'several packages',\n",
              "  'easy use userfriendly interface',\n",
              "  'new ways'],\n",
              " ['Human episodic memory',\n",
              "  'plausible patterns',\n",
              "  'retrieval system',\n",
              "  'smaller perceptual maps',\n",
              "  'paper'],\n",
              " ['candidate approximate theories',\n",
              "  'results testing theory space search',\n",
              "  'training examples',\n",
              "  'Empirical data',\n",
              "  'nonoptimal'],\n",
              " ['generalsum stochastic games framework multiagent reinforcement',\n",
              "  'Nash equilibrium',\n",
              "  'optimal strategy',\n",
              "  'work',\n",
              "  'algorithm'],\n",
              " ['paper',\n",
              "  'emerging discipline knowledge management',\n",
              "  'Corporate memories',\n",
              "  'case libraries',\n",
              "  'existing techniques'],\n",
              " ['selfknowledge',\n",
              "  'Specific kinds',\n",
              "  'alternatives',\n",
              "  'domains',\n",
              "  'principled way'],\n",
              " ['Theory revision',\n",
              "  'advanced theoryguided learning systems',\n",
              "  'accurate theory',\n",
              "  'theoryguided constructive induction Experiments',\n",
              "  'improvement'],\n",
              " ['neural computing',\n",
              "  'initial architecture backpropagation training multilayer perceptron precise replication',\n",
              "  'experiment',\n",
              "  'First attempt',\n",
              "  'support maximum replicability use'],\n",
              " ['visual categories movements',\n",
              "  'robot',\n",
              "  'neural network',\n",
              "  'different kind mazes',\n",
              "  'difficulty'],\n",
              " ['instrument',\n",
              "  'nonlinear mapping control data audio space',\n",
              "  'Audio time series boundary conditions',\n",
              "  'resulting model',\n",
              "  'datadriven probabilistic inference'],\n",
              " ['ILP SRT',\n",
              "  'class problems',\n",
              "  'ILP algorithm',\n",
              "  'many realworld domains task machine learning algorithms',\n",
              "  'numerical values'],\n",
              " ['Bayesian evidence',\n",
              "  'interpolation models',\n",
              "  'framework',\n",
              "  'paper',\n",
              "  'measure'],\n",
              " ['performance potential simultaneous multithreading',\n",
              "  'throughput',\n",
              "  'multiple independent threads',\n",
              "  'architecture',\n",
              "  'architectural impact'],\n",
              " ['deficient domain theory', 'information', 'PTR', 'examples', 'proof theory'],\n",
              " ['New methodology',\n",
              "  'analysis univariate normal mixtures',\n",
              "  'approach',\n",
              "  'weak prior information',\n",
              "  'posterior distribution'],\n",
              " ['Recent discussions',\n",
              "  'original interest questions',\n",
              "  'Satinder Singh Vijay Gullapalli',\n",
              "  'Andy Barto',\n",
              "  'work'],\n",
              " ['information',\n",
              "  'passive learning examples',\n",
              "  'selective sampling show',\n",
              "  'consider problem',\n",
              "  'paper'],\n",
              " ['speculative execution instructions unresolved branch',\n",
              "  'impact branch operations Microprocessor',\n",
              "  'Predication',\n",
              "  'branch predicate form',\n",
              "  'paper'],\n",
              " ['case',\n",
              "  'model precedents',\n",
              "  'justifications warrants',\n",
              "  'specific facts',\n",
              "  'example'],\n",
              " ['Hlearning',\n",
              "  'current value function',\n",
              "  'greedy actions',\n",
              "  'unexplored parts state space',\n",
              "  'Adaptive RealTime Dynamic Programming simulated robot scheduling task'],\n",
              " ['Dynamic Parametric GA GA',\n",
              "  'parameter settings',\n",
              "  'genetic algorithms GAs',\n",
              "  'improvement application',\n",
              "  'design phase'],\n",
              " ['Olshausen Field algorithm',\n",
              "  'research',\n",
              "  'ARPA',\n",
              "  'funds',\n",
              "  'Several useful insights'],\n",
              " ['networks',\n",
              "  'large deviations',\n",
              "  'weighted sums',\n",
              "  'efficient algorithms',\n",
              "  'computation upper lower bounds well generic transfer function parameterizations'],\n",
              " ['valuable technique',\n",
              "  'task',\n",
              "  'efficiency search',\n",
              "  'optimal description',\n",
              "  'issues'],\n",
              " ['strengths weaknesses',\n",
              "  'several promising directions',\n",
              "  'different learning paradigms symbol processing systems connectionist networks statistical syntactic pattern recognition systems possible candidates',\n",
              "  'capabilities',\n",
              "  'paper'],\n",
              " ['SARDNET',\n",
              "  'successful mapping arbitrary sequences binary real numbers',\n",
              "  'network',\n",
              "  'Kohonen Feature Map architecture activation retention decay order',\n",
              "  'Potential applications'],\n",
              " ['knowledge integration',\n",
              "  'performance integrated theory',\n",
              "  'experiments',\n",
              "  'aim',\n",
              "  'results'],\n",
              " ['define term bias',\n",
              "  'introduction',\n",
              "  'machine learning systems',\n",
              "  'selecting biases',\n",
              "  'importance automated methods'],\n",
              " ['decision trees',\n",
              "  'store knowledge form decision rules',\n",
              "  'method initial results',\n",
              "  'disadvantage approach decision tree',\n",
              "  'AQDT'],\n",
              " ['radial basis functions',\n",
              "  'regularizers',\n",
              "  'RW',\n",
              "  'direct enforcement smoothness',\n",
              "  'illustrative sample problems'],\n",
              " ['production reduced memory representations',\n",
              "  'reductionist theories',\n",
              "  'structural importance musical events',\n",
              "  'variations melodies',\n",
              "  'mental representations music'],\n",
              " ['variety statistical inference problems',\n",
              "  'tool',\n",
              "  'paper',\n",
              "  'linear regression model parameters hyperparameters',\n",
              "  'optimized ensemble approximation posterior probability distribution parameters'],\n",
              " ['stationary distribution',\n",
              "  'adaptive scheme',\n",
              "  'implement',\n",
              "  'theoretical results',\n",
              "  'method'],\n",
              " ['knowledge',\n",
              "  'complex case representations relevance object',\n",
              "  'prior experiences',\n",
              "  'proper adaptations attributevalue representations',\n",
              "  'relations'],\n",
              " ['multipath execution', 'paper', 'performance', 'limits', 'several paths'],\n",
              " ['perturbations',\n",
              "  'probabilistic model',\n",
              "  'Bayesian networks global neighborhoods',\n",
              "  'robustness analysis',\n",
              "  'posterior values'],\n",
              " ['selflearning control system mobile robot',\n",
              "  'collision',\n",
              "  'reinforcement learning scheme',\n",
              "  'external reinforcement signal',\n",
              "  'collisions obstacles'],\n",
              " ['network output decisions',\n",
              "  'rulebased system',\n",
              "  'trained feedforward networks',\n",
              "  'rule evaluation',\n",
              "  'Detailed experiments'],\n",
              " ['recurrent neural networks fit',\n",
              "  'genetic algorithms inappropriate network acquisition',\n",
              "  'structure weights',\n",
              "  'paper',\n",
              "  'GNARL'],\n",
              " ['object recognition task',\n",
              "  'aspects network structure',\n",
              "  'effectiveness encoding scheme',\n",
              "  'genetic algorithms',\n",
              "  'mechanism'],\n",
              " ['Bayesian confidence intervals components decomposition',\n",
              "  'several variables',\n",
              "  'ANOVA decomposition',\n",
              "  'main effect functions',\n",
              "  'actual properties'],\n",
              " ['Neural Information Processing Systems San Francisco',\n",
              "  'Advances',\n",
              "  'page limitation',\n",
              "  'paper',\n",
              "  'CA Morgan Kaufmann Publishers'],\n",
              " ['largescale sequencing projects',\n",
              "  'essential improve quality automated assemblies',\n",
              "  'size',\n",
              "  'GenBank',\n",
              "  'fluorescentlylabeled DNA fragments'],\n",
              " ['parallelism',\n",
              "  'MIMD architectures',\n",
              "  'results',\n",
              "  'investigation ways',\n",
              "  'new architecture'],\n",
              " ['system',\n",
              "  'lowest level processor design',\n",
              "  'message',\n",
              "  'parallel',\n",
              "  'approach'],\n",
              " ['transitions', 'methods', 'versions bridge problem', 'define', 'paper'],\n",
              " ['EEG paralyzed person',\n",
              "  'representations',\n",
              "  'several mental states',\n",
              "  'patterns',\n",
              "  'classification twolayer'],\n",
              " ['tight bounds sample complexity',\n",
              "  'paper',\n",
              "  'account correlations dependences',\n",
              "  'input coordinates',\n",
              "  'classical perceptron model'],\n",
              " ['timevarying patterns',\n",
              "  'network',\n",
              "  'tasks',\n",
              "  'example',\n",
              "  'distinct components shortterm memory'],\n",
              " ['aphasic impairments',\n",
              "  'separate feature maps',\n",
              "  'lexicon',\n",
              "  'dyslexic',\n",
              "  'various damage lexical system'],\n",
              " ['errordriven manner',\n",
              "  'Problem decomposition',\n",
              "  'resulting subtasks',\n",
              "  'highdimensional mappings',\n",
              "  'autonomous agents'],\n",
              " ['evaluation function random variable',\n",
              "  'state exploration',\n",
              "  'trading accuracy estimates',\n",
              "  'Searching space',\n",
              "  'recent feature subset selection algorithms machine'],\n",
              " ['parallel implementations',\n",
              "  'SIMD architecture',\n",
              "  'dataparallel approach',\n",
              "  'reason',\n",
              "  'supercomputers'],\n",
              " ['reinforcementlearning algorithms',\n",
              "  'convergence Qlearning',\n",
              "  'prior analyses',\n",
              "  'modelbased reinforcement',\n",
              "  'powerful new theorem'],\n",
              " ['different materials',\n",
              "  'pixel',\n",
              "  'information',\n",
              "  'specific case blind source separation problem data',\n",
              "  'technique'],\n",
              " ['various incremental methods',\n",
              "  'multiple steps',\n",
              "  'rewards',\n",
              "  'new method',\n",
              "  'paper'],\n",
              " ['environmental input',\n",
              "  'junk inputs',\n",
              "  'Bayesian methods',\n",
              "  'models',\n",
              "  'random correlations'],\n",
              " ['Several different approaches',\n",
              "  'learning tasks',\n",
              "  'incremental neural networks',\n",
              "  'paper',\n",
              "  'concepts'],\n",
              " ['parallelism',\n",
              "  'MIMD architectures',\n",
              "  'new architecture',\n",
              "  'advantages',\n",
              "  'multiple instruction stream design addressing limitations'],\n",
              " ['performance prediction method',\n",
              "  'based times',\n",
              "  'feature map',\n",
              "  'processor one communication link performance speedup efficiency',\n",
              "  'GCel transputer system Agreement model measurements'],\n",
              " ['Bayesian statistics',\n",
              "  'paper',\n",
              "  'et al Breiman et als',\n",
              "  'splitting rule',\n",
              "  'Publication'],\n",
              " ['probabilistic Many problems',\n",
              "  'interest formulated pomdps',\n",
              "  'advantage',\n",
              "  'approach clean semantics ability',\n",
              "  'navigation planning'],\n",
              " ['reasoning task',\n",
              "  'conclusions',\n",
              "  'appropriate learning strategy',\n",
              "  'explicit declarative manner system',\n",
              "  'results'],\n",
              " ['student',\n",
              "  'students',\n",
              "  'methods',\n",
              "  'plausible hypotheses',\n",
              "  'detailed example system'],\n",
              " ['characteristics target problem',\n",
              "  'usual way',\n",
              "  'different ways',\n",
              "  'machine learning algorithms parameter',\n",
              "  'user'],\n",
              " ['explicit negative examples',\n",
              "  'legal outputs',\n",
              "  'paper presents method',\n",
              "  'target',\n",
              "  'training input'],\n",
              " ['data',\n",
              "  'paper review advantages',\n",
              "  'query search database',\n",
              "  'new algorithm',\n",
              "  'database'],\n",
              " ['results',\n",
              "  'algorithm',\n",
              "  'realworld clustering problems',\n",
              "  'multiresolution techniques',\n",
              "  'hyperboxes hierarchial manner'],\n",
              " ['small trees',\n",
              "  'algorithm',\n",
              "  'real simulated data',\n",
              "  'oblique hyperplanes',\n",
              "  'cases'],\n",
              " ['ICET',\n",
              "  'costsensitive classification',\n",
              "  'first set',\n",
              "  'new algorithm',\n",
              "  'population biases decision tree induction'],\n",
              " ['linear programming training neural networks',\n",
              "  'terms',\n",
              "  'planes input space',\n",
              "  'square error output space',\n",
              "  'neural network description'],\n",
              " ['creativity',\n",
              "  'Dissatisfaction existing standard casebased reasoning',\n",
              "  'CBR creative problem',\n",
              "  'role cases',\n",
              "  'methodological issues'],\n",
              " ['hidden Markov models',\n",
              "  'important property natural DNA sequences',\n",
              "  'isochore theory',\n",
              "  'support',\n",
              "  'landscape'],\n",
              " ['weight matrix terms activations',\n",
              "  'previous weight change',\n",
              "  'hardwired algorithms',\n",
              "  'many specific limitations',\n",
              "  'Weight modifications traditional neural nets'],\n",
              " ['paper',\n",
              "  'multiassociative memory',\n",
              "  'problem',\n",
              "  'MM several possible variants',\n",
              "  'connectionist models'],\n",
              " ['neural circuit',\n",
              "  'eye movements',\n",
              "  'shifts controlled eye position signals',\n",
              "  'triadic connections',\n",
              "  'simulations'],\n",
              " ['predictive outcome international conflict management attempts',\n",
              "  'results',\n",
              "  'decision trees prediction rules',\n",
              "  'simple patterns rules',\n",
              "  'rules factors'],\n",
              " ['Abstract A technique',\n",
              "  'algorithm',\n",
              "  'iteration',\n",
              "  'unimodal function optimization methods',\n",
              "  'least fast fitness sharing methods'],\n",
              " ['DAGSP algorithm', 'V fl frontier alreadycorrect', 'backups', 'state', 'VI'],\n",
              " ['optimization strategies',\n",
              "  'executable dataflow language',\n",
              "  'multiple stages optimization',\n",
              "  'design engineer',\n",
              "  'system'],\n",
              " ['available ground truth polygons training test sets',\n",
              "  'classification performance neural network combined sixband',\n",
              "  'PRI imagery scene',\n",
              "  'LandsatTM oneband ERSSAR',\n",
              "  'Different combinations data'],\n",
              " ['algorithm',\n",
              "  'viable noise',\n",
              "  'particular show class Markov chains variable memory length',\n",
              "  'case output',\n",
              "  'model class'],\n",
              " ['approximate advice functions',\n",
              "  'users',\n",
              "  'approach',\n",
              "  'case study',\n",
              "  'basic functions'],\n",
              " ['attributes',\n",
              "  'relevant task concepts',\n",
              "  'concept learning objects domain',\n",
              "  'known advance',\n",
              "  'entirety learning'],\n",
              " ['infinite number mixture components',\n",
              "  'method',\n",
              "  'prior distribution mixing proportions',\n",
              "  'need',\n",
              "  'difficulty'],\n",
              " ['SANE',\n",
              "  'inverted pendulum problem',\n",
              "  'Such efficient learning combined domain assumptions',\n",
              "  'new reinforcement learning method',\n",
              "  'loss generalization'],\n",
              " ['plan',\n",
              "  'graphical criterion',\n",
              "  'effects',\n",
              "  'passive observations measured variables',\n",
              "  'closedform expression'],\n",
              " ['dynamic ILP processors',\n",
              "  'prediction',\n",
              "  'dynamic window',\n",
              "  'information control flow graph program',\n",
              "  'ability'],\n",
              " ['mean field theory sigmoid belief networks based ideas statistical mechanics',\n",
              "  'tractable approximation true probability distribution networks',\n",
              "  'lower bound likelihood evidence',\n",
              "  'utility framework benchmark problem statistical pattern'],\n",
              " ['performance element PE',\n",
              "  'distribution problems',\n",
              "  'similar problems',\n",
              "  'new element PE',\n",
              "  'transformations'],\n",
              " ['composite tasks',\n",
              "  'use array',\n",
              "  'Individual skills',\n",
              "  'Cerebellar Model Articulation Controller CMAC Albus',\n",
              "  'incorporation domain knowledge reinforcement'],\n",
              " ['paper dynamics decision hyperplanes',\n",
              "  'adaptation process',\n",
              "  'electromechanical analogy',\n",
              "  'interaction forces hyperplanes particles',\n",
              "  'picture'],\n",
              " ['realvalued representations',\n",
              "  'store',\n",
              "  'deeper complex data structures',\n",
              "  'weights',\n",
              "  'integer'],\n",
              " ['efficient algorithm',\n",
              "  'different search engines',\n",
              "  'preferences',\n",
              "  'performance',\n",
              "  'RankBoost'],\n",
              " ['decision trees',\n",
              "  'CBL systems',\n",
              "  'semiflexible prediction',\n",
              "  'CBL hybrid approach',\n",
              "  'performance'],\n",
              " ['visible variables',\n",
              "  'analysis model',\n",
              "  'values',\n",
              "  'comparable simplicity',\n",
              "  'learning procedure'],\n",
              " ['HMMs multiple alignments',\n",
              "  'Dirichlet mixture densities',\n",
              "  'method',\n",
              "  'amino acid distributions',\n",
              "  'motif'],\n",
              " ['models',\n",
              "  'onetime cost deploying system rate return investment',\n",
              "  'decision',\n",
              "  'example',\n",
              "  'free lunch theorems learning theory'],\n",
              " ['complex information external interventions',\n",
              "  'Markovian account causation show',\n",
              "  'simple transformation',\n",
              "  'graphs',\n",
              "  'paper'],\n",
              " ['limited success', 'point', 'current systems', 'paper', 'important role'],\n",
              " ['linear models', 'study model', 'theoretical aspects', 'data', 'comparison'],\n",
              " ['coverage',\n",
              "  'paper',\n",
              "  'algorithm number concepts',\n",
              "  'good learning algorithms',\n",
              "  'size'],\n",
              " ['Markov models',\n",
              "  'paper states',\n",
              "  'transient behavior genetic algorithms GAs',\n",
              "  'alternative orderings states',\n",
              "  'Nix Vose'],\n",
              " ['emergent behaviour',\n",
              "  'coevolutionary approach design',\n",
              "  'new insights',\n",
              "  'definitions',\n",
              "  'Artificial Life ALife research community'],\n",
              " ['main results', 'noise', 'attributes labels', 'data', 'addition'],\n",
              " ['new Hidden Markov Model HMM system',\n",
              "  'uncharacterized genomic DNA sequences',\n",
              "  'exons introns intergenic regions',\n",
              "  'exact exon prediction',\n",
              "  'stringent test'],\n",
              " ['tasks',\n",
              "  'TC algorithm',\n",
              "  'multiple learning tasks',\n",
              "  'new learning task',\n",
              "  'danger'],\n",
              " ['Belief revision belief update',\n",
              "  'model',\n",
              "  'belief change',\n",
              "  'generalized update',\n",
              "  'agent'],\n",
              " ['issues',\n",
              "  'Bayesian framework regression problems',\n",
              "  'Kalman',\n",
              "  'solution',\n",
              "  'Simulations'],\n",
              " ['parallel vector code',\n",
              "  'memory systems',\n",
              "  'CNS',\n",
              "  'efficient mapping',\n",
              "  'performance'],\n",
              " ['results simulations',\n",
              "  'variability fitness population',\n",
              "  'diploid genotypes',\n",
              "  'paper',\n",
              "  'gene'],\n",
              " ['beliefs',\n",
              "  'epistemic state',\n",
              "  'second status observations',\n",
              "  'belief change',\n",
              "  'controversy'],\n",
              " ['surprising observation sign',\n",
              "  'qualitative Markov assumption',\n",
              "  'previous beliefs',\n",
              "  'agent',\n",
              "  'change'],\n",
              " ['online search cases',\n",
              "  'rough solution',\n",
              "  'hard problem',\n",
              "  'good trajectories',\n",
              "  'single state'],\n",
              " ['particular queries',\n",
              "  'PCFGs',\n",
              "  'Bayesian network',\n",
              "  'distribution',\n",
              "  'parse trees'],\n",
              " ['observations',\n",
              "  'logic probabilities',\n",
              "  'closed beliefs',\n",
              "  'constraints rankings worlds',\n",
              "  'modularity causal organizations'],\n",
              " ['adaptive reinforcement',\n",
              "  'advantage',\n",
              "  'Clay',\n",
              "  'assemblages groups motor schemas',\n",
              "  'robot'],\n",
              " ['hidden units',\n",
              "  'algorithms',\n",
              "  'local space',\n",
              "  'global computations',\n",
              "  'connections'],\n",
              " ['creativity',\n",
              "  'portion ISAAC',\n",
              "  'Integrated Story Analysis',\n",
              "  'Creativity',\n",
              "  'algorithm'],\n",
              " ['serendipitous recognition solutions',\n",
              "  'design problems',\n",
              "  'ability',\n",
              "  'observations',\n",
              "  'context forms'],\n",
              " ['wellknown measures',\n",
              "  'different methods',\n",
              "  'selection decision tree induction informativity gini index',\n",
              "  'results experiments',\n",
              "  'probabilities'],\n",
              " ['adversarial models',\n",
              "  'relationships',\n",
              "  'learning situations',\n",
              "  'high probability bounded number switches',\n",
              "  'queries'],\n",
              " ['similarity measures', 'way', 'cases case base', 'report', 'addition'],\n",
              " ['GP',\n",
              "  'human written programs',\n",
              "  'data structures software',\n",
              "  'use memory',\n",
              "  'genetic programming'],\n",
              " ['neural networks research',\n",
              "  'capabilities',\n",
              "  'polynomialtime',\n",
              "  'ABSTRACT',\n",
              "  'powerful Turing Machines A similar restricted model'],\n",
              " ['applicability utility computational expense interpretability',\n",
              "  'method advantages',\n",
              "  'many existing methods',\n",
              "  'diagnostic',\n",
              "  'Illustrative examples'],\n",
              " ['ICA algorithm',\n",
              "  'EEG',\n",
              "  'electroencephalographic EEG data',\n",
              "  'Nonstationarities',\n",
              "  'changes'],\n",
              " ['Psychological Review',\n",
              "  'Schmidhuber J b',\n",
              "  'capacity processing information',\n",
              "  'magical number',\n",
              "  'Miller G'],\n",
              " ['greedy approach trees',\n",
              "  'standard approach decision tree induction',\n",
              "  'trees',\n",
              "  'trees accurate trees',\n",
              "  'main results'],\n",
              " ['machine learning model',\n",
              "  'discrete classes',\n",
              "  'continuous valued input',\n",
              "  'simulated results',\n",
              "  'information available solve problem'],\n",
              " ['problem',\n",
              "  'multiple tasks',\n",
              "  'attention resource',\n",
              "  'new theoreticallysound dynamic programming algorithm',\n",
              "  'optimal solution task isolation paper'],\n",
              " ['n fi n distance matrix D tree',\n",
              "  'additive tree T k T D k',\n",
              "  'algorithm',\n",
              "  'problem',\n",
              "  'Second show'],\n",
              " ['CaseBased Planning CBP',\n",
              "  'cases',\n",
              "  'Large problems',\n",
              "  'domainindependent planning',\n",
              "  'retrieval errors'],\n",
              " ['confidence estimation mechanisms',\n",
              "  'architects speculation control',\n",
              "  'performance metrics',\n",
              "  'Modern processors',\n",
              "  'confidence estimators'],\n",
              " ['used algorithms',\n",
              "  'representations',\n",
              "  'approaches',\n",
              "  'empirical evaluations',\n",
              "  'highlights commonalities'],\n",
              " ['learning process',\n",
              "  'hidden units',\n",
              "  'absence',\n",
              "  'computational complexity exact algorithm exponential number neurons',\n",
              "  'solutions'],\n",
              " ['search control policy', 'methodology', 'cases', 'Results', 'approach'],\n",
              " ['MDPs',\n",
              "  'policy yields',\n",
              "  'stochastic exploration state space',\n",
              "  'undiscounted rewards',\n",
              "  'maximum expected return'],\n",
              " ['partial full predication',\n",
              "  'end design spectrum architectural support full predicated execution',\n",
              "  'support',\n",
              "  'predicated execution',\n",
              "  'end'],\n",
              " ['complexity',\n",
              "  'number mistakes',\n",
              "  'learning models',\n",
              "  'DNF',\n",
              "  'orthogonal rectangles'],\n",
              " ['optimal solution exponential convergence rate',\n",
              "  'paper',\n",
              "  'discussion',\n",
              "  'immediate problems',\n",
              "  'new genetic algorithm'],\n",
              " ['first model',\n",
              "  'paper study forecasting model based mixture experts',\n",
              "  'parts',\n",
              "  'task',\n",
              "  'electricity demand exogenous variables temperature degree cloud cover'],\n",
              " ['represen tation cost function',\n",
              "  'Suttons TD metho',\n",
              "  'simple example',\n",
              "  'variation',\n",
              "  'better circumstances'],\n",
              " ['term graphstructured representations',\n",
              "  'costs',\n",
              "  'set relations',\n",
              "  'different kinds',\n",
              "  'example'],\n",
              " ['modification',\n",
              "  'regression tree',\n",
              "  'trees',\n",
              "  'artificial reallife domains',\n",
              "  'paper'],\n",
              " ['theory',\n",
              "  'collective dynamics reminiscent hydrodynamics',\n",
              "  'human genotype',\n",
              "  'empirical findings',\n",
              "  'collective phenomenon'],\n",
              " ['small changes original theory',\n",
              "  'new data',\n",
              "  'theory',\n",
              "  'measure',\n",
              "  'minimum number edit operations'],\n",
              " ['dataset method',\n",
              "  'meaningful intermediate concepts',\n",
              "  'decomposition',\n",
              "  'realworld housing loans allocation dataset',\n",
              "  'hierarchy'],\n",
              " ['Authors case studies',\n",
              "  'multiple algorithms',\n",
              "  'empirical method',\n",
              "  'dependent measures',\n",
              "  'others'],\n",
              " ['multiple descriptions class data',\n",
              "  'paper',\n",
              "  'errors',\n",
              "  'variation',\n",
              "  'hypothesis amount error reduction'],\n",
              " ['Plannett system',\n",
              "  'ANNs',\n",
              "  'input features',\n",
              "  'dimensions',\n",
              "  'classification module threestage image analysis system'],\n",
              " ['abstract models', 'paper', 'primitive actions', 'Sutton', 'prior work'],\n",
              " ['approximate statistical tests',\n",
              "  'show test',\n",
              "  'learning algorithm',\n",
              "  'fourth test McNemars test',\n",
              "  'algorithms'],\n",
              " ['active classifier cost',\n",
              "  'paper',\n",
              "  'wrong classification',\n",
              "  'outputs',\n",
              "  'contrast'],\n",
              " ['principle common many algorithms',\n",
              "  'bucket elimination',\n",
              "  'relationship',\n",
              "  'nonserial dynamic programming algorithms',\n",
              "  'function problems'],\n",
              " ['research',\n",
              "  'NIH grant RHD',\n",
              "  'version',\n",
              "  'Sociological Methodology',\n",
              "  'anonymous reviewers'],\n",
              " ['problem structure',\n",
              "  'possible select spectrum algorithm',\n",
              "  'optimization tasks',\n",
              "  'treeclustering conditioning trade space time',\n",
              "  'Such algorithms useful reasoning probabilistic deterministic networks'],\n",
              " ['loopcutset conditioning thought special case method',\n",
              "  'framework',\n",
              "  'new opportunities',\n",
              "  'approach',\n",
              "  'Suermondt others'],\n",
              " ['neurons',\n",
              "  'first level binary patterns',\n",
              "  'results',\n",
              "  'Special emphasis',\n",
              "  'network'],\n",
              " ['new method',\n",
              "  'subpopulations',\n",
              "  'standard generational evolutionary algorithm',\n",
              "  'diversity',\n",
              "  'methods'],\n",
              " ['unchanged Alternatively cost function training',\n",
              "  'training data',\n",
              "  'regularization term',\n",
              "  'group G',\n",
              "  'regularizer'],\n",
              " ['independence',\n",
              "  'simple algorithm',\n",
              "  'Bayesian network',\n",
              "  'conditional probabilities',\n",
              "  'new method'],\n",
              " ['results',\n",
              "  'paper',\n",
              "  'goal',\n",
              "  'fitting human execution data task',\n",
              "  'novel variant action models'],\n",
              " ['statistical query',\n",
              "  'general types queries',\n",
              "  'paper',\n",
              "  'learning model',\n",
              "  'optimal upper bounds'],\n",
              " ['problems',\n",
              "  'Reduced Error Pruning relational learning algorithms',\n",
              "  'Experiments',\n",
              "  'many noisy domains',\n",
              "  'new method'],\n",
              " ['store particular metrical patterns',\n",
              "  'process speech',\n",
              "  'metrical structure',\n",
              "  'hierarchy',\n",
              "  'kinds notes'],\n",
              " ['explanations',\n",
              "  'instance observation',\n",
              "  'terms',\n",
              "  'normality plausibility',\n",
              "  'reconstruction'],\n",
              " ['Sparse',\n",
              "  'designs',\n",
              "  'Memory namely Kanervas original design Jaeckels selectedcoordinates',\n",
              "  'ISSN Abstract',\n",
              "  'optimal probability activation corresponding performance'],\n",
              " ['hard locations',\n",
              "  'unknown number T random data vectors',\n",
              "  'sparse distributed memory',\n",
              "  'method',\n",
              "  'fact'],\n",
              " ['formalism',\n",
              "  'causation',\n",
              "  'coherent framework',\n",
              "  'many facets',\n",
              "  'causal reasoning'],\n",
              " ['projection matrix P',\n",
              "  'EM terms',\n",
              "  'maximum likelihood',\n",
              "  'special properties',\n",
              "  'approaches'],\n",
              " ['knowledge',\n",
              "  'first order regression algorithm',\n",
              "  'clause',\n",
              "  'domain experts',\n",
              "  'models'],\n",
              " ['resulting measures',\n",
              "  'performance',\n",
              "  'several topographic maps',\n",
              "  'humans',\n",
              "  'Measures'],\n",
              " ['example',\n",
              "  'musical structure',\n",
              "  'problem net',\n",
              "  'hidden units',\n",
              "  'global aspects'],\n",
              " ['recurrent neuralnetworks',\n",
              "  'incremental introduction new units',\n",
              "  'higher orders',\n",
              "  'connection weights',\n",
              "  'incremental higherorder nonrecurrent neuralnetwork'],\n",
              " ['classical nonparametric tests',\n",
              "  'hidden Markov chains convergence MCMC algorithms',\n",
              "  'Bayes',\n",
              "  'graphical control spreadsheets',\n",
              "  'parameters interest'],\n",
              " ['training test',\n",
              "  'neural network',\n",
              "  'discriminant analysis',\n",
              "  'backpropagation',\n",
              "  'statistical method'],\n",
              " ['mixtures',\n",
              "  'real world',\n",
              "  'multiunit Principal Component Analysis PCA neural networks',\n",
              "  'earlier authors',\n",
              "  'networks nonlinear Hebbian learning rules related signal expansions'],\n",
              " ['model patterns',\n",
              "  'circadian pattern',\n",
              "  'semiparametric periodic spline function',\n",
              "  'functional form appropriate asymmetry peak nadir phases',\n",
              "  'paper'],\n",
              " ['effectiveness solution largescale graph partitioning problems',\n",
              "  'partial solutions',\n",
              "  'integer variables',\n",
              "  'standard formulation approach',\n",
              "  'measured deviations'],\n",
              " ['adverse effects',\n",
              "  'certain subgroups',\n",
              "  'harmful environmental exposures',\n",
              "  'paper',\n",
              "  'spatiotemporal interactions'],\n",
              " ['features',\n",
              "  'multimodality',\n",
              "  'connection exploratory projection pursuit methods',\n",
              "  'directions',\n",
              "  'phoneme recognition experiment'],\n",
              " ['experiments',\n",
              "  'constructive induction mediate effect input representation accuracy',\n",
              "  'inductive learning system',\n",
              "  'representation',\n",
              "  'ability'],\n",
              " ['role selection',\n",
              "  'paper',\n",
              "  'global competition replacement schemes',\n",
              "  'analyse',\n",
              "  'group evolutionary algorithm'],\n",
              " ['Selfsupervised backpropagation',\n",
              "  'parallel machines',\n",
              "  'Topologypreserving maps',\n",
              "  'case selfsupervised backpropagation version',\n",
              "  'approach'],\n",
              " ['frequencies',\n",
              "  'patterns',\n",
              "  'model',\n",
              "  'network oscillators',\n",
              "  'interesting memorable deviate metrical hierarchy'],\n",
              " ['several results',\n",
              "  'uniform approximation orders radial basis functions',\n",
              "  'scattered centres',\n",
              "  'particular approximants spaces',\n",
              "  'paper'],\n",
              " ['approximation problem',\n",
              "  'ffi',\n",
              "  'literature',\n",
              "  'discrete set',\n",
              "  'IR many optimal quasioptimal approximation schemes'],\n",
              " ['principal shiftinvariant spaces',\n",
              "  'p',\n",
              "  'mild assumptions generator',\n",
              "  'exponential box splines polyharmonic splines',\n",
              "  'stationary nonstationary ladders'],\n",
              " ['RL standard EBL', 'EBRL', 'paper', 'online versions', 'RL'],\n",
              " ['research',\n",
              "  'representative centers',\n",
              "  'National Science Foundation contract',\n",
              "  'state variables',\n",
              "  'present extensions'],\n",
              " ['clusteringvector quantization VQ multidimensional scaling MDS',\n",
              "  'SOM',\n",
              "  'maps',\n",
              "  'remaining ability',\n",
              "  'relevant theory SOMs'],\n",
              " ['exploration', 'paper presents method', 'RL', 'cases', 'set actions'],\n",
              " ['inclusion input variables',\n",
              "  'unneeded weights network',\n",
              "  'source',\n",
              "  'connectionist network',\n",
              "  'problems'],\n",
              " ['simulations',\n",
              "  'environments',\n",
              "  'phenotypic feature',\n",
              "  'proteins',\n",
              "  'parallel biological findings'],\n",
              " ['compiler heuristics',\n",
              "  'processor organization tasklevel speculation',\n",
              "  'tasks',\n",
              "  'favorable characteristics',\n",
              "  'fundamental performance issues'],\n",
              " ['speed learner', 'fact', 'learning agent', 'policy', 'Guidance'],\n",
              " ['appropriate method',\n",
              "  'problems',\n",
              "  'constructive induction algorithms',\n",
              "  'classification task',\n",
              "  'higher classification accuracy'],\n",
              " ['latent classes data',\n",
              "  'approach',\n",
              "  'exploratory data analysis',\n",
              "  'possibility',\n",
              "  'full joint probability models'],\n",
              " ['pruning algorithms',\n",
              "  'tree',\n",
              "  'results',\n",
              "  'significant speed ups efficient use parameters',\n",
              "  'branches'],\n",
              " ['data random errors',\n",
              "  'realworld data',\n",
              "  'first present framework',\n",
              "  'paper',\n",
              "  'issues'],\n",
              " ['variety differing problem formulations',\n",
              "  'connection size generality',\n",
              "  'addition',\n",
              "  'effectiveness evolution process',\n",
              "  'sort problem formulation'],\n",
              " ['new measure',\n",
              "  'Length MDL',\n",
              "  'available data',\n",
              "  'account',\n",
              "  'alternative present application'],\n",
              " ['rules', 'overlap', 'problem', 'rule', 'Such algorithms'],\n",
              " ['fuzzy graphs example data',\n",
              "  'build models',\n",
              "  'methodologies',\n",
              "  'attention',\n",
              "  'interpretation'],\n",
              " ['RL',\n",
              "  'superior hand coding teaching strategies',\n",
              "  'methodology',\n",
              "  'drawback',\n",
              "  'flexible handling'],\n",
              " ['neural model', 'intelligent system', 'leaky integrators', 'STM', 'work'],\n",
              " ['level alertness',\n",
              "  'Changes',\n",
              "  'electroencephalographic EEG power spectrum accompany fluctuations',\n",
              "  'simultaneous changes',\n",
              "  'nuclear power plants'],\n",
              " ['Bayesian networks',\n",
              "  'exact inference algorithms',\n",
              "  'paper',\n",
              "  'first transformation',\n",
              "  'probabilistic model'],\n",
              " ['benign malignant tumors',\n",
              "  'perceptron',\n",
              "  'different classes',\n",
              "  'examples',\n",
              "  'examination'],\n",
              " ['possible train model',\n",
              "  'parameters',\n",
              "  'inputs',\n",
              "  'description data terms',\n",
              "  'probability data'],\n",
              " ['dependencies',\n",
              "  'generalized information',\n",
              "  'Bayesian two step approximation',\n",
              "  'paper studies',\n",
              "  'nonapproximation aspects'],\n",
              " ['edge encoding',\n",
              "  'graphbased queries',\n",
              "  'automata',\n",
              "  'alternative cellular encoding technique',\n",
              "  'recurrent neural networks finite'],\n",
              " ['classifications',\n",
              "  'similarity classes',\n",
              "  'technique',\n",
              "  'objects',\n",
              "  'ndimensional hyperspace'],\n",
              " ['salient phenomena',\n",
              "  'Truth Trash model',\n",
              "  'environmental feedback',\n",
              "  'truthful indicators',\n",
              "  'main aim'],\n",
              " ['causal effect',\n",
              "  'identification',\n",
              "  'singleton variable X set variables',\n",
              "  'probabilistic evaluation effects actions',\n",
              "  'presence unmeasured variables'],\n",
              " ['important minor differences',\n",
              "  'attention',\n",
              "  'ambiguous objects',\n",
              "  'stable behavior',\n",
              "  'Experiments'],\n",
              " ['general induction algorithm',\n",
              "  'framework',\n",
              "  'moves',\n",
              "  'spectrum show tradeoffs model accuracy',\n",
              "  'speed'],\n",
              " ['traits', 'level learning population', 'benefits', 'idea', 'models'],\n",
              " ['evolution population',\n",
              "  'phenotypic space adaptive processes',\n",
              "  'phenotypic traits',\n",
              "  'small distance',\n",
              "  'conditions'],\n",
              " ['input vector',\n",
              "  'probability',\n",
              "  'subtrees',\n",
              "  'probabilities',\n",
              "  'system Probabilistic decisions'],\n",
              " ['online BP',\n",
              "  'accumulation point',\n",
              "  'gradient method',\n",
              "  'certain natural assumptions series',\n",
              "  'learning rates'],\n",
              " ['DFA',\n",
              "  'simple algorithm',\n",
              "  'sigmoidal discriminant',\n",
              "  'instability internal representation',\n",
              "  'neural network'],\n",
              " ['Converse Lyapunov Function Theorem',\n",
              "  'Recent Results',\n",
              "  'various aspects',\n",
              "  'wellknown classical theorems',\n",
              "  'Lyapunovtheoretic Techniques Nonlinear Stability ABSTRACT'],\n",
              " ['deterministic finitestate automata DFAs',\n",
              "  'extraction symbolic knowledge',\n",
              "  'Abstract',\n",
              "  'MD',\n",
              "  'recurrent neural networks Discretetime'],\n",
              " ['previous work',\n",
              "  'Experimental tests',\n",
              "  'timedelay neural network TDNN architecture',\n",
              "  'paper',\n",
              "  'irregularlength schedules'],\n",
              " ['SYCON',\n",
              "  'evolving processors',\n",
              "  'interconnections',\n",
              "  'state',\n",
              "  'Such networks'],\n",
              " ['stationary moving goal state',\n",
              "  'start',\n",
              "  'paper',\n",
              "  'new LRTAbased algorithms variety tasks',\n",
              "  'bidirectional LRTS algorithm'],\n",
              " ['function spaces', 'results', 'approximation L norm', 'paper', 'research'],\n",
              " ['iterative recursive process',\n",
              "  'similar problems',\n",
              "  'specific example',\n",
              "  'empirical results',\n",
              "  'value'],\n",
              " ['Gibbs sampler',\n",
              "  'convergence properties',\n",
              "  'smoothness boundary R',\n",
              "  'smooth boundaries',\n",
              "  'ergodic jagged boundaries sampler'],\n",
              " ['paper',\n",
              "  'method',\n",
              "  'real functions',\n",
              "  'attributevector representation intermediate concepts',\n",
              "  'develop technique'],\n",
              " ['Uncertainty sampling methods',\n",
              "  'previous labeled instances',\n",
              "  'classes',\n",
              "  'number instances expert need label One problem approach classifier best suited application',\n",
              "  'class labels training instances'],\n",
              " ['unmeasured variables',\n",
              "  'independence constraints',\n",
              "  'formula',\n",
              "  'help',\n",
              "  'possible test'],\n",
              " ['asymptotic formula sample size calculations',\n",
              "  'Bayesian confidence intervals smoothing spline',\n",
              "  'California',\n",
              "  'Santa Barbara',\n",
              "  'paper'],\n",
              " ['specific method',\n",
              "  'AdaBoost',\n",
              "  'Freund Schapires',\n",
              "  'simplified analysis',\n",
              "  'confidences predictions'],\n",
              " ['learning process population level first level',\n",
              "  'tasks',\n",
              "  'adaptation',\n",
              "  'focused Genetic Algorithms',\n",
              "  'wider sense'],\n",
              " ['Bayesian networks data',\n",
              "  'possible models',\n",
              "  'local structures',\n",
              "  'resulting learning procedure',\n",
              "  'procedure'],\n",
              " ['committees members',\n",
              "  'trained classifiers',\n",
              "  'pool',\n",
              "  'useful error bounds',\n",
              "  'method bound test errors'],\n",
              " ['PI controller neural network',\n",
              "  'performance',\n",
              "  'steadystate output PI controller',\n",
              "  'nstep ahead error coil output set point reinforcement learning agent',\n",
              "  'sum squared error time'],\n",
              " ['ordered list classification rules examples',\n",
              "  'present use',\n",
              "  'Laplacian error estimate alternative evaluation function',\n",
              "  'changes',\n",
              "  'improved performances'],\n",
              " ['weaknesses',\n",
              "  'connectionist approaches',\n",
              "  'strengths',\n",
              "  'impressive applications',\n",
              "  'links disciplines statistics control theory'],\n",
              " ['multiple paths',\n",
              "  'instructions',\n",
              "  'Selective Eager Execution SEE execution model',\n",
              "  'paper present',\n",
              "  'benchmark average SPECint'],\n",
              " ['algorithm',\n",
              "  'algorithms',\n",
              "  'competitive tree learning algorithm',\n",
              "  'many supervised model learning tasks',\n",
              "  'Comparative experiments'],\n",
              " ['subset features',\n",
              "  'previous subset selection algorithms',\n",
              "  'definitions',\n",
              "  'supervised induction algorithm',\n",
              "  'behavior'],\n",
              " ['values',\n",
              "  'DNF decision',\n",
              "  'machine learning method',\n",
              "  'multiple input variables',\n",
              "  'Experimental'],\n",
              " ['limited form dual path execution',\n",
              "  'hybrid branch predictor scheme',\n",
              "  'conditional branch',\n",
              "  'dynamic branch prediction',\n",
              "  'confidence information'],\n",
              " ['existing hardware Simultaneous Multithreading SMT processor',\n",
              "  'hardtopredict branches',\n",
              "  'multipath execution',\n",
              "  'fewer threads',\n",
              "  'paper'],\n",
              " ['machine',\n",
              "  'response',\n",
              "  'psychological literature growing evidence',\n",
              "  'concrete computational models',\n",
              "  'rhetoric'],\n",
              " ['query',\n",
              "  'known homologs',\n",
              "  'Hidden Markov models',\n",
              "  'HMMs',\n",
              "  'sequences homologous original sequence'],\n",
              " ['Current limitations',\n",
              "  'present new approach problem',\n",
              "  'useful data',\n",
              "  'Pattern Theoretic approach',\n",
              "  'results'],\n",
              " ['results',\n",
              "  'original paper Revision History Version',\n",
              "  'former see',\n",
              "  'Chapters',\n",
              "  'immunoglobulin sequences'],\n",
              " ['attributes',\n",
              "  'domains',\n",
              "  'OC',\n",
              "  'system',\n",
              "  'new system induction oblique decision trees'],\n",
              " ['sequence subgoals',\n",
              "  'ExplanationBased Reinforcement Learning EBRL',\n",
              "  'Dietterich Flann',\n",
              "  'ability',\n",
              "  'optimal fashion Hierarchical EBRL'],\n",
              " ['paradigm', 'objectives', 'reasons', 'potential extension', 'algorithm'],\n",
              " ['attributes',\n",
              "  'Bayesian classifier searching dependencies',\n",
              "  'data sets',\n",
              "  'training examples',\n",
              "  'Equation'],\n",
              " ['available alignment methods',\n",
              "  'challenge',\n",
              "  'related viral proteins',\n",
              "  'hidden Markov model approach',\n",
              "  'new flexible method generation multiple sequence alignments'],\n",
              " ['Giles et al Watrous Kuhn Cleeremans',\n",
              "  'recurrent network',\n",
              "  'researchers',\n",
              "  'Several recurrent networks',\n",
              "  'information processing'],\n",
              " ['useful learning algorithm',\n",
              "  'recent years bias',\n",
              "  'examples',\n",
              "  'illustrate fact',\n",
              "  'paper'],\n",
              " ['undiscounted average reward',\n",
              "  'methods',\n",
              "  'fewer steps',\n",
              "  'many cases',\n",
              "  'Hlearning robust respect changes domain parameters'],\n",
              " ['wellknown classical theorems',\n",
              "  'various aspects',\n",
              "  'problems',\n",
              "  'work',\n",
              "  'unified natural manner'],\n",
              " ['simulated robotic agents',\n",
              "  'intelligent behavior',\n",
              "  'experiments',\n",
              "  'comprehensive optimization',\n",
              "  'neural networks'],\n",
              " ['variety knowledge sources',\n",
              "  'requirement complete correct domain theory',\n",
              "  'types performance errors',\n",
              "  'past systems purpose',\n",
              "  'types knowledge'],\n",
              " ['maximal posteriori MAP instantiation Bayesian network variables',\n",
              "  'stochastic approximation algorithm',\n",
              "  'method',\n",
              "  'task',\n",
              "  'change time'],\n",
              " ['paper',\n",
              "  'messages networks',\n",
              "  'network grid topology',\n",
              "  'Parameterized heuristics',\n",
              "  'large networks'],\n",
              " ['Simon Byers', 'ONR grants', 'authors', 'Gilles', 'N N'],\n",
              " ['predictions',\n",
              "  'best expert sequence expectation',\n",
              "  'algorithms',\n",
              "  'number mistakes',\n",
              "  'assumptions'],\n",
              " ['approach',\n",
              "  'existing theories',\n",
              "  'solutions',\n",
              "  'theorybased inference',\n",
              "  'foundation systematic evaluation appropriate usage Cases primary repository knowledge'],\n",
              " ['critics',\n",
              "  'trainer',\n",
              "  'sparse weakly informative training information',\n",
              "  'results',\n",
              "  'learning agent'],\n",
              " ['algorithm',\n",
              "  'accuracy algorithms',\n",
              "  'improvement',\n",
              "  'large number hypotheses',\n",
              "  'Valiants polynomial PAC learning framework'],\n",
              " ['model ratio decidendi justification structure',\n",
              "  'abstract predicates',\n",
              "  'precedential effect',\n",
              "  'model',\n",
              "  'contrast'],\n",
              " ['neighbourhood preserving map call topographic homeomorphism',\n",
              "  'usual case',\n",
              "  'many equally valid choices',\n",
              "  'particular measure',\n",
              "  'definition'],\n",
              " ['random noise',\n",
              "  'probability present algorithm',\n",
              "  'small amounts noise',\n",
              "  'monomials',\n",
              "  'unknown noise rate'],\n",
              " ['agents', 'reinforcement', 'heterogeneous behaviors', 'results', 'feedback'],\n",
              " ['Product units',\n",
              "  'problems',\n",
              "  'training algorithms networks',\n",
              "  'performance transfer functions product units',\n",
              "  'possible reason'],\n",
              " ['NRL Navigation task',\n",
              "  'data experiments',\n",
              "  'cognitive model humans',\n",
              "  'goal',\n",
              "  'inputs'],\n",
              " ['belief revision process',\n",
              "  'additional postulates',\n",
              "  'Contrary AGM framework',\n",
              "  'epistemic state',\n",
              "  'elements'],\n",
              " ['search strategies',\n",
              "  'twolayer connectionist system',\n",
              "  'weak taskspecific strategy finetunes performance',\n",
              "  'simulated realtime balancecontrol task',\n",
              "  'finetuning behavior'],\n",
              " ['adaptive control',\n",
              "  'existing indirect method',\n",
              "  'related direct reinforcement learning method applying methods',\n",
              "  'indirect learning methods',\n",
              "  'difficult suggest'],\n",
              " ['framework',\n",
              "  'knowledge plausibility agent',\n",
              "  'belief terms',\n",
              "  'properties',\n",
              "  'prior probabilities'],\n",
              " ['functions',\n",
              "  'adaptation',\n",
              "  'interest target distribution',\n",
              "  'expectations',\n",
              "  'MCMC run'],\n",
              " ['regularizer',\n",
              "  'interpolation models',\n",
              "  'choice',\n",
              "  'interpolant choice noise model',\n",
              "  'attributes'],\n",
              " ['StatLog',\n",
              "  'MLalgorithms',\n",
              "  'different applications',\n",
              "  'real industrial commercial applications',\n",
              "  'research'],\n",
              " ['elevator domain',\n",
              "  'results simulation',\n",
              "  'team',\n",
              "  'global reinforcement signal',\n",
              "  'application reinforcement'],\n",
              " ['agents',\n",
              "  'current state space Experimental',\n",
              "  'possible shortterm memories',\n",
              "  'statistics space',\n",
              "  'many exploration techniques'],\n",
              " ['policy iteration dynamic programming',\n",
              "  'existing methods',\n",
              "  'advantages actions',\n",
              "  'Baird',\n",
              "  'absolute measures utility actions'],\n",
              " ['features pool',\n",
              "  'decision tree',\n",
              "  'small nonredundant feature sets pools',\n",
              "  'compact description training data',\n",
              "  'protein secondarystructure task'],\n",
              " ['extension package',\n",
              "  'extension',\n",
              "  'Basic Sugal system',\n",
              "  'Sequential Serial Genetic Algorithms',\n",
              "  'used research'],\n",
              " ['different viewpoints',\n",
              "  'objects',\n",
              "  'training process',\n",
              "  'unsupervised Hebbian relaxation network',\n",
              "  'representations'],\n",
              " ['paper', 'learning paradigm', 'Internal models', 'outcomes', 'approach'],\n",
              " ['numeric symbolic variables',\n",
              "  'paper',\n",
              "  'order',\n",
              "  'February',\n",
              "  'incremental induction decision trees'],\n",
              " ['nicklresearchnjneccom',\n",
              "  'Supported ONR grants NK NJ Part research',\n",
              "  'Harvard',\n",
              "  'partial support ONR grants NK NK Address Department Computer Science University',\n",
              "  'ONR grant NK Harvard University'],\n",
              " ['utility control knowledge',\n",
              "  'simple selection strategy',\n",
              "  'utility problem',\n",
              "  'data',\n",
              "  'significant numbers'],\n",
              " ['find solution',\n",
              "  'feasible trajectories goal regions',\n",
              "  'cases',\n",
              "  'techniques',\n",
              "  'gametheory computational geometry'],\n",
              " ['predictive distribution',\n",
              "  'data',\n",
              "  'approaches',\n",
              "  'Rissanens new definition stochastic complexity',\n",
              "  'logscore sense'],\n",
              " ['problem',\n",
              "  'CBR',\n",
              "  'neural network architecture',\n",
              "  'rigorous Bayesian probability propagation algorithm',\n",
              "  'approach'],\n",
              " ['lower bounds',\n",
              "  'due Haussler Benedek Itai',\n",
              "  'techniques',\n",
              "  'scalesensitive notion dimension',\n",
              "  'numbers'],\n",
              " ['first step direction', 'Minos', 'number', 'wetware details', 'reliability'],\n",
              " ['realistic problems',\n",
              "  'several simple solution methods',\n",
              "  'study pomdps',\n",
              "  'contrast',\n",
              "  'literature'],\n",
              " ['available techniques',\n",
              "  'algorithm',\n",
              "  'stationary distribution',\n",
              "  'proposed method',\n",
              "  'many advantages'],\n",
              " ['Markov Decision Process',\n",
              "  'uncertain conditions',\n",
              "  'optimal decisions',\n",
              "  'central Artificial Intelligence',\n",
              "  'MDP MDPs'],\n",
              " ['consequences explanations',\n",
              "  'observation terms',\n",
              "  'certain assumptions',\n",
              "  'possibility',\n",
              "  'world'],\n",
              " ['structures',\n",
              "  'feedbackguided reweighting links',\n",
              "  'houses',\n",
              "  'architecture brainstructured networks perceptual recognition Results',\n",
              "  'digitized photographs'],\n",
              " ['several variants',\n",
              "  'new computational classifier characteristics',\n",
              "  'quality DMTI',\n",
              "  'measure tree quality',\n",
              "  'incremental tree induction ITI nonincremental tree induction'],\n",
              " ['binary belief networks',\n",
              "  'results',\n",
              "  'posterior predictive model',\n",
              "  'data',\n",
              "  'latent variable density model'],\n",
              " ['efficient approximations posterior probability distributions graphical models',\n",
              "  'Mean field methods',\n",
              "  'efficient methods',\n",
              "  'parameters models',\n",
              "  'mean field approximation cases'],\n",
              " ['classic pole balancing problem',\n",
              "  'efficiency systems',\n",
              "  'new benchmarks',\n",
              "  'standard control learning tasks',\n",
              "  'viable yardstick'],\n",
              " ['parallel networks',\n",
              "  'eg perceptual recognition network',\n",
              "  'tasks',\n",
              "  'temporal spatiotemporal patterns',\n",
              "  'parsimony'],\n",
              " ['size stateaction space',\n",
              "  'lookuptables',\n",
              "  'previous online Q implementations',\n",
              "  'update complexity',\n",
              "  'faster algorithms'],\n",
              " ['parallel networks',\n",
              "  'inductive learning systems',\n",
              "  'variety learning structures',\n",
              "  'processes',\n",
              "  'function experience Generative learning algorithms'],\n",
              " ['neural system drive vehicle',\n",
              "  'promising results',\n",
              "  'addresses',\n",
              "  'several areas',\n",
              "  'modular neural architecture'],\n",
              " ['linear experts', 'expert', 'data', 'way', 'Only prediction query'],\n",
              " ['perfect monitoring case agent',\n",
              "  'nonBayesian agent',\n",
              "  'optimality criterion',\n",
              "  'addition',\n",
              "  'model'],\n",
              " ['D',\n",
              "  'n points rectangle',\n",
              "  'probability',\n",
              "  'polynomialtime algorithm',\n",
              "  'accuracy hypothesis'],\n",
              " ['method',\n",
              "  'program',\n",
              "  'HINT HIerarchy Induction Tool',\n",
              "  'terms',\n",
              "  'classification accuracy discovery meaningful concept hierarchies'],\n",
              " ['theoretical results',\n",
              "  'estimation probabilities',\n",
              "  'application construction regression trees',\n",
              "  'paper',\n",
              "  'present mdistribution estimate extension mprobability estimate'],\n",
              " ['highdimensional data',\n",
              "  'part',\n",
              "  'research',\n",
              "  'statistical framework',\n",
              "  'National Science Foundation contract ASC Support'],\n",
              " ['tolerance weight perturbation',\n",
              "  'sigmoidal discriminant functions',\n",
              "  'secondorder',\n",
              "  'desired network performance',\n",
              "  'analog implementation neurons weights'],\n",
              " ['Abhijit Dasgupta graduate student Department Biostatistics University Washington Box Seattle WA email address',\n",
              "  'Office Naval Research Grant NJ',\n",
              "  'authors',\n",
              "  'Washington',\n",
              "  'research'],\n",
              " ['arm',\n",
              "  'perround payoff algorithm',\n",
              "  'arm K nonidentical slot machines',\n",
              "  'sequence trials',\n",
              "  'classical problem'],\n",
              " ['approximate probabilistic inference',\n",
              "  'sensitivities',\n",
              "  'probability distributions',\n",
              "  'exact algorithm',\n",
              "  'conditional probabilities'],\n",
              " ['design',\n",
              "  'new massively parallel supercomputer',\n",
              "  'processing nodes',\n",
              "  'peak performance',\n",
              "  'mesh network'],\n",
              " ['large number training examples',\n",
              "  'committee learners',\n",
              "  'text categorization',\n",
              "  'approach',\n",
              "  'paper'],\n",
              " ['work divideandconquer technique',\n",
              "  'covering',\n",
              "  'alternatives',\n",
              "  'discriminating positive negative examples',\n",
              "  'Experimental results'],\n",
              " ['linear programming',\n",
              "  'context',\n",
              "  'Computational results',\n",
              "  'recurrence times',\n",
              "  'censored training examples examples'],\n",
              " ['MML inductive inference',\n",
              "  'statistical parameter',\n",
              "  'message lengths',\n",
              "  'posterior probability theory',\n",
              "  'constant logarithm'],\n",
              " ['many tasks',\n",
              "  'model',\n",
              "  'known psychophysical data human visual attention',\n",
              "  'thesis',\n",
              "  'VISIT connectionist model covert visual attention'],\n",
              " ['Lyapunov function',\n",
              "  'excitatory inhibitory populations neurons antisymmetric interactions populations',\n",
              "  'sufficient conditions',\n",
              "  'asymmetric networks',\n",
              "  'global asymptotic stability fixed points'],\n",
              " ['different dimensions',\n",
              "  'cases',\n",
              "  'posteriors',\n",
              "  'current Monte Carlo',\n",
              "  'importance sampling bridge sampling ratio importance sampling problems different dimensions'],\n",
              " ['structure matching algorithm',\n",
              "  'inference',\n",
              "  'dependent efficient flexible access large base exemplars cases',\n",
              "  'top PARKA',\n",
              "  'parallel knowledge representation system'],\n",
              " ['number training examples',\n",
              "  'sequential learning procedures',\n",
              "  'large training sample',\n",
              "  'worst case',\n",
              "  'hypothesizer'],\n",
              " ['novel approach',\n",
              "  'retrieval matching adaptation group',\n",
              "  'structural similarity guidance adaptation',\n",
              "  'performance',\n",
              "  'Cbr explainability case selection adaptation'],\n",
              " ['types',\n",
              "  'blameassignment tasks',\n",
              "  'modelbased approach',\n",
              "  'structurebehaviorfunction models',\n",
              "  'information'],\n",
              " ['knowledge base design support system',\n",
              "  'knowledge',\n",
              "  'contract',\n",
              "  'IW Project partners',\n",
              "  'formal integrated model knowledge design'],\n",
              " ['statistical classifiers',\n",
              "  'unsupervised classification',\n",
              "  'neural network classifiers',\n",
              "  'data',\n",
              "  'Snob'],\n",
              " ['trace processing problemsolving episode',\n",
              "  'AI research casebased reasoning',\n",
              "  'many laboratory casebased systems',\n",
              "  'development',\n",
              "  'paper'],\n",
              " ['optimal number pseudocounts',\n",
              "  'way estimate amino acid frequencies',\n",
              "  'minimumrisk estimates',\n",
              "  'formulas',\n",
              "  'risk function'],\n",
              " ['innateness bias',\n",
              "  'socalled generalist models',\n",
              "  'properties',\n",
              "  'choose',\n",
              "  'ability'],\n",
              " ['ALVINN Pomerleau',\n",
              "  'important performing task',\n",
              "  'saliency map',\n",
              "  'retina',\n",
              "  'mechanism'],\n",
              " ['MDP value function', 'critical problem', 'demands', 'solution', 'paper'],\n",
              " ['algorithms',\n",
              "  'Such probabilistic concepts pconcepts',\n",
              "  'efficient general sense',\n",
              "  'demands',\n",
              "  'distribution domain'],\n",
              " ['problem',\n",
              "  'knowledge',\n",
              "  'learned rule',\n",
              "  'backtracking search procedure use',\n",
              "  'backtracking mechanism problem solvers'],\n",
              " ['Rich Sutton Chris Watkins',\n",
              "  'earlier version article',\n",
              "  'error',\n",
              "  'insight',\n",
              "  'numerous discussions'],\n",
              " ['selection network',\n",
              "  'new architecture',\n",
              "  'spatial relations input',\n",
              "  'rise',\n",
              "  'neural networks winnertakeall WTA'],\n",
              " ['algorithms',\n",
              "  'analogous popular TD Qlearning algorithms',\n",
              "  'new averagepayoff',\n",
              "  'RL algorithms stochastic approximation methods',\n",
              "  'paper'],\n",
              " ['learner', 'first case', 'algorithms', 'outputs', 'output state'],\n",
              " ['problem robot', 'vertices', 'G', 'paper', 'mapping problem'],\n",
              " ['Bayesian networks',\n",
              "  'sample complexity MDL',\n",
              "  'learning procedure',\n",
              "  'Previous work',\n",
              "  'converge target distribution'],\n",
              " ['Hlearning', 'large state spaces', 'domains', 'action models', 'extensions'],\n",
              " ['maps',\n",
              "  'algorithm',\n",
              "  'highdimensional topology',\n",
              "  'topologypreserving characteristics',\n",
              "  'paper'],\n",
              " ['SDTs',\n",
              "  'multiple tasks applications',\n",
              "  'class sequential decision tasks',\n",
              "  'learning agent',\n",
              "  'solutions elemental SDTs'],\n",
              " ['obstacles',\n",
              "  'supervised methods',\n",
              "  'control robot arm',\n",
              "  'various locations',\n",
              "  'neuroevolution'],\n",
              " ['crucial scaling reinforcement',\n",
              "  'tables',\n",
              "  'use compact representations',\n",
              "  'lookup table representations',\n",
              "  'reinforcement learning'],\n",
              " ['new methods',\n",
              "  'realworld prediction problems',\n",
              "  'credit means difference',\n",
              "  'conventional predictionlearning methods',\n",
              "  'successive predictions'],\n",
              " ['DynaPI architecture',\n",
              "  'world',\n",
              "  'simpler implement use',\n",
              "  'dynamic programming methods Dyna architectures',\n",
              "  'paper'],\n",
              " ['parameterized function approximators',\n",
              "  'large problems',\n",
              "  'Boyan Moore',\n",
              "  'cases',\n",
              "  'strong theoretical results accuracy convergence computational results'],\n",
              " ['realtime results',\n",
              "  'abundance methods',\n",
              "  'maps',\n",
              "  'Kohonens',\n",
              "  'contrary researchers'],\n",
              " ['model study',\n",
              "  'set options',\n",
              "  'resources',\n",
              "  'online framework',\n",
              "  'weaker cases'],\n",
              " ['GramCharlier expansion',\n",
              "  'outputs',\n",
              "  'Edgeworth',\n",
              "  'new online learning algorithm',\n",
              "  'MI'],\n",
              " ['backpropagation learning', 'bpsom', 'training', 'soms', 'addition'],\n",
              " ['minimal conditional revision',\n",
              "  'acceptance conditions',\n",
              "  'agent',\n",
              "  'arbitrary rightnested conditionals',\n",
              "  'changes'],\n",
              " ['Reinforcement learning techniques address problem',\n",
              "  'complex domains',\n",
              "  'use',\n",
              "  'paper',\n",
              "  'failures practice'],\n",
              " ['information',\n",
              "  'network nonlinear units',\n",
              "  'knowledge input distributions',\n",
              "  'conditions',\n",
              "  'tonysalkedu'],\n",
              " ['Wellknown examples graphical models',\n",
              "  'Graphical operations',\n",
              "  'schemas popular algorithms',\n",
              "  'model data analysis',\n",
              "  'Bayesian networks'],\n",
              " ['knowledge',\n",
              "  'utility problem',\n",
              "  'number training examples',\n",
              "  'curve cost',\n",
              "  'utility control knowledge'],\n",
              " ['kernel estimators',\n",
              "  'distributed networks',\n",
              "  'linear perceptron',\n",
              "  'local methods',\n",
              "  'examples'],\n",
              " ['adaptation knowledge',\n",
              "  'current CBR systems case adaptation',\n",
              "  'tenets',\n",
              "  'approach types knowledge',\n",
              "  'reasoning scratch'],\n",
              " ['types',\n",
              "  'relationships',\n",
              "  'introspective reasoning',\n",
              "  'information expectations',\n",
              "  'actual behavior information search process'],\n",
              " ['techniques',\n",
              "  'acquisition knowledge',\n",
              "  'perspectives',\n",
              "  'weaknesses',\n",
              "  'alternative learning strategies'],\n",
              " ['theory',\n",
              "  'particular learning strategies',\n",
              "  'taxonomy',\n",
              "  'knowledge world',\n",
              "  'possible reasoning failures'],\n",
              " ['statistics networks',\n",
              "  'strengths weaknesses',\n",
              "  'statistical pattern recognition',\n",
              "  'resort sampling',\n",
              "  'mean field equations'],\n",
              " ['case examples',\n",
              "  'available system',\n",
              "  'selflearning control system mobile robot Based sensor information control system',\n",
              "  'paper',\n",
              "  'adaptive algorithm'],\n",
              " ['Advanced Research Projects Agency AFOSR'],\n",
              " ['ffi', 'case', 'problem', 'translation', 'work'],\n",
              " ['positive negative results',\n",
              "  'Correct PAC learning model attempt',\n",
              "  'belief',\n",
              "  'Nature',\n",
              "  'agnostic learning'],\n",
              " ['individual goals',\n",
              "  'previous plan derivations',\n",
              "  'new problem situation',\n",
              "  'complete solution',\n",
              "  'replayed path'],\n",
              " ['fast weights', 'experiment', 'system', 'approach', 'paper'],\n",
              " ['DCM', 'related taxa', 'large trees', 'time', 'advantages'],\n",
              " ['semantic grammars',\n",
              "  'construction',\n",
              "  'parsers',\n",
              "  'well novel sentences',\n",
              "  'difficult interesting problem machine'],\n",
              " ['instruction commit',\n",
              "  'branch prediction',\n",
              "  'conditional branch Predicated execution',\n",
              "  'issue instructions',\n",
              "  'certain branches'],\n",
              " ['map',\n",
              "  'signal based owls',\n",
              "  'visual attention',\n",
              "  'corresponding location',\n",
              "  'shift complete'],\n",
              " ['hippocampal cells old animals',\n",
              "  'CA region hippocampus',\n",
              "  'Samsonovich McNaughton',\n",
              "  'theory',\n",
              "  'maps'],\n",
              " ['visual attention',\n",
              "  'reinforcement learning paradigm',\n",
              "  'targets',\n",
              "  'active camera foveate salient features',\n",
              "  'foveate based goal successful recognition'],\n",
              " ['optima comprehensively population',\n",
              "  'peaks',\n",
              "  'implicit sharing',\n",
              "  'different circumstances',\n",
              "  'advantages'],\n",
              " ['construction heterogeneous knowledge system',\n",
              "  'Modern knowledge systems design',\n",
              "  'different kinds knowledge',\n",
              "  'multiple problemsolving methods',\n",
              "  'methodspecific datatoknowledge compilation potential mechanism'],\n",
              " ['mixture experts ME model',\n",
              "  'main results',\n",
              "  'time series analysis',\n",
              "  'disadvantages',\n",
              "  'single networks'],\n",
              " ['network dynamics',\n",
              "  'first neighbors pattern sequence',\n",
              "  'different views object',\n",
              "  'independent component ICA representation',\n",
              "  'successive views'],\n",
              " ['analysis',\n",
              "  'improvement',\n",
              "  'due decreased synchronization',\n",
              "  'preliminary evidence',\n",
              "  'asynchronous versions'],\n",
              " ['decision tree',\n",
              "  'decision trees',\n",
              "  'result method',\n",
              "  'Key ideas statistical learning theory support vector machines',\n",
              "  'preliminary results'],\n",
              " ['particular standard smoothness functionals',\n",
              "  'subclass regularization networks',\n",
              "  'different classes basis functions',\n",
              "  'Regularization Networks',\n",
              "  'hinge functions'],\n",
              " ['paper',\n",
              "  'research',\n",
              "  'many neural networks',\n",
              "  'Generalized Radial Basis Functions GRBF',\n",
              "  'neurobiological data'],\n",
              " ['novel situations',\n",
              "  'case',\n",
              "  'reasoner',\n",
              "  'Casebased reasoning process',\n",
              "  'past experiences'],\n",
              " ['cardinality constraints',\n",
              "  'Genie',\n",
              "  'simple solutions',\n",
              "  'specificity exons',\n",
              "  'indels'],\n",
              " ['strategies',\n",
              "  'questions optimality domination repeated stage games',\n",
              "  'different computationally bounded sets',\n",
              "  'players',\n",
              "  'infinite payoff'],\n",
              " ['efficient algorithms',\n",
              "  'finite automata',\n",
              "  'current action',\n",
              "  'recent history adversaries',\n",
              "  'play game'],\n",
              " ['MORGAN integrated system',\n",
              "  'task distinctive decision tree classifier',\n",
              "  'coding exons',\n",
              "  'probability sequence',\n",
              "  'Experimental results database vertebrate DNA sequences'],\n",
              " ['characteristics',\n",
              "  'based neural networks',\n",
              "  'advice method parameters',\n",
              "  'numerical simulation applications',\n",
              "  'PDE based application'],\n",
              " ['reduction',\n",
              "  'learning algorithm',\n",
              "  'probability',\n",
              "  'approximate correct learning results',\n",
              "  'hypotheses'],\n",
              " ['new learning algorithm',\n",
              "  'effect unit receptive field parameters factors',\n",
              "  'analysis',\n",
              "  'sample density structure target function',\n",
              "  'principle factors'],\n",
              " ['SemiMarkov Decision Problems continuous time generalizations',\n",
              "  'semiMarkov',\n",
              "  'problem',\n",
              "  'algorithms',\n",
              "  'Bellmans optimality equation context'],\n",
              " ['classification regression statistics',\n",
              "  'multiple models',\n",
              "  'HME classification results',\n",
              "  'paper',\n",
              "  'neural networks communities'],\n",
              " ['application',\n",
              "  'simple networks proce dure',\n",
              "  'idea',\n",
              "  'computational efficiency',\n",
              "  'time procedure approximate evaluation probabilistic networks'],\n",
              " ['specific learning problems',\n",
              "  'researchers',\n",
              "  'difficulties',\n",
              "  'various areas',\n",
              "  'lack satisfactory generic complexity measure'],\n",
              " ['bias',\n",
              "  'study',\n",
              "  'results empirical study statistical bias backpropagation',\n",
              "  'paper',\n",
              "  'statistical effects'],\n",
              " ['SGNG',\n",
              "  'Radial Basis Function RBF networks',\n",
              "  'onestage errordriven learning strategy',\n",
              "  'literature',\n",
              "  'segmentation'],\n",
              " ['symbolic rules',\n",
              "  'artificial neural networks',\n",
              "  'NofM',\n",
              "  'representations form',\n",
              "  'extraction algorithm network training method'],\n",
              " ['neural networks',\n",
              "  'Parallel Computers',\n",
              "  'Artificial Neural Networks Journal',\n",
              "  'backpropagation algorithms',\n",
              "  'Second'],\n",
              " ['system',\n",
              "  'performance current task Introspection',\n",
              "  'knowledge world',\n",
              "  'failure types',\n",
              "  'program'],\n",
              " ['artificial neural networks',\n",
              "  'perspective',\n",
              "  'obvious deficiency neural network representations',\n",
              "  'variety realworld',\n",
              "  'remarkable success'],\n",
              " ['method feature subset selection',\n",
              "  'conditions',\n",
              "  'approximate algorithm successful examined Empirical results',\n",
              "  'particular case',\n",
              "  'irrelevant redundant features'],\n",
              " ['irrelevant features',\n",
              "  'closing',\n",
              "  'artificial domains',\n",
              "  'discuss implications experiments',\n",
              "  'others'],\n",
              " ['simulated real robots',\n",
              "  'best results',\n",
              "  'number experiments',\n",
              "  'simulations',\n",
              "  'Animatlike behaviors'],\n",
              " ['states',\n",
              "  'property similarity',\n",
              "  'multiple similar states',\n",
              "  'show',\n",
              "  'practical cases'],\n",
              " ['higher order statistical relations',\n",
              "  'higher levels',\n",
              "  'feedback',\n",
              "  'model',\n",
              "  'stochastic recurrent network ambiguity lowerlevel states'],\n",
              " ['Such errors',\n",
              "  'learning algorithm',\n",
              "  'general methods',\n",
              "  'rate error',\n",
              "  'standard combinatorial optimization problems'],\n",
              " ['general posterior',\n",
              "  'posterior probability model class',\n",
              "  'realworld applications',\n",
              "  'data sample',\n",
              "  'problem'],\n",
              " ['results',\n",
              "  'finite mixture models',\n",
              "  'model',\n",
              "  'realization',\n",
              "  'ExpectationMaximization EM algorithm'],\n",
              " ['repair failures reasoning process',\n",
              "  'application models',\n",
              "  'reasoner',\n",
              "  'behavior',\n",
              "  'model planning processes'],\n",
              " ['Computer experiments',\n",
              "  'theoretical results',\n",
              "  'optimal decisions',\n",
              "  'reinforcement learning algorithms',\n",
              "  'insight learning processes'],\n",
              " ['ADGs',\n",
              "  'distributions',\n",
              "  'variables',\n",
              "  'particular likelihood functions',\n",
              "  'dependences'],\n",
              " ['maximal probability network model',\n",
              "  'data',\n",
              "  'task',\n",
              "  'Bayesian prototype trees',\n",
              "  'due exponential amount time'],\n",
              " ['probabilities',\n",
              "  'opinion due experience',\n",
              "  'Evidential Probability',\n",
              "  'main ideas',\n",
              "  'compound experiments events'],\n",
              " ['work',\n",
              "  'advantages',\n",
              "  'selective attention shortterm memory simultaneously address',\n",
              "  'active perception',\n",
              "  'simulated eye movements'],\n",
              " ['general exhaustive search',\n",
              "  'relevant features',\n",
              "  'optimal subset',\n",
              "  'measure guaranteed complete exhaustive Experiments',\n",
              "  'work'],\n",
              " ['algorithms',\n",
              "  'novel method dialogue agent',\n",
              "  'multiple ways',\n",
              "  'agents choices',\n",
              "  'combination'],\n",
              " ['problems',\n",
              "  'Reduced Error Pruning Inductive Logic Programming',\n",
              "  'Experiments',\n",
              "  'many noisy domains',\n",
              "  'algorithm'],\n",
              " ['EEG analysis',\n",
              "  'reduceddimensional representation',\n",
              "  'representations',\n",
              "  'patterns',\n",
              "  'KarhunenLoeve transform'],\n",
              " ['word reinforcement',\n",
              "  'work',\n",
              "  'trialanderror interactions',\n",
              "  'behavior',\n",
              "  'dynamic environment'],\n",
              " ['Experimental results',\n",
              "  'internal memory',\n",
              "  'XCSM nonMarkovian environments',\n",
              "  'aliasing states',\n",
              "  'XCSM'],\n",
              " ['probability',\n",
              "  'vector single entries',\n",
              "  'probabilities appearance entries nbit vectors',\n",
              "  'optimization',\n",
              "  'task Resemblance genetic algorithms'],\n",
              " ['FOCUS new algorithm',\n",
              "  'algorithms',\n",
              "  'efficient methods',\n",
              "  'many irrelevant features',\n",
              "  'present training data'],\n",
              " ['estimate parameters',\n",
              "  'input sequence decisions',\n",
              "  'efficient algorithm',\n",
              "  'resulting model yields',\n",
              "  'measure'],\n",
              " ['problem',\n",
              "  'z A',\n",
              "  'statistical properties',\n",
              "  'assumptions',\n",
              "  'discrete variables'],\n",
              " ['neuroanatomical morphological well behavioral studies development visual perception',\n",
              "  'results',\n",
              "  'paper',\n",
              "  'computational framework',\n",
              "  'behavioral deficits'],\n",
              " ['longterm context sequential data',\n",
              "  'paper studies',\n",
              "  'approaches',\n",
              "  'phenomenon',\n",
              "  'results'],\n",
              " ['neural networks',\n",
              "  'paper application areas',\n",
              "  'requirements',\n",
              "  'Several applications',\n",
              "  'information'],\n",
              " ['Karlsruhe',\n",
              "  'PTX',\n",
              "  'metal loss',\n",
              "  'defects',\n",
              "  'special ultrasonic based probe'],\n",
              " ['images digits',\n",
              "  'Different models',\n",
              "  'recognition',\n",
              "  'digit',\n",
              "  'EMbased algorithm'],\n",
              " ['gated experts',\n",
              "  'nonlinear gating network',\n",
              "  'article',\n",
              "  'key problems',\n",
              "  'expert'],\n",
              " ['machine learning tools', 'results', 'paper', 'literature', 'experiments'],\n",
              " ['heterogeneous databases',\n",
              "  'query',\n",
              "  'problem',\n",
              "  'front end evaluated mapping',\n",
              "  'HIPED'],\n",
              " ['paper',\n",
              "  'applied problem',\n",
              "  'dynamic goals',\n",
              "  'DGlearning',\n",
              "  'special structure'],\n",
              " ['problems',\n",
              "  'results',\n",
              "  'intractability',\n",
              "  'methods',\n",
              "  'number wellknown publickey cryptosys tems'],\n",
              " ['consensus sequence', 'TraceEvidence', 'new method', 'evidence', 'sums'],\n",
              " ['model',\n",
              "  'words',\n",
              "  'lexical grammatical morphemes',\n",
              "  'separate hiddenlayer modules tasks',\n",
              "  'Experiments'],\n",
              " ['traditional EBL',\n",
              "  'paper presents algorithm',\n",
              "  'improvement',\n",
              "  'original program',\n",
              "  'significant speedup'],\n",
              " ['trace rule',\n",
              "  'elucidate manner representations',\n",
              "  'neurons',\n",
              "  'attempt',\n",
              "  'hierarchical processing areas'],\n",
              " ['observed variables',\n",
              "  'static data input variables',\n",
              "  'hand scheme',\n",
              "  'probabilistic models',\n",
              "  'case'],\n",
              " ['repeated transformations',\n",
              "  'optimization dynamics suitable objective functions',\n",
              "  'simplification products expressions',\n",
              "  'fixpoints',\n",
              "  'Many neural networks'],\n",
              " ['reasoning process model design',\n",
              "  'development implementation',\n",
              "  'system',\n",
              "  'paper',\n",
              "  'casebased design systems CASECAD'],\n",
              " ['Kalman',\n",
              "  'model',\n",
              "  'hierarchical network',\n",
              "  'current visual recognition state lower level',\n",
              "  'successive levels'],\n",
              " ['Hiding effect',\n",
              "  'evolutionary speed',\n",
              "  'measure',\n",
              "  'one',\n",
              "  'speeds rate evolution'],\n",
              " ['racing algorithm',\n",
              "  'continuous optimization problems',\n",
              "  'parameters',\n",
              "  'approximator',\n",
              "  'less time'],\n",
              " ['greediness forward feature selection algorithms',\n",
              "  'linear regression',\n",
              "  'empirical results',\n",
              "  'weighted regression knearestneighbor models',\n",
              "  'greedier algorithms order'],\n",
              " ['data parameters',\n",
              "  'overlapping distributions',\n",
              "  'single component distribution',\n",
              "  'length MML criterion',\n",
              "  'experiments'],\n",
              " ['model',\n",
              "  'performances',\n",
              "  'new T transputer systems',\n",
              "  'Estimates',\n",
              "  'GCel transputer system Measurements'],\n",
              " ['prototypes',\n",
              "  'algorithms',\n",
              "  'accuracy',\n",
              "  'nearest neighbor computation instances',\n",
              "  'order'],\n",
              " ['neural network model',\n",
              "  'toperform positioning RBF units',\n",
              "  'first variant',\n",
              "  'possible contrast',\n",
              "  'existing approaches'],\n",
              " ['trained networks',\n",
              "  'executed robot',\n",
              "  'face',\n",
              "  'knowledge transfer',\n",
              "  'minimalcost paths'],\n",
              " ['GAs',\n",
              "  'problem',\n",
              "  'ASP',\n",
              "  'implicit parallelism problem',\n",
              "  'Genetic Algorithm GA'],\n",
              " ['parameters',\n",
              "  'common crossvalidation',\n",
              "  'classifier confidence levels',\n",
              "  'break ties',\n",
              "  'cross validation'],\n",
              " ['formulation reinforcement learning',\n",
              "  'learning space use behaviors conditions',\n",
              "  'mobile robots',\n",
              "  'paper',\n",
              "  'methodology'],\n",
              " ['trees',\n",
              "  'greedy tree induction',\n",
              "  'greedy approach',\n",
              "  'thousands',\n",
              "  'synthetic data sets'],\n",
              " ['ABSTRACT', 'Previous results', 'SYCON', 'comparisons', 'factorizations'],\n",
              " ['set attractors',\n",
              "  'localist attractor nets similar dynamics distributed counterparts',\n",
              "  'attractor basins',\n",
              "  'effectthe presence attractor',\n",
              "  'gang'],\n",
              " ['theorems',\n",
              "  'Wolpert',\n",
              "  'effective generalisation logical impossibility',\n",
              "  'bad performance',\n",
              "  'situation'],\n",
              " ['new algorithm',\n",
              "  'appropriate network structure',\n",
              "  'network designer',\n",
              "  'number',\n",
              "  'recognition'],\n",
              " ['probability model mixture trees',\n",
              "  'paper',\n",
              "  'EM Minimum Spanning Tree algorithm',\n",
              "  'family efficient algorithms',\n",
              "  'sparse dynamically changing dependence relationships'],\n",
              " ['DNA sequences',\n",
              "  'performance ANNs',\n",
              "  'reading frames',\n",
              "  'several conventional methods',\n",
              "  'coding regions'],\n",
              " ['correct mapping discrete sensor input space steering signal',\n",
              "  'available system',\n",
              "  'case examples',\n",
              "  'basis external reinforcement signal negative case collision',\n",
              "  'algorithm'],\n",
              " ['able transfer knowledge',\n",
              "  'seperatist view',\n",
              "  'subprocess',\n",
              "  'paper',\n",
              "  'number conceptual difficulties'],\n",
              " ['subproblem target network task goal',\n",
              "  'approach',\n",
              "  'speed',\n",
              "  'general problem call network transfer',\n",
              "  'studies'],\n",
              " ['ALVINN',\n",
              "  'Quickprop Cascade Correlation Cascade',\n",
              "  'Backprop',\n",
              "  'report',\n",
              "  'neural network'],\n",
              " ['unsupervised learning process',\n",
              "  'Bayesian approach',\n",
              "  'first phase selection model class ie number parameters',\n",
              "  'work',\n",
              "  'simple discrete finite mixture models'],\n",
              " ['new algorithm', 'images', 'handwritten digits', 'experiments', 'Vapniks'],\n",
              " ['ILP',\n",
              "  'instructionlevel parallelism',\n",
              "  'different threads',\n",
              "  'simultaneous multithreading SMT',\n",
              "  'share processors resources'],\n",
              " ['certain classes',\n",
              "  'relations',\n",
              "  'Mstep',\n",
              "  'Gibbs distributions',\n",
              "  'generalized iterative scaling procedure'],\n",
              " ['committee regressors',\n",
              "  'regression context',\n",
              "  'fundamental building blocks',\n",
              "  'cases',\n",
              "  'techniques'],\n",
              " ['imprecise incomplete information',\n",
              "  'background',\n",
              "  'neural expert system shell NEULA',\n",
              "  'noisy environments',\n",
              "  'pattern recognition operations'],\n",
              " ['Red Queen effect',\n",
              "  'appropriate measures fitness',\n",
              "  'rise',\n",
              "  'populations',\n",
              "  'others fitness landscapes'],\n",
              " ['sensitive modeling assumptions',\n",
              "  'use flexible parametric models',\n",
              "  'DMS Wassermans research',\n",
              "  'NSF',\n",
              "  'efficiency parametric inference'],\n",
              " ['arbitrary n gt number parents',\n",
              "  'experiments',\n",
              "  'tough function optimization problems',\n",
              "  'GA behavior',\n",
              "  'standard uniform crossover diagonal crossover'],\n",
              " ['Department Statistics GN University',\n",
              "  'Seattle',\n",
              "  'Professor',\n",
              "  'Adrian E Raftery',\n",
              "  'CA'],\n",
              " ['tutorial overview neural networks',\n",
              "  'article',\n",
              "  'know statistics',\n",
              "  'classification',\n",
              "  'brain'],\n",
              " ['classification scheme',\n",
              "  'trained codebook Gaussians',\n",
              "  'algorithm',\n",
              "  'regular classification schemes',\n",
              "  'case'],\n",
              " ['training use',\n",
              "  'large number features',\n",
              "  'method',\n",
              "  'simple lifetime predictor',\n",
              "  'better prediction'],\n",
              " ['successful combinations genes',\n",
              "  'problem specific domain knowledge',\n",
              "  'system',\n",
              "  'efficient codings',\n",
              "  'variety applications turbine design scheduling problems'],\n",
              " ['coverage',\n",
              "  'paper',\n",
              "  'algorithm number concepts',\n",
              "  'good learning algorithms',\n",
              "  'size'],\n",
              " ['SPI', 'algorithm', 'MDPs', 'structured policy iteration', 'effectiveness'],\n",
              " ['ASOCS',\n",
              "  'inputoutput vectors processing network',\n",
              "  'model',\n",
              "  'output',\n",
              "  'parallel fashion Learning'],\n",
              " ['Markov chain Monte Carlo MCMC',\n",
              "  'example',\n",
              "  'KEY WORDS Convergence posterior distributions',\n",
              "  'Maximum working likelihood MWL inference presence',\n",
              "  'remaining components'],\n",
              " ['Natural images',\n",
              "  'forms structure',\n",
              "  'characteristic statistical regularities',\n",
              "  'linear Hebbian',\n",
              "  'models'],\n",
              " ['study effects epistasis performance EAs',\n",
              "  'empirical methodology',\n",
              "  'use ideas',\n",
              "  'generators',\n",
              "  'paper'],\n",
              " ['higher numbers',\n",
              "  'benefits',\n",
              "  'Many recent empirical studies',\n",
              "  'point crossover operators',\n",
              "  'opposing views'],\n",
              " ['worlds',\n",
              "  'possible decision problem',\n",
              "  'complexity',\n",
              "  'several variants',\n",
              "  'nesting conditionals'],\n",
              " ['higherorder connections incremental introduction new units',\n",
              "  'connection weights',\n",
              "  'higher orders',\n",
              "  'next timestep information previous step temporal tasks',\n",
              "  'use'],\n",
              " ['binary factorial codes',\n",
              "  'unit remaining units',\n",
              "  'novel general principle',\n",
              "  'predictability',\n",
              "  'environment'],\n",
              " ['models examples',\n",
              "  'distribution examples',\n",
              "  'PAC model',\n",
              "  'sufficient conditions',\n",
              "  'Valiant example oracle'],\n",
              " ['learning architecture',\n",
              "  'results computer simulation',\n",
              "  'inherent learning parameters',\n",
              "  'goal',\n",
              "  'half life learners'],\n",
              " ['witness algorithm compute updated value functions',\n",
              "  'crucial operation wide range pomdp solution methods',\n",
              "  'Dynamicprogramming',\n",
              "  'existing algorithms',\n",
              "  'computational complexity viewpoint'],\n",
              " ['paper',\n",
              "  'programs particular SPEC benchmark suite',\n",
              "  'result compiler',\n",
              "  'nonessential true dependencies',\n",
              "  'stack subroutine linkage'],\n",
              " ['certain classes',\n",
              "  'relations',\n",
              "  'Mstep',\n",
              "  'Gibbs distributions',\n",
              "  'generalized iterative scaling procedure'],\n",
              " ['constraint',\n",
              "  'correlated inputs',\n",
              "  'receptive field',\n",
              "  'subtractive enforcement yields',\n",
              "  'final state'],\n",
              " ['project',\n",
              "  'DARPA HPCC program',\n",
              "  'Michael I',\n",
              "  'funds',\n",
              "  'Jordan NSF Presidential Young Investigator'],\n",
              " ['criteria',\n",
              "  'assumption hypothesis space',\n",
              "  'information',\n",
              "  'different criteria data selection',\n",
              "  'alternative specifications'],\n",
              " ['D case dimensional input space',\n",
              "  'approach',\n",
              "  'proposed paper nodes',\n",
              "  'structure clusters input',\n",
              "  'cluster boundaries'],\n",
              " ['normal data',\n",
              "  'LCI models',\n",
              "  'ADGs Markov equivalent transitive ADG',\n",
              "  'analysis nonmonotone',\n",
              "  'dependent linear regression models'],\n",
              " ['method',\n",
              "  'engineering design Empirical results',\n",
              "  'modification',\n",
              "  'results',\n",
              "  'geneticalgorithmbased optimization'],\n",
              " ['design domains',\n",
              "  'Empirical results',\n",
              "  'GA continuous designspace optimization',\n",
              "  'structure properties',\n",
              "  'paper'],\n",
              " ['Parallel Distributed Processing Explorations Microstructure Cognition',\n",
              "  'Vol MIT Press',\n",
              "  'D E Rumelhart G E Hinton R J Williams Learning Internal Representations Error Propagation D E Rumelhart J L McClelland'],\n",
              " ['universal model',\n",
              "  'Evolutionary trees',\n",
              "  'cases',\n",
              "  'nonparsimonous data convergent evolution',\n",
              "  'address'],\n",
              " ['sensory stimuli',\n",
              "  'response',\n",
              "  'local rules',\n",
              "  'suppression layer IV feedforward synapses',\n",
              "  'synapses'],\n",
              " ['Gibbs sampling',\n",
              "  'Markov chain',\n",
              "  'overrelaxed versions slice sampling',\n",
              "  'Toronto',\n",
              "  'Abstract One way sample distribution sample uniformly region plot density function'],\n",
              " ['MDPs', 'running time', 'complexity', 'results', 'paper'],\n",
              " ['advice', 'approach', 'reward', 'learner', 'knowledgebased neural networks'],\n",
              " ['mixtures',\n",
              "  'mathematical foundations Dirichlet mixtures',\n",
              "  'paper',\n",
              "  'database search',\n",
              "  'information protein database mixture'],\n",
              " ['problem',\n",
              "  'mismatches',\n",
              "  'derivational analogy',\n",
              "  'research addresses',\n",
              "  'experiences'],\n",
              " ['networks',\n",
              "  'languages',\n",
              "  'extraction minimization',\n",
              "  'paper',\n",
              "  'finite state automaton'],\n",
              " ['algorithm',\n",
              "  'Empirical results',\n",
              "  'variables controlled manner',\n",
              "  'small accurate trees',\n",
              "  'linear machine'],\n",
              " ['familiar structures', 'evolutionary process', 'future work', 'ways', 'way'],\n",
              " ['knowledge bases',\n",
              "  'several domain experts',\n",
              "  'knowledge integration',\n",
              "  'aim',\n",
              "  'opinions'],\n",
              " ['overview',\n",
              "  'current research',\n",
              "  'architectures',\n",
              "  'controllers',\n",
              "  'artificial neural networks'],\n",
              " ['reversible jump',\n",
              "  'example',\n",
              "  'procedure',\n",
              "  'approximation acceptance probability',\n",
              "  'method'],\n",
              " ['data',\n",
              "  'paper review advantages',\n",
              "  'query search database',\n",
              "  'new algorithm',\n",
              "  'database'],\n",
              " ['instance',\n",
              "  'apple tasting model enhanced standard model false acceptances',\n",
              "  'standard online model learning algorithm',\n",
              "  'results',\n",
              "  'appropriate response'],\n",
              " ['algorithm',\n",
              "  'tree',\n",
              "  'algorithm exploits error distribution',\n",
              "  'new points',\n",
              "  'partition space'],\n",
              " ['neural networks', 'design', 'tasks', 'current applications', 'PREENS'],\n",
              " ['number problems',\n",
              "  'results experiments',\n",
              "  'simulation',\n",
              "  'paper',\n",
              "  'payoff oscillation'],\n",
              " ['simple penalizing amount information',\n",
              "  'weights',\n",
              "  'squared error network amount information weights',\n",
              "  'idea',\n",
              "  'output units'],\n",
              " ['conventional means preference function form PREFu v',\n",
              "  'problem',\n",
              "  'desirable order',\n",
              "  'simple greedy algorithm',\n",
              "  'online learning algorithm based Hedge algorithm'],\n",
              " ['relation evolutionary techniques numerical classical search methods',\n",
              "  'algorithm',\n",
              "  'GA fl',\n",
              "  'paper',\n",
              "  'natural selection genetics'],\n",
              " ['neural net architecture',\n",
              "  'hairy fly noun phrase',\n",
              "  'complex sequences',\n",
              "  'embedded noun phrase',\n",
              "  'hierarchical recursive structure symbol strings'],\n",
              " ['closest Euclidian distance input vector',\n",
              "  'weights',\n",
              "  'resulting selforganizing process',\n",
              "  'weight vector',\n",
              "  'unit'],\n",
              " ['algorithm',\n",
              "  'ability agents',\n",
              "  'IQalgorithm',\n",
              "  'imitation',\n",
              "  'Qlearning Roughly Qlearner'],\n",
              " ['error',\n",
              "  'method',\n",
              "  'number images',\n",
              "  'map neural network convolutional neural network',\n",
              "  'person training database'],\n",
              " ['new algorithm',\n",
              "  'modified policy iteration algorithm',\n",
              "  'convergence',\n",
              "  'general initial conditions',\n",
              "  'state updating policy'],\n",
              " ['IWMDE',\n",
              "  'marginal posterior densities',\n",
              "  'properties',\n",
              "  'posterior distribution',\n",
              "  'conditional density'],\n",
              " ['PAC learning presence classification noise',\n",
              "  'complexity noisetolerant learning PAC model',\n",
              "  'paper',\n",
              "  'Simon',\n",
              "  'sample size'],\n",
              " ['paper',\n",
              "  'simulations study effect modifier genes',\n",
              "  'shortsighted withinhost competition',\n",
              "  'parasites',\n",
              "  'shortsighted development virulence'],\n",
              " ['numerical envelopes',\n",
              "  'physical systems',\n",
              "  'models',\n",
              "  'paper',\n",
              "  'systematic method computing bounding envelope multivariate monotonic function'],\n",
              " ['methods',\n",
              "  'memory',\n",
              "  'examples',\n",
              "  'application MemoryBased Learning problem',\n",
              "  'common benchmark dataset show method'],\n",
              " ['responses electrochemical stimulation individual neurotransmitter release sites',\n",
              "  'features',\n",
              "  'Such priors',\n",
              "  'Further developments',\n",
              "  'experimental contexts'],\n",
              " ['need software modules',\n",
              "  'NLP tasks',\n",
              "  'MBL',\n",
              "  'high generalization accuracy',\n",
              "  'mandatory Recent work'],\n",
              " ['interpolation algorithm',\n",
              "  'class readonce formulas',\n",
              "  'boolean threshold functions',\n",
              "  'membership equivalence queries',\n",
              "  'generic transformation Angluin Hellerstein Karpinski'],\n",
              " ['decision tree Markov temporal structure',\n",
              "  'Markov calculations',\n",
              "  'time steps',\n",
              "  'time series model',\n",
              "  'artificial data Bach chorales'],\n",
              " ['ER',\n",
              "  'Stochastic simulation algorithms likelihood weighting',\n",
              "  'reality process',\n",
              "  'evidence',\n",
              "  'set trials'],\n",
              " ['energy', 'good solution', 'goal', 'probability', 'expEk B T'],\n",
              " ['disjuncts', 'paper', 'noise', 'prone large disjuncts', 'problem'],\n",
              " ['membership equivalence queries',\n",
              "  'class DNF',\n",
              "  'counterexamples',\n",
              "  'several natural classes',\n",
              "  'exact identification unknown function class'],\n",
              " ['learning algorithm',\n",
              "  'local exception rules',\n",
              "  'Rippledown rule sets',\n",
              "  'constant number alternations',\n",
              "  'hand decision'],\n",
              " ['algorithm',\n",
              "  'class basic concepts',\n",
              "  'k levels',\n",
              "  'rules higher levels',\n",
              "  'PAC model'],\n",
              " ['hidden units results',\n",
              "  'criterion',\n",
              "  'network settle',\n",
              "  'model',\n",
              "  'words dense semantic neighborhood faster words'],\n",
              " ['cached cases',\n",
              "  'form utility problem',\n",
              "  'cost model system',\n",
              "  'time average caching',\n",
              "  'paper'],\n",
              " ['GGLA',\n",
              "  'experiments',\n",
              "  'various alternative design choices',\n",
              "  'cases',\n",
              "  'codebook'],\n",
              " ['CBP',\n",
              "  'stored cases memory',\n",
              "  'unnecessary large casebases',\n",
              "  'indexing',\n",
              "  'plans'],\n",
              " ['efficient method',\n",
              "  'minutes',\n",
              "  'instances problem',\n",
              "  'comparisons methods',\n",
              "  'network workstations algorithm'],\n",
              " ['approach',\n",
              "  'Sutton',\n",
              "  'existing uses exploration bonuses reinforcement',\n",
              "  'components statistical model uncertainty world way',\n",
              "  'compute suboptimal estimates'],\n",
              " ['stronger assumptions finiteness set functions',\n",
              "  'rise',\n",
              "  'countability',\n",
              "  'critical points quadratic loss function',\n",
              "  'singlehidden layer'],\n",
              " ['constructive modeling interpretation',\n",
              "  'philosophical theory',\n",
              "  'generic models central conceptual change science',\n",
              "  'theories',\n",
              "  'adaptive modeling'],\n",
              " ['specific problems',\n",
              "  'framework neurocontrol',\n",
              "  'adaptive control',\n",
              "  'techniques solution',\n",
              "  'design neural networks'],\n",
              " ['information input patterns',\n",
              "  'output',\n",
              "  'robust binary discriminators',\n",
              "  'simple data sets',\n",
              "  'dynamics'],\n",
              " ['ASOCS', 'paper', 'new rule', 'parallel', 'adaptive network'],\n",
              " ['Markov models',\n",
              "  'state space',\n",
              "  'currencies',\n",
              "  'British pound Canadian dollar Deutsch',\n",
              "  'formulation'],\n",
              " ['parallelism',\n",
              "  'available network workstations',\n",
              "  'evaluation',\n",
              "  'strategy',\n",
              "  'autonomous robots'],\n",
              " ['paper',\n",
              "  'dynamic topologies',\n",
              "  'many problems',\n",
              "  'ability',\n",
              "  'LocationIndependent Transformations LITs general strategy'],\n",
              " ['necessary condition genetic algorithm',\n",
              "  'determination',\n",
              "  'new problem',\n",
              "  'research genetic algorithms',\n",
              "  'scheduling'],\n",
              " ['SelfOrganizing Concurrent System',\n",
              "  'VLSI implementation Priority Adaptive',\n",
              "  'paper',\n",
              "  'learning model',\n",
              "  'pattern recognition robotics'],\n",
              " ['simulation method',\n",
              "  'realworld scheduling',\n",
              "  'dynamic problem',\n",
              "  'second step',\n",
              "  'job shop'],\n",
              " ['pruning method lprune',\n",
              "  'Neural network pruning methods',\n",
              "  'training pruning',\n",
              "  'empirical study',\n",
              "  'generalization'],\n",
              " ['similarity assessment',\n",
              "  'new adaptations',\n",
              "  'stored cases',\n",
              "  'Empirical tests',\n",
              "  'library'],\n",
              " ['learning mechanisms',\n",
              "  'casebased reasoning process',\n",
              "  'importance interactions',\n",
              "  'promising method',\n",
              "  'individual knowledge source'],\n",
              " ['CBR systems',\n",
              "  'paper',\n",
              "  'casebased components CBR system',\n",
              "  'knowledge case adaptation criteria similarity assessment',\n",
              "  'large part knowledge acquisition burden'],\n",
              " ['succession sufficiently small linear programs',\n",
              "  'dimensional space',\n",
              "  'points',\n",
              "  'finite number steps',\n",
              "  'ability'],\n",
              " ['famous NETtalk system',\n",
              "  'machine learning approach',\n",
              "  'chapter',\n",
              "  'many extensions',\n",
              "  'different learning algorithm'],\n",
              " ['problem',\n",
              "  'general LPEC',\n",
              "  'convex hulls',\n",
              "  'ndimensional real space formulated linear program equilibrium',\n",
              "  'quadratic objective linear constraints'],\n",
              " ['multiple past planning cases',\n",
              "  'complex situations',\n",
              "  'issues implications',\n",
              "  'paper',\n",
              "  'multiple goals retrieval'],\n",
              " ['plans',\n",
              "  'ForMAT casebased system',\n",
              "  'specific objectives',\n",
              "  'annotated plan rationale reuse',\n",
              "  'MICBP'],\n",
              " ['several separately trained neural networks',\n",
              "  'certain assumptions',\n",
              "  'standard way',\n",
              "  'possible local minima',\n",
              "  'predictions'],\n",
              " ['algorithms',\n",
              "  'PC IC',\n",
              "  'conditional independence',\n",
              "  'linear multiple regression',\n",
              "  'interpretation parameters'],\n",
              " ['hierarchical method',\n",
              "  'Intermediate nodes',\n",
              "  'samples',\n",
              "  'locality basis functions',\n",
              "  'multiresolution'],\n",
              " ['OIL existing algorithms',\n",
              "  'advantage',\n",
              "  'twospirals',\n",
              "  'Net Talk benchmark problems',\n",
              "  'buildup'],\n",
              " ['number criteria',\n",
              "  'learning model selection',\n",
              "  'accuracy',\n",
              "  'researchers',\n",
              "  'predictive accuracy clearly important criterion'],\n",
              " ['attractive fixed points dynamics',\n",
              "  'recurrent neural network associative memory',\n",
              "  'complete patterns',\n",
              "  'attractors',\n",
              "  'missing information network'],\n",
              " ['penalty function',\n",
              "  'SAWing',\n",
              "  'problem independent constraint handling mechanism',\n",
              "  'working graph coloring problems',\n",
              "  'First'],\n",
              " ['estimate',\n",
              "  'independent components sphered data',\n",
              "  'simple Hebbianlike learning rules',\n",
              "  'results',\n",
              "  'independent component negative kurtosis others'],\n",
              " ['evidence grids',\n",
              "  'approach problem',\n",
              "  'distinct places',\n",
              "  'framework',\n",
              "  'physical simulated robots'],\n",
              " ['constructive induction',\n",
              "  'clean distinction',\n",
              "  'theoretical model',\n",
              "  'CI learners',\n",
              "  'paper'],\n",
              " ['intelligent system',\n",
              "  'example database',\n",
              "  'designer task',\n",
              "  'definition',\n",
              "  'defined predicates'],\n",
              " ['different formats',\n",
              "  'common basis',\n",
              "  'unifying framework',\n",
              "  'knowledge bases',\n",
              "  'semantics combined mechanism'],\n",
              " ['suited tasks',\n",
              "  'training time',\n",
              "  'technique',\n",
              "  'sparse training data',\n",
              "  'advantage sparseness'],\n",
              " ['nondecomposable graphical Gaussian model',\n",
              "  'proposal',\n",
              "  'new device sample',\n",
              "  'posterior probability',\n",
              "  'result methodology'],\n",
              " ['TD', 'simple example function', 'state values', 'differences', 'Bertsekas'],\n",
              " ['control tasks', 'ways', 'paper', 'learning type', 'discussion section'],\n",
              " ['trees', 'feasibility symbolic regression', 'paper', 'examples', 'GP'],\n",
              " ['data', 'analysis drug design', 'test compounds', 'known monomers', 'tests'],\n",
              " ['fl fraction data',\n",
              "  'natural measures difficulty',\n",
              "  'analysis generalization error cross validation terms',\n",
              "  'combination formal analysis',\n",
              "  'bound respect'],\n",
              " ['unknown distribution',\n",
              "  'true error',\n",
              "  'new efficient approach model selection',\n",
              "  'size',\n",
              "  'estimate'],\n",
              " ['generalization clauses',\n",
              "  'Timplication decidable clauses',\n",
              "  'logical implication',\n",
              "  'inductive learning generalization main operation usual definition induction',\n",
              "  'technique'],\n",
              " ['different types data',\n",
              "  'capabilities',\n",
              "  'unsupervised data classification',\n",
              "  'incremental concept',\n",
              "  'paper uniform application theory'],\n",
              " ['error reduction', 'output codes', 'limit', 'column separation', 'bias'],\n",
              " ['search problem complexity',\n",
              "  'complexity natural question',\n",
              "  'collective memory search',\n",
              "  'search',\n",
              "  'Such system'],\n",
              " ['relevance',\n",
              "  'Contrary systems',\n",
              "  'context similarity',\n",
              "  'document',\n",
              "  'similar items'],\n",
              " ['selfimproving reactive control system autonomous robotic navigation',\n",
              "  'online adaptation',\n",
              "  'casebased reasoning component',\n",
              "  'navigation system experience',\n",
              "  'navigation module'],\n",
              " ['account addition',\n",
              "  'QuerybyCommittee algorithm',\n",
              "  'model',\n",
              "  'Seung et al',\n",
              "  'querybased filtering methods'],\n",
              " ['papers',\n",
              "  'addition',\n",
              "  'response treebased genetic programming take value',\n",
              "  'experimental results',\n",
              "  'studies'],\n",
              " ['Holtes recentlypublished article',\n",
              "  'Holte',\n",
              "  'accurate decision trees',\n",
              "  'representativeness databases',\n",
              "  'addition'],\n",
              " ['rules',\n",
              "  'implicit training data',\n",
              "  'input spelling words',\n",
              "  'language',\n",
              "  'output phonetic transcription'],\n",
              " ['density', 'entropy', 'contrast', 'differential learning rule', 'EMMA'],\n",
              " ['order',\n",
              "  'probabilistic experiments',\n",
              "  'repetitions',\n",
              "  'optimal search strategies',\n",
              "  'configuration successes failures'],\n",
              " ['method',\n",
              "  'phase',\n",
              "  'highdimensional variant',\n",
              "  'ansatz tesselation data space',\n",
              "  'different form'],\n",
              " ['distributed system',\n",
              "  'precise framework study adaptive load',\n",
              "  'use',\n",
              "  'properties',\n",
              "  'results'],\n",
              " ['bitsback coding',\n",
              "  'Boltzmann distribution based codeword lengths',\n",
              "  'maximum likelihood estimation',\n",
              "  'new algorithm',\n",
              "  'coding application Bayesian network source model'],\n",
              " ['player',\n",
              "  'opponent model',\n",
              "  'information',\n",
              "  'agents',\n",
              "  'distinct advantage competitive situations'],\n",
              " ['Gibbs sampling meanfield approximation',\n",
              "  'Estep',\n",
              "  'ExpectationMaximization EM framework',\n",
              "  'interaction',\n",
              "  'problems'],\n",
              " ['inputs',\n",
              "  'nonlinear transformation estimated sources',\n",
              "  'existing approaches',\n",
              "  'contrast',\n",
              "  'IOIdentification device'],\n",
              " ['Many source separation algorithms',\n",
              "  'Source separation',\n",
              "  'additive noise',\n",
              "  'instantaneous mixtures signals',\n",
              "  'n'],\n",
              " ['multilayer architecture',\n",
              "  'local online learning rules',\n",
              "  'singlelayer one',\n",
              "  'performance robustness separation',\n",
              "  'main motivation'],\n",
              " ['experts',\n",
              "  'simple algorithms',\n",
              "  'predictions',\n",
              "  'various prediction models',\n",
              "  'applications'],\n",
              " ['current ILP systems',\n",
              "  'naive Bayesian classifier',\n",
              "  'combination',\n",
              "  'learner',\n",
              "  'results'],\n",
              " ['stability efficiency method',\n",
              "  'event',\n",
              "  'dynamic nonsmooth process simulation',\n",
              "  'paper',\n",
              "  'capabilities'],\n",
              " ['Different individuals',\n",
              "  'massivelyparallel genetic algorithm',\n",
              "  'behavior Changes',\n",
              "  'new approach',\n",
              "  'rule'],\n",
              " ['datasets',\n",
              "  'similar problems',\n",
              "  'set rules conventions',\n",
              "  'Proben collection problems',\n",
              "  'neural network training'],\n",
              " ['NeuroChess program',\n",
              "  'strengths',\n",
              "  'weaknesses',\n",
              "  'chess board evaluation functions',\n",
              "  'chess final outcome games'],\n",
              " ['simple efficient indexing system structure',\n",
              "  'performances',\n",
              "  'retrieval phase',\n",
              "  'CBR CaseBased Reasoning system complexity accuracy retrieval phase Both flat memory inductive approaches',\n",
              "  'case hierarchy'],\n",
              " ['PAClearning concept class geometric patterns',\n",
              "  'Hausdorff',\n",
              "  'visual resemblance',\n",
              "  'notion',\n",
              "  'Informally'],\n",
              " ['measure function',\n",
              "  'set classifier',\n",
              "  'concept measure functions generalization performance',\n",
              "  'great value practical applications',\n",
              "  'computational problem'],\n",
              " ['articulated attractors',\n",
              "  'feedforward networks',\n",
              "  'results',\n",
              "  'weights',\n",
              "  'conditions'],\n",
              " ['Induced decision trees',\n",
              "  'good classification accuracy tree simplification',\n",
              "  'present framework',\n",
              "  'many tree induction algorithms',\n",
              "  'comprehensible users'],\n",
              " ['cusum path plot',\n",
              "  'examples',\n",
              "  'dimensional summary statistic',\n",
              "  'paper propose monitor Markov chain sampler',\n",
              "  'sequential plot aspects'],\n",
              " ['Gibbs sampler',\n",
              "  'presence external field',\n",
              "  'key words',\n",
              "  'N number pixels',\n",
              "  'Bayesian image reconstruction'],\n",
              " ['hmms model systems',\n",
              "  'hidden Markov models',\n",
              "  'methods',\n",
              "  'resulting models',\n",
              "  'multiple state variables'],\n",
              " ['fertility patterns', 'paper', 'Problems', 'detail', 'outliers'],\n",
              " ['divergence criterion',\n",
              "  'parallel chains',\n",
              "  'finite Markov chains',\n",
              "  'Birkhoffs',\n",
              "  'pointwise ergodic theorem'],\n",
              " ['population chains',\n",
              "  'state space',\n",
              "  'process',\n",
              "  'partial solution problem',\n",
              "  'article'],\n",
              " ['QMR',\n",
              "  'variational approximation methods',\n",
              "  'diagnostic inference QMRDT database',\n",
              "  'paper',\n",
              "  'QMR DT network practical diagnostic tool'],\n",
              " ['solution problem RBF networks',\n",
              "  'process',\n",
              "  'output information',\n",
              "  'Kmeans',\n",
              "  'neural networks topology performance'],\n",
              " ['genetic algorithms decision tree learning order',\n",
              "  'GA',\n",
              "  'search space',\n",
              "  'genetic algorithm',\n",
              "  'features'],\n",
              " ['behavior humancomputer system crisis response',\n",
              "  'hypotheses',\n",
              "  'INCA',\n",
              "  'intelligent assistant planning scheduling domain relation human users',\n",
              "  'results'],\n",
              " ['high performance reactive rules',\n",
              "  'method',\n",
              "  'implemented system',\n",
              "  'laboratory scale tactical problem',\n",
              "  'explanations'],\n",
              " ['robots highlevel processing planning capabilities',\n",
              "  'approaches',\n",
              "  'terms',\n",
              "  'grammars',\n",
              "  'basic actions'],\n",
              " ['various methods',\n",
              "  'terms',\n",
              "  'diagnostic techniques',\n",
              "  'interpretability applicability recommendations',\n",
              "  'convergence'],\n",
              " ['paper',\n",
              "  'several anticipative controllers',\n",
              "  'approximated feedforward neural network',\n",
              "  'desired camerajoint mapping',\n",
              "  'use time derivatives position object manipulator controller'],\n",
              " ['fbd algorithm',\n",
              "  'Covariance information help',\n",
              "  'predictive causal models',\n",
              "  'problems',\n",
              "  'difficult regression algorithms'],\n",
              " ['decision rules',\n",
              "  'problem',\n",
              "  'competition',\n",
              "  'notion',\n",
              "  'genetic algorithms search space decision policies'],\n",
              " ['concepts domain',\n",
              "  'transference bias',\n",
              "  'method',\n",
              "  'MFOCL Horn clause relational learning algorithm',\n",
              "  'learning concept'],\n",
              " ['issues',\n",
              "  'important problems',\n",
              "  'feedforward neural networks',\n",
              "  'neural network',\n",
              "  'statisticians'],\n",
              " ['inductive reasoning',\n",
              "  'standard norms',\n",
              "  'prooftheoretical procedure',\n",
              "  'large class data structures',\n",
              "  'spurious covariations'],\n",
              " ['analyses',\n",
              "  'run time model network',\n",
              "  'CNS',\n",
              "  'lower bound run time present algorithm meeting',\n",
              "  'performance alternative interface'],\n",
              " ['framework',\n",
              "  'complicated complexity knowledge',\n",
              "  'descriptive contextsensitive knowledge',\n",
              "  'phenomena',\n",
              "  'contextsensitive variations'],\n",
              " ['number methods',\n",
              "  'delta method',\n",
              "  'based Hessian bootstrap estimators sandwich estimator',\n",
              "  'values multilayer perceptron',\n",
              "  'standard error'],\n",
              " ['Dirichlet process', 'models', 'convolutions', 'j j x n j', 'j'],\n",
              " ['paper',\n",
              "  'several predictive controllers',\n",
              "  'use time derivatives position object manipulator controller',\n",
              "  'DOF',\n",
              "  'arbitrary placed table'],\n",
              " ['AA actual data',\n",
              "  'fashion network',\n",
              "  'fit problem',\n",
              "  'AA topologically dynamic network',\n",
              "  'features'],\n",
              " ['ML',\n",
              "  'maximum likelihood',\n",
              "  'paper',\n",
              "  'noisy mixture independent sources',\n",
              "  'discrete sources'],\n",
              " ['diagnosticrecovery procedure',\n",
              "  'health system',\n",
              "  'ranked set probable causes',\n",
              "  'prioritized checklist',\n",
              "  'corrective action'],\n",
              " ['conflicts',\n",
              "  'previous work formalized case combination',\n",
              "  'algorithm',\n",
              "  'situations',\n",
              "  'cases'],\n",
              " ['CSP techniques',\n",
              "  'previous work',\n",
              "  'casebased reasoning process case adaptation',\n",
              "  'Dynamic Constraint Satisfaction Problem',\n",
              "  'time'],\n",
              " ['paper',\n",
              "  'concept speed task',\n",
              "  'boolean prepositions',\n",
              "  'concepts',\n",
              "  'PAC analysis determinations type relevance knowledge'],\n",
              " ['free parameters', 'form', 'calibrationcan', 'process', 'learning presence'],\n",
              " ['paper',\n",
              "  'close approximations cases',\n",
              "  'virtual seens',\n",
              "  'NN algorithm',\n",
              "  'training'],\n",
              " ['large case libraries',\n",
              "  'difficult CBR vendors',\n",
              "  'efficiency',\n",
              "  'guidelines',\n",
              "  'difficult apply'],\n",
              " ['sequential manner diagnosis',\n",
              "  'additional benefit',\n",
              "  'missing data database',\n",
              "  'EM algorithm',\n",
              "  'new information'],\n",
              " ['example',\n",
              "  'function weights',\n",
              "  'neural net',\n",
              "  'sum squared errors',\n",
              "  'local minimum global minimum'],\n",
              " ['accuracy probability answer',\n",
              "  'default theory',\n",
              "  'ffi gt OptAcc',\n",
              "  'R',\n",
              "  'distribution queries'],\n",
              " ['inherent compression pressure',\n",
              "  'hypothesis',\n",
              "  'successful evolution',\n",
              "  'balance',\n",
              "  'basis analysis effects suggestions'],\n",
              " ['recent XCS classifier system',\n",
              "  'optimal populations representations populations',\n",
              "  'Wilsons Generalization Hypothesis XCS tendency',\n",
              "  'evolutionary search',\n",
              "  'selfmonitoring performance statistics'],\n",
              " ['successive rules',\n",
              "  'eg CN',\n",
              "  'alternative',\n",
              "  'Rise system Empirical comparison',\n",
              "  'approach'],\n",
              " ['tree',\n",
              "  'depth width',\n",
              "  'nextascent hillclimbing search',\n",
              "  'problems',\n",
              "  'weights'],\n",
              " ['human subjects',\n",
              "  'facial expressions',\n",
              "  'performance neural network',\n",
              "  'interpolated imagery',\n",
              "  'experiments'],\n",
              " ['genetic programming',\n",
              "  'techniques',\n",
              "  'contrast',\n",
              "  'appropriate arithmetic expression order',\n",
              "  'defined submodels'],\n",
              " ['genetic search',\n",
              "  'dynamic ranking hyperplanes',\n",
              "  'static measurements',\n",
              "  'degree dynamic ranking induced simple genetic algorithm highly correlated degree static ranking inherent function',\n",
              "  'metric measuring degree ranking'],\n",
              " ['answers questions',\n",
              "  'example',\n",
              "  'paper',\n",
              "  'theoretical fashion',\n",
              "  'roles crossover mutation roles'],\n",
              " ['discrete attributes',\n",
              "  'classifier',\n",
              "  'based Bayesian networks',\n",
              "  'new method',\n",
              "  'form'],\n",
              " ['complex systems',\n",
              "  'Dynamic Bayesian networks',\n",
              "  'structured representation language',\n",
              "  'ways',\n",
              "  'inference algorithm'],\n",
              " ['preliminary approach',\n",
              "  'limitations',\n",
              "  'simple constructive training method',\n",
              "  'many examples',\n",
              "  'neurons training'],\n",
              " ['several weighting methods',\n",
              "  'weights',\n",
              "  'numeric attributes',\n",
              "  'several benchmark tests',\n",
              "  'Experiments'],\n",
              " ['system',\n",
              "  'obvious necessary ones',\n",
              "  'conditions',\n",
              "  'arbitrary saturation functions',\n",
              "  'terms'],\n",
              " ['several Ensembles Neural Networks',\n",
              "  'multiple Ensembles ANNs',\n",
              "  'classification scheme',\n",
              "  'seismic signals',\n",
              "  'integration'],\n",
              " ['Paul Deheuvels',\n",
              "  'institutions',\n",
              "  'Gilles',\n",
              "  'Christine Montfort',\n",
              "  'hearty hospitality Paris sabbatical part chapter'],\n",
              " ['CABINS',\n",
              "  'acquisition user optimization',\n",
              "  'paper',\n",
              "  'incremental revision framework',\n",
              "  'time'],\n",
              " ['formulation rules',\n",
              "  'behaviorbased architecture',\n",
              "  'article',\n",
              "  'responsible necessary levels intelligence',\n",
              "  'behavior hierarchy mechanisms control decisionmaking'],\n",
              " ['paper',\n",
              "  'first algorithm',\n",
              "  'approximated combination model',\n",
              "  'properties',\n",
              "  'distribution representation scheme'],\n",
              " ['task allocation',\n",
              "  'collective adaptation',\n",
              "  'ability society',\n",
              "  'test role society information center',\n",
              "  'simplicity collective action pattern detection collective memory'],\n",
              " ['naive annealed theory',\n",
              "  'temperature',\n",
              "  'boolean functions',\n",
              "  'similar inverse square root bound VapnikChervonenkis theory Tighter nonuniversal learning curve bounds',\n",
              "  'concept class finite cardinality'],\n",
              " ['approach',\n",
              "  'track',\n",
              "  'underwater sonar targets nearfield bearing range estimation case large passive arrays',\n",
              "  'requirement',\n",
              "  'elements'],\n",
              " ['constructive inductionbased learning agent CILA',\n",
              "  'knowledge representation space',\n",
              "  'paper',\n",
              "  'adaptive agents ability',\n",
              "  'user task'],\n",
              " ['partitioning neurons',\n",
              "  'disjoint clusters',\n",
              "  'method',\n",
              "  'clusterbasis',\n",
              "  'Nneuron network N samples'],\n",
              " ['Incy inductive learner',\n",
              "  'hypotheses',\n",
              "  'datadriven restriction encoded algorithm modelbased restrictions',\n",
              "  'groups',\n",
              "  'explicit form declarative bias'],\n",
              " ['tactical plans',\n",
              "  'model target environment',\n",
              "  'effect',\n",
              "  'noise',\n",
              "  'decision rules'],\n",
              " ['realtime performance critical requirement navigation',\n",
              "  'work',\n",
              "  'SAMUEL',\n",
              "  'robust behavior',\n",
              "  'mine'],\n",
              " ['rigorous theory',\n",
              "  'curves',\n",
              "  'based ideas statistical mechanics',\n",
              "  'introduce',\n",
              "  'many concrete examples'],\n",
              " ['task', 'ways', 'paper', 'eg', 'nontrivial languages'],\n",
              " ['analogous used Boltzmann machines',\n",
              "  'visible variables',\n",
              "  'feedforward nature connections negative phase Boltzmann machine',\n",
              "  'correlations',\n",
              "  'Conditional probability distributions'],\n",
              " ['variable size representations programs',\n",
              "  'Size',\n",
              "  'paper',\n",
              "  'size generality issues',\n",
              "  'controlled factor'],\n",
              " ['traditional view causation',\n",
              "  'definition',\n",
              "  'approach',\n",
              "  'added clarity notion cause',\n",
              "  'causal assertions'],\n",
              " ['control systems', 'rules', 'fuzzy logic controllers', 'problem', 'GP'],\n",
              " ['asymptotic properties',\n",
              "  'failure',\n",
              "  'time semiparametric regression models',\n",
              "  'proportional odds',\n",
              "  'computational procedures'],\n",
              " ['paper',\n",
              "  'fundamental relationship performance complexity',\n",
              "  'structures',\n",
              "  'essence parsimony problem',\n",
              "  'parsimonious programs'],\n",
              " ['DPNs',\n",
              "  'DPN',\n",
              "  'posterior distribution state variables',\n",
              "  'paper',\n",
              "  'observations'],\n",
              " ['experimental evidence',\n",
              "  'Pessimism implicit hypothesis testing',\n",
              "  'knowledge',\n",
              "  'cases optimism',\n",
              "  'earlier findings'],\n",
              " ['HMMs',\n",
              "  'Markov models',\n",
              "  'hidden state variables',\n",
              "  'multiple time',\n",
              "  'delays'],\n",
              " ['new algorithm',\n",
              "  'flat minimum error function',\n",
              "  'input',\n",
              "  'Various experiments',\n",
              "  'units'],\n",
              " ['reactive rules',\n",
              "  'explanations execution traces',\n",
              "  'knowledge gaps',\n",
              "  'method',\n",
              "  'new domain knowledge'],\n",
              " ['neural network',\n",
              "  'backtracks',\n",
              "  'valueordering decisions',\n",
              "  'problemgeneral heuristics',\n",
              "  'new method'],\n",
              " ['library design guidelines',\n",
              "  'knowledge cases',\n",
              "  'rulebased expert systems',\n",
              "  'contrast',\n",
              "  'difficult software'],\n",
              " ['types skills',\n",
              "  'speedaccuracy tradeoffone robust phenomena human motor behavior',\n",
              "  'observation improved practice',\n",
              "  'class trajectory',\n",
              "  'movements'],\n",
              " ['paper',\n",
              "  'tabular Qlearning',\n",
              "  'discounted max simple classifier system D MAX VSCS',\n",
              "  'similarities',\n",
              "  'research contexts'],\n",
              " ['compact coding',\n",
              "  'dichotomy',\n",
              "  'sensitive sparse distributed codes',\n",
              "  'filters',\n",
              "  'dimensionality reduction'],\n",
              " ['n parameters',\n",
              "  'special case',\n",
              "  'piecewiseanalytic functions',\n",
              "  'open sets samples length',\n",
              "  'weaker result'],\n",
              " ['computer system',\n",
              "  'difficult casebased reasoning systems systems',\n",
              "  'domain',\n",
              "  'response',\n",
              "  'methodology'],\n",
              " ['casebased reasoner',\n",
              "  'abstract cases',\n",
              "  'approach',\n",
              "  'brainstormer planner',\n",
              "  'requirement'],\n",
              " ['MLE regression parameter',\n",
              "  'current status data',\n",
              "  'main results',\n",
              "  'tumoriginicity study Introduction',\n",
              "  'general theorem'],\n",
              " ['advice', 'stories', 'general conditions', 'Stories', 'course action'],\n",
              " ['reparameterisation secondary components mixture terms',\n",
              "  'Mengersen Robert',\n",
              "  'normal mixtures',\n",
              "  'possible reparameterisations',\n",
              "  'associated poor convergence properties'],\n",
              " ['presentationbased interfaces sophisticated form processing',\n",
              "  'interfaces systems inductive rule',\n",
              "  'naturallanguage question',\n",
              "  'conclusions',\n",
              "  'Continuing research'],\n",
              " ['single model',\n",
              "  'survival patients',\n",
              "  'inference',\n",
              "  'partial Bayes factors',\n",
              "  'examples'],\n",
              " ['individual bootstrap samples',\n",
              "  'selection',\n",
              "  'bootstrapbased method model',\n",
              "  'estimates',\n",
              "  'alternatives'],\n",
              " ['existing arcing algorithms',\n",
              "  'Adaboost Freund Schapire others',\n",
              "  'explanation',\n",
              "  'maximum error training',\n",
              "  'situation'],\n",
              " ['partial problem description text',\n",
              "  'approach',\n",
              "  'CCBR',\n",
              "  'Conversational casebased reasoning',\n",
              "  'questions'],\n",
              " ['Such formulas',\n",
              "  'results',\n",
              "  'membership queries',\n",
              "  'Valiants',\n",
              "  'polynomial time algorithm'],\n",
              " ['distributed patterns',\n",
              "  'collection hierarchical structures',\n",
              "  'sequential RAAM',\n",
              "  'technique',\n",
              "  'difficult explains'],\n",
              " ['learning algorithm',\n",
              "  'similar structure',\n",
              "  'Markov',\n",
              "  'sources',\n",
              "  'natural English text'],\n",
              " ['first order clausal theories',\n",
              "  'claudien',\n",
              "  'data regularities',\n",
              "  'papers',\n",
              "  'focuss semantics logical problem specification claudien discovery algorithm'],\n",
              " ['RELIEFF',\n",
              "  'dependencies',\n",
              "  'RELIEF algorithm',\n",
              "  'current inductive machine learning algorithms',\n",
              "  'impurity functions'],\n",
              " ['chaotic time series prediction',\n",
              "  'Genetic Programming',\n",
              "  'simple modification crossover operator',\n",
              "  'others',\n",
              "  'Genetic Programmings flexible tree structure particular problem'],\n",
              " ['greedy search',\n",
              "  'beam candidate literals',\n",
              "  'interesting declarative bias',\n",
              "  'Current ILP algorithms',\n",
              "  'step'],\n",
              " ['ReliefF heuristic guidance',\n",
              "  'classification problems',\n",
              "  'extended algorithm',\n",
              "  'noisy incomplete data',\n",
              "  'regressional variant RReliefF deal regression problems'],\n",
              " ['comparisons', 'TD', 'chess backgammon', 'experiments', 'utility'],\n",
              " ['unknown approximated sequential estimator density',\n",
              "  'natural extension',\n",
              "  'problem',\n",
              "  'MetropolisHastings',\n",
              "  'previous work'],\n",
              " ['Griniasty et al associates',\n",
              "  'generalization',\n",
              "  'ICA basis vectors data',\n",
              "  'visual experience biological system',\n",
              "  'faces'],\n",
              " ['fitted regression functions',\n",
              "  'Dirichlet mixture models',\n",
              "  'similar generalised kernel regression estimates',\n",
              "  'theoretical basis semiparametric regression methods',\n",
              "  'conditional predictive distributions'],\n",
              " ['genetic algorithms',\n",
              "  'point crossover operators standard mechanisms',\n",
              "  'aspects',\n",
              "  'number recent studies',\n",
              "  'recombination'],\n",
              " ['Many observations',\n",
              "  'aspects',\n",
              "  'methodological issues',\n",
              "  'linear discrimin ants',\n",
              "  'approach traditional method'],\n",
              " ['SASAT GSAT', 'paper', 'SASAT', 'Selman et al', 'satisfiability problems'],\n",
              " ['discretization',\n",
              "  'comparison',\n",
              "  'approaches',\n",
              "  'Length Principle',\n",
              "  'Minimum Description'],\n",
              " ['z', 'first n components', 'CA', 'first output terms', 'equal n case'],\n",
              " ['linear systems', 'Sontag ED', 'ffi N', 'jyj ev', 'k'],\n",
              " ['data',\n",
              "  'paper concentrate robust estimators exploratory statistical methods',\n",
              "  'variables',\n",
              "  'observability redundancy properties',\n",
              "  'outliers'],\n",
              " ['class hierarchy',\n",
              "  'large number categories',\n",
              "  'documents',\n",
              "  'subject categories library congress scheme',\n",
              "  'improvement'],\n",
              " ['new method', 'decision tree data', 'predictions', 'data', 'procedure'],\n",
              " ['concept class C study',\n",
              "  'T associate boolean indicator function',\n",
              "  'lt',\n",
              "  'arbitrary point',\n",
              "  'halfspaces'],\n",
              " ['new criteria',\n",
              "  'method',\n",
              "  'based theoretical concepts',\n",
              "  'pessimistic decision tree',\n",
              "  'work'],\n",
              " ['initial experiments',\n",
              "  'methods',\n",
              "  'different models',\n",
              "  'predictions',\n",
              "  'precise quantitative semantics'],\n",
              " ['worstcase error estimate',\n",
              "  'worse training error',\n",
              "  'Previous bounds',\n",
              "  'algorithms',\n",
              "  'new weaker notion error stability'],\n",
              " ['simulated world', 'states', 'behaviour actors', 'program', 'experiments'],\n",
              " ['system',\n",
              "  'conceptual makeup',\n",
              "  'mirrors',\n",
              "  'good underlying software structure',\n",
              "  'loose collection software components'],\n",
              " ['noisy controllers',\n",
              "  'Coevolution competitive species',\n",
              "  'predator',\n",
              "  'Different types',\n",
              "  'proteanism'],\n",
              " ['calculation second derivatives',\n",
              "  'networks radial basis units',\n",
              "  'connectionist networks elimination',\n",
              "  'exact approximate algorithms',\n",
              "  'components'],\n",
              " ['reason',\n",
              "  'treat programs syntactical structures',\n",
              "  'structures',\n",
              "  'metric determining distance',\n",
              "  'principles problem'],\n",
              " ['several generalization styles',\n",
              "  'Empirical results',\n",
              "  'training set data',\n",
              "  'efficient terms',\n",
              "  'time space'],\n",
              " ['systemtheoretic aspects',\n",
              "  'exposition recent research',\n",
              "  'continuoustime recurrent dynamic neural networks sigmoidal activation',\n",
              "  'discussed result',\n",
              "  'paper'],\n",
              " ['LIA',\n",
              "  'dynamic topologies',\n",
              "  'description',\n",
              "  'LIT',\n",
              "  'basic ASOCS mechanisms definitions'],\n",
              " ['Bellman equation', 'finite number', 'MDP', 'actions', 'approach'],\n",
              " ['structural indices design cases',\n",
              "  'right level generalization',\n",
              "  'SBF model design',\n",
              "  'indices',\n",
              "  'new knowledge system designers'],\n",
              " ['Empirical results',\n",
              "  'system',\n",
              "  'classes',\n",
              "  'movements',\n",
              "  'representation temporal structure'],\n",
              " ['best representation space',\n",
              "  'decision rules',\n",
              "  'problem',\n",
              "  'implemented system AQDCI',\n",
              "  'inductive hypothesis'],\n",
              " ['handwritten digit classifiers',\n",
              "  'different types',\n",
              "  'classification task',\n",
              "  'small subset data base',\n",
              "  'addition'],\n",
              " ['navigation Two classes reconstruction methods',\n",
              "  'reconstruction analysis',\n",
              "  'related computational problems visual object recognition',\n",
              "  'addition',\n",
              "  'related result'],\n",
              " ['static activity profile network dynamic shift mechanism',\n",
              "  'selfmotion information',\n",
              "  'specific onedimensional example computational mechanism',\n",
              "  'model',\n",
              "  'rats'],\n",
              " ['biasvariance decomposition',\n",
              "  'learning algorithms',\n",
              "  'biasvariance decomposition quadratic loss functions',\n",
              "  'classification',\n",
              "  'loss function'],\n",
              " ['f g u r b l e f e l programmable gate arrays FPGAs',\n",
              "  'r',\n",
              "  'step sorter',\n",
              "  'f',\n",
              "  'timeconsuming fitness evaluation task'],\n",
              " ['Ax b p corruption p',\n",
              "  'parsimonious solution',\n",
              "  'number nonzero elements',\n",
              "  'linear system',\n",
              "  'signalprocessingbased example'],\n",
              " ['set simulations',\n",
              "  'viewpoint invariant representations',\n",
              "  'interaction temporal smoothing activity',\n",
              "  'face',\n",
              "  'Hebbian'],\n",
              " ['incomprehensible models',\n",
              "  'Neural networks',\n",
              "  'long training times',\n",
              "  'first type approach',\n",
              "  'article'],\n",
              " ['asymptotic gain generalization error',\n",
              "  'order',\n",
              "  'optimum performance',\n",
              "  'training testing sets',\n",
              "  'ratio examples'],\n",
              " ['robust representation',\n",
              "  'fundamental problems',\n",
              "  'feature selection',\n",
              "  'real data',\n",
              "  'database'],\n",
              " ['search space concept descriptions',\n",
              "  'proposed stochastic search method',\n",
              "  'results',\n",
              "  'experiments',\n",
              "  'algorithm'],\n",
              " ['local selection algorithms',\n",
              "  'size shape neighborhood',\n",
              "  'sequential EAs',\n",
              "  'selection methods',\n",
              "  'techniques'],\n",
              " ['ambiguous qualitative relationships',\n",
              "  'first approach',\n",
              "  'qualitative relationship nodes',\n",
              "  'tradeoffs relationships',\n",
              "  'Bayesian network'],\n",
              " ['cooperative distribution',\n",
              "  'Gaussian',\n",
              "  'translations pattern',\n",
              "  'representational power',\n",
              "  'Gaussian constrained nonnegative enabling use nonconvex energy functions'],\n",
              " ['novel fast algorithm',\n",
              "  'simple',\n",
              "  'accurate solution',\n",
              "  'time',\n",
              "  'nonGaussian independent components'],\n",
              " ['seminal work minimal entropy codes',\n",
              "  'probability events',\n",
              "  'variant',\n",
              "  'BCM learning rule',\n",
              "  'Barlows'],\n",
              " ['best representation space',\n",
              "  'decision rules',\n",
              "  'problem',\n",
              "  'implemented system AQDCI',\n",
              "  'inductive hypothesis'],\n",
              " ['ReliefF',\n",
              "  'quality attributes',\n",
              "  'domains strong dependencies',\n",
              "  'us',\n",
              "  'analysis'],\n",
              " ['new research area',\n",
              "  'Inductive Logic Programming',\n",
              "  'terms',\n",
              "  'logic',\n",
              "  'RLGG'],\n",
              " ['Bayesian methods',\n",
              "  'advantages',\n",
              "  'conventional frequentist model training selection',\n",
              "  'review principles',\n",
              "  'applied neural network models'],\n",
              " ['efficient algorithm',\n",
              "  'data',\n",
              "  'experimental results',\n",
              "  'pairs',\n",
              "  'normal DAGFaithful'],\n",
              " ['efficient algorithm',\n",
              "  'pairs',\n",
              "  'data',\n",
              "  'experimental results',\n",
              "  'computation mutual information'],\n",
              " ['SVM',\n",
              "  'Support Vector Machine SVM',\n",
              "  'better approaches',\n",
              "  'technique',\n",
              "  'mathematical point view'],\n",
              " ['paper',\n",
              "  'multichip modules',\n",
              "  'implementation',\n",
              "  'MCMs interconnect medium',\n",
              "  'dense interconnect artificial neural network systems'],\n",
              " ['clauses', 'negative examples', 'recursive ones', 'algorithm', 'work'],\n",
              " ['program wrt positive negative examples',\n",
              "  'algorithm spectre',\n",
              "  'SLDtree',\n",
              "  'experiments',\n",
              "  'shape'],\n",
              " ['Cognitive mapping qualitative decision modeling technique',\n",
              "  'context',\n",
              "  'cognitive maps',\n",
              "  'paper',\n",
              "  'firm semantic foundation'],\n",
              " ['highlevel reasoning problem domains',\n",
              "  'autonomous robotic navigation',\n",
              "  'continuous representations',\n",
              "  'new method continuous casebased reasoning',\n",
              "  'performance task'],\n",
              " ['goal competition',\n",
              "  'programs',\n",
              "  'ideas research',\n",
              "  'TRAINS problems',\n",
              "  'authors'],\n",
              " ['algorithm', 'ordering nodes', 'approaches', 'CI tests', 'user'],\n",
              " ['general prediction problems',\n",
              "  'covariance inflation criterion',\n",
              "  'byproduct',\n",
              "  'measure effective number parameters',\n",
              "  'criterion'],\n",
              " ['data', 'heterogeneous clusters', 'MNG', 'different classes', 'basic idea'],\n",
              " ['National Science Foundation Fellowship',\n",
              "  'views conclusions',\n",
              "  'document authors',\n",
              "  'John Anderson',\n",
              "  'research'],\n",
              " ['estimating model parameters',\n",
              "  'difficulty profiling methods',\n",
              "  'applied models',\n",
              "  'Linear approximations',\n",
              "  'uncertainty'],\n",
              " ['model based idea',\n",
              "  'plasticity Features',\n",
              "  'representation',\n",
              "  'advantage',\n",
              "  'temporal continuity image sequences'],\n",
              " ['AdaBoost',\n",
              "  'many individual hypotheses',\n",
              "  'practice',\n",
              "  'large amount memory required store hypotheses',\n",
              "  'composite hypothesis'],\n",
              " ['synaptic plasticity rules Marshall',\n",
              "  'EXIN',\n",
              "  'ocular dominance',\n",
              "  'model plasticity afferent pathways neurons',\n",
              "  'novel account effects pharmacological treatments'],\n",
              " ['membership equivalence queries',\n",
              "  'log',\n",
              "  'union discretized axisparallel boxes',\n",
              "  'polyhedron',\n",
              "  'first algorithm'],\n",
              " ['neural network design training topology optimization',\n",
              "  'genetic algorithms',\n",
              "  'much work',\n",
              "  'result',\n",
              "  'number aspects'],\n",
              " ['optimal beliefs',\n",
              "  'belief update belief revision',\n",
              "  'connected networks',\n",
              "  'networks single loop',\n",
              "  'multiple loops'],\n",
              " ['GA',\n",
              "  'evolution',\n",
              "  'paper',\n",
              "  'Langdon',\n",
              "  'known schedule base South Wales problem'],\n",
              " ['search space search mechanism',\n",
              "  'class evolutionary algorithms',\n",
              "  'user',\n",
              "  'problemspecific constraints',\n",
              "  'many searches'],\n",
              " ['possible revisions',\n",
              "  'coherent whole Forte',\n",
              "  'theory refinement',\n",
              "  'Operators',\n",
              "  'variety sources'],\n",
              " ['FGEN',\n",
              "  'Boolean features',\n",
              "  'domains DNA sequences',\n",
              "  'range tasks',\n",
              "  'Unix command'],\n",
              " ['algorithm',\n",
              "  'Genetic algorithms',\n",
              "  'various parameters',\n",
              "  'parallel serial implementations',\n",
              "  'comparisons'],\n",
              " ['data base international conflicts',\n",
              "  'KOSIMO',\n",
              "  'retrieval algorithms',\n",
              "  'VIECBR deveolped',\n",
              "  'addition case'],\n",
              " ['CB H',\n",
              "  'results',\n",
              "  'algorithm',\n",
              "  'improved choosing similarity measure appropriate concept',\n",
              "  'sample complexity'],\n",
              " ['newcomers',\n",
              "  'Emerging activity beginnings',\n",
              "  'common themes',\n",
              "  'annoying bewildering oldtimers',\n",
              "  'important open issues'],\n",
              " ['data',\n",
              "  'MBR algorithms',\n",
              "  'metric popular Bayesian classifier',\n",
              "  'distributions concept classes',\n",
              "  'Pebls'],\n",
              " ['Knearestneighbor procedures',\n",
              "  'metric distance Euclidean space input measurement variables',\n",
              "  'metric chosen deflne distance',\n",
              "  'estimate',\n",
              "  'object unknown class plurality class'],\n",
              " ['intensive local search methods',\n",
              "  'traditional hybrid genetic algorithm',\n",
              "  'interference',\n",
              "  'offspring',\n",
              "  'results'],\n",
              " ['immune system model',\n",
              "  'model',\n",
              "  'genetic algorithm',\n",
              "  'GA central component model',\n",
              "  'understanding pattern recognition processes'],\n",
              " ['representations function',\n",
              "  'input space',\n",
              "  'method',\n",
              "  'depths tree',\n",
              "  'learning process good generalisation'],\n",
              " ['linear Boltzmann chain',\n",
              "  'HMM',\n",
              "  'models',\n",
              "  'expA ii ii expB ij b',\n",
              "  'HMMs Saul Jordan'],\n",
              " ['coevolutionary approach',\n",
              "  'results',\n",
              "  'addition',\n",
              "  'Results',\n",
              "  'significant learning rate speedup'],\n",
              " ['new algorithm',\n",
              "  'work',\n",
              "  'previous learning experience',\n",
              "  'derivation',\n",
              "  'Jacobs fully incremental single free parameter'],\n",
              " ['pruning method lprune',\n",
              "  'extensive experimentation',\n",
              "  'results',\n",
              "  'Neural network pruning methods',\n",
              "  'algorithm parameter adjustment user'],\n",
              " ['Sather',\n",
              "  'user',\n",
              "  'efficient customized implementations',\n",
              "  'ICSI',\n",
              "  'meet requirements flexibility'],\n",
              " ['experiencebased casebased reasoning',\n",
              "  'modelbased method',\n",
              "  'new problems',\n",
              "  'paper',\n",
              "  'different types'],\n",
              " ['systems', 'systems performance', 'utility problem', 'attempt', 'knowledge'],\n",
              " ['second stage',\n",
              "  'model',\n",
              "  'items',\n",
              "  'frequent structural remindings',\n",
              "  'psychological phenomena'],\n",
              " ['constant factor respect bounds sum squared errors',\n",
              "  'linear functions',\n",
              "  'algorithm',\n",
              "  'Key words',\n",
              "  'Machine'],\n",
              " ['new retrieved cases',\n",
              "  'reasoning similarity assessment',\n",
              "  'Many methods',\n",
              "  'input case descriptions cases',\n",
              "  'simple comparison'],\n",
              " ['implementation model',\n",
              "  'Much recent research modeling memory processes',\n",
              "  'paper',\n",
              "  'based lessons',\n",
              "  'issues'],\n",
              " ['structured variational approximations',\n",
              "  'probability distribution',\n",
              "  'mathematics',\n",
              "  'mathematical result',\n",
              "  'statistics communication theory machine'],\n",
              " ['ASOCS',\n",
              "  'adaptive algorithm',\n",
              "  'data processing mode learning mode',\n",
              "  'paper',\n",
              "  'fashion'],\n",
              " ['novel search algorithm',\n",
              "  'dynamic hill climbing',\n",
              "  'ideas',\n",
              "  'coarsegrained search finegrained search function space changing mutation rate',\n",
              "  'new regions'],\n",
              " ['intelligent controller autonomous vehicle',\n",
              "  'approach',\n",
              "  'sophisticated software controllers',\n",
              "  'genetic algorithm',\n",
              "  'search'],\n",
              " ['problem',\n",
              "  'new theoretical model',\n",
              "  'performance',\n",
              "  'theoretical results',\n",
              "  'usergiven set problems'],\n",
              " ['Nonparametric density estimation problem',\n",
              "  'probability',\n",
              "  'density function',\n",
              "  'samples',\n",
              "  'values'],\n",
              " ['constant arity',\n",
              "  'firstorder Horn programs entailment',\n",
              "  'learnable equivalence entailment membership queries',\n",
              "  'closure conditions',\n",
              "  'consequence'],\n",
              " ['NPcomplete problems', 'problem', 'Genetic Algorithms GAs', 'others', 'GA'],\n",
              " ['actions',\n",
              "  'special interest',\n",
              "  'likelihood estimates',\n",
              "  'individual agents',\n",
              "  'AI'],\n",
              " ['new domain',\n",
              "  'generic mechanisms',\n",
              "  'problems',\n",
              "  'important issues generalization experiences',\n",
              "  'type abstractions'],\n",
              " ['objective functions',\n",
              "  'optimization single bit string',\n",
              "  'simple fitness functions',\n",
              "  'respect',\n",
              "  'counting ones'],\n",
              " ['real systems',\n",
              "  'simulation',\n",
              "  'resulting behaviors',\n",
              "  'learning',\n",
              "  'useful behaviors simulations'],\n",
              " ['researchers',\n",
              "  'startling progress management uncertainty',\n",
              "  'recent years',\n",
              "  'uncertainty',\n",
              "  'architecture'],\n",
              " ['GSAT',\n",
              "  'problem instances',\n",
              "  'satisfiability problems',\n",
              "  'difficult traditional satisfiability algorithms Results',\n",
              "  'neural network algorithm'],\n",
              " ['Artificial Neural Networks Explicitly',\n",
              "  'differences',\n",
              "  'several researchers',\n",
              "  'research',\n",
              "  'aim paper'],\n",
              " ['recognition D', 'VIEWNET', 'properties', 'sequences', 'aircraft'],\n",
              " ['number algorithms',\n",
              "  'Simulation results',\n",
              "  'gradients',\n",
              "  'different approaches',\n",
              "  'present short unifying account different algorithms'],\n",
              " ['optimal number learning samples',\n",
              "  'desired accuracy function approximation feedforward network',\n",
              "  'methodology estimate',\n",
              "  'combination knowledge',\n",
              "  'computational complexity learning rule optimal learning set size number hidden units'],\n",
              " ['graph', 'distributions', 'models', 'marginalisation', 'elements'],\n",
              " ['way goals',\n",
              "  'opportunities',\n",
              "  'computational model working memory',\n",
              "  'ability',\n",
              "  'suspended problem contexts'],\n",
              " ['task known optimal training error',\n",
              "  'c',\n",
              "  'certain cases',\n",
              "  'committee ensemble techniques beneficial level noise training data',\n",
              "  'optimal solution case'],\n",
              " ['many reasons',\n",
              "  'training behavior',\n",
              "  'known optimal training error',\n",
              "  'neural networks',\n",
              "  'question'],\n",
              " ['Rulearner',\n",
              "  'heuristics',\n",
              "  'explicit map guide search rule space',\n",
              "  'novel induction algorithm',\n",
              "  'rule sets'],\n",
              " ['case base', 'collected cases', 'aspects', 'requested case', 'problem'],\n",
              " ['PGA',\n",
              "  'salesman problem',\n",
              "  'parallel genetic algorithm',\n",
              "  'local minima third',\n",
              "  'correlation'],\n",
              " ['useful tasks',\n",
              "  'feature vectors',\n",
              "  'classifying cases',\n",
              "  'representations',\n",
              "  'recent literature'],\n",
              " ['computational lexicology language technology',\n",
              "  'consequences',\n",
              "  'alternative propose',\n",
              "  'particular performanceoriented approach Natural Language Processing',\n",
              "  'application approach number lexical acquisition disambiguation'],\n",
              " ['H',\n",
              "  'stepwise estimators',\n",
              "  'mild conditions',\n",
              "  'convergence law algorithm',\n",
              "  'defined approximable sequence H n n functional estimators'],\n",
              " ['informationtheoretic criterion',\n",
              "  'stochastic complexity',\n",
              "  'modelbased imputation procedure relative model class ie functional form probability distribution complete data matrix case',\n",
              "  'data problem',\n",
              "  'shortest code length'],\n",
              " ['general optimization problems',\n",
              "  'genetic algorithms',\n",
              "  'periods',\n",
              "  'mechanisms',\n",
              "  'tabu search'],\n",
              " ['finite alphabet', 'addition', 'models', 'behavioural data', 'MML'],\n",
              " ['Results',\n",
              "  'synthetic audio time series',\n",
              "  'new parameters',\n",
              "  'compared alternative method moves cheaper compute proposals',\n",
              "  'full conditional density AR parameters'],\n",
              " ['casebased reasoning', 'benefits', 'flexible planning', 'support', 'view'],\n",
              " ['paper',\n",
              "  'V SCBR simple instancebased learning algorithm',\n",
              "  'many examples',\n",
              "  'weighted similarity measure',\n",
              "  'different target concepts'],\n",
              " ['use',\n",
              "  'admissible heuristic exhaustive search',\n",
              "  'partial determinations',\n",
              "  'viability',\n",
              "  'known MDL formula'],\n",
              " ['information theoretic measure finite state machine explanations',\n",
              "  'evaluation candidate explanations',\n",
              "  'optimal finite state machine explanation symbol strings',\n",
              "  'induction',\n",
              "  'search nearoptimal explanation'],\n",
              " ['GA',\n",
              "  'evolutionary process',\n",
              "  'synchronous regions',\n",
              "  'defects',\n",
              "  'underlying mediums potential form embedded particles'],\n",
              " ['general bootstrap theorem',\n",
              "  'infinitedimensional Zestimators',\n",
              "  'recent infinitedimensional Ztheorem',\n",
              "  'finitedimensional results type bootstrap',\n",
              "  'Vaart'],\n",
              " ['recurrence times',\n",
              "  'paper',\n",
              "  'method',\n",
              "  'accuracy individual',\n",
              "  'Survival Curve RSA SCRSA extension RSA approach'],\n",
              " ['query',\n",
              "  'Keywords',\n",
              "  'perceptrons',\n",
              "  'informative queries',\n",
              "  'query committee algorithm method'],\n",
              " ['new method',\n",
              "  'images',\n",
              "  'first experimental results',\n",
              "  'nonlinear form Principal Component Analysis',\n",
              "  'use'],\n",
              " ['probabilistic knowledge',\n",
              "  'graphical decision model encodes',\n",
              "  'relevant factors decision problem',\n",
              "  'domain',\n",
              "  'probabilistic dependencies'],\n",
              " ['algorithm',\n",
              "  'new approach',\n",
              "  'multiple learning algorithms',\n",
              "  'best learners region example space',\n",
              "  'past performance region'],\n",
              " ['program',\n",
              "  'new concepts extent learner',\n",
              "  'concept',\n",
              "  'hypotheses',\n",
              "  'role memory'],\n",
              " ['role environmental complexity',\n",
              "  'adaptive process',\n",
              "  'Latent',\n",
              "  'Energy Environments LEE model',\n",
              "  'motivation'],\n",
              " ['linked Horn clauses',\n",
              "  'C',\n",
              "  'notion determinate clauses',\n",
              "  'subsumption',\n",
              "  'D C NPcomplete'],\n",
              " ['arguments functions values',\n",
              "  'variation genetic programming',\n",
              "  'known closure',\n",
              "  'limitation',\n",
              "  'data type'],\n",
              " ['results units',\n",
              "  'proof',\n",
              "  'shows',\n",
              "  'sigmoidal hardthreshold transfer functions',\n",
              "  'computational limitations'],\n",
              " ['subsumption',\n",
              "  'decidable incomplete approximation logic implication',\n",
              "  'combination approaches',\n",
              "  'empirical results',\n",
              "  'effective pruning rule'],\n",
              " ['new algorithm',\n",
              "  'small numbers',\n",
              "  'features',\n",
              "  'classifiers',\n",
              "  'hypothesisboosting method'],\n",
              " ['several artificial several real world problems results',\n",
              "  'algorithm',\n",
              "  'Current inductive machine learning algorithms',\n",
              "  'selection step',\n",
              "  'advantage'],\n",
              " ['previous work hierarchical reinforcement',\n",
              "  'paper',\n",
              "  'interesting issues',\n",
              "  'optimal value function',\n",
              "  'convergence shows'],\n",
              " ['Causality',\n",
              "  'weak causality',\n",
              "  'GP search',\n",
              "  'correlated search space exploitation',\n",
              "  'GP architecture evolution'],\n",
              " ['unstable methods',\n",
              "  'AdaBoost',\n",
              "  'classification algorithms',\n",
              "  'probabilistic estimates',\n",
              "  'variants'],\n",
              " ['paper',\n",
              "  'gradual evolution',\n",
              "  'role',\n",
              "  'directions',\n",
              "  'formal conception rationality'],\n",
              " ['distributed representations',\n",
              "  'compositional structure',\n",
              "  'vectors',\n",
              "  'Arbitrary variable bindings short sequences',\n",
              "  'circular convolution associate items'],\n",
              " ['algorithm',\n",
              "  'samples',\n",
              "  'model',\n",
              "  'based Angluins',\n",
              "  'prefixclosed samples behavior'],\n",
              " ...]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topicrank_keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4umRoYZOT1x"
      },
      "source": [
        "### Create Keyword Text Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg-e-2GpOT1y"
      },
      "outputs": [],
      "source": [
        "# Combine the lists and provide corresponding file names\n",
        "lists_of_keywords = [yake_keywords, tfidf_keywords, textrank_keywords, positionrank_keywords, topicrank_keywords]\n",
        "file_names = ['cora/YAKE.txt', 'cora/TFIDF.txt', 'cora/TextRank.txt', 'cora/PositionRank.txt', 'cora/TopicRank.txt']\n",
        "\n",
        "# Save the keywords to separate text files\n",
        "save_keywords_to_files(lists_of_keywords, file_names)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Keyword-Extraction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}